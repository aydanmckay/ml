{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b43db49-f88d-44af-8188-9c546a2bb2e1",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "source": [
    "Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12337364-915d-45e0-aa68-ff9ad349e998",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "# # Tell Tensorflow not to allocate all GPU memory right away.\n",
    "# # This is very important in shared environments!\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU') \n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from glob import glob\n",
    "from time import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b0b4d-d609-4535-82f4-76f5979bb893",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### The dataloder used by Green+2020 which will be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f39968a5-1090-448f-a6dc-b53829db1f41",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(fname, return_attrs=False):\n",
    "    print(f'Loading {fname} ...')\n",
    "    attrs = {}\n",
    "    with h5py.File(fname, 'r') as f:\n",
    "        dset = f['io_data']\n",
    "        for key in dset.attrs.keys():\n",
    "            attrs[key] = dset.attrs[key]\n",
    "        d = dset[:]\n",
    "    \n",
    "    if return_attrs:\n",
    "        return d, attrs\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a7c2e5-f232-46ff-b235-d6604c1b5d35",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Obtaining a correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e0eccc-4ffd-4904-a210-7b430692c477",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_corr_matrix(cov):\n",
    "    rho = cov.copy()\n",
    "    sqrt_cov_diag = np.sqrt(cov[np.diag_indices(cov.shape[0])])\n",
    "    rho /= sqrt_cov_diag[:,None]\n",
    "    rho /= sqrt_cov_diag[None,:]\n",
    "    rho[np.diag_indices(cov.shape[0])] = sqrt_cov_diag\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f2ec3-9dba-4970-ab73-494dddd61534",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Cannot be explained in one markdown cell above, need to look through it more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72257ca9-2c06-4d52-9589-9b9086876356",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_inputs_outputs(d, pretrained_model=None,\n",
    "                          recalc_reddening=False,\n",
    "                          rchisq_max=None,\n",
    "                          return_cov_components=False):\n",
    "    n_bands = 13 # Gaia (G, BP, RP), PS1 (grizy), 2MASS (JHK), unWISE (W1,W2)\n",
    "    n_atm_params = 3 # (T_eff, logg, [M/H])\n",
    "    \n",
    "    large_err = 999.\n",
    "\n",
    "    # Stellar spectroscopic parameters\n",
    "    print('Fill in stellar atmospheric parameters ...')\n",
    "    x = np.empty((d.size,3), dtype='f4')\n",
    "    x[:] = d['atm_param'][:]\n",
    "\n",
    "    x_p = np.empty((d.size,3), dtype='f4')\n",
    "    x_p = d['atm_param_p'][:]\n",
    "\n",
    "    # Magnitudes\n",
    "    print('Fill in stellar magnitudes ...')\n",
    "    y = np.empty((d.size,n_bands), dtype='f4')\n",
    "    y[:] = d['mag'][:]\n",
    "\n",
    "    # Covariance of y\n",
    "    print('Empty covariance matrix ...')\n",
    "    cov_y = np.zeros((d.size,n_bands,n_bands), dtype='f4')\n",
    "\n",
    "    # \\delta m\n",
    "    print('Covariance: \\delta m ...')\n",
    "    for i in range(n_bands):\n",
    "        cov_y[:,i,i] = d['mag_err'][:,i]**2\n",
    "\n",
    "    # Replace NaN magnitudes with median (in each band).\n",
    "    # Also set corresponding variances to large number.\n",
    "    print('Replace NaN magnitudes ...')\n",
    "    for b in range(n_bands):\n",
    "        idx = (\n",
    "              ~np.isfinite(y[:,b])\n",
    "            | ~np.isfinite(cov_y[:,b,b])\n",
    "        )\n",
    "        n_bad = np.count_nonzero(idx)\n",
    "        n_tot = idx.size\n",
    "        y0 = np.median(y[~idx,b])\n",
    "        if np.isnan(y0):\n",
    "            y0 = 0.\n",
    "        print(f'Band {b}: {n_bad} of {n_tot} bad. Replacing with {y0:.5f}.')\n",
    "        y[idx,b] = y0\n",
    "        cov_y[idx,b,b] = large_err**2.\n",
    "\n",
    "    # Transform both y and its covariance\n",
    "    B = np.identity(n_bands, dtype='f4')\n",
    "    B[1:,0] = -1.\n",
    "    \n",
    "    print('Transform y -> B y ...')\n",
    "    y = np.einsum('ij,nj->ni', B, y) # y' = B y\n",
    "    print('Transform C -> B C B^T ...')\n",
    "    #cov_y = np.einsum('ik,nkl,jl->nij', B, cov_y, B) # C' = B C B^T\n",
    "    cov_y = np.einsum('nik,jk->nij', cov_y, B)\n",
    "    cov_y = np.einsum('ik,nkj->nij', B, cov_y)\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp = {\n",
    "            'delta_m': cov_y.copy()\n",
    "        }\n",
    "    \n",
    "    # Add in dM/dtheta and dR/dtheta terms\n",
    "    if pretrained_model is not None:\n",
    "        print('Calculate J = dM/dtheta ...')\n",
    "        J_M = calc_dmag_color_dtheta(pretrained_model, x_p)\n",
    "        cov_x = d['atm_param_cov_p']\n",
    "        print('Covariance: J C_theta J^T ...')\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_M)\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['dM/dtheta'] = np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_M)\n",
    "\n",
    "    # If pretrained model provided, could calculate reduced chi^2\n",
    "    # with maximum-likelihood (mu, E) here.\n",
    "\n",
    "    # \\delta \\mu (must be added in after transformation,\n",
    "    #             due to possibly infinite terms).\n",
    "    print('{:d} NaN parallaxes'.format(\n",
    "        np.count_nonzero(np.isnan(d['parallax']))\n",
    "    ))\n",
    "    err_over_plx = d['parallax_err'] / d['parallax']\n",
    "    print('Covariance: DM uncertainty term ...')\n",
    "    cov_y[:,0,0] += (5./np.log(10.) * err_over_plx)**2.\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp['dm'] = np.zeros_like(cov_y)\n",
    "        cov_comp['dm'][:,0,0] = (5./np.log(10.) * err_over_plx)**2.\n",
    "\n",
    "    # Subtract distance modulus from m_G\n",
    "    #dm = -5. * (np.log10(d['parallax']) - 2.)\n",
    "    #dm_corr = 0.5 * err_over_plx**2 + 0.75 * err_over_plx**4\n",
    "    #dm_corr_pct = np.percentile(dm_corr, [1., 5., 10., 50., 90., 95., 99.])\n",
    "    #print(dm_corr_pct)\n",
    "\n",
    "    print('Estimate DM ...')\n",
    "    dm = 10. - 5.*np.log10(d['parallax'])# + 5./np.log(10.)*dm_corr\n",
    "    y[:,0] -= dm\n",
    "\n",
    "    # Don't attempt to predict M_G for poor plx/err or when plx < 0\n",
    "    print('Filter out M_G for poor parallax measurements ...')\n",
    "    idx = (\n",
    "          (err_over_plx > 0.2)\n",
    "        | (d['parallax'] < 1.e-8)\n",
    "        | ~np.isfinite(d['parallax'])\n",
    "        | ~np.isfinite(d['parallax_err'])\n",
    "    )\n",
    "    n_use = idx.size - np.count_nonzero(idx)\n",
    "    print(r'Using {:d} of {:d} ({:.3f}%) of stellar parallaxes.'.format(\n",
    "        n_use, idx.size, n_use/idx.size*100.\n",
    "    ))\n",
    "    cov_y[idx,0,0] = large_err**2\n",
    "    y[idx,0] = np.nanmedian(y[:,0])\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp['dm'][idx,0,0] = large_err**2\n",
    "\n",
    "    # Reddenings\n",
    "    print('Copy reddenings ...')\n",
    "    r = np.empty((d.size,), dtype='f4')\n",
    "    r[:] = d['r'][:]\n",
    "    \n",
    "    if pretrained_model is None:\n",
    "        # If R has not yet been estimated, then\n",
    "        # cut out stars with sigma_r > 0.2 mag.\n",
    "        idx = (d['r_err'] > 0.2)\n",
    "        print(f'Cutting {np.count_nonzero(idx)} stars with large sigma_r.')\n",
    "        for k in range(cov_y.shape[1]):\n",
    "            cov_y[idx,k,k] += large_err**2\n",
    "\n",
    "    if pretrained_model is not None:\n",
    "        # Update reddenings, based on vector R and (y_obs - y_pred).\n",
    "        # Use provided reddenings as a prior.\n",
    "\n",
    "        # First, need to calculate inv_cov_y\n",
    "        print('Invert C_y matrices ...')\n",
    "        inv_cov_y = np.stack([np.linalg.inv(c) for c in cov_y])\n",
    "\n",
    "        # Predict M & R for each star based on atm. params\n",
    "        M_pred = predict_M(pretrained_model, x_p)\n",
    "        R = predict_R(pretrained_model, x_p)\n",
    "        \n",
    "        r_var = d['r_err']**2\n",
    "        \n",
    "        # Calculate posterior on reddening\n",
    "        if recalc_reddening:\n",
    "            print('Calculate posterior on reddening ...')\n",
    "            r_pred, r_var = update_reddenings(\n",
    "                M_pred, R, y,\n",
    "                inv_cov_y,\n",
    "                r, r_var\n",
    "            )\n",
    "            \n",
    "            # Clip mean and variance of reddenings\n",
    "            print('Clip reddenings and reddening variances ...')\n",
    "            r[:] = np.clip(r_pred, 0., 10.) # TODO: Update upper limit?\n",
    "        \n",
    "        # TODO: Different lower bounds on error for different sources?\n",
    "        r_var[:] = np.clip(r_var, 0.02**2 + (0.1*r)**2, 10.**2)\n",
    "        \n",
    "        # Reddening uncertainty term in covariance of y\n",
    "        print('Covariance: reddening uncertainty term ...')\n",
    "        cov_y += r_var[:,None,None] * R[:,:,None]*R[:,None,:]\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['r'] = r_var[:,None,None] * R[:,:,None]*R[:,None,:]\n",
    "        \n",
    "        # Propagate uncertainty in theta to uncertainty in R\n",
    "        print('Calculate J = dA/dtheta ...')\n",
    "        J_A = calc_dext_red_dtheta(pretrained_model, x_p, r)\n",
    "        cov_x = d['atm_param_cov_p']\n",
    "        print('Covariance: J C_theta J^T ...')\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_A)\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_A)\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_M)\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['dA/dtheta'] = np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_A)\n",
    "            cov_comp['dMA/dtheta'] = np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_A)\n",
    "            cov_comp['dAM/dtheta'] = np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_M)\n",
    "        \n",
    "        # Calculate chi^2 for each star\n",
    "        chisq = calc_chisq(M_pred+r[:,None]*R-y, inv_cov_y)\n",
    "        print('chisq =', chisq)\n",
    "\n",
    "        # Calculate d.o.f. of each star\n",
    "        print('Calculate d.o.f. of each star ...')\n",
    "        n_dof = np.zeros(d.size, dtype='i4')\n",
    "        for k in range(n_bands):\n",
    "            n_dof += (cov_y[:,k,k] < (large_err-1.)**2).astype('i4')\n",
    "        #print('n_dof =', n_dof)\n",
    "\n",
    "        # Calculate reduced chi^2 for each star\n",
    "        print('Calculate chi^2/d.o.f. for each star ...')\n",
    "        rchisq = chisq / (n_dof - 1.)\n",
    "        pct = (0., 1., 10., 50., 90., 99., 100.)\n",
    "        rchisq_pct = np.percentile(rchisq[np.isfinite(rchisq)], pct)\n",
    "        print('chi^2/dof percentiles:')\n",
    "        for p,rc in zip(pct,rchisq_pct):\n",
    "            print(rf'  {p:.0f}% : {rc:.3g}')\n",
    "        idx_rchisq = (rchisq < 10.)\n",
    "        print(f'<chi^2/d.o.f.> = {np.mean(rchisq[idx_rchisq]):.3g}')\n",
    "        \n",
    "        # Filter on reduced chi^2\n",
    "        if rchisq_max is not None:\n",
    "            print('Filter on chi^2/d.o.f. ...')\n",
    "            idx = np.isfinite(rchisq) & (rchisq > 0.) & (rchisq < rchisq_max)\n",
    "            n_filt = np.count_nonzero(~idx)\n",
    "            pct_filt = 100. * n_filt / idx.size\n",
    "            print(\n",
    "                rf'Filtering {n_filt:d} stars ({pct_filt:.3g}%) ' +\n",
    "                rf'based on chi^2/dof > {rchisq_max:.1f}'\n",
    "            )\n",
    "            x = x[idx]\n",
    "            x_p = x_p[idx]\n",
    "            r = r[idx]\n",
    "            y = y[idx]\n",
    "            cov_y = cov_y[idx]\n",
    "            r_var = r_var[idx]\n",
    "            rchisq = rchisq[idx]\n",
    "            \n",
    "            if return_cov_components:\n",
    "                for key in cov_comp:\n",
    "                    cov_comp[key] = cov_comp[key][idx]\n",
    "\n",
    "    # Cholesky transform of inverse covariance: L L^T = C^(-1).\n",
    "    print('Cholesky transform of each stellar covariance matrix ...')\n",
    "    LT = np.empty_like(cov_y)\n",
    "    inv_cov_y = np.empty_like(cov_y)\n",
    "    for k,c in enumerate(cov_y):\n",
    "        try:\n",
    "            # Inflate diagonal of cov slightly, to ensure\n",
    "            # positive-definiteness\n",
    "            c_diag = c[np.diag_indices_from(c)]\n",
    "            c[np.diag_indices_from(c)] += 1.e-4 + 1.e-3 * c_diag\n",
    "            \n",
    "            inv_cov_y[k] = np.linalg.inv(c)\n",
    "            LT[k] = np.linalg.cholesky(inv_cov_y[k]).T\n",
    "            #ic = np.linalg.inv(c)\n",
    "            #LT.append(np.linalg.cholesky(ic).T)\n",
    "            #inv_cov_y.append(ic)\n",
    "        except np.linalg.LinAlgError as e:\n",
    "            rho = get_corr_matrix(c)\n",
    "            print('Offending correlation matrix:')\n",
    "            print(np.array2string(\n",
    "                rho[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >7.4f}'.format(z)}\n",
    "            ))\n",
    "            print('Offending covariance matrix:')\n",
    "            print(np.array2string(\n",
    "                c[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >9.6f}'.format(z)}\n",
    "            ))\n",
    "            print('Covariance matrix of (normed) atmospheric parameters:')\n",
    "            print(d['atm_param_cov_p'][k])\n",
    "            if pretrained_model is not None:\n",
    "                print(f'Variance of r: {r_var[k]:.8f}')\n",
    "            \n",
    "            # Inflate errors along the diagonal and try again\n",
    "            c_diag = c[np.diag_indices_from(c)]\n",
    "            c[np.diag_indices_from(c)] += 0.02 + 0.02 * c_diag\n",
    "            rho = get_corr_matrix(c)\n",
    "            print('Inflated correlation matrix:')\n",
    "            print(np.array2string(\n",
    "                rho[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >7.4f}'.format(z)}\n",
    "            ))\n",
    "            \n",
    "            inv_cov_y[k] = np.linalg.inv(c)\n",
    "            LT[k] = np.linalg.cholesky(inv_cov_y[k]).T\n",
    "            #raise e\n",
    "\n",
    "    #print('Stack L^T matrices ...')\n",
    "    #LT = np.stack(LT)\n",
    "    #print('Stack C^(-1) matrices ...')\n",
    "    #inv_cov_y = np.stack(inv_cov_y)\n",
    "\n",
    "    # L^T y\n",
    "    print('Calculate L^T y ...')\n",
    "    LTy = np.einsum('nij,nj->ni', LT, y)\n",
    "\n",
    "    print('Gather inputs and outputs and return ...')\n",
    "    inputs_outputs = {\n",
    "        'x':x, 'x_p':x_p, 'r':r, 'y':y,\n",
    "        'LT':LT, 'LTy':LTy,\n",
    "        'cov_y':cov_y, 'inv_cov_y':inv_cov_y,\n",
    "    }\n",
    "    \n",
    "    if return_cov_components:\n",
    "        inputs_outputs['cov_comp'] = cov_comp\n",
    "    \n",
    "    if pretrained_model is not None:\n",
    "        inputs_outputs['r_var'] = r_var\n",
    "        inputs_outputs['rchisq'] = rchisq\n",
    "\n",
    "    # Check that there are no NaNs or Infs in results\n",
    "    for key in inputs_outputs:\n",
    "        if isinstance(inputs_outputs[key], dict):\n",
    "            continue\n",
    "        if key == 'rchisq': # Infs appear when d.o.f. = 1\n",
    "            continue\n",
    "        if np.any(~np.isfinite(inputs_outputs[key])):\n",
    "            raise ValueError(f'NaNs or Infs detected in {key}.')\n",
    "\n",
    "    return inputs_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caad35d-51ad-4e5f-8e27-57ac56e80468",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Predicts the absolute magnitude in the Gaia G-band and the colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb5329ec-4d17-4a14-9ec3-936b60844ca9",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_M(nn_model, x_p):\n",
    "    \"\"\"\n",
    "    Predicts (absmag0,color1,color2,...) for input\n",
    "    normalized stellar parameters.\n",
    "\n",
    "    Inputs:\n",
    "        nn_model (keras.Model): Neural network model.\n",
    "        x_p (np.ndarray): Normalized stellar parameters.\n",
    "            Shape = (n_stars, 3).\n",
    "    \n",
    "    Outputs:\n",
    "        M (np.ndarray): Shape = (n_stars, n_bands).\n",
    "    \"\"\"\n",
    "    inputs = nn_model.get_layer(name='theta').input\n",
    "    outputs = nn_model.get_layer(name='BM').output\n",
    "    mag_color_model = keras.Model(inputs, outputs)\n",
    "    M = mag_color_model.predict(x_p)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14482c31-4986-4451-b4f7-295c2b3530b0",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Predicting the redenning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b36fc92-d995-4531-a1e4-994b63a9a954",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_R(nn_model, x_p=None):\n",
    "    inputs = nn_model.get_layer(name='theta').input\n",
    "    outputs = nn_model.get_layer(name='R').output\n",
    "    R_model = keras.Model(inputs, outputs)\n",
    "    if x_p is None:\n",
    "        R = R_model.predict(np.array([[0.,0.,0.]]))[0]\n",
    "        R[1:] -= R[0]\n",
    "    else:\n",
    "        R = R_model.predict(x_p)\n",
    "        R[:,1:] -= R[:,0][:,None]\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2cab63-a66c-4c34-a7f1-50cb9568337b",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Saving the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52ee4e30-e866-45c2-a60f-37f5d8996b9f",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_predictions(fname, nn_model, d_test, io_test):\n",
    "    M_pred = predict_M(nn_model, io_test['x_p'])\n",
    "    R_pred = predict_R(nn_model, io_test['x_p'])\n",
    "    R0 = predict_R(nn_model)\n",
    "    \n",
    "    with h5py.File(fname, 'w') as f:\n",
    "        f.create_dataset('/data', data=d_test, chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/y_obs', data=io_test['y'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/cov_y', data=io_test['cov_y'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/r_fit', data=io_test['r'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/M_pred', data=M_pred, chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/R_pred', data=R_pred, chunks=True,\n",
    "                        compression='gzip', compression_opts=3)\n",
    "        f.attrs['R0'] = R0\n",
    "        \n",
    "        if 'cov_comp' in io_test:\n",
    "            for key in io_test['cov_comp']:\n",
    "                f.create_dataset(\n",
    "                    f'/cov_comp/{key.replace(r\"/\",\"_\")}',\n",
    "                    data=io_test['cov_comp'][key],\n",
    "                    chunks=True,\n",
    "                    compression='gzip',\n",
    "                    compression_opts=3\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9dbfb5-0fa8-47b6-b59e-5507d8182916",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Updates the redenning, as in the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12ce532d-8584-46ea-b538-a65837b35597",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_reddenings(M_pred, R, y_obs, inv_cov_y, r0, r_var0):\n",
    "    \"\"\"\n",
    "    Updates the posterior on reddening of each star, given\n",
    "    the predicted absolute magnitudes, reddening vector,\n",
    "    observed magnitudes, inverse covariance matrix, and priors on\n",
    "    reddening.\n",
    "    \n",
    "    The model is given by\n",
    "    \n",
    "        y_obs = M_pred + R r,\n",
    "    \n",
    "    with the uncertainties in y_obs described by inv_cov_y, and\n",
    "    with a prior on r described by (r0, r_var0). We solve for\n",
    "    the Gaussian posterior on r: p(r|y_obs,M_pred,R,r0,r_var0).\n",
    "    \n",
    "    Let n = # of bands, k = # of stars.\n",
    "\n",
    "    Inputs:\n",
    "        M_pred (np.ndarray): Shape-(k,n) array containing predicted\n",
    "            zero-reddening asbolute magnitude & colors for each star.\n",
    "        R (np.ndarray): Shape-(k,n) array containing reddening vector\n",
    "            for each star.\n",
    "        inv_cov_y (np.ndarray): Shape-(k,n,n) array containing\n",
    "            covariance matrix of y_obs-y_pred for each star.\n",
    "        y_obs (np.ndarray): Shape-(k,n) array containing observed\n",
    "            magnitude (minus distance modulus) & colors for each star.\n",
    "        r0 (np.ndarray): Shape-(k,) array containing mean of prior on\n",
    "            reddening for each star.\n",
    "        r_var0 (np.ndarray): Shape-(k,) array containing variance of\n",
    "            prior on reddening for each star.\n",
    "\n",
    "    Outputs:\n",
    "        r_mean (np.ndarray): Shape-(k,) array containing mean posterior\n",
    "            reddening of each star.\n",
    "        r_var (np.ndarray): Shape-(k,) array containing variance of\n",
    "            reddening posterior for each star.\n",
    "    \"\"\"\n",
    "    print('Updating reddenings:')\n",
    "    print('  * R^T C_y^(-1) ...')\n",
    "    RT_Cinv = np.einsum('ni,nij->nj', R, inv_cov_y)\n",
    "    print('  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...')\n",
    "    num = r0/r_var0 + np.einsum('ni,ni->n', RT_Cinv, y_obs - M_pred)\n",
    "    print('  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...')\n",
    "    den = np.einsum('ni,ni->n', RT_Cinv, R) + 1./r_var0\n",
    "    print('  * r_mean, r_var ...')\n",
    "    r_mean = num / den\n",
    "    r_var = 1. / den\n",
    "\n",
    "    return r_mean, r_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d6a72-37ab-4d7a-bfb3-cd329804a9ca",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### calculates the chi^2, as in docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c76cf577-6ee4-41db-a3ea-bada40e97afb",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_chisq(dy, inv_cov_y):\n",
    "    \"\"\"\n",
    "    Returns the chi^2 for each observation, given\n",
    "    an array of residuals and inverse covariance matrices.\n",
    "    \n",
    "        chi^2 = dy^T C^{-1} dy.\n",
    "    \n",
    "    Inputs:\n",
    "        dy (np.ndarray): Residual values. Shape = (n_obs, n_dim),\n",
    "            where n_obs is the number of observations, and n_dim is\n",
    "            the dimensionality of the vector space.\n",
    "        inv_cov_y (np.ndarray): Inverse covariance matrices.\n",
    "            Shape = (n_obs, n_dim, n_dim).\n",
    "    \n",
    "    Returns:\n",
    "        chisq (np.ndarray): Chi^2 for each observation. Shape=(n_obs,).\n",
    "    \"\"\"\n",
    "    C_inv_dy = np.einsum('nij,nj->ni', inv_cov_y, dy)\n",
    "    chisq = np.einsum('ni,ni->n', dy, C_inv_dy)\n",
    "    return chisq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50c262-4e28-419e-83d5-8b75ec32470b",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Creates the architecture of the NN as described in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45204db0-8dfb-448f-879b-11102036d543",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_nn_model(n_hidden_layers=1, hidden_size=32, l1=1.e0, l2=1.e-4, n_bands=13):\n",
    "    # Stellar model: B M(theta)\n",
    "    atm = keras.Input(shape=(3,), name='theta')\n",
    "    x = atm\n",
    "    for i in range(n_hidden_layers):\n",
    "        x = keras.layers.Dense(\n",
    "            hidden_size,\n",
    "            activation='sigmoid',\n",
    "            kernel_regularizer=keras.regularizers.l2(l=l2),\n",
    "            name=f'stellar_model_hidden_{i+1}'\n",
    "        )(x)\n",
    "    mag_color = keras.layers.Dense(n_bands, name='BM')(x)\n",
    "\n",
    "    # Reddening measurement E\n",
    "    red = keras.Input(shape=(1,), name='E')\n",
    "    \n",
    "    # Extinction vector: R(theta)\n",
    "    r = atm\n",
    "    #for i in range(n_hidden_layers):\n",
    "    #    r = keras.layers.Dense(\n",
    "    #        6,\n",
    "    #        use_bias=True,\n",
    "    #        activation='sigmoid',\n",
    "    #        kernel_regularizer=keras.regularizers.l2(l=l2),\n",
    "    #        name=f'extinction_model_hidden_{i+1}'\n",
    "    #    )(r)\n",
    "    ext_vec = keras.layers.Dense(\n",
    "        n_bands,\n",
    "        use_bias=True,\n",
    "        activation='exponential',\n",
    "        #kernel_regularizer=keras.regularizers.l1_l2(l1=1.e0, l2=1.e0),\n",
    "        kernel_regularizer=keras.regularizers.l1(l=l1),\n",
    "        name='R'\n",
    "    )(r)\n",
    "    \n",
    "    # Extinction A = ER\n",
    "    ext = keras.layers.Multiply(name='A')([red, ext_vec])\n",
    "    \n",
    "    # Transform extinction to extinction,reddening using B: BA\n",
    "    B = np.identity(n_bands, dtype='f4')\n",
    "    B[1:,0] = -1.\n",
    "    ext_red = keras.layers.Dense(\n",
    "        n_bands,\n",
    "        use_bias=False,\n",
    "        trainable=False,\n",
    "        weights=[B.T],\n",
    "        name='BA'\n",
    "    )(ext)\n",
    "\n",
    "    # Predicted mag,color, B(M+A)\n",
    "    y = keras.layers.Add(name='B_M_plus_A')([mag_color, ext_red])\n",
    "\n",
    "    # Cholesky decomposition of inverse covariance matrix, L L^T = C^(-1)\n",
    "    LT = keras.Input(shape=(n_bands,n_bands), name='LT')\n",
    "\n",
    "    # Multiply y_pred by L^T, since loss is given by |L^T (y_pred - y_obs)|^2,\n",
    "    # where y_pred = B(M+A), and y_obs = B(m-mu).\n",
    "    LTy = keras.layers.Dot((2,1), name='LT_B_M_plus_A')([LT, y])\n",
    "\n",
    "    # Compile model\n",
    "    model = keras.Model(\n",
    "        inputs=[atm,red,LT],\n",
    "        outputs=LTy,\n",
    "        name='stellar_photometry_model'\n",
    "    )\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer='Adam',\n",
    "        metrics=['mse']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c98052-09ff-4591-830a-446eedd1c701",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### splits the dataset according to a fraction selected by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f096cf60-242d-4eef-8d91-59430a2672dc",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_dataset(frac, *args):\n",
    "    assert len(args) != 0\n",
    "\n",
    "    n_tot = args[0].shape[0]\n",
    "    idx = np.arange(n_tot)\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    n = int(frac * n_tot)\n",
    "    idx_left = idx[:n]\n",
    "    idx_right = idx[n:]\n",
    "\n",
    "    left, right = [], []\n",
    "\n",
    "    for x in args:\n",
    "        left.append(x[idx_left])\n",
    "        right.append(x[idx_right])\n",
    "    \n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a650c5-2ed5-4cfd-bd99-92ff0587e213",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7632b11-b152-4bbf-833b-53c16c38e4c1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "class PlotLearning(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback to plot the learning curves of the model during training.\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.metrics = {}\n",
    "        for metric in logs:\n",
    "            self.metrics[metric] = []\n",
    "            \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Storing metrics\n",
    "        for metric in logs:\n",
    "            if metric in self.metrics:\n",
    "                self.metrics[metric].append(logs.get(metric))\n",
    "            else:\n",
    "                self.metrics[metric] = [logs.get(metric)]\n",
    "        \n",
    "        # Plotting\n",
    "        metrics = [x for x in logs if 'val' not in x]\n",
    "        \n",
    "        f, axs = plt.subplots(1, len(metrics), figsize=(15,5))\n",
    "        # clear_output(wait=True)\n",
    "\n",
    "        for i, metric in enumerate(metrics):\n",
    "            axs[i].plot(range(1, epoch + 2), \n",
    "                        self.metrics[metric], \n",
    "                        label=metric)\n",
    "            if logs['val_' + metric]:\n",
    "                axs[i].plot(range(1, epoch + 2), \n",
    "                            self.metrics['val_' + metric], \n",
    "                            label='val_' + metric)\n",
    "                \n",
    "            axs[i].legend()\n",
    "            axs[i].grid()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d4f6eac-a9dd-4e9d-9d27-f9995997b7a2",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(nn_model, io_train, k, n_iterations, epochs=100,\n",
    "                checkpoint_fn='checkpoint', batch_size=32,\n",
    "                suff='_'):\n",
    "    checkpoint_fn = (\n",
    "          'checkpoints/'\n",
    "        + checkpoint_fn\n",
    "        + '.e{epoch:03d}_vl{val_loss:.3f}.h5'\n",
    "    )\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_fn,\n",
    "            save_best_only=True,\n",
    "            monitor='val_loss',\n",
    "            verbose=1\n",
    "        )#, PlotLearning()\n",
    "    ]\n",
    "    inputs = [io_train['x_p'], io_train['r'], io_train['LT']]\n",
    "    outputs = io_train['LTy']\n",
    "    nn_model.fit(\n",
    "        inputs, outputs,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.25/0.9,\n",
    "        callbacks=callbacks,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    plt.title('Loss: Iteration {} of {}.'.format(k+1, n_iterations))\n",
    "    plt.plot(range(1,epochs+1),nn_model.history.history['loss'],label='loss')\n",
    "    plt.plot(range(1,epochs+1),nn_model.history.history['val_loss'],label='val_loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig('/arc/home/aydanmckay/networkplots/train_val_loss'+suff+'.svg', dpi=150)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d76b11-59a7-41ca-a531-13411c1a6ce9",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### tests and makes sure the loss is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7eb14a0f-a62d-4d46-ab6d-4b33476566da",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(nn_model, io_eval, batch_size=32, rchisq_max=None):\n",
    "    \"\"\"\n",
    "    Runs the model on the given inputs and outputs, and returns the\n",
    "    MSE and loss.\n",
    "    \n",
    "    Inputs:\n",
    "        nn_model (keras.Model): The neural network model.\n",
    "        io_eval (dict): A dictionary containing, among other things,\n",
    "            x_p, r, LT and LTy. If rchisq_max is provided, then the\n",
    "            dictionary must also contain rchisq.\n",
    "        batch_size (int): Defaults to 32.\n",
    "        rchisq_max (float): Stars with greater than this reduced chi^2\n",
    "            will not be included in the calculation. Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "        A list containing the MSE and loss.\n",
    "    \"\"\"\n",
    "    inputs = [io_eval['x_p'], io_eval['r'], io_eval['LT']]\n",
    "    outputs = io_eval['LTy']\n",
    "    \n",
    "    if rchisq_max is not None:\n",
    "        idx = (io_eval['rchisq'] < rchisq_max)\n",
    "        inputs = [x[idx] for x in inputs]\n",
    "        outputs = outputs[idx]\n",
    "    \n",
    "    loss = nn_model.evaluate(\n",
    "        inputs,\n",
    "        outputs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    loss = [float(x) for x in loss] # Make JSON serializable\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd030e3e-55e6-419d-9a07-ce0a6baeb62c",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### plots? follow up here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d65e396c-7677-41d8-b229-8c3b2377a7b6",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def diagnostic_plots(nn_model, io_test, d_test, suffix=None):\n",
    "    if suffix is None:\n",
    "        suff = ''\n",
    "    else:\n",
    "        suff = '_' + suffix\n",
    "    \n",
    "    inputs = [\n",
    "        nn_model.get_layer(name='theta').input,\n",
    "        nn_model.get_layer(name='E').input\n",
    "    ]\n",
    "    outputs = nn_model.get_layer(name='B_M_plus_A').output\n",
    "    absmag_model = keras.Model(inputs, outputs)\n",
    "\n",
    "    # Predict y for the test dataset\n",
    "    test_pred = {\n",
    "        'y': absmag_model.predict([\n",
    "            io_test['x_p'],\n",
    "            io_test['r']\n",
    "        ]),\n",
    "        'y_dered': absmag_model.predict([\n",
    "            io_test['x_p'],\n",
    "            np.zeros_like(io_test['r'])\n",
    "        ])\n",
    "    }\n",
    "    test_pred['y_resid'] = io_test['y'] - test_pred['y']\n",
    "\n",
    "    # Get the extinction vector\n",
    "    R = predict_R(nn_model)\n",
    "    R[1:] += R[0]\n",
    "    print(\n",
    "          'R(<theta>) = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,R)))\n",
    "        + ']'\n",
    "    )\n",
    "    R_all = predict_R(nn_model, io_test['x_p'])\n",
    "    R_all[:,1:] += R_all[:,0][:,None]\n",
    "    print(\n",
    "          '<R> = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,np.median(R_all,axis=0))))\n",
    "        + ']'\n",
    "    )\n",
    "    print(\n",
    "          's_R = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,np.std(R_all,axis=0))))\n",
    "        + ']'\n",
    "    )\n",
    "\n",
    "    # Read out colors, magnitudes\n",
    "    g = io_test['y'][:,3] + io_test['y'][:,0]\n",
    "    ri = io_test['y'][:,4] - io_test['y'][:,5]\n",
    "    gr = io_test['y'][:,3] - io_test['y'][:,4]\n",
    "    g_pred = test_pred['y'][:,3] + test_pred['y'][:,0]\n",
    "    ri_pred = test_pred['y'][:,4] - test_pred['y'][:,5]\n",
    "    gr_pred = test_pred['y'][:,3] - test_pred['y'][:,4]\n",
    "    g_pred_dered = test_pred['y_dered'][:,3] + test_pred['y_dered'][:,0]\n",
    "    ri_pred_dered = test_pred['y_dered'][:,4] - test_pred['y_dered'][:,5]\n",
    "    gr_pred_dered = test_pred['y_dered'][:,3] - test_pred['y_dered'][:,4]\n",
    "    A_g = 0.25 * R[3]\n",
    "    E_ri = 0.25 * (R[4] - R[5])\n",
    "    E_gr = 0.25 * (R[3] - R[4])\n",
    "\n",
    "    gaia_g = io_test['y'][:,0]\n",
    "    bp_rp = io_test['y'][:,1] - io_test['y'][:,2]\n",
    "    gaia_g_pred = test_pred['y'][:,0]\n",
    "    bp_rp_pred = test_pred['y'][:,1] - test_pred['y'][:,2]\n",
    "    gaia_g_pred_dered = test_pred['y_dered'][:,0]\n",
    "    gaia_bp_rp_pred_dered = test_pred['y_dered'][:,1] - test_pred['y_dered'][:,2]\n",
    "    A_gaia_g = 0.25 * R[0]\n",
    "    E_bp_rp = 0.25 * (R[1] - R[2])\n",
    "\n",
    "    print('g =', g)\n",
    "    print('ri =', ri)\n",
    "    print('gr =', gr)\n",
    "    print('gaia_g =', gaia_g)\n",
    "    print('bp_rp =', bp_rp)\n",
    "\n",
    "    # Plot HRD\n",
    "    params = {\n",
    "        'density': (None, r'$N$', (None, None)),\n",
    "        'teff': (d_test['atm_param'][:,0], r'$T_{\\mathrm{eff}}$', (4000., 8000.)),\n",
    "        'logg': (d_test['atm_param'][:,1], r'$\\log \\left( g \\right)$', (0., 5.)),\n",
    "        'mh': (d_test['atm_param'][:,2], r'$\\left[ \\mathrm{M} / \\mathrm{H} \\right]$', (-2.5, 0.5))\n",
    "    }\n",
    "\n",
    "    plot_spec = [\n",
    "        {\n",
    "            'colors': [(1,2), (4,5)],\n",
    "            'mag': 0\n",
    "        },\n",
    "        {\n",
    "            'colors': [(3,4), (4,5)],\n",
    "            'mag': 0\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    idx_goodobs = np.isfinite(d_test['mag_err'])\n",
    "    idx_goodobs &= (np.abs(io_test['cov_y'][:,0,0]) < 90.)[:,None]\n",
    "    idx_goodobs = idx_goodobs.T\n",
    "\n",
    "    def scatter_or_hexbin(ax, x, y, c, vmin, vmax, extent):\n",
    "        if p == 'density':\n",
    "            im = ax.hexbin(\n",
    "                x, y,\n",
    "                extent=extent,\n",
    "                bins='log',\n",
    "                rasterized=True\n",
    "            )\n",
    "        else:\n",
    "            im = ax.scatter(\n",
    "                x,\n",
    "                y,\n",
    "                c=c,\n",
    "                edgecolors='none',\n",
    "                alpha=0.1,\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "                rasterized=True\n",
    "            )\n",
    "        return im\n",
    "\n",
    "    def get_lim(*args, **kwargs):\n",
    "        expand = kwargs.get('expand', 0.4)\n",
    "        expand_low = kwargs.get('expand_low', expand)\n",
    "        expand_high = kwargs.get('expand_high', expand)\n",
    "        pct = kwargs.get('pct', 1.)\n",
    "        lim = [np.inf, -np.inf]\n",
    "        for a in args:\n",
    "            a0,a1 = np.nanpercentile(a, [pct, 100.-pct])\n",
    "            lim[0] = min(a0, lim[0])\n",
    "            lim[1] = max(a1, lim[1])\n",
    "        w = lim[1] - lim[0]\n",
    "        lim[0] -= expand_low * w\n",
    "        lim[1] += expand_high * w\n",
    "        return lim\n",
    "\n",
    "    labels = ['G', 'BP', 'RP', 'g', 'r', 'i', 'z', 'y']\n",
    "\n",
    "    for ps in plot_spec:\n",
    "        mag_label = r'$M_{{ {} }}$'.format(labels[ps['mag']])\n",
    "        mag_obs = io_test['y'][:,ps['mag']]\n",
    "        mag_pred = test_pred['y'][:,ps['mag']]\n",
    "        mag_pred_dered = test_pred['y_dered'][:,ps['mag']]\n",
    "        A_vec = 0.25 * R[ps['mag']]\n",
    "        print('mag_pred:',mag_pred)\n",
    "\n",
    "        if ps['mag'] != 0:\n",
    "            mag_obs += io_test['y'][:,0]\n",
    "            mag_pred += io_test['y'][:,0]\n",
    "            mag_pred_dered += io_test['y'][:,0]\n",
    "            A_vec += 0.25 * R[0]\n",
    "\n",
    "        color_labels = []\n",
    "        colors_obs = []\n",
    "        colors_pred = []\n",
    "        colors_pred_dered = []\n",
    "        idx_colors_obs = []\n",
    "        E_vec = []\n",
    "        for i1,i2 in ps['colors']:\n",
    "            color_labels.append(r'${} - {}$'.format(labels[i1], labels[i2]))\n",
    "            colors_obs.append(io_test['y'][:,i1] - io_test['y'][:,i2])\n",
    "            colors_pred.append(test_pred['y'][:,i1] - test_pred['y'][:,i2])\n",
    "            colors_pred_dered.append(\n",
    "                test_pred['y_dered'][:,i1] - test_pred['y_dered'][:,i2]\n",
    "            )\n",
    "            idx_colors_obs.append(idx_goodobs[i1] & idx_goodobs[i2])\n",
    "            E_vec.append(0.25 * (R[i1] - R[i2]))\n",
    "\n",
    "        mag_lim = get_lim(\n",
    "            mag_obs[idx_goodobs[ps['mag']]],\n",
    "            pct=2.\n",
    "        )[::-1]\n",
    "        color_lim = [\n",
    "            get_lim(c[idx_colors_obs[k]], expand_low=0.5, expand_high=0.4)\n",
    "            for k,c in enumerate(colors_obs)\n",
    "        ]\n",
    "        \n",
    "        for p in params.keys():\n",
    "            c, label, (vmin,vmax) = params[p]\n",
    "            \n",
    "            fig = plt.figure(figsize=(14,4.5), dpi=150)\n",
    "            fig.patch.set_alpha(0.)\n",
    "            gs = GridSpec(\n",
    "                1,4,\n",
    "                width_ratios=[1,1,1,0.1],\n",
    "                left=0.07, right=0.93,\n",
    "                bottom=0.10, top=0.92\n",
    "            )\n",
    "            ax_obs = fig.add_subplot(gs[0,0], facecolor='gray')\n",
    "            ax_pred = fig.add_subplot(gs[0,1], facecolor='gray')\n",
    "            ax_dered = fig.add_subplot(gs[0,2], facecolor='gray')\n",
    "            cax = fig.add_subplot(gs[0,3], facecolor='w')\n",
    "\n",
    "            extent = color_lim[0] + mag_lim\n",
    "\n",
    "            idx = (\n",
    "                  idx_goodobs[ps['mag']]\n",
    "                & idx_goodobs[ps['colors'][0][0]]\n",
    "                & idx_goodobs[ps['colors'][0][1]]\n",
    "            )\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_obs,\n",
    "                colors_obs[0][idx],\n",
    "                mag_obs[idx],\n",
    "                c if c is None else c[idx],\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "                #(-0.3,1.0,11.5,-2.0)\n",
    "            )\n",
    "\n",
    "            ax_obs.set_xlim(color_lim[0])\n",
    "            ax_obs.set_ylim(mag_lim)\n",
    "            ax_obs.set_xlabel(color_labels[0])\n",
    "            ax_obs.set_ylabel(mag_label)\n",
    "            ax_obs.grid('on', alpha=0.3)\n",
    "            ax_obs.set_title(r'$\\mathrm{Observed}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_pred,\n",
    "                colors_pred[0],\n",
    "                mag_pred,\n",
    "                c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "\n",
    "            ax_pred.set_xlim(color_lim[0])\n",
    "            ax_pred.set_ylim(mag_lim)\n",
    "            ax_pred.set_xlabel(color_labels[0])\n",
    "            ax_pred.grid('on', alpha=0.3)\n",
    "            ax_pred.set_title(r'$\\mathrm{Predicted}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_dered,\n",
    "                colors_pred_dered[0],\n",
    "                mag_pred_dered,\n",
    "                c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "\n",
    "            ax_dered.set_xlim(color_lim[0])\n",
    "            ax_dered.set_ylim(mag_lim)\n",
    "            ax_dered.set_xlabel(color_labels[0])\n",
    "            ax_dered.grid('on', alpha=0.3)\n",
    "            ax_dered.set_title(r'$\\mathrm{Predicted+Dereddened}$')\n",
    "\n",
    "            ax_dered.annotate(\n",
    "                '',\n",
    "                xy=(0.35+E_vec[0], 1.+A_vec),\n",
    "                xytext=(0.35, 1.),\n",
    "                arrowprops=dict(color='r', width=1., headwidth=5., headlength=5.)\n",
    "            )\n",
    "\n",
    "            cb = fig.colorbar(im, cax=cax)\n",
    "            cb.set_label(label)\n",
    "            cb.set_alpha(1.)\n",
    "            cb.draw_all()\n",
    "\n",
    "            cm_desc = '{}_vs_{}{}'.format(\n",
    "                labels[ps['mag']],\n",
    "                labels[ps['colors'][0][0]],\n",
    "                labels[ps['colors'][0][1]]\n",
    "            )\n",
    "            fig.savefig(\n",
    "                '/arc/home/aydanmckay/networkplots/nn_predictions_'+cm_desc+'_'+p+suff+'.svg',\n",
    "                dpi=150,\n",
    "                facecolor=fig.get_facecolor(),\n",
    "                edgecolor='none'\n",
    "            )\n",
    "            plt.close(fig)\n",
    "\n",
    "            # Color-color diagrams\n",
    "            fig = plt.figure(figsize=(14,4.5), dpi=150)\n",
    "            fig.patch.set_alpha(0.)\n",
    "            gs = GridSpec(\n",
    "                1,4,\n",
    "                width_ratios=[1,1,1,0.1],\n",
    "                left=0.07, right=0.93,\n",
    "                bottom=0.10, top=0.92\n",
    "            )\n",
    "            ax_obs = fig.add_subplot(gs[0,0], facecolor='gray')\n",
    "            ax_pred = fig.add_subplot(gs[0,1], facecolor='gray')\n",
    "            ax_dered = fig.add_subplot(gs[0,2], facecolor='gray')\n",
    "            cax = fig.add_subplot(gs[0,3], facecolor='w')\n",
    "\n",
    "            extent = color_lim[0] + color_lim[1]\n",
    "\n",
    "            idx = (\n",
    "                  idx_goodobs[ps['colors'][0][0]]\n",
    "                & idx_goodobs[ps['colors'][0][1]]\n",
    "                & idx_goodobs[ps['colors'][1][0]]\n",
    "                & idx_goodobs[ps['colors'][1][1]]\n",
    "            )\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_obs,\n",
    "                colors_obs[0][idx],\n",
    "                colors_obs[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "                #(-0.2,1.5,-0.15,0.8)\n",
    "            )\n",
    "            ax_obs.set_xlim(color_lim[0])\n",
    "            ax_obs.set_ylim(color_lim[1])\n",
    "            ax_obs.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_obs.set_ylabel(color_labels[1], fontsize=14)\n",
    "            ax_obs.grid('on', alpha=0.3)\n",
    "            ax_obs.set_title(r'$\\mathrm{Observed}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_pred,\n",
    "                colors_pred[0][idx],\n",
    "                colors_pred[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                #c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "            ax_pred.set_xlim(color_lim[0])\n",
    "            ax_pred.set_ylim(color_lim[1])\n",
    "            ax_pred.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_pred.grid('on', alpha=0.3)\n",
    "            ax_pred.set_title(r'$\\mathrm{Predicted}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_dered,\n",
    "                colors_pred_dered[0][idx],\n",
    "                colors_pred_dered[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                #c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "            ax_dered.set_xlim(color_lim[0])\n",
    "            ax_dered.set_ylim(color_lim[1])\n",
    "            ax_dered.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_dered.grid('on', alpha=0.3)\n",
    "            ax_dered.set_title(r'$\\mathrm{Predicted+Dereddened}$')\n",
    "\n",
    "            ax_dered.annotate(\n",
    "                '',\n",
    "                xy=(0.4+E_vec[0], 0.3+E_vec[1]),\n",
    "                xytext=(0.4, 0.3),\n",
    "                arrowprops=dict(color='r', width=1., headwidth=5., headlength=5.)\n",
    "            )\n",
    "\n",
    "            cb = fig.colorbar(im, cax=cax)\n",
    "            cb.set_label(label, fontsize=14)\n",
    "            cb.set_alpha(1.)\n",
    "            cb.draw_all()\n",
    "\n",
    "            cc_desc = '{}{}_vs_{}{}'.format(\n",
    "                labels[ps['colors'][0][0]],\n",
    "                labels[ps['colors'][0][1]],\n",
    "                labels[ps['colors'][1][0]],\n",
    "                labels[ps['colors'][1][1]]\n",
    "            )\n",
    "            fig.savefig(\n",
    "                '/arc/home/aydanmckay/networkplots/test_'+cc_desc+'_'+p+suff+'.svg',\n",
    "                dpi=150,\n",
    "                facecolor=fig.get_facecolor(),\n",
    "                edgecolor='none'\n",
    "            )\n",
    "            plt.close(fig)\n",
    "    \n",
    "    # Plot histograms of residuals\n",
    "    dr = (io_test['r'] - d_test['r'])/np.hypot(np.nanstd(d_test['r']),.01)\n",
    "    # dmag = (io_test['LTy'] - d_test['mag'])\n",
    "    # dm1,dm2,dm3,dm4,dm5,dm6,dm7,dm8,dm9,dm10,dm11,dm12,dm13 = dmag.T\n",
    "    names = ['G','(BP-G)','(RP-G)','(g-G)','(r-G)','(i-G)','(z-G)','(y-G)','(J-G)','(H-G)','(K_s-G)','(W_1-G)','(W_2-G)']\n",
    "    # ds = [dm1,dm2,dm3,dm4,dm5,dm6,dm7,dm8,dm9,dm10,dm11,dm12,dm13]\n",
    "    fig = plt.figure(figsize=(12,18))\n",
    "    ax = fig.add_subplot(5,3,1)\n",
    "    dr_mean = np.nanmean(dr)\n",
    "    dr_std = np.nanstd(dr)\n",
    "    ax.hist(dr, bins=50)\n",
    "    dr_skew = scipy.stats.moment(dr, moment=3, nan_policy='omit')\n",
    "    dr_txt = r'$\\Delta E = {:+.3f} \\pm {:.3f}$'.format(dr_mean, dr_std)\n",
    "    dr_skew /= (dr_std**1.5 + 1.e-5)\n",
    "    dr_txt += '\\n' + r'$\\tilde{{\\mu}}_3 = {:+.3f}$'.format(dr_skew)\n",
    "    ax.text(0.05, 0.95, dr_txt, ha='left', va='top', transform=ax.transAxes)\n",
    "    ax.set_xlabel(r'$\\Delta E \\ \\left( \\mathrm{estimated} - \\mathrm{Bayestar19} \\right)$',fontsize=10)\n",
    "    for it,(io,dm,name) in enumerate(zip(io_test['LTy'].T,d_test['mag'].T,names)):\n",
    "        dd = (io - dm)/np.hypot(np.nanstd(dm),.01)\n",
    "        ax = fig.add_subplot(5,3,it+2)\n",
    "        dd_mean = np.nanmean(dd)\n",
    "        dd_std = np.nanstd(dd)\n",
    "        ax.hist(dd, bins=50)\n",
    "        dd_skew = scipy.stats.moment(dd, moment=3, nan_policy='omit')\n",
    "        dd_txt = r'$\\Delta '+name+r' = {:+.3f} \\pm {:.3f}$'.format(dd_mean, dd_std)\n",
    "        dd_skew /= (dd_std**1.5 + 1.e-5)\n",
    "        dd_txt += '\\n' + r'$\\tilde{{\\mu}}_3 = {:+.3f}$'.format(dd_skew)\n",
    "        ax.text(0.05, 0.95, dd_txt, ha='left', va='top', transform=ax.transAxes)\n",
    "        ax.set_xlabel(r'$\\Delta '+name+r'\\ \\left( \\mathrm{estimated} - \\mathrm{observed} \\right)$',fontsize=10)\n",
    "    fig.savefig('/arc/home/aydanmckay/networkplots/test_z-score_dE'+suff+'.svg', dpi=150)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc50d23-d49f-4732-87e4-a7e1ec8fc816",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "source": [
    "##### Calculates the derivative of the stellar model portion for gradient descent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8c296da-d523-4953-87b3-738be2e038fe",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_dmag_color_dtheta(nn_model, x_p):\n",
    "    m = keras.Model(\n",
    "        inputs=nn_model.get_layer(name='theta').input,\n",
    "        outputs=nn_model.get_layer(name='BM').output\n",
    "    )\n",
    "    with tf.GradientTape() as g:\n",
    "        x_p = tf.constant(x_p)\n",
    "        g.watch(x_p)\n",
    "        mag_color = m(x_p)\n",
    "    J = g.batch_jacobian(mag_color, x_p).numpy()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb05c4c2-5d82-4311-b6f2-b46532797a41",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Calculates the derivative of the extinction model portion for gradient descent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2af63500-d06a-4ba6-bcc1-5fd5c3df6247",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_dext_red_dtheta(nn_model, x_p, r):\n",
    "    A_model = keras.Model(\n",
    "        inputs=[\n",
    "            nn_model.get_layer(name='theta').input,\n",
    "            nn_model.get_layer(name='E').input\n",
    "        ],\n",
    "        outputs=nn_model.get_layer(name='BA').output\n",
    "    )\n",
    "    r = tf.constant(np.reshape(r, (r.size,1)))\n",
    "    #r = tf.reshape(r, (tf.size(r), 1))\n",
    "    with tf.GradientTape() as g:\n",
    "        x_p = tf.constant(x_p)\n",
    "        g.watch(x_p)\n",
    "        A = A_model([x_p, r])\n",
    "    J = g.batch_jacobian(A, x_p).numpy()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fb7f2c-5df5-4b99-aae0-39035aa43797",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Saves the normalizations, which seen in the tutorial is useful for scaling and shifting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86cef280-6cca-48f4-93ce-a8f4b7336300",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_theta_norm(d_attrs, fname):\n",
    "    d = {\n",
    "        'theta_med': d_attrs['atm_param_med'].tolist(),\n",
    "        'theta_std': d_attrs['atm_param_std'].tolist()\n",
    "    }\n",
    "    with open(fname, 'w') as f:\n",
    "        json.dump(d, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab8ecb-d1c9-438d-8794-1ff0b7eceef3",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### start of main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b834ddb7-6836-4e26-b7d7-81ce6cf146fd",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"stellar_photometry_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " theta (InputLayer)             [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " stellar_model_hidden_1 (Dense)  (None, 32)          128         ['theta[0][0]']                  \n",
      "                                                                                                  \n",
      " E (InputLayer)                 [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " R (Dense)                      (None, 13)           52          ['theta[0][0]']                  \n",
      "                                                                                                  \n",
      " stellar_model_hidden_2 (Dense)  (None, 32)          1056        ['stellar_model_hidden_1[0][0]'] \n",
      "                                                                                                  \n",
      " A (Multiply)                   (None, 13)           0           ['E[0][0]',                      \n",
      "                                                                  'R[0][0]']                      \n",
      "                                                                                                  \n",
      " BM (Dense)                     (None, 13)           429         ['stellar_model_hidden_2[0][0]'] \n",
      "                                                                                                  \n",
      " BA (Dense)                     (None, 13)           169         ['A[0][0]']                      \n",
      "                                                                                                  \n",
      " LT (InputLayer)                [(None, 13, 13)]     0           []                               \n",
      "                                                                                                  \n",
      " B_M_plus_A (Add)               (None, 13)           0           ['BM[0][0]',                     \n",
      "                                                                  'BA[0][0]']                     \n",
      "                                                                                                  \n",
      " LT_B_M_plus_A (Dot)            (None, 13)           0           ['LT[0][0]',                     \n",
      "                                                                  'B_M_plus_A[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,834\n",
      "Trainable params: 1,665\n",
      "Non-trainable params: 169\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load/create neural network\n",
    "nn_name = 'ext_4h_l1n2'\n",
    "n_hidden = 2\n",
    "nn_model = get_nn_model(n_hidden_layers=n_hidden, l2=1.e-4, l1=1.e-2)\n",
    "#nn_model = keras.models.load_model(\n",
    "#    'models/{:s}_{:d}hidden_it14.h5'.format(nn_name, n_hidden)\n",
    "#)\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07e4514b-44a8-4a5c-8512-e7feaa15e94e",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Loading /arc/home/aydanmckay/ml/network/datav4.h5 ...\n"
     ]
    }
   ],
   "source": [
    "# Load stellar data\n",
    "print('Loading data ...')\n",
    "fname = '/arc/home/aydanmckay/ml/network/datav4.h5'\n",
    "d, d_attrs = load_data(fname, return_attrs=True)\n",
    "#d = d[::25]\n",
    "save_theta_norm(d_attrs, '4_theta_normalization.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d54baa9f-60d9-4fc0-acb7-e4c49cd83a66",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    183594 training/validation stars.\n",
      "     20400 test stars.\n"
     ]
    }
   ],
   "source": [
    "# (training+validation) / test split\n",
    "# Fix random seed (same split every run)\n",
    "np.random.seed(7)\n",
    "(d_train,), (d_test,) = split_dataset(0.9, d)\n",
    "np.random.shuffle(d_train) # Want d_train to be in random order\n",
    "print(f'{d_train.size: >10d} training/validation stars.')\n",
    "print(f'{d_test.size: >10d} test stars.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa8b04a6-3b93-4b72-9d3f-8855c3111e8c",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi^2/dof = [None, 100.00000000000004, 79.41833348134496, 63.07271692954115, 50.09130066684769, 39.78167620874025, 31.593944275926187, 25.091384024965357, 19.927159040031896, 15.825817619770502, 12.56860061341878, 9.981773149103292, 7.927357886906197, 6.295775522882865, 4.999999999999999, 5.0, 5.0, 5.0, 5.0, 5.0]\n"
     ]
    }
   ],
   "source": [
    "# Iteratively update dM/dtheta contribution to uncertainties,\n",
    "# reddening estimates and reduced chi^2 cut, and retrain.\n",
    "n_iterations = 20\n",
    "\n",
    "# On GPU, use large batch sizes for memory transfer efficiency\n",
    "# batch_size = 1024\n",
    "batch_size = 64\n",
    "\n",
    "rchisq_max_init = 100.\n",
    "rchisq_max_final = 5.\n",
    "rchisq_max = np.exp(np.linspace(\n",
    "    np.log(rchisq_max_init),\n",
    "    np.log(rchisq_max_final),\n",
    "    n_iterations-6\n",
    "))\n",
    "rchisq_max = [None] + rchisq_max.tolist() + 5*[rchisq_max_final]\n",
    "print('chi^2/dof = {}'.format(rchisq_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b3ee798-6cee-458d-b5e3-e6f014c0c873",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 183594 bad. Replacing with 14.76263.\n",
      "Band 1: 4 of 183594 bad. Replacing with 15.15992.\n",
      "Band 2: 4 of 183594 bad. Replacing with 14.19274.\n",
      "Band 3: 113 of 183594 bad. Replacing with 15.23890.\n",
      "Band 4: 216 of 183594 bad. Replacing with 14.74910.\n",
      "Band 5: 7858 of 183594 bad. Replacing with 14.61460.\n",
      "Band 6: 243 of 183594 bad. Replacing with 14.49620.\n",
      "Band 7: 71 of 183594 bad. Replacing with 14.44220.\n",
      "Band 8: 365 of 183594 bad. Replacing with 13.53800.\n",
      "Band 9: 383 of 183594 bad. Replacing with 13.15900.\n",
      "Band 10: 1558 of 183594 bad. Replacing with 13.07700.\n",
      "Band 11: 207 of 183594 bad. Replacing with 15.74246.\n",
      "Band 12: 227 of 183594 bad. Replacing with 16.41537.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 183591 of 183594 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Cutting 0 stars with large sigma_r.\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20400 bad. Replacing with 14.76272.\n",
      "Band 1: 1 of 20400 bad. Replacing with 15.16133.\n",
      "Band 2: 1 of 20400 bad. Replacing with 14.19002.\n",
      "Band 3: 12 of 20400 bad. Replacing with 15.23615.\n",
      "Band 4: 30 of 20400 bad. Replacing with 14.75020.\n",
      "Band 5: 901 of 20400 bad. Replacing with 14.62020.\n",
      "Band 6: 32 of 20400 bad. Replacing with 14.49545.\n",
      "Band 7: 8 of 20400 bad. Replacing with 14.43955.\n",
      "Band 8: 44 of 20400 bad. Replacing with 13.53900.\n",
      "Band 9: 38 of 20400 bad. Replacing with 13.16000.\n",
      "Band 10: 158 of 20400 bad. Replacing with 13.08300.\n",
      "Band 11: 12 of 20400 bad. Replacing with 15.74840.\n",
      "Band 12: 15 of 20400 bad. Replacing with 16.41809.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20400 of 20400 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Cutting 0 stars with large sigma_r.\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 26.48 s\n",
      "learning rate = 0.0010000000474974513\n",
      "setting learning rate to 0.001\n",
      "Iteration 1 of 20.\n",
      "Epoch 1/25\n",
      "2046/2072 [============================>.] - ETA: 0s - loss: 568.2561 - mse: 568.1385\n",
      "Epoch 1: val_loss improved from inf to 965.99072, saving model to checkpoints/ext_4h_l1n2_2hidden_it0.e001_vl965.991.h5\n",
      "2072/2072 [==============================] - 6s 2ms/step - loss: 561.4839 - mse: 561.3663 - val_loss: 965.9907 - val_mse: 965.8797\n",
      "Epoch 2/25\n",
      "2055/2072 [============================>.] - ETA: 0s - loss: 121.9168 - mse: 121.8100\n",
      "Epoch 2: val_loss improved from 965.99072 to 232.78938, saving model to checkpoints/ext_4h_l1n2_2hidden_it0.e002_vl232.789.h5\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 123.8443 - mse: 123.7376 - val_loss: 232.7894 - val_mse: 232.6876\n",
      "Epoch 3/25\n",
      "2049/2072 [============================>.] - ETA: 0s - loss: 48.4145 - mse: 48.3161\n",
      "Epoch 3: val_loss improved from 232.78938 to 90.33171, saving model to checkpoints/ext_4h_l1n2_2hidden_it0.e003_vl90.332.h5\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 48.0453 - mse: 47.9469 - val_loss: 90.3317 - val_mse: 90.2353\n",
      "Epoch 4/25\n",
      "2059/2072 [============================>.] - ETA: 0s - loss: 29.9473 - mse: 29.8543\n",
      "Epoch 4: val_loss improved from 90.33171 to 47.16886, saving model to checkpoints/ext_4h_l1n2_2hidden_it0.e004_vl47.169.h5\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 29.8931 - mse: 29.8001 - val_loss: 47.1689 - val_mse: 47.0799\n",
      "Epoch 5/25\n",
      "2047/2072 [============================>.] - ETA: 0s - loss: 22.6324 - mse: 22.5470\n",
      "Epoch 5: val_loss improved from 47.16886 to 27.63748, saving model to checkpoints/ext_4h_l1n2_2hidden_it0.e005_vl27.637.h5\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 22.6696 - mse: 22.5843 - val_loss: 27.6375 - val_mse: 27.5559\n",
      "Epoch 6/25\n",
      "2071/2072 [============================>.] - ETA: 0s - loss: 19.6143 - mse: 19.5376\n",
      "Epoch 6: val_loss improved from 27.63748 to 22.02308, saving model to checkpoints/ext_4h_l1n2_2hidden_it0.e006_vl22.023.h5\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 19.6104 - mse: 19.5337 - val_loss: 22.0231 - val_mse: 21.9531\n",
      "Epoch 7/25\n",
      "2071/2072 [============================>.] - ETA: 0s - loss: 17.9444 - mse: 17.8782\n",
      "Epoch 7: val_loss improved from 22.02308 to 18.55373, saving model to checkpoints/ext_4h_l1n2_2hidden_it0.e007_vl18.554.h5\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 17.9454 - mse: 17.8791 - val_loss: 18.5537 - val_mse: 18.4910\n",
      "Epoch 8/25\n",
      "2062/2072 [============================>.] - ETA: 0s - loss: 17.0178 - mse: 16.9595\n",
      "Epoch 8: val_loss improved from 18.55373 to 17.36743, saving model to checkpoints/ext_4h_l1n2_2hidden_it0.e008_vl17.367.h5\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 17.0235 - mse: 16.9652 - val_loss: 17.3674 - val_mse: 17.3126\n",
      "Epoch 9/25\n",
      "2069/2072 [============================>.] - ETA: 0s - loss: 16.5690 - mse: 16.5186\n",
      "Epoch 9: val_loss improved from 17.36743 to 16.62127, saving model to checkpoints/ext_4h_l1n2_2hidden_it0.e009_vl16.621.h5\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 16.5737 - mse: 16.5234 - val_loss: 16.6213 - val_mse: 16.5759\n",
      "Epoch 10/25\n",
      "2068/2072 [============================>.] - ETA: 0s - loss: 16.2817 - mse: 16.2395\n",
      "Epoch 10: val_loss improved from 16.62127 to 16.48342, saving model to checkpoints/ext_4h_l1n2_2hidden_it0.e010_vl16.483.h5\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 16.2803 - mse: 16.2381 - val_loss: 16.4834 - val_mse: 16.4444\n",
      "Epoch 11/25\n",
      "2056/2072 [============================>.] - ETA: 0s - loss: 16.0379 - mse: 16.0006\n",
      "Epoch 11: val_loss improved from 16.48342 to 16.24704, saving model to checkpoints/ext_4h_l1n2_2hidden_it0.e011_vl16.247.h5\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 16.0496 - mse: 16.0124 - val_loss: 16.2470 - val_mse: 16.2118\n",
      "Epoch 12/25\n",
      "2070/2072 [============================>.] - ETA: 0s - loss: 15.8755 - mse: 15.8406\n",
      "Epoch 12: val_loss improved from 16.24704 to 16.19061, saving model to checkpoints/ext_4h_l1n2_2hidden_it0.e012_vl16.191.h5\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 15.8746 - mse: 15.8397 - val_loss: 16.1906 - val_mse: 16.1566\n",
      "Epoch 13/25\n",
      "2050/2072 [============================>.] - ETA: 0s - loss: 15.7334 - mse: 15.6995\n",
      "Epoch 13: val_loss improved from 16.19061 to 16.11357, saving model to checkpoints/ext_4h_l1n2_2hidden_it0.e013_vl16.114.h5\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 15.7569 - mse: 15.7230 - val_loss: 16.1136 - val_mse: 16.0789\n",
      "Epoch 14/25\n",
      "2070/2072 [============================>.] - ETA: 0s - loss: 15.6535 - mse: 15.6202\n",
      "Epoch 14: val_loss improved from 16.11357 to 15.83632, saving model to checkpoints/ext_4h_l1n2_2hidden_it0.e014_vl15.836.h5\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 15.6483 - mse: 15.6150 - val_loss: 15.8363 - val_mse: 15.8033\n",
      "Epoch 15/25\n",
      "2072/2072 [==============================] - ETA: 0s - loss: 15.5519 - mse: 15.5197\n",
      "Epoch 15: val_loss improved from 15.83632 to 15.82019, saving model to checkpoints/ext_4h_l1n2_2hidden_it0.e015_vl15.820.h5\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 15.5519 - mse: 15.5197 - val_loss: 15.8202 - val_mse: 15.7887\n",
      "Epoch 16/25\n",
      "2056/2072 [============================>.] - ETA: 0s - loss: 15.4281 - mse: 15.3966\n",
      "Epoch 16: val_loss did not improve from 15.82019\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 15.4509 - mse: 15.4194 - val_loss: 16.0652 - val_mse: 16.0333\n",
      "Epoch 17/25\n",
      "2062/2072 [============================>.] - ETA: 0s - loss: 15.4178 - mse: 15.3854\n",
      "Epoch 17: val_loss improved from 15.82019 to 15.55934, saving model to checkpoints/ext_4h_l1n2_2hidden_it0.e017_vl15.559.h5\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 15.4087 - mse: 15.3763 - val_loss: 15.5593 - val_mse: 15.5266\n",
      "Epoch 18/25\n",
      "2058/2072 [============================>.] - ETA: 0s - loss: 15.3564 - mse: 15.3229\n",
      "Epoch 18: val_loss improved from 15.55934 to 15.45374, saving model to checkpoints/ext_4h_l1n2_2hidden_it0.e018_vl15.454.h5\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 15.3340 - mse: 15.3005 - val_loss: 15.4537 - val_mse: 15.4199\n",
      "Epoch 19/25\n",
      "2061/2072 [============================>.] - ETA: 0s - loss: 15.2661 - mse: 15.2316\n",
      "Epoch 19: val_loss did not improve from 15.45374\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 15.2913 - mse: 15.2568 - val_loss: 15.6525 - val_mse: 15.6183\n",
      "Epoch 20/25\n",
      "2058/2072 [============================>.] - ETA: 0s - loss: 15.1159 - mse: 15.0807\n",
      "Epoch 20: val_loss did not improve from 15.45374\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 15.2037 - mse: 15.1684 - val_loss: 15.6118 - val_mse: 15.5754\n",
      "Epoch 21/25\n",
      "2056/2072 [============================>.] - ETA: 0s - loss: 15.1638 - mse: 15.1274\n",
      "Epoch 21: val_loss did not improve from 15.45374\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 15.1462 - mse: 15.1098 - val_loss: 15.5993 - val_mse: 15.5629\n",
      "Epoch 22/25\n",
      "2072/2072 [==============================] - ETA: 0s - loss: 15.1117 - mse: 15.0743\n",
      "Epoch 22: val_loss did not improve from 15.45374\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 15.1117 - mse: 15.0743 - val_loss: 15.7640 - val_mse: 15.7268\n",
      "Epoch 23/25\n",
      "2069/2072 [============================>.] - ETA: 0s - loss: 15.0433 - mse: 15.0052\n",
      "Epoch 23: val_loss improved from 15.45374 to 15.27615, saving model to checkpoints/ext_4h_l1n2_2hidden_it0.e023_vl15.276.h5\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 15.0519 - mse: 15.0137 - val_loss: 15.2762 - val_mse: 15.2378\n",
      "Epoch 24/25\n",
      "2067/2072 [============================>.] - ETA: 0s - loss: 15.0355 - mse: 14.9967\n",
      "Epoch 24: val_loss did not improve from 15.27615\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 15.0429 - mse: 15.0041 - val_loss: 15.5035 - val_mse: 15.4637\n",
      "Epoch 25/25\n",
      "2055/2072 [============================>.] - ETA: 0s - loss: 14.9951 - mse: 14.9554\n",
      "Epoch 25: val_loss improved from 15.27615 to 15.22433, saving model to checkpoints/ext_4h_l1n2_2hidden_it0.e025_vl15.224.h5\n",
      "2072/2072 [==============================] - 5s 2ms/step - loss: 14.9722 - mse: 14.9325 - val_loss: 15.2243 - val_mse: 15.1844\n",
      "Time elapsed to train: 121.58 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.246 2.888 1.576 3.213 2.277 1.691 1.226 0.947 0.597 0.338 0.186 0.124 0.070]\n",
      "<R> = [2.248 2.889 1.576 3.219 2.281 1.691 1.226 0.947 0.597 0.338 0.186 0.124 0.070]\n",
      "s_R = [0.037 0.055 0.009 0.084 0.051 0.002 0.006 0.009 0.001 0.000 0.000 0.000 0.000]\n",
      "g = [5.4884996 4.379217  4.7197266 ... 3.6638107 3.4673586 5.705307 ]\n",
      "ri = [0.1566     0.11399937 0.09399986 ... 0.14400005 0.10769939 0.18040085]\n",
      "gr = [0.40940094 0.30720043 0.33909988 ... 0.39439964 0.3547001  0.54629993]\n",
      "gaia_g = [5.092581  4.0506763 4.3923035 ... 3.2777119 3.1194954 5.188401 ]\n",
      "bp_rp = [0.87466145 0.76038456 0.7539873  ... 0.8580713  0.80200386 1.0124731 ]\n",
      "mag_pred: [5.117024  4.191297  4.4564505 ... 3.675897  3.7548726 5.0651608]\n",
      "mag_pred: [5.117024  4.191297  4.4564505 ... 3.675897  3.7548726 5.0651608]\n",
      "Time elapsed to make plots: 18.03 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 183594 bad. Replacing with 14.76263.\n",
      "Band 1: 4 of 183594 bad. Replacing with 15.15992.\n",
      "Band 2: 4 of 183594 bad. Replacing with 14.19274.\n",
      "Band 3: 113 of 183594 bad. Replacing with 15.23890.\n",
      "Band 4: 216 of 183594 bad. Replacing with 14.74910.\n",
      "Band 5: 7858 of 183594 bad. Replacing with 14.61460.\n",
      "Band 6: 243 of 183594 bad. Replacing with 14.49620.\n",
      "Band 7: 71 of 183594 bad. Replacing with 14.44220.\n",
      "Band 8: 365 of 183594 bad. Replacing with 13.53800.\n",
      "Band 9: 383 of 183594 bad. Replacing with 13.15900.\n",
      "Band 10: 1558 of 183594 bad. Replacing with 13.07700.\n",
      "Band 11: 207 of 183594 bad. Replacing with 15.74246.\n",
      "Band 12: 227 of 183594 bad. Replacing with 16.41537.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 183591 of 183594 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 8.489399   7.5186744  4.0436893 ... 10.370424   8.839837   7.9237013]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0238\n",
      "  1% : 0.144\n",
      "  10% : 0.294\n",
      "  50% : 0.77\n",
      "  90% : 4.33\n",
      "  99% : 38.7\n",
      "  100% : 7.28e+03\n",
      "<chi^2/d.o.f.> = 1.3\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 814 stars (0.443%) based on chi^2/dof > 100.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20400 bad. Replacing with 14.76272.\n",
      "Band 1: 1 of 20400 bad. Replacing with 15.16133.\n",
      "Band 2: 1 of 20400 bad. Replacing with 14.19002.\n",
      "Band 3: 12 of 20400 bad. Replacing with 15.23615.\n",
      "Band 4: 30 of 20400 bad. Replacing with 14.75020.\n",
      "Band 5: 901 of 20400 bad. Replacing with 14.62020.\n",
      "Band 6: 32 of 20400 bad. Replacing with 14.49545.\n",
      "Band 7: 8 of 20400 bad. Replacing with 14.43955.\n",
      "Band 8: 44 of 20400 bad. Replacing with 13.53900.\n",
      "Band 9: 38 of 20400 bad. Replacing with 13.16000.\n",
      "Band 10: 158 of 20400 bad. Replacing with 13.08300.\n",
      "Band 11: 12 of 20400 bad. Replacing with 15.74840.\n",
      "Band 12: 15 of 20400 bad. Replacing with 16.41809.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20400 of 20400 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 3.65174    5.056941  10.843134  ... 47.701153  23.375065   3.3024573]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0414\n",
      "  1% : 0.144\n",
      "  10% : 0.297\n",
      "  50% : 0.77\n",
      "  90% : 4.46\n",
      "  99% : 45.3\n",
      "  100% : 4.04e+03\n",
      "<chi^2/d.o.f.> = 1.3\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 57.31 s\n",
      "learning rate = 0.0010000000474974513\n",
      "setting learning rate to 0.0008187307530779819\n",
      "Iteration 2 of 20.\n",
      "Epoch 1/25\n",
      "2063/2063 [==============================] - ETA: 0s - loss: 1.5117 - mse: 1.4723\n",
      "Epoch 1: val_loss improved from inf to 1.52192, saving model to checkpoints/ext_4h_l1n2_2hidden_it1.e001_vl1.522.h5\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.5117 - mse: 1.4723 - val_loss: 1.5219 - val_mse: 1.4827\n",
      "Epoch 2/25\n",
      "2047/2063 [============================>.] - ETA: 0s - loss: 1.4876 - mse: 1.4485\n",
      "Epoch 2: val_loss improved from 1.52192 to 1.51102, saving model to checkpoints/ext_4h_l1n2_2hidden_it1.e002_vl1.511.h5\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.4883 - mse: 1.4493 - val_loss: 1.5110 - val_mse: 1.4723\n",
      "Epoch 3/25\n",
      "2055/2063 [============================>.] - ETA: 0s - loss: 1.4763 - mse: 1.4380\n",
      "Epoch 3: val_loss did not improve from 1.51102\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.4772 - mse: 1.4389 - val_loss: 1.5258 - val_mse: 1.4880\n",
      "Epoch 4/25\n",
      "2042/2063 [============================>.] - ETA: 0s - loss: 1.4672 - mse: 1.4300\n",
      "Epoch 4: val_loss improved from 1.51102 to 1.50783, saving model to checkpoints/ext_4h_l1n2_2hidden_it1.e004_vl1.508.h5\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.4674 - mse: 1.4302 - val_loss: 1.5078 - val_mse: 1.4713\n",
      "Epoch 5/25\n",
      "2044/2063 [============================>.] - ETA: 0s - loss: 1.4595 - mse: 1.4235\n",
      "Epoch 5: val_loss improved from 1.50783 to 1.49858, saving model to checkpoints/ext_4h_l1n2_2hidden_it1.e005_vl1.499.h5\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.4607 - mse: 1.4247 - val_loss: 1.4986 - val_mse: 1.4632\n",
      "Epoch 6/25\n",
      "2063/2063 [==============================] - ETA: 0s - loss: 1.4561 - mse: 1.4211\n",
      "Epoch 6: val_loss improved from 1.49858 to 1.48975, saving model to checkpoints/ext_4h_l1n2_2hidden_it1.e006_vl1.490.h5\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.4561 - mse: 1.4211 - val_loss: 1.4898 - val_mse: 1.4545\n",
      "Epoch 7/25\n",
      "2055/2063 [============================>.] - ETA: 0s - loss: 1.4551 - mse: 1.4210\n",
      "Epoch 7: val_loss improved from 1.48975 to 1.47556, saving model to checkpoints/ext_4h_l1n2_2hidden_it1.e007_vl1.476.h5\n",
      "2063/2063 [==============================] - 5s 3ms/step - loss: 1.4546 - mse: 1.4205 - val_loss: 1.4756 - val_mse: 1.4420\n",
      "Epoch 8/25\n",
      "2047/2063 [============================>.] - ETA: 0s - loss: 1.4512 - mse: 1.4177\n",
      "Epoch 8: val_loss did not improve from 1.47556\n",
      "2063/2063 [==============================] - 5s 3ms/step - loss: 1.4509 - mse: 1.4175 - val_loss: 1.4802 - val_mse: 1.4472\n",
      "Epoch 9/25\n",
      "2052/2063 [============================>.] - ETA: 0s - loss: 1.4499 - mse: 1.4170\n",
      "Epoch 9: val_loss did not improve from 1.47556\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.4495 - mse: 1.4166 - val_loss: 1.4831 - val_mse: 1.4503\n",
      "Epoch 10/25\n",
      "2062/2063 [============================>.] - ETA: 0s - loss: 1.4462 - mse: 1.4138\n",
      "Epoch 10: val_loss improved from 1.47556 to 1.47300, saving model to checkpoints/ext_4h_l1n2_2hidden_it1.e010_vl1.473.h5\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.4463 - mse: 1.4139 - val_loss: 1.4730 - val_mse: 1.4409\n",
      "Epoch 11/25\n",
      "2047/2063 [============================>.] - ETA: 0s - loss: 1.4450 - mse: 1.4130\n",
      "Epoch 11: val_loss did not improve from 1.47300\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.4449 - mse: 1.4129 - val_loss: 1.4735 - val_mse: 1.4419\n",
      "Epoch 12/25\n",
      "2048/2063 [============================>.] - ETA: 0s - loss: 1.4413 - mse: 1.4097\n",
      "Epoch 12: val_loss did not improve from 1.47300\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.4435 - mse: 1.4119 - val_loss: 1.4730 - val_mse: 1.4416\n",
      "Epoch 13/25\n",
      "2049/2063 [============================>.] - ETA: 0s - loss: 1.4415 - mse: 1.4103\n",
      "Epoch 13: val_loss did not improve from 1.47300\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.4414 - mse: 1.4101 - val_loss: 1.4741 - val_mse: 1.4429\n",
      "Epoch 14/25\n",
      "2049/2063 [============================>.] - ETA: 0s - loss: 1.4415 - mse: 1.4107\n",
      "Epoch 14: val_loss improved from 1.47300 to 1.47266, saving model to checkpoints/ext_4h_l1n2_2hidden_it1.e014_vl1.473.h5\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.4400 - mse: 1.4091 - val_loss: 1.4727 - val_mse: 1.4421\n",
      "Epoch 15/25\n",
      "2056/2063 [============================>.] - ETA: 0s - loss: 1.4402 - mse: 1.4095\n",
      "Epoch 15: val_loss did not improve from 1.47266\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.4401 - mse: 1.4095 - val_loss: 1.4748 - val_mse: 1.4443\n",
      "Epoch 16/25\n",
      "2053/2063 [============================>.] - ETA: 0s - loss: 1.4389 - mse: 1.4083\n",
      "Epoch 16: val_loss did not improve from 1.47266\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.4386 - mse: 1.4081 - val_loss: 1.4730 - val_mse: 1.4431\n",
      "Epoch 17/25\n",
      "2057/2063 [============================>.] - ETA: 0s - loss: 1.4382 - mse: 1.4080\n",
      "Epoch 17: val_loss improved from 1.47266 to 1.46941, saving model to checkpoints/ext_4h_l1n2_2hidden_it1.e017_vl1.469.h5\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.4383 - mse: 1.4081 - val_loss: 1.4694 - val_mse: 1.4392\n",
      "Epoch 18/25\n",
      "2060/2063 [============================>.] - ETA: 0s - loss: 1.4367 - mse: 1.4068\n",
      "Epoch 18: val_loss improved from 1.46941 to 1.46641, saving model to checkpoints/ext_4h_l1n2_2hidden_it1.e018_vl1.466.h5\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.4369 - mse: 1.4070 - val_loss: 1.4664 - val_mse: 1.4367\n",
      "Epoch 19/25\n",
      "2044/2063 [============================>.] - ETA: 0s - loss: 1.4364 - mse: 1.4066\n",
      "Epoch 19: val_loss did not improve from 1.46641\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.4357 - mse: 1.4059 - val_loss: 1.4682 - val_mse: 1.4385\n",
      "Epoch 20/25\n",
      "2037/2063 [============================>.] - ETA: 0s - loss: 1.4353 - mse: 1.4058\n",
      "Epoch 20: val_loss did not improve from 1.46641\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.4346 - mse: 1.4051 - val_loss: 1.4935 - val_mse: 1.4637\n",
      "Epoch 21/25\n",
      "2060/2063 [============================>.] - ETA: 0s - loss: 1.4358 - mse: 1.4063\n",
      "Epoch 21: val_loss improved from 1.46641 to 1.46366, saving model to checkpoints/ext_4h_l1n2_2hidden_it1.e021_vl1.464.h5\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.4353 - mse: 1.4059 - val_loss: 1.4637 - val_mse: 1.4343\n",
      "Epoch 22/25\n",
      "2059/2063 [============================>.] - ETA: 0s - loss: 1.4353 - mse: 1.4060\n",
      "Epoch 22: val_loss improved from 1.46366 to 1.46243, saving model to checkpoints/ext_4h_l1n2_2hidden_it1.e022_vl1.462.h5\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.4354 - mse: 1.4061 - val_loss: 1.4624 - val_mse: 1.4331\n",
      "Epoch 23/25\n",
      "2046/2063 [============================>.] - ETA: 0s - loss: 1.4324 - mse: 1.4033\n",
      "Epoch 23: val_loss did not improve from 1.46243\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.4332 - mse: 1.4041 - val_loss: 1.4917 - val_mse: 1.4627\n",
      "Epoch 24/25\n",
      "2052/2063 [============================>.] - ETA: 0s - loss: 1.4326 - mse: 1.4037\n",
      "Epoch 24: val_loss did not improve from 1.46243\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.4334 - mse: 1.4044 - val_loss: 1.4687 - val_mse: 1.4397\n",
      "Epoch 25/25\n",
      "2044/2063 [============================>.] - ETA: 0s - loss: 1.4342 - mse: 1.4053\n",
      "Epoch 25: val_loss improved from 1.46243 to 1.45990, saving model to checkpoints/ext_4h_l1n2_2hidden_it1.e025_vl1.460.h5\n",
      "2063/2063 [==============================] - 5s 2ms/step - loss: 1.4325 - mse: 1.4037 - val_loss: 1.4599 - val_mse: 1.4313\n",
      "Time elapsed to train: 123.93 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.561 3.310 1.777 3.670 2.601 1.881 1.365 1.072 0.661 0.338 0.168 0.079 0.011]\n",
      "<R> = [2.561 3.311 1.777 3.670 2.596 1.881 1.365 1.072 0.661 0.338 0.168 0.079 0.011]\n",
      "s_R = [0.011 0.018 0.005 0.049 0.073 0.002 0.001 0.001 0.002 0.001 0.000 0.000 0.000]\n",
      "g = [5.4884996 4.379217  4.7197266 ... 3.6638107 3.4673586 5.705307 ]\n",
      "ri = [0.1566     0.11399937 0.09399986 ... 0.14400005 0.10769939 0.18040085]\n",
      "gr = [0.40940094 0.30720043 0.33909988 ... 0.39439964 0.3547001  0.54629993]\n",
      "gaia_g = [5.092581  4.0506763 4.3923035 ... 3.2777119 3.1194954 5.188401 ]\n",
      "bp_rp = [0.87466145 0.76038456 0.7539873  ... 0.8580713  0.80200386 1.0124731 ]\n",
      "mag_pred: [5.084076  4.1367564 4.3554034 ... 3.5191069 3.688497  4.8798847]\n",
      "mag_pred: [5.084076  4.1367564 4.3554034 ... 3.5191069 3.688497  4.8798847]\n",
      "Time elapsed to make plots: 17.37 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 183594 bad. Replacing with 14.76263.\n",
      "Band 1: 4 of 183594 bad. Replacing with 15.15992.\n",
      "Band 2: 4 of 183594 bad. Replacing with 14.19274.\n",
      "Band 3: 113 of 183594 bad. Replacing with 15.23890.\n",
      "Band 4: 216 of 183594 bad. Replacing with 14.74910.\n",
      "Band 5: 7858 of 183594 bad. Replacing with 14.61460.\n",
      "Band 6: 243 of 183594 bad. Replacing with 14.49620.\n",
      "Band 7: 71 of 183594 bad. Replacing with 14.44220.\n",
      "Band 8: 365 of 183594 bad. Replacing with 13.53800.\n",
      "Band 9: 383 of 183594 bad. Replacing with 13.15900.\n",
      "Band 10: 1558 of 183594 bad. Replacing with 13.07700.\n",
      "Band 11: 207 of 183594 bad. Replacing with 15.74246.\n",
      "Band 12: 227 of 183594 bad. Replacing with 16.41537.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7f3874034790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 183591 of 183594 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7f386616b9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [9.011921  6.8579426 3.5655298 ... 9.848235  5.665486  8.587538 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0161\n",
      "  1% : 0.123\n",
      "  10% : 0.259\n",
      "  50% : 0.679\n",
      "  90% : 3.08\n",
      "  99% : 36.1\n",
      "  100% : 7.66e+03\n",
      "<chi^2/d.o.f.> = 1.11\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 913 stars (0.497%) based on chi^2/dof > 79.4\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20400 bad. Replacing with 14.76272.\n",
      "Band 1: 1 of 20400 bad. Replacing with 15.16133.\n",
      "Band 2: 1 of 20400 bad. Replacing with 14.19002.\n",
      "Band 3: 12 of 20400 bad. Replacing with 15.23615.\n",
      "Band 4: 30 of 20400 bad. Replacing with 14.75020.\n",
      "Band 5: 901 of 20400 bad. Replacing with 14.62020.\n",
      "Band 6: 32 of 20400 bad. Replacing with 14.49545.\n",
      "Band 7: 8 of 20400 bad. Replacing with 14.43955.\n",
      "Band 8: 44 of 20400 bad. Replacing with 13.53900.\n",
      "Band 9: 38 of 20400 bad. Replacing with 13.16000.\n",
      "Band 10: 158 of 20400 bad. Replacing with 13.08300.\n",
      "Band 11: 12 of 20400 bad. Replacing with 15.74840.\n",
      "Band 12: 15 of 20400 bad. Replacing with 16.41809.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20400 of 20400 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 3.7223656  5.637992   7.232112  ... 19.61695    9.403721   3.5936987]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.04\n",
      "  1% : 0.118\n",
      "  10% : 0.262\n",
      "  50% : 0.689\n",
      "  90% : 3.22\n",
      "  99% : 39.8\n",
      "  100% : 4.06e+03\n",
      "<chi^2/d.o.f.> = 1.12\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 60.11 s\n",
      "learning rate = 0.0008187307394109666\n",
      "setting learning rate to 0.0006703200460356394\n",
      "Iteration 3 of 20.\n",
      "Epoch 1/25\n",
      "2050/2062 [============================>.] - ETA: 0s - loss: 1.2676 - mse: 1.2391\n",
      "Epoch 1: val_loss improved from inf to 1.28213, saving model to checkpoints/ext_4h_l1n2_2hidden_it2.e001_vl1.282.h5\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2677 - mse: 1.2392 - val_loss: 1.2821 - val_mse: 1.2537\n",
      "Epoch 2/25\n",
      "2055/2062 [============================>.] - ETA: 0s - loss: 1.2657 - mse: 1.2374\n",
      "Epoch 2: val_loss did not improve from 1.28213\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2657 - mse: 1.2375 - val_loss: 1.2837 - val_mse: 1.2558\n",
      "Epoch 3/25\n",
      "2057/2062 [============================>.] - ETA: 0s - loss: 1.2652 - mse: 1.2371\n",
      "Epoch 3: val_loss did not improve from 1.28213\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2648 - mse: 1.2368 - val_loss: 1.2897 - val_mse: 1.2617\n",
      "Epoch 4/25\n",
      "2039/2062 [============================>.] - ETA: 0s - loss: 1.2639 - mse: 1.2361\n",
      "Epoch 4: val_loss improved from 1.28213 to 1.27648, saving model to checkpoints/ext_4h_l1n2_2hidden_it2.e004_vl1.276.h5\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2649 - mse: 1.2371 - val_loss: 1.2765 - val_mse: 1.2489\n",
      "Epoch 5/25\n",
      "2054/2062 [============================>.] - ETA: 0s - loss: 1.2632 - mse: 1.2355\n",
      "Epoch 5: val_loss improved from 1.27648 to 1.27513, saving model to checkpoints/ext_4h_l1n2_2hidden_it2.e005_vl1.275.h5\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2635 - mse: 1.2358 - val_loss: 1.2751 - val_mse: 1.2477\n",
      "Epoch 6/25\n",
      "2062/2062 [==============================] - ETA: 0s - loss: 1.2632 - mse: 1.2357\n",
      "Epoch 6: val_loss did not improve from 1.27513\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2632 - mse: 1.2357 - val_loss: 1.2822 - val_mse: 1.2548\n",
      "Epoch 7/25\n",
      "2060/2062 [============================>.] - ETA: 0s - loss: 1.2637 - mse: 1.2363\n",
      "Epoch 7: val_loss improved from 1.27513 to 1.27219, saving model to checkpoints/ext_4h_l1n2_2hidden_it2.e007_vl1.272.h5\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2638 - mse: 1.2365 - val_loss: 1.2722 - val_mse: 1.2450\n",
      "Epoch 8/25\n",
      "2044/2062 [============================>.] - ETA: 0s - loss: 1.2630 - mse: 1.2358\n",
      "Epoch 8: val_loss did not improve from 1.27219\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2626 - mse: 1.2354 - val_loss: 1.2913 - val_mse: 1.2642\n",
      "Epoch 9/25\n",
      "2062/2062 [==============================] - ETA: 0s - loss: 1.2617 - mse: 1.2346\n",
      "Epoch 9: val_loss did not improve from 1.27219\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2617 - mse: 1.2346 - val_loss: 1.2848 - val_mse: 1.2576\n",
      "Epoch 10/25\n",
      "2054/2062 [============================>.] - ETA: 0s - loss: 1.2613 - mse: 1.2344\n",
      "Epoch 10: val_loss did not improve from 1.27219\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2613 - mse: 1.2344 - val_loss: 1.2757 - val_mse: 1.2490\n",
      "Epoch 11/25\n",
      "2036/2062 [============================>.] - ETA: 0s - loss: 1.2613 - mse: 1.2346\n",
      "Epoch 11: val_loss did not improve from 1.27219\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2623 - mse: 1.2355 - val_loss: 1.2782 - val_mse: 1.2515\n",
      "Epoch 12/25\n",
      "2057/2062 [============================>.] - ETA: 0s - loss: 1.2616 - mse: 1.2349\n",
      "Epoch 12: val_loss did not improve from 1.27219\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2611 - mse: 1.2344 - val_loss: 1.2789 - val_mse: 1.2524\n",
      "Epoch 13/25\n",
      "2035/2062 [============================>.] - ETA: 0s - loss: 1.2587 - mse: 1.2321\n",
      "Epoch 13: val_loss did not improve from 1.27219\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2603 - mse: 1.2338 - val_loss: 1.2764 - val_mse: 1.2498\n",
      "Epoch 14/25\n",
      "2051/2062 [============================>.] - ETA: 0s - loss: 1.2600 - mse: 1.2336\n",
      "Epoch 14: val_loss did not improve from 1.27219\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2609 - mse: 1.2345 - val_loss: 1.2971 - val_mse: 1.2704\n",
      "Epoch 15/25\n",
      "2052/2062 [============================>.] - ETA: 0s - loss: 1.2589 - mse: 1.2326\n",
      "Epoch 15: val_loss did not improve from 1.27219\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2597 - mse: 1.2334 - val_loss: 1.2997 - val_mse: 1.2735\n",
      "Epoch 16/25\n",
      "2050/2062 [============================>.] - ETA: 0s - loss: 1.2604 - mse: 1.2342\n",
      "Epoch 16: val_loss did not improve from 1.27219\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2606 - mse: 1.2343 - val_loss: 1.2795 - val_mse: 1.2535\n",
      "Epoch 17/25\n",
      "2052/2062 [============================>.] - ETA: 0s - loss: 1.2587 - mse: 1.2325\n",
      "Epoch 17: val_loss did not improve from 1.27219\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2598 - mse: 1.2337 - val_loss: 1.2795 - val_mse: 1.2534\n",
      "Epoch 18/25\n",
      "2050/2062 [============================>.] - ETA: 0s - loss: 1.2585 - mse: 1.2324\n",
      "Epoch 18: val_loss did not improve from 1.27219\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2585 - mse: 1.2324 - val_loss: 1.2782 - val_mse: 1.2522\n",
      "Epoch 19/25\n",
      "2051/2062 [============================>.] - ETA: 0s - loss: 1.2611 - mse: 1.2351\n",
      "Epoch 19: val_loss did not improve from 1.27219\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2598 - mse: 1.2339 - val_loss: 1.2723 - val_mse: 1.2464\n",
      "Epoch 20/25\n",
      "2057/2062 [============================>.] - ETA: 0s - loss: 1.2586 - mse: 1.2327\n",
      "Epoch 20: val_loss did not improve from 1.27219\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2587 - mse: 1.2329 - val_loss: 1.2846 - val_mse: 1.2586\n",
      "Epoch 21/25\n",
      "2035/2062 [============================>.] - ETA: 0s - loss: 1.2596 - mse: 1.2338\n",
      "Epoch 21: val_loss did not improve from 1.27219\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2594 - mse: 1.2336 - val_loss: 1.2895 - val_mse: 1.2639\n",
      "Epoch 22/25\n",
      "2043/2062 [============================>.] - ETA: 0s - loss: 1.2601 - mse: 1.2344\n",
      "Epoch 22: val_loss did not improve from 1.27219\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2585 - mse: 1.2329 - val_loss: 1.2764 - val_mse: 1.2506\n",
      "Epoch 23/25\n",
      "2042/2062 [============================>.] - ETA: 0s - loss: 1.2587 - mse: 1.2331\n",
      "Epoch 23: val_loss did not improve from 1.27219\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2586 - mse: 1.2330 - val_loss: 1.2793 - val_mse: 1.2539\n",
      "Epoch 24/25\n",
      "2048/2062 [============================>.] - ETA: 0s - loss: 1.2581 - mse: 1.2326\n",
      "Epoch 24: val_loss improved from 1.27219 to 1.27117, saving model to checkpoints/ext_4h_l1n2_2hidden_it2.e024_vl1.271.h5\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2576 - mse: 1.2321 - val_loss: 1.2712 - val_mse: 1.2459\n",
      "Epoch 25/25\n",
      "2044/2062 [============================>.] - ETA: 0s - loss: 1.2565 - mse: 1.2311\n",
      "Epoch 25: val_loss did not improve from 1.27117\n",
      "2062/2062 [==============================] - 5s 2ms/step - loss: 1.2578 - mse: 1.2323 - val_loss: 1.2840 - val_mse: 1.2587\n",
      "Time elapsed to train: 122.77 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.644 3.420 1.839 3.826 2.660 1.943 1.422 1.118 0.679 0.317 0.140 0.061 0.001]\n",
      "<R> = [2.644 3.420 1.839 3.828 2.655 1.943 1.422 1.118 0.679 0.317 0.140 0.061 0.001]\n",
      "s_R = [0.008 0.016 0.007 0.028 0.056 0.012 0.008 0.007 0.001 0.000 0.000 0.000 0.000]\n",
      "g = [5.4884996 4.379217  4.7197266 ... 3.6638107 3.4673586 5.705307 ]\n",
      "ri = [0.1566     0.11399937 0.09399986 ... 0.14400005 0.10769939 0.18040085]\n",
      "gr = [0.40940094 0.30720043 0.33909988 ... 0.39439964 0.3547001  0.54629993]\n",
      "gaia_g = [5.092581  4.0506763 4.3923035 ... 3.2777119 3.1194954 5.188401 ]\n",
      "bp_rp = [0.87466145 0.76038456 0.7539873  ... 0.8580713  0.80200386 1.0124731 ]\n",
      "mag_pred: [5.0055766 4.1183558 4.3228593 ... 3.5066247 3.6525187 4.9109707]\n",
      "mag_pred: [5.0055766 4.1183558 4.3228593 ... 3.5066247 3.6525187 4.9109707]\n",
      "Time elapsed to make plots: 17.66 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 183594 bad. Replacing with 14.76263.\n",
      "Band 1: 4 of 183594 bad. Replacing with 15.15992.\n",
      "Band 2: 4 of 183594 bad. Replacing with 14.19274.\n",
      "Band 3: 113 of 183594 bad. Replacing with 15.23890.\n",
      "Band 4: 216 of 183594 bad. Replacing with 14.74910.\n",
      "Band 5: 7858 of 183594 bad. Replacing with 14.61460.\n",
      "Band 6: 243 of 183594 bad. Replacing with 14.49620.\n",
      "Band 7: 71 of 183594 bad. Replacing with 14.44220.\n",
      "Band 8: 365 of 183594 bad. Replacing with 13.53800.\n",
      "Band 9: 383 of 183594 bad. Replacing with 13.15900.\n",
      "Band 10: 1558 of 183594 bad. Replacing with 13.07700.\n",
      "Band 11: 207 of 183594 bad. Replacing with 15.74246.\n",
      "Band 12: 227 of 183594 bad. Replacing with 16.41537.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 183591 of 183594 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [9.6723795 6.959021  4.3789062 ... 9.971315  4.333706  8.357291 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0225\n",
      "  1% : 0.131\n",
      "  10% : 0.27\n",
      "  50% : 0.684\n",
      "  90% : 3.07\n",
      "  99% : 35.2\n",
      "  100% : 7.74e+03\n",
      "<chi^2/d.o.f.> = 1.11\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 1108 stars (0.604%) based on chi^2/dof > 63.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20400 bad. Replacing with 14.76272.\n",
      "Band 1: 1 of 20400 bad. Replacing with 15.16133.\n",
      "Band 2: 1 of 20400 bad. Replacing with 14.19002.\n",
      "Band 3: 12 of 20400 bad. Replacing with 15.23615.\n",
      "Band 4: 30 of 20400 bad. Replacing with 14.75020.\n",
      "Band 5: 901 of 20400 bad. Replacing with 14.62020.\n",
      "Band 6: 32 of 20400 bad. Replacing with 14.49545.\n",
      "Band 7: 8 of 20400 bad. Replacing with 14.43955.\n",
      "Band 8: 44 of 20400 bad. Replacing with 13.53900.\n",
      "Band 9: 38 of 20400 bad. Replacing with 13.16000.\n",
      "Band 10: 158 of 20400 bad. Replacing with 13.08300.\n",
      "Band 11: 12 of 20400 bad. Replacing with 15.74840.\n",
      "Band 12: 15 of 20400 bad. Replacing with 16.41809.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20400 of 20400 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 3.940339   5.7872667  9.288245  ... 13.882662   9.032535   3.5267072]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0526\n",
      "  1% : 0.13\n",
      "  10% : 0.274\n",
      "  50% : 0.691\n",
      "  90% : 3.2\n",
      "  99% : 38.3\n",
      "  100% : 3.93e+03\n",
      "<chi^2/d.o.f.> = 1.12\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 59.39 s\n",
      "learning rate = 0.0006703200633637607\n",
      "setting learning rate to 0.0005488116360940264\n",
      "Iteration 4 of 20.\n",
      "Epoch 1/25\n",
      "2056/2060 [============================>.] - ETA: 0s - loss: 1.1766 - mse: 1.1512\n",
      "Epoch 1: val_loss improved from inf to 1.18817, saving model to checkpoints/ext_4h_l1n2_2hidden_it3.e001_vl1.188.h5\n",
      "2060/2060 [==============================] - 6s 3ms/step - loss: 1.1764 - mse: 1.1510 - val_loss: 1.1882 - val_mse: 1.1629\n",
      "Epoch 2/25\n",
      "2054/2060 [============================>.] - ETA: 0s - loss: 1.1754 - mse: 1.1501\n",
      "Epoch 2: val_loss did not improve from 1.18817\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1762 - mse: 1.1508 - val_loss: 1.1912 - val_mse: 1.1658\n",
      "Epoch 3/25\n",
      "2051/2060 [============================>.] - ETA: 0s - loss: 1.1766 - mse: 1.1513\n",
      "Epoch 3: val_loss improved from 1.18817 to 1.18677, saving model to checkpoints/ext_4h_l1n2_2hidden_it3.e003_vl1.187.h5\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1755 - mse: 1.1502 - val_loss: 1.1868 - val_mse: 1.1614\n",
      "Epoch 4/25\n",
      "2042/2060 [============================>.] - ETA: 0s - loss: 1.1760 - mse: 1.1508\n",
      "Epoch 4: val_loss did not improve from 1.18677\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1758 - mse: 1.1506 - val_loss: 1.1922 - val_mse: 1.1669\n",
      "Epoch 5/25\n",
      "2057/2060 [============================>.] - ETA: 0s - loss: 1.1744 - mse: 1.1494\n",
      "Epoch 5: val_loss improved from 1.18677 to 1.18600, saving model to checkpoints/ext_4h_l1n2_2hidden_it3.e005_vl1.186.h5\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1750 - mse: 1.1499 - val_loss: 1.1860 - val_mse: 1.1609\n",
      "Epoch 6/25\n",
      "2060/2060 [==============================] - ETA: 0s - loss: 1.1755 - mse: 1.1505\n",
      "Epoch 6: val_loss improved from 1.18600 to 1.18379, saving model to checkpoints/ext_4h_l1n2_2hidden_it3.e006_vl1.184.h5\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1755 - mse: 1.1505 - val_loss: 1.1838 - val_mse: 1.1591\n",
      "Epoch 7/25\n",
      "2041/2060 [============================>.] - ETA: 0s - loss: 1.1752 - mse: 1.1503\n",
      "Epoch 7: val_loss improved from 1.18379 to 1.18204, saving model to checkpoints/ext_4h_l1n2_2hidden_it3.e007_vl1.182.h5\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1754 - mse: 1.1505 - val_loss: 1.1820 - val_mse: 1.1570\n",
      "Epoch 8/25\n",
      "2034/2060 [============================>.] - ETA: 0s - loss: 1.1727 - mse: 1.1479\n",
      "Epoch 8: val_loss did not improve from 1.18204\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1746 - mse: 1.1498 - val_loss: 1.1857 - val_mse: 1.1610\n",
      "Epoch 9/25\n",
      "2044/2060 [============================>.] - ETA: 0s - loss: 1.1744 - mse: 1.1496\n",
      "Epoch 9: val_loss did not improve from 1.18204\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1743 - mse: 1.1495 - val_loss: 1.1900 - val_mse: 1.1654\n",
      "Epoch 10/25\n",
      "2053/2060 [============================>.] - ETA: 0s - loss: 1.1744 - mse: 1.1498\n",
      "Epoch 10: val_loss did not improve from 1.18204\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1745 - mse: 1.1499 - val_loss: 1.1956 - val_mse: 1.1710\n",
      "Epoch 11/25\n",
      "2046/2060 [============================>.] - ETA: 0s - loss: 1.1734 - mse: 1.1489\n",
      "Epoch 11: val_loss did not improve from 1.18204\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1742 - mse: 1.1496 - val_loss: 1.1878 - val_mse: 1.1630\n",
      "Epoch 12/25\n",
      "2047/2060 [============================>.] - ETA: 0s - loss: 1.1736 - mse: 1.1491\n",
      "Epoch 12: val_loss improved from 1.18204 to 1.18169, saving model to checkpoints/ext_4h_l1n2_2hidden_it3.e012_vl1.182.h5\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1740 - mse: 1.1495 - val_loss: 1.1817 - val_mse: 1.1572\n",
      "Epoch 13/25\n",
      "2053/2060 [============================>.] - ETA: 0s - loss: 1.1741 - mse: 1.1497\n",
      "Epoch 13: val_loss did not improve from 1.18169\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1738 - mse: 1.1494 - val_loss: 1.1914 - val_mse: 1.1672\n",
      "Epoch 14/25\n",
      "2051/2060 [============================>.] - ETA: 0s - loss: 1.1732 - mse: 1.1489\n",
      "Epoch 14: val_loss did not improve from 1.18169\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1731 - mse: 1.1488 - val_loss: 1.1861 - val_mse: 1.1616\n",
      "Epoch 15/25\n",
      "2045/2060 [============================>.] - ETA: 0s - loss: 1.1740 - mse: 1.1497\n",
      "Epoch 15: val_loss improved from 1.18169 to 1.17986, saving model to checkpoints/ext_4h_l1n2_2hidden_it3.e015_vl1.180.h5\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1735 - mse: 1.1492 - val_loss: 1.1799 - val_mse: 1.1549\n",
      "Epoch 16/25\n",
      "2060/2060 [==============================] - ETA: 0s - loss: 1.1734 - mse: 1.1492\n",
      "Epoch 16: val_loss did not improve from 1.17986\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1734 - mse: 1.1492 - val_loss: 1.1831 - val_mse: 1.1589\n",
      "Epoch 17/25\n",
      "2056/2060 [============================>.] - ETA: 0s - loss: 1.1732 - mse: 1.1490\n",
      "Epoch 17: val_loss did not improve from 1.17986\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1728 - mse: 1.1486 - val_loss: 1.1932 - val_mse: 1.1687\n",
      "Epoch 18/25\n",
      "2044/2060 [============================>.] - ETA: 0s - loss: 1.1723 - mse: 1.1481\n",
      "Epoch 18: val_loss did not improve from 1.17986\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1734 - mse: 1.1493 - val_loss: 1.1881 - val_mse: 1.1639\n",
      "Epoch 19/25\n",
      "2060/2060 [==============================] - ETA: 0s - loss: 1.1727 - mse: 1.1487\n",
      "Epoch 19: val_loss did not improve from 1.17986\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1727 - mse: 1.1487 - val_loss: 1.1920 - val_mse: 1.1679\n",
      "Epoch 20/25\n",
      "2044/2060 [============================>.] - ETA: 0s - loss: 1.1724 - mse: 1.1485\n",
      "Epoch 20: val_loss did not improve from 1.17986\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1729 - mse: 1.1489 - val_loss: 1.1836 - val_mse: 1.1597\n",
      "Epoch 21/25\n",
      "2039/2060 [============================>.] - ETA: 0s - loss: 1.1709 - mse: 1.1470\n",
      "Epoch 21: val_loss did not improve from 1.17986\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1728 - mse: 1.1489 - val_loss: 1.1950 - val_mse: 1.1712\n",
      "Epoch 22/25\n",
      "2054/2060 [============================>.] - ETA: 0s - loss: 1.1715 - mse: 1.1477\n",
      "Epoch 22: val_loss did not improve from 1.17986\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1720 - mse: 1.1482 - val_loss: 1.1847 - val_mse: 1.1605\n",
      "Epoch 23/25\n",
      "2047/2060 [============================>.] - ETA: 0s - loss: 1.1731 - mse: 1.1493\n",
      "Epoch 23: val_loss did not improve from 1.17986\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1721 - mse: 1.1483 - val_loss: 1.1833 - val_mse: 1.1595\n",
      "Epoch 24/25\n",
      "2046/2060 [============================>.] - ETA: 0s - loss: 1.1710 - mse: 1.1473\n",
      "Epoch 24: val_loss did not improve from 1.17986\n",
      "2060/2060 [==============================] - 5s 2ms/step - loss: 1.1719 - mse: 1.1482 - val_loss: 1.1892 - val_mse: 1.1656\n",
      "Epoch 25/25\n",
      "2039/2060 [============================>.] - ETA: 0s - loss: 1.1732 - mse: 1.1495\n",
      "Epoch 25: val_loss did not improve from 1.17986\n",
      "2060/2060 [==============================] - 5s 3ms/step - loss: 1.1729 - mse: 1.1492 - val_loss: 1.1907 - val_mse: 1.1671\n",
      "Time elapsed to train: 122.41 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.662 3.490 1.864 3.881 2.727 1.963 1.437 1.130 0.695 0.329 0.144 0.060 0.000]\n",
      "<R> = [2.662 3.492 1.864 3.884 2.724 1.963 1.438 1.131 0.695 0.329 0.144 0.060 0.000]\n",
      "s_R = [0.019 0.024 0.005 0.059 0.083 0.005 0.006 0.002 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [5.4884996 4.379217  4.7197266 ... 3.6638107 3.4673586 5.705307 ]\n",
      "ri = [0.1566     0.11399937 0.09399986 ... 0.14400005 0.10769939 0.18040085]\n",
      "gr = [0.40940094 0.30720043 0.33909988 ... 0.39439964 0.3547001  0.54629993]\n",
      "gaia_g = [5.092581  4.0506763 4.3923035 ... 3.2777119 3.1194954 5.188401 ]\n",
      "bp_rp = [0.87466145 0.76038456 0.7539873  ... 0.8580713  0.80200386 1.0124731 ]\n",
      "mag_pred: [4.957961  4.1258583 4.323496  ... 3.5692172 3.67963   4.9480095]\n",
      "mag_pred: [4.957961  4.1258583 4.323496  ... 3.5692172 3.67963   4.9480095]\n",
      "Time elapsed to make plots: 17.17 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 183594 bad. Replacing with 14.76263.\n",
      "Band 1: 4 of 183594 bad. Replacing with 15.15992.\n",
      "Band 2: 4 of 183594 bad. Replacing with 14.19274.\n",
      "Band 3: 113 of 183594 bad. Replacing with 15.23890.\n",
      "Band 4: 216 of 183594 bad. Replacing with 14.74910.\n",
      "Band 5: 7858 of 183594 bad. Replacing with 14.61460.\n",
      "Band 6: 243 of 183594 bad. Replacing with 14.49620.\n",
      "Band 7: 71 of 183594 bad. Replacing with 14.44220.\n",
      "Band 8: 365 of 183594 bad. Replacing with 13.53800.\n",
      "Band 9: 383 of 183594 bad. Replacing with 13.15900.\n",
      "Band 10: 1558 of 183594 bad. Replacing with 13.07700.\n",
      "Band 11: 207 of 183594 bad. Replacing with 15.74246.\n",
      "Band 12: 227 of 183594 bad. Replacing with 16.41537.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 183591 of 183594 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [8.670985  6.7884207 4.0727377 ... 8.384884  4.950962  8.052622 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0233\n",
      "  1% : 0.116\n",
      "  10% : 0.245\n",
      "  50% : 0.659\n",
      "  90% : 3.14\n",
      "  99% : 35.3\n",
      "  100% : 7.74e+03\n",
      "<chi^2/d.o.f.> = 1.1\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 1349 stars (0.735%) based on chi^2/dof > 50.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20400 bad. Replacing with 14.76272.\n",
      "Band 1: 1 of 20400 bad. Replacing with 15.16133.\n",
      "Band 2: 1 of 20400 bad. Replacing with 14.19002.\n",
      "Band 3: 12 of 20400 bad. Replacing with 15.23615.\n",
      "Band 4: 30 of 20400 bad. Replacing with 14.75020.\n",
      "Band 5: 901 of 20400 bad. Replacing with 14.62020.\n",
      "Band 6: 32 of 20400 bad. Replacing with 14.49545.\n",
      "Band 7: 8 of 20400 bad. Replacing with 14.43955.\n",
      "Band 8: 44 of 20400 bad. Replacing with 13.53900.\n",
      "Band 9: 38 of 20400 bad. Replacing with 13.16000.\n",
      "Band 10: 158 of 20400 bad. Replacing with 13.08300.\n",
      "Band 11: 12 of 20400 bad. Replacing with 15.74840.\n",
      "Band 12: 15 of 20400 bad. Replacing with 16.41809.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20400 of 20400 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 4.3633885  7.017692   8.314087  ... 14.236769  10.599746   3.0481045]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0357\n",
      "  1% : 0.116\n",
      "  10% : 0.247\n",
      "  50% : 0.667\n",
      "  90% : 3.29\n",
      "  99% : 37.2\n",
      "  100% : 3.93e+03\n",
      "<chi^2/d.o.f.> = 1.11\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 58.24 s\n",
      "learning rate = 0.0005488116294145584\n",
      "setting learning rate to 0.0004493289641172216\n",
      "Iteration 5 of 20.\n",
      "Epoch 1/25\n",
      "2042/2057 [============================>.] - ETA: 0s - loss: 1.1230 - mse: 1.0995\n",
      "Epoch 1: val_loss improved from inf to 1.13445, saving model to checkpoints/ext_4h_l1n2_2hidden_it4.e001_vl1.134.h5\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1228 - mse: 1.0993 - val_loss: 1.1345 - val_mse: 1.1108\n",
      "Epoch 2/25\n",
      "2056/2057 [============================>.] - ETA: 0s - loss: 1.1234 - mse: 1.0999\n",
      "Epoch 2: val_loss improved from 1.13445 to 1.12848, saving model to checkpoints/ext_4h_l1n2_2hidden_it4.e002_vl1.128.h5\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1233 - mse: 1.0998 - val_loss: 1.1285 - val_mse: 1.1050\n",
      "Epoch 3/25\n",
      "2055/2057 [============================>.] - ETA: 0s - loss: 1.1233 - mse: 1.0998\n",
      "Epoch 3: val_loss improved from 1.12848 to 1.12846, saving model to checkpoints/ext_4h_l1n2_2hidden_it4.e003_vl1.128.h5\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1233 - mse: 1.0998 - val_loss: 1.1285 - val_mse: 1.1051\n",
      "Epoch 4/25\n",
      "2042/2057 [============================>.] - ETA: 0s - loss: 1.1232 - mse: 1.0998\n",
      "Epoch 4: val_loss did not improve from 1.12846\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1228 - mse: 1.0995 - val_loss: 1.1450 - val_mse: 1.1215\n",
      "Epoch 5/25\n",
      "2030/2057 [============================>.] - ETA: 0s - loss: 1.1234 - mse: 1.1001\n",
      "Epoch 5: val_loss did not improve from 1.12846\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1230 - mse: 1.0996 - val_loss: 1.1335 - val_mse: 1.1103\n",
      "Epoch 6/25\n",
      "2040/2057 [============================>.] - ETA: 0s - loss: 1.1221 - mse: 1.0988\n",
      "Epoch 6: val_loss did not improve from 1.12846\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1231 - mse: 1.0998 - val_loss: 1.1286 - val_mse: 1.1054\n",
      "Epoch 7/25\n",
      "2031/2057 [============================>.] - ETA: 0s - loss: 1.1224 - mse: 1.0992\n",
      "Epoch 7: val_loss did not improve from 1.12846\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1225 - mse: 1.0993 - val_loss: 1.1395 - val_mse: 1.1163\n",
      "Epoch 8/25\n",
      "2042/2057 [============================>.] - ETA: 0s - loss: 1.1219 - mse: 1.0987\n",
      "Epoch 8: val_loss did not improve from 1.12846\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1218 - mse: 1.0985 - val_loss: 1.1317 - val_mse: 1.1086\n",
      "Epoch 9/25\n",
      "2052/2057 [============================>.] - ETA: 0s - loss: 1.1220 - mse: 1.0988\n",
      "Epoch 9: val_loss did not improve from 1.12846\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1219 - mse: 1.0988 - val_loss: 1.1302 - val_mse: 1.1070\n",
      "Epoch 10/25\n",
      "2035/2057 [============================>.] - ETA: 0s - loss: 1.1223 - mse: 1.0992\n",
      "Epoch 10: val_loss did not improve from 1.12846\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1216 - mse: 1.0985 - val_loss: 1.1306 - val_mse: 1.1076\n",
      "Epoch 11/25\n",
      "2041/2057 [============================>.] - ETA: 0s - loss: 1.1225 - mse: 1.0994\n",
      "Epoch 11: val_loss did not improve from 1.12846\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1224 - mse: 1.0993 - val_loss: 1.1354 - val_mse: 1.1123\n",
      "Epoch 12/25\n",
      "2046/2057 [============================>.] - ETA: 0s - loss: 1.1218 - mse: 1.0988\n",
      "Epoch 12: val_loss did not improve from 1.12846\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1215 - mse: 1.0985 - val_loss: 1.1301 - val_mse: 1.1071\n",
      "Epoch 13/25\n",
      "2038/2057 [============================>.] - ETA: 0s - loss: 1.1223 - mse: 1.0993\n",
      "Epoch 13: val_loss did not improve from 1.12846\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1218 - mse: 1.0988 - val_loss: 1.1291 - val_mse: 1.1058\n",
      "Epoch 14/25\n",
      "2033/2057 [============================>.] - ETA: 0s - loss: 1.1217 - mse: 1.0987\n",
      "Epoch 14: val_loss improved from 1.12846 to 1.12736, saving model to checkpoints/ext_4h_l1n2_2hidden_it4.e014_vl1.127.h5\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1219 - mse: 1.0990 - val_loss: 1.1274 - val_mse: 1.1046\n",
      "Epoch 15/25\n",
      "2039/2057 [============================>.] - ETA: 0s - loss: 1.1222 - mse: 1.0993\n",
      "Epoch 15: val_loss did not improve from 1.12736\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1221 - mse: 1.0992 - val_loss: 1.1350 - val_mse: 1.1121\n",
      "Epoch 16/25\n",
      "2045/2057 [============================>.] - ETA: 0s - loss: 1.1224 - mse: 1.0996\n",
      "Epoch 16: val_loss improved from 1.12736 to 1.12575, saving model to checkpoints/ext_4h_l1n2_2hidden_it4.e016_vl1.126.h5\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1216 - mse: 1.0988 - val_loss: 1.1257 - val_mse: 1.1029\n",
      "Epoch 17/25\n",
      "2056/2057 [============================>.] - ETA: 0s - loss: 1.1218 - mse: 1.0990\n",
      "Epoch 17: val_loss did not improve from 1.12575\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1216 - mse: 1.0988 - val_loss: 1.1378 - val_mse: 1.1148\n",
      "Epoch 18/25\n",
      "2040/2057 [============================>.] - ETA: 0s - loss: 1.1221 - mse: 1.0994\n",
      "Epoch 18: val_loss did not improve from 1.12575\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1218 - mse: 1.0991 - val_loss: 1.1286 - val_mse: 1.1059\n",
      "Epoch 19/25\n",
      "2035/2057 [============================>.] - ETA: 0s - loss: 1.1215 - mse: 1.0988\n",
      "Epoch 19: val_loss did not improve from 1.12575\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1213 - mse: 1.0986 - val_loss: 1.1305 - val_mse: 1.1078\n",
      "Epoch 20/25\n",
      "2033/2057 [============================>.] - ETA: 0s - loss: 1.1224 - mse: 1.0998\n",
      "Epoch 20: val_loss did not improve from 1.12575\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1217 - mse: 1.0990 - val_loss: 1.1300 - val_mse: 1.1075\n",
      "Epoch 21/25\n",
      "2043/2057 [============================>.] - ETA: 0s - loss: 1.1203 - mse: 1.0977\n",
      "Epoch 21: val_loss did not improve from 1.12575\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1212 - mse: 1.0986 - val_loss: 1.1352 - val_mse: 1.1127\n",
      "Epoch 22/25\n",
      "2053/2057 [============================>.] - ETA: 0s - loss: 1.1217 - mse: 1.0991\n",
      "Epoch 22: val_loss did not improve from 1.12575\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1218 - mse: 1.0992 - val_loss: 1.1265 - val_mse: 1.1041\n",
      "Epoch 23/25\n",
      "2045/2057 [============================>.] - ETA: 0s - loss: 1.1199 - mse: 1.0973\n",
      "Epoch 23: val_loss did not improve from 1.12575\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1207 - mse: 1.0981 - val_loss: 1.1294 - val_mse: 1.1069\n",
      "Epoch 24/25\n",
      "2045/2057 [============================>.] - ETA: 0s - loss: 1.1219 - mse: 1.0994\n",
      "Epoch 24: val_loss did not improve from 1.12575\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1211 - mse: 1.0986 - val_loss: 1.1460 - val_mse: 1.1233\n",
      "Epoch 25/25\n",
      "2041/2057 [============================>.] - ETA: 0s - loss: 1.1206 - mse: 1.0981\n",
      "Epoch 25: val_loss did not improve from 1.12575\n",
      "2057/2057 [==============================] - 5s 2ms/step - loss: 1.1206 - mse: 1.0981 - val_loss: 1.1331 - val_mse: 1.1108\n",
      "Time elapsed to train: 120.59 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.705 3.498 1.885 3.892 2.727 1.990 1.452 1.140 0.697 0.330 0.144 0.056 0.000]\n",
      "<R> = [2.705 3.500 1.885 3.893 2.725 1.990 1.452 1.140 0.697 0.330 0.144 0.056 0.000]\n",
      "s_R = [0.013 0.019 0.005 0.058 0.077 0.004 0.002 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [5.4884996 4.379217  4.7197266 ... 3.6638107 3.4673586 5.705307 ]\n",
      "ri = [0.1566     0.11399937 0.09399986 ... 0.14400005 0.10769939 0.18040085]\n",
      "gr = [0.40940094 0.30720043 0.33909988 ... 0.39439964 0.3547001  0.54629993]\n",
      "gaia_g = [5.092581  4.0506763 4.3923035 ... 3.2777119 3.1194954 5.188401 ]\n",
      "bp_rp = [0.87466145 0.76038456 0.7539873  ... 0.8580713  0.80200386 1.0124731 ]\n",
      "mag_pred: [4.9471655 4.102643  4.3050747 ... 3.5316355 3.646511  4.980317 ]\n",
      "mag_pred: [4.9471655 4.102643  4.3050747 ... 3.5316355 3.646511  4.980317 ]\n",
      "Time elapsed to make plots: 17.60 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 183594 bad. Replacing with 14.76263.\n",
      "Band 1: 4 of 183594 bad. Replacing with 15.15992.\n",
      "Band 2: 4 of 183594 bad. Replacing with 14.19274.\n",
      "Band 3: 113 of 183594 bad. Replacing with 15.23890.\n",
      "Band 4: 216 of 183594 bad. Replacing with 14.74910.\n",
      "Band 5: 7858 of 183594 bad. Replacing with 14.61460.\n",
      "Band 6: 243 of 183594 bad. Replacing with 14.49620.\n",
      "Band 7: 71 of 183594 bad. Replacing with 14.44220.\n",
      "Band 8: 365 of 183594 bad. Replacing with 13.53800.\n",
      "Band 9: 383 of 183594 bad. Replacing with 13.15900.\n",
      "Band 10: 1558 of 183594 bad. Replacing with 13.07700.\n",
      "Band 11: 207 of 183594 bad. Replacing with 15.74246.\n",
      "Band 12: 227 of 183594 bad. Replacing with 16.41537.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 183591 of 183594 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [9.026825 8.142115 4.120222 ... 9.587377 5.533541 7.371588]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0203\n",
      "  1% : 0.126\n",
      "  10% : 0.262\n",
      "  50% : 0.682\n",
      "  90% : 3.1\n",
      "  99% : 35\n",
      "  100% : 7.72e+03\n",
      "<chi^2/d.o.f.> = 1.11\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 1647 stars (0.897%) based on chi^2/dof > 39.8\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20400 bad. Replacing with 14.76272.\n",
      "Band 1: 1 of 20400 bad. Replacing with 15.16133.\n",
      "Band 2: 1 of 20400 bad. Replacing with 14.19002.\n",
      "Band 3: 12 of 20400 bad. Replacing with 15.23615.\n",
      "Band 4: 30 of 20400 bad. Replacing with 14.75020.\n",
      "Band 5: 901 of 20400 bad. Replacing with 14.62020.\n",
      "Band 6: 32 of 20400 bad. Replacing with 14.49545.\n",
      "Band 7: 8 of 20400 bad. Replacing with 14.43955.\n",
      "Band 8: 44 of 20400 bad. Replacing with 13.53900.\n",
      "Band 9: 38 of 20400 bad. Replacing with 13.16000.\n",
      "Band 10: 158 of 20400 bad. Replacing with 13.08300.\n",
      "Band 11: 12 of 20400 bad. Replacing with 15.74840.\n",
      "Band 12: 15 of 20400 bad. Replacing with 16.41809.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20400 of 20400 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 5.887719   5.5254297 13.934378  ... 12.04328    9.270958   3.8745098]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0422\n",
      "  1% : 0.125\n",
      "  10% : 0.267\n",
      "  50% : 0.688\n",
      "  90% : 3.26\n",
      "  99% : 36.4\n",
      "  100% : 3.9e+03\n",
      "<chi^2/d.o.f.> = 1.12\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 56.84 s\n",
      "learning rate = 0.0004493289743550122\n",
      "setting learning rate to 0.00036787944117144236\n",
      "Iteration 6 of 20.\n",
      "Epoch 1/25\n",
      "2052/2054 [============================>.] - ETA: 0s - loss: 1.0691 - mse: 1.0467\n",
      "Epoch 1: val_loss improved from inf to 1.06844, saving model to checkpoints/ext_4h_l1n2_2hidden_it5.e001_vl1.068.h5\n",
      "2054/2054 [==============================] - 6s 3ms/step - loss: 1.0690 - mse: 1.0466 - val_loss: 1.0684 - val_mse: 1.0460\n",
      "Epoch 2/25\n",
      "2047/2054 [============================>.] - ETA: 0s - loss: 1.0686 - mse: 1.0462\n",
      "Epoch 2: val_loss did not improve from 1.06844\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0687 - mse: 1.0463 - val_loss: 1.0742 - val_mse: 1.0518\n",
      "Epoch 3/25\n",
      "2044/2054 [============================>.] - ETA: 0s - loss: 1.0685 - mse: 1.0461\n",
      "Epoch 3: val_loss did not improve from 1.06844\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0684 - mse: 1.0461 - val_loss: 1.0694 - val_mse: 1.0472\n",
      "Epoch 4/25\n",
      "2035/2054 [============================>.] - ETA: 0s - loss: 1.0691 - mse: 1.0468\n",
      "Epoch 4: val_loss did not improve from 1.06844\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0684 - mse: 1.0460 - val_loss: 1.0815 - val_mse: 1.0593\n",
      "Epoch 5/25\n",
      "2052/2054 [============================>.] - ETA: 0s - loss: 1.0682 - mse: 1.0460\n",
      "Epoch 5: val_loss did not improve from 1.06844\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0683 - mse: 1.0461 - val_loss: 1.0711 - val_mse: 1.0489\n",
      "Epoch 6/25\n",
      "2037/2054 [============================>.] - ETA: 0s - loss: 1.0690 - mse: 1.0468\n",
      "Epoch 6: val_loss improved from 1.06844 to 1.06720, saving model to checkpoints/ext_4h_l1n2_2hidden_it5.e006_vl1.067.h5\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0686 - mse: 1.0464 - val_loss: 1.0672 - val_mse: 1.0451\n",
      "Epoch 7/25\n",
      "2051/2054 [============================>.] - ETA: 0s - loss: 1.0686 - mse: 1.0464\n",
      "Epoch 7: val_loss did not improve from 1.06720\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0685 - mse: 1.0463 - val_loss: 1.0700 - val_mse: 1.0478\n",
      "Epoch 8/25\n",
      "2046/2054 [============================>.] - ETA: 0s - loss: 1.0691 - mse: 1.0470\n",
      "Epoch 8: val_loss did not improve from 1.06720\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0687 - mse: 1.0466 - val_loss: 1.0683 - val_mse: 1.0462\n",
      "Epoch 9/25\n",
      "2045/2054 [============================>.] - ETA: 0s - loss: 1.0685 - mse: 1.0464\n",
      "Epoch 9: val_loss did not improve from 1.06720\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0682 - mse: 1.0460 - val_loss: 1.0723 - val_mse: 1.0503\n",
      "Epoch 10/25\n",
      "2029/2054 [============================>.] - ETA: 0s - loss: 1.0680 - mse: 1.0459\n",
      "Epoch 10: val_loss did not improve from 1.06720\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0681 - mse: 1.0461 - val_loss: 1.0735 - val_mse: 1.0513\n",
      "Epoch 11/25\n",
      "2048/2054 [============================>.] - ETA: 0s - loss: 1.0681 - mse: 1.0460\n",
      "Epoch 11: val_loss did not improve from 1.06720\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0680 - mse: 1.0460 - val_loss: 1.0730 - val_mse: 1.0511\n",
      "Epoch 12/25\n",
      "2030/2054 [============================>.] - ETA: 0s - loss: 1.0679 - mse: 1.0459\n",
      "Epoch 12: val_loss did not improve from 1.06720\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0682 - mse: 1.0461 - val_loss: 1.0699 - val_mse: 1.0480\n",
      "Epoch 13/25\n",
      "2037/2054 [============================>.] - ETA: 0s - loss: 1.0684 - mse: 1.0464\n",
      "Epoch 13: val_loss did not improve from 1.06720\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0683 - mse: 1.0463 - val_loss: 1.0738 - val_mse: 1.0519\n",
      "Epoch 14/25\n",
      "2038/2054 [============================>.] - ETA: 0s - loss: 1.0681 - mse: 1.0462\n",
      "Epoch 14: val_loss did not improve from 1.06720\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0679 - mse: 1.0460 - val_loss: 1.0680 - val_mse: 1.0460\n",
      "Epoch 15/25\n",
      "2043/2054 [============================>.] - ETA: 0s - loss: 1.0687 - mse: 1.0469\n",
      "Epoch 15: val_loss did not improve from 1.06720\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0680 - mse: 1.0462 - val_loss: 1.0728 - val_mse: 1.0510\n",
      "Epoch 16/25\n",
      "2038/2054 [============================>.] - ETA: 0s - loss: 1.0682 - mse: 1.0463\n",
      "Epoch 16: val_loss did not improve from 1.06720\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0679 - mse: 1.0460 - val_loss: 1.0727 - val_mse: 1.0510\n",
      "Epoch 17/25\n",
      "2040/2054 [============================>.] - ETA: 0s - loss: 1.0683 - mse: 1.0465\n",
      "Epoch 17: val_loss did not improve from 1.06720\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0679 - mse: 1.0460 - val_loss: 1.0682 - val_mse: 1.0462\n",
      "Epoch 18/25\n",
      "2038/2054 [============================>.] - ETA: 0s - loss: 1.0670 - mse: 1.0451\n",
      "Epoch 18: val_loss did not improve from 1.06720\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0672 - mse: 1.0454 - val_loss: 1.0710 - val_mse: 1.0492\n",
      "Epoch 19/25\n",
      "2036/2054 [============================>.] - ETA: 0s - loss: 1.0682 - mse: 1.0464\n",
      "Epoch 19: val_loss did not improve from 1.06720\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0678 - mse: 1.0460 - val_loss: 1.0694 - val_mse: 1.0476\n",
      "Epoch 20/25\n",
      "2039/2054 [============================>.] - ETA: 0s - loss: 1.0675 - mse: 1.0457\n",
      "Epoch 20: val_loss did not improve from 1.06720\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0675 - mse: 1.0458 - val_loss: 1.0757 - val_mse: 1.0539\n",
      "Epoch 21/25\n",
      "2048/2054 [============================>.] - ETA: 0s - loss: 1.0678 - mse: 1.0460\n",
      "Epoch 21: val_loss did not improve from 1.06720\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0675 - mse: 1.0458 - val_loss: 1.0717 - val_mse: 1.0501\n",
      "Epoch 22/25\n",
      "2033/2054 [============================>.] - ETA: 0s - loss: 1.0683 - mse: 1.0466\n",
      "Epoch 22: val_loss did not improve from 1.06720\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0678 - mse: 1.0461 - val_loss: 1.0691 - val_mse: 1.0470\n",
      "Epoch 23/25\n",
      "2046/2054 [============================>.] - ETA: 0s - loss: 1.0680 - mse: 1.0463\n",
      "Epoch 23: val_loss did not improve from 1.06720\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0673 - mse: 1.0456 - val_loss: 1.0886 - val_mse: 1.0669\n",
      "Epoch 24/25\n",
      "2051/2054 [============================>.] - ETA: 0s - loss: 1.0678 - mse: 1.0461\n",
      "Epoch 24: val_loss did not improve from 1.06720\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0676 - mse: 1.0460 - val_loss: 1.0722 - val_mse: 1.0505\n",
      "Epoch 25/25\n",
      "2051/2054 [============================>.] - ETA: 0s - loss: 1.0671 - mse: 1.0455\n",
      "Epoch 25: val_loss did not improve from 1.06720\n",
      "2054/2054 [==============================] - 5s 2ms/step - loss: 1.0673 - mse: 1.0457 - val_loss: 1.0720 - val_mse: 1.0504\n",
      "Time elapsed to train: 122.60 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.707 3.523 1.892 3.925 2.754 1.996 1.460 1.146 0.704 0.333 0.145 0.056 0.000]\n",
      "<R> = [2.707 3.525 1.892 3.924 2.751 1.996 1.460 1.146 0.704 0.333 0.145 0.056 0.000]\n",
      "s_R = [0.027 0.024 0.003 0.070 0.087 0.005 0.001 0.001 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [5.4884996 4.379217  4.7197266 ... 3.6638107 3.4673586 5.705307 ]\n",
      "ri = [0.1566     0.11399937 0.09399986 ... 0.14400005 0.10769939 0.18040085]\n",
      "gr = [0.40940094 0.30720043 0.33909988 ... 0.39439964 0.3547001  0.54629993]\n",
      "gaia_g = [5.092581  4.0506763 4.3923035 ... 3.2777119 3.1194954 5.188401 ]\n",
      "bp_rp = [0.87466145 0.76038456 0.7539873  ... 0.8580713  0.80200386 1.0124731 ]\n",
      "mag_pred: [4.9300137 4.0820518 4.2779202 ... 3.512107  3.6324532 4.959097 ]\n",
      "mag_pred: [4.9300137 4.0820518 4.2779202 ... 3.512107  3.6324532 4.959097 ]\n",
      "Time elapsed to make plots: 16.72 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 183594 bad. Replacing with 14.76263.\n",
      "Band 1: 4 of 183594 bad. Replacing with 15.15992.\n",
      "Band 2: 4 of 183594 bad. Replacing with 14.19274.\n",
      "Band 3: 113 of 183594 bad. Replacing with 15.23890.\n",
      "Band 4: 216 of 183594 bad. Replacing with 14.74910.\n",
      "Band 5: 7858 of 183594 bad. Replacing with 14.61460.\n",
      "Band 6: 243 of 183594 bad. Replacing with 14.49620.\n",
      "Band 7: 71 of 183594 bad. Replacing with 14.44220.\n",
      "Band 8: 365 of 183594 bad. Replacing with 13.53800.\n",
      "Band 9: 383 of 183594 bad. Replacing with 13.15900.\n",
      "Band 10: 1558 of 183594 bad. Replacing with 13.07700.\n",
      "Band 11: 207 of 183594 bad. Replacing with 15.74246.\n",
      "Band 12: 227 of 183594 bad. Replacing with 16.41537.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 183591 of 183594 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [8.467773  7.0104485 4.049582  ... 9.401035  5.7822323 7.0472674]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0119\n",
      "  1% : 0.117\n",
      "  10% : 0.246\n",
      "  50% : 0.664\n",
      "  90% : 3.12\n",
      "  99% : 35.1\n",
      "  100% : 7.71e+03\n",
      "<chi^2/d.o.f.> = 1.1\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 2017 stars (1.1%) based on chi^2/dof > 31.6\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20400 bad. Replacing with 14.76272.\n",
      "Band 1: 1 of 20400 bad. Replacing with 15.16133.\n",
      "Band 2: 1 of 20400 bad. Replacing with 14.19002.\n",
      "Band 3: 12 of 20400 bad. Replacing with 15.23615.\n",
      "Band 4: 30 of 20400 bad. Replacing with 14.75020.\n",
      "Band 5: 901 of 20400 bad. Replacing with 14.62020.\n",
      "Band 6: 32 of 20400 bad. Replacing with 14.49545.\n",
      "Band 7: 8 of 20400 bad. Replacing with 14.43955.\n",
      "Band 8: 44 of 20400 bad. Replacing with 13.53900.\n",
      "Band 9: 38 of 20400 bad. Replacing with 13.16000.\n",
      "Band 10: 158 of 20400 bad. Replacing with 13.08300.\n",
      "Band 11: 12 of 20400 bad. Replacing with 15.74840.\n",
      "Band 12: 15 of 20400 bad. Replacing with 16.41809.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20400 of 20400 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 5.436441  6.156753 12.596657 ... 10.23283   9.53333   3.498212]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.043\n",
      "  1% : 0.116\n",
      "  10% : 0.252\n",
      "  50% : 0.672\n",
      "  90% : 3.25\n",
      "  99% : 36.5\n",
      "  100% : 3.93e+03\n",
      "<chi^2/d.o.f.> = 1.11\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 58.90 s\n",
      "learning rate = 0.0003678794309962541\n",
      "setting learning rate to 0.00030119421191220205\n",
      "Iteration 7 of 20.\n",
      "Epoch 1/25\n",
      "2042/2050 [============================>.] - ETA: 0s - loss: 1.0144 - mse: 0.9928\n",
      "Epoch 1: val_loss improved from inf to 1.02508, saving model to checkpoints/ext_4h_l1n2_2hidden_it6.e001_vl1.025.h5\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0141 - mse: 0.9925 - val_loss: 1.0251 - val_mse: 1.0035\n",
      "Epoch 2/25\n",
      "2050/2050 [==============================] - ETA: 0s - loss: 1.0146 - mse: 0.9931\n",
      "Epoch 2: val_loss did not improve from 1.02508\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0146 - mse: 0.9931 - val_loss: 1.0338 - val_mse: 1.0122\n",
      "Epoch 3/25\n",
      "2045/2050 [============================>.] - ETA: 0s - loss: 1.0143 - mse: 0.9928\n",
      "Epoch 3: val_loss did not improve from 1.02508\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0142 - mse: 0.9927 - val_loss: 1.0297 - val_mse: 1.0082\n",
      "Epoch 4/25\n",
      "2046/2050 [============================>.] - ETA: 0s - loss: 1.0143 - mse: 0.9929\n",
      "Epoch 4: val_loss did not improve from 1.02508\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0142 - mse: 0.9927 - val_loss: 1.0462 - val_mse: 1.0248\n",
      "Epoch 5/25\n",
      "2031/2050 [============================>.] - ETA: 0s - loss: 1.0150 - mse: 0.9936\n",
      "Epoch 5: val_loss did not improve from 1.02508\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0145 - mse: 0.9931 - val_loss: 1.0294 - val_mse: 1.0080\n",
      "Epoch 6/25\n",
      "2049/2050 [============================>.] - ETA: 0s - loss: 1.0142 - mse: 0.9928\n",
      "Epoch 6: val_loss improved from 1.02508 to 1.02366, saving model to checkpoints/ext_4h_l1n2_2hidden_it6.e006_vl1.024.h5\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0142 - mse: 0.9928 - val_loss: 1.0237 - val_mse: 1.0021\n",
      "Epoch 7/25\n",
      "2037/2050 [============================>.] - ETA: 0s - loss: 1.0142 - mse: 0.9929\n",
      "Epoch 7: val_loss did not improve from 1.02366\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0143 - mse: 0.9929 - val_loss: 1.0302 - val_mse: 1.0089\n",
      "Epoch 8/25\n",
      "2033/2050 [============================>.] - ETA: 0s - loss: 1.0142 - mse: 0.9929\n",
      "Epoch 8: val_loss did not improve from 1.02366\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0139 - mse: 0.9926 - val_loss: 1.0343 - val_mse: 1.0128\n",
      "Epoch 9/25\n",
      "2039/2050 [============================>.] - ETA: 0s - loss: 1.0140 - mse: 0.9928\n",
      "Epoch 9: val_loss did not improve from 1.02366\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0142 - mse: 0.9929 - val_loss: 1.0254 - val_mse: 1.0041\n",
      "Epoch 10/25\n",
      "2039/2050 [============================>.] - ETA: 0s - loss: 1.0139 - mse: 0.9927\n",
      "Epoch 10: val_loss did not improve from 1.02366\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0135 - mse: 0.9922 - val_loss: 1.0241 - val_mse: 1.0029\n",
      "Epoch 11/25\n",
      "2047/2050 [============================>.] - ETA: 0s - loss: 1.0141 - mse: 0.9929\n",
      "Epoch 11: val_loss did not improve from 1.02366\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0141 - mse: 0.9929 - val_loss: 1.0452 - val_mse: 1.0239\n",
      "Epoch 12/25\n",
      "2050/2050 [==============================] - ETA: 0s - loss: 1.0140 - mse: 0.9928\n",
      "Epoch 12: val_loss did not improve from 1.02366\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0140 - mse: 0.9928 - val_loss: 1.0277 - val_mse: 1.0065\n",
      "Epoch 13/25\n",
      "2026/2050 [============================>.] - ETA: 0s - loss: 1.0142 - mse: 0.9930\n",
      "Epoch 13: val_loss did not improve from 1.02366\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0136 - mse: 0.9925 - val_loss: 1.0364 - val_mse: 1.0153\n",
      "Epoch 14/25\n",
      "2028/2050 [============================>.] - ETA: 0s - loss: 1.0143 - mse: 0.9932\n",
      "Epoch 14: val_loss did not improve from 1.02366\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0135 - mse: 0.9923 - val_loss: 1.0333 - val_mse: 1.0123\n",
      "Epoch 15/25\n",
      "2032/2050 [============================>.] - ETA: 0s - loss: 1.0135 - mse: 0.9924\n",
      "Epoch 15: val_loss did not improve from 1.02366\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0137 - mse: 0.9926 - val_loss: 1.0271 - val_mse: 1.0059\n",
      "Epoch 16/25\n",
      "2026/2050 [============================>.] - ETA: 0s - loss: 1.0132 - mse: 0.9922\n",
      "Epoch 16: val_loss did not improve from 1.02366\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0136 - mse: 0.9925 - val_loss: 1.0249 - val_mse: 1.0038\n",
      "Epoch 17/25\n",
      "2045/2050 [============================>.] - ETA: 0s - loss: 1.0137 - mse: 0.9927\n",
      "Epoch 17: val_loss did not improve from 1.02366\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0135 - mse: 0.9925 - val_loss: 1.0324 - val_mse: 1.0114\n",
      "Epoch 18/25\n",
      "2050/2050 [==============================] - ETA: 0s - loss: 1.0136 - mse: 0.9925\n",
      "Epoch 18: val_loss did not improve from 1.02366\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0136 - mse: 0.9925 - val_loss: 1.0274 - val_mse: 1.0064\n",
      "Epoch 19/25\n",
      "2049/2050 [============================>.] - ETA: 0s - loss: 1.0135 - mse: 0.9925\n",
      "Epoch 19: val_loss did not improve from 1.02366\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0135 - mse: 0.9925 - val_loss: 1.0257 - val_mse: 1.0047\n",
      "Epoch 20/25\n",
      "2034/2050 [============================>.] - ETA: 0s - loss: 1.0140 - mse: 0.9930\n",
      "Epoch 20: val_loss did not improve from 1.02366\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0136 - mse: 0.9926 - val_loss: 1.0266 - val_mse: 1.0056\n",
      "Epoch 21/25\n",
      "2044/2050 [============================>.] - ETA: 0s - loss: 1.0139 - mse: 0.9930\n",
      "Epoch 21: val_loss did not improve from 1.02366\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0135 - mse: 0.9926 - val_loss: 1.0248 - val_mse: 1.0035\n",
      "Epoch 22/25\n",
      "2025/2050 [============================>.] - ETA: 0s - loss: 1.0136 - mse: 0.9927\n",
      "Epoch 22: val_loss did not improve from 1.02366\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0137 - mse: 0.9927 - val_loss: 1.0410 - val_mse: 1.0202\n",
      "Epoch 23/25\n",
      "2044/2050 [============================>.] - ETA: 0s - loss: 1.0135 - mse: 0.9926\n",
      "Epoch 23: val_loss improved from 1.02366 to 1.02213, saving model to checkpoints/ext_4h_l1n2_2hidden_it6.e023_vl1.022.h5\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0135 - mse: 0.9926 - val_loss: 1.0221 - val_mse: 1.0013\n",
      "Epoch 24/25\n",
      "2045/2050 [============================>.] - ETA: 0s - loss: 1.0128 - mse: 0.9919\n",
      "Epoch 24: val_loss did not improve from 1.02213\n",
      "2050/2050 [==============================] - 5s 3ms/step - loss: 1.0133 - mse: 0.9924 - val_loss: 1.0526 - val_mse: 1.0314\n",
      "Epoch 25/25\n",
      "2025/2050 [============================>.] - ETA: 0s - loss: 1.0143 - mse: 0.9935\n",
      "Epoch 25: val_loss did not improve from 1.02213\n",
      "2050/2050 [==============================] - 5s 2ms/step - loss: 1.0141 - mse: 0.9932 - val_loss: 1.0338 - val_mse: 1.0129\n",
      "Time elapsed to train: 122.51 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.704 3.517 1.888 3.921 2.748 1.996 1.456 1.144 0.701 0.331 0.145 0.055 0.000]\n",
      "<R> = [2.704 3.519 1.888 3.921 2.743 1.996 1.456 1.144 0.701 0.331 0.145 0.055 0.000]\n",
      "s_R = [0.026 0.024 0.003 0.076 0.083 0.006 0.001 0.001 0.001 0.000 0.000 0.000 0.000]\n",
      "g = [5.4884996 4.379217  4.7197266 ... 3.6638107 3.4673586 5.705307 ]\n",
      "ri = [0.1566     0.11399937 0.09399986 ... 0.14400005 0.10769939 0.18040085]\n",
      "gr = [0.40940094 0.30720043 0.33909988 ... 0.39439964 0.3547001  0.54629993]\n",
      "gaia_g = [5.092581  4.0506763 4.3923035 ... 3.2777119 3.1194954 5.188401 ]\n",
      "bp_rp = [0.87466145 0.76038456 0.7539873  ... 0.8580713  0.80200386 1.0124731 ]\n",
      "mag_pred: [4.9699917 4.0798044 4.303029  ... 3.4962585 3.622853  4.944245 ]\n",
      "mag_pred: [4.9699917 4.0798044 4.303029  ... 3.4962585 3.622853  4.944245 ]\n",
      "Time elapsed to make plots: 19.16 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 183594 bad. Replacing with 14.76263.\n",
      "Band 1: 4 of 183594 bad. Replacing with 15.15992.\n",
      "Band 2: 4 of 183594 bad. Replacing with 14.19274.\n",
      "Band 3: 113 of 183594 bad. Replacing with 15.23890.\n",
      "Band 4: 216 of 183594 bad. Replacing with 14.74910.\n",
      "Band 5: 7858 of 183594 bad. Replacing with 14.61460.\n",
      "Band 6: 243 of 183594 bad. Replacing with 14.49620.\n",
      "Band 7: 71 of 183594 bad. Replacing with 14.44220.\n",
      "Band 8: 365 of 183594 bad. Replacing with 13.53800.\n",
      "Band 9: 383 of 183594 bad. Replacing with 13.15900.\n",
      "Band 10: 1558 of 183594 bad. Replacing with 13.07700.\n",
      "Band 11: 207 of 183594 bad. Replacing with 15.74246.\n",
      "Band 12: 227 of 183594 bad. Replacing with 16.41537.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 183591 of 183594 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 8.420792   8.1161785  2.9928694 ... 10.510479   5.5849733  6.271627 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0187\n",
      "  1% : 0.122\n",
      "  10% : 0.257\n",
      "  50% : 0.673\n",
      "  90% : 3.02\n",
      "  99% : 35.2\n",
      "  100% : 7.74e+03\n",
      "<chi^2/d.o.f.> = 1.09\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 2460 stars (1.34%) based on chi^2/dof > 25.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20400 bad. Replacing with 14.76272.\n",
      "Band 1: 1 of 20400 bad. Replacing with 15.16133.\n",
      "Band 2: 1 of 20400 bad. Replacing with 14.19002.\n",
      "Band 3: 12 of 20400 bad. Replacing with 15.23615.\n",
      "Band 4: 30 of 20400 bad. Replacing with 14.75020.\n",
      "Band 5: 901 of 20400 bad. Replacing with 14.62020.\n",
      "Band 6: 32 of 20400 bad. Replacing with 14.49545.\n",
      "Band 7: 8 of 20400 bad. Replacing with 14.43955.\n",
      "Band 8: 44 of 20400 bad. Replacing with 13.53900.\n",
      "Band 9: 38 of 20400 bad. Replacing with 13.16000.\n",
      "Band 10: 158 of 20400 bad. Replacing with 13.08300.\n",
      "Band 11: 12 of 20400 bad. Replacing with 15.74840.\n",
      "Band 12: 15 of 20400 bad. Replacing with 16.41809.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20400 of 20400 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 5.042268  6.826993 12.732317 ... 11.584389  8.430665  4.024042]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0411\n",
      "  1% : 0.119\n",
      "  10% : 0.26\n",
      "  50% : 0.679\n",
      "  90% : 3.17\n",
      "  99% : 36.8\n",
      "  100% : 3.92e+03\n",
      "<chi^2/d.o.f.> = 1.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 60.48 s\n",
      "learning rate = 0.0003011942026205361\n",
      "setting learning rate to 0.00024659696394160646\n",
      "Iteration 8 of 20.\n",
      "Epoch 1/25\n",
      "2030/2045 [============================>.] - ETA: 0s - loss: 0.9602 - mse: 0.9394\n",
      "Epoch 1: val_loss improved from inf to 0.96948, saving model to checkpoints/ext_4h_l1n2_2hidden_it7.e001_vl0.969.h5\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9599 - mse: 0.9391 - val_loss: 0.9695 - val_mse: 0.9488\n",
      "Epoch 2/25\n",
      "2039/2045 [============================>.] - ETA: 0s - loss: 0.9597 - mse: 0.9390\n",
      "Epoch 2: val_loss improved from 0.96948 to 0.96870, saving model to checkpoints/ext_4h_l1n2_2hidden_it7.e002_vl0.969.h5\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9599 - mse: 0.9392 - val_loss: 0.9687 - val_mse: 0.9479\n",
      "Epoch 3/25\n",
      "2030/2045 [============================>.] - ETA: 0s - loss: 0.9597 - mse: 0.9390\n",
      "Epoch 3: val_loss improved from 0.96870 to 0.96775, saving model to checkpoints/ext_4h_l1n2_2hidden_it7.e003_vl0.968.h5\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9605 - mse: 0.9398 - val_loss: 0.9677 - val_mse: 0.9470\n",
      "Epoch 4/25\n",
      "2032/2045 [============================>.] - ETA: 0s - loss: 0.9601 - mse: 0.9394\n",
      "Epoch 4: val_loss improved from 0.96775 to 0.96602, saving model to checkpoints/ext_4h_l1n2_2hidden_it7.e004_vl0.966.h5\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9600 - mse: 0.9393 - val_loss: 0.9660 - val_mse: 0.9454\n",
      "Epoch 5/25\n",
      "2028/2045 [============================>.] - ETA: 0s - loss: 0.9608 - mse: 0.9402\n",
      "Epoch 5: val_loss did not improve from 0.96602\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9599 - mse: 0.9393 - val_loss: 0.9719 - val_mse: 0.9513\n",
      "Epoch 6/25\n",
      "2042/2045 [============================>.] - ETA: 0s - loss: 0.9597 - mse: 0.9391\n",
      "Epoch 6: val_loss did not improve from 0.96602\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9598 - mse: 0.9392 - val_loss: 0.9662 - val_mse: 0.9457\n",
      "Epoch 7/25\n",
      "2028/2045 [============================>.] - ETA: 0s - loss: 0.9597 - mse: 0.9392\n",
      "Epoch 7: val_loss improved from 0.96602 to 0.96511, saving model to checkpoints/ext_4h_l1n2_2hidden_it7.e007_vl0.965.h5\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9599 - mse: 0.9393 - val_loss: 0.9651 - val_mse: 0.9445\n",
      "Epoch 8/25\n",
      "2025/2045 [============================>.] - ETA: 0s - loss: 0.9602 - mse: 0.9397\n",
      "Epoch 8: val_loss did not improve from 0.96511\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9600 - mse: 0.9394 - val_loss: 0.9666 - val_mse: 0.9460\n",
      "Epoch 9/25\n",
      "2021/2045 [============================>.] - ETA: 0s - loss: 0.9600 - mse: 0.9395\n",
      "Epoch 9: val_loss did not improve from 0.96511\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9603 - mse: 0.9397 - val_loss: 0.9661 - val_mse: 0.9456\n",
      "Epoch 10/25\n",
      "2044/2045 [============================>.] - ETA: 0s - loss: 0.9598 - mse: 0.9392\n",
      "Epoch 10: val_loss did not improve from 0.96511\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9598 - mse: 0.9392 - val_loss: 0.9689 - val_mse: 0.9482\n",
      "Epoch 11/25\n",
      "2021/2045 [============================>.] - ETA: 0s - loss: 0.9604 - mse: 0.9398\n",
      "Epoch 11: val_loss improved from 0.96511 to 0.96273, saving model to checkpoints/ext_4h_l1n2_2hidden_it7.e011_vl0.963.h5\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9602 - mse: 0.9397 - val_loss: 0.9627 - val_mse: 0.9423\n",
      "Epoch 12/25\n",
      "2026/2045 [============================>.] - ETA: 0s - loss: 0.9589 - mse: 0.9384\n",
      "Epoch 12: val_loss did not improve from 0.96273\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9595 - mse: 0.9391 - val_loss: 0.9652 - val_mse: 0.9449\n",
      "Epoch 13/25\n",
      "2026/2045 [============================>.] - ETA: 0s - loss: 0.9588 - mse: 0.9384\n",
      "Epoch 13: val_loss did not improve from 0.96273\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9600 - mse: 0.9396 - val_loss: 0.9635 - val_mse: 0.9431\n",
      "Epoch 14/25\n",
      "2038/2045 [============================>.] - ETA: 0s - loss: 0.9591 - mse: 0.9387\n",
      "Epoch 14: val_loss did not improve from 0.96273\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9595 - mse: 0.9391 - val_loss: 0.9656 - val_mse: 0.9452\n",
      "Epoch 15/25\n",
      "2023/2045 [============================>.] - ETA: 0s - loss: 0.9594 - mse: 0.9390\n",
      "Epoch 15: val_loss did not improve from 0.96273\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9595 - mse: 0.9391 - val_loss: 0.9634 - val_mse: 0.9431\n",
      "Epoch 16/25\n",
      "2020/2045 [============================>.] - ETA: 0s - loss: 0.9587 - mse: 0.9383\n",
      "Epoch 16: val_loss did not improve from 0.96273\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9595 - mse: 0.9391 - val_loss: 0.9690 - val_mse: 0.9486\n",
      "Epoch 17/25\n",
      "2038/2045 [============================>.] - ETA: 0s - loss: 0.9598 - mse: 0.9394\n",
      "Epoch 17: val_loss did not improve from 0.96273\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9597 - mse: 0.9394 - val_loss: 0.9647 - val_mse: 0.9443\n",
      "Epoch 18/25\n",
      "2022/2045 [============================>.] - ETA: 0s - loss: 0.9595 - mse: 0.9392\n",
      "Epoch 18: val_loss did not improve from 0.96273\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9594 - mse: 0.9391 - val_loss: 0.9690 - val_mse: 0.9487\n",
      "Epoch 19/25\n",
      "2018/2045 [============================>.] - ETA: 0s - loss: 0.9601 - mse: 0.9398\n",
      "Epoch 19: val_loss did not improve from 0.96273\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9599 - mse: 0.9396 - val_loss: 0.9779 - val_mse: 0.9576\n",
      "Epoch 20/25\n",
      "2026/2045 [============================>.] - ETA: 0s - loss: 0.9601 - mse: 0.9398\n",
      "Epoch 20: val_loss did not improve from 0.96273\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9599 - mse: 0.9396 - val_loss: 0.9680 - val_mse: 0.9477\n",
      "Epoch 21/25\n",
      "2024/2045 [============================>.] - ETA: 0s - loss: 0.9586 - mse: 0.9383\n",
      "Epoch 21: val_loss did not improve from 0.96273\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9595 - mse: 0.9392 - val_loss: 0.9742 - val_mse: 0.9539\n",
      "Epoch 22/25\n",
      "2028/2045 [============================>.] - ETA: 0s - loss: 0.9599 - mse: 0.9397\n",
      "Epoch 22: val_loss did not improve from 0.96273\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9594 - mse: 0.9392 - val_loss: 0.9716 - val_mse: 0.9513\n",
      "Epoch 23/25\n",
      "2022/2045 [============================>.] - ETA: 0s - loss: 0.9588 - mse: 0.9386\n",
      "Epoch 23: val_loss did not improve from 0.96273\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9593 - mse: 0.9390 - val_loss: 0.9659 - val_mse: 0.9457\n",
      "Epoch 24/25\n",
      "2035/2045 [============================>.] - ETA: 0s - loss: 0.9589 - mse: 0.9386\n",
      "Epoch 24: val_loss did not improve from 0.96273\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9590 - mse: 0.9388 - val_loss: 0.9630 - val_mse: 0.9429\n",
      "Epoch 25/25\n",
      "2044/2045 [============================>.] - ETA: 0s - loss: 0.9596 - mse: 0.9394\n",
      "Epoch 25: val_loss did not improve from 0.96273\n",
      "2045/2045 [==============================] - 5s 2ms/step - loss: 0.9596 - mse: 0.9394 - val_loss: 0.9727 - val_mse: 0.9525\n",
      "Time elapsed to train: 121.96 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.694 3.499 1.878 3.898 2.734 1.984 1.445 1.135 0.699 0.330 0.146 0.054 0.000]\n",
      "<R> = [2.694 3.499 1.878 3.898 2.729 1.984 1.445 1.135 0.699 0.330 0.146 0.054 0.000]\n",
      "s_R = [0.029 0.010 0.002 0.072 0.078 0.002 0.002 0.001 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [5.4884996 4.379217  4.7197266 ... 3.6638107 3.4673586 5.705307 ]\n",
      "ri = [0.1566     0.11399937 0.09399986 ... 0.14400005 0.10769939 0.18040085]\n",
      "gr = [0.40940094 0.30720043 0.33909988 ... 0.39439964 0.3547001  0.54629993]\n",
      "gaia_g = [5.092581  4.0506763 4.3923035 ... 3.2777119 3.1194954 5.188401 ]\n",
      "bp_rp = [0.87466145 0.76038456 0.7539873  ... 0.8580713  0.80200386 1.0124731 ]\n",
      "mag_pred: [5.0032578 4.1151648 4.336132  ... 3.5237176 3.6559916 4.978505 ]\n",
      "mag_pred: [5.0032578 4.1151648 4.336132  ... 3.5237176 3.6559916 4.978505 ]\n",
      "Time elapsed to make plots: 18.42 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 183594 bad. Replacing with 14.76263.\n",
      "Band 1: 4 of 183594 bad. Replacing with 15.15992.\n",
      "Band 2: 4 of 183594 bad. Replacing with 14.19274.\n",
      "Band 3: 113 of 183594 bad. Replacing with 15.23890.\n",
      "Band 4: 216 of 183594 bad. Replacing with 14.74910.\n",
      "Band 5: 7858 of 183594 bad. Replacing with 14.61460.\n",
      "Band 6: 243 of 183594 bad. Replacing with 14.49620.\n",
      "Band 7: 71 of 183594 bad. Replacing with 14.44220.\n",
      "Band 8: 365 of 183594 bad. Replacing with 13.53800.\n",
      "Band 9: 383 of 183594 bad. Replacing with 13.15900.\n",
      "Band 10: 1558 of 183594 bad. Replacing with 13.07700.\n",
      "Band 11: 207 of 183594 bad. Replacing with 15.74246.\n",
      "Band 12: 227 of 183594 bad. Replacing with 16.41537.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 183591 of 183594 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [8.884254  6.638278  4.897757  ... 7.877363  5.6434326 6.6465235]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0203\n",
      "  1% : 0.114\n",
      "  10% : 0.239\n",
      "  50% : 0.647\n",
      "  90% : 3.1\n",
      "  99% : 35\n",
      "  100% : 7.73e+03\n",
      "<chi^2/d.o.f.> = 1.09\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 3062 stars (1.67%) based on chi^2/dof > 19.9\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20400 bad. Replacing with 14.76272.\n",
      "Band 1: 1 of 20400 bad. Replacing with 15.16133.\n",
      "Band 2: 1 of 20400 bad. Replacing with 14.19002.\n",
      "Band 3: 12 of 20400 bad. Replacing with 15.23615.\n",
      "Band 4: 30 of 20400 bad. Replacing with 14.75020.\n",
      "Band 5: 901 of 20400 bad. Replacing with 14.62020.\n",
      "Band 6: 32 of 20400 bad. Replacing with 14.49545.\n",
      "Band 7: 8 of 20400 bad. Replacing with 14.43955.\n",
      "Band 8: 44 of 20400 bad. Replacing with 13.53900.\n",
      "Band 9: 38 of 20400 bad. Replacing with 13.16000.\n",
      "Band 10: 158 of 20400 bad. Replacing with 13.08300.\n",
      "Band 11: 12 of 20400 bad. Replacing with 15.74840.\n",
      "Band 12: 15 of 20400 bad. Replacing with 16.41809.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20400 of 20400 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 4.0037775  6.2165713 10.831266  ... 10.802736   9.3673725  3.0490007]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0344\n",
      "  1% : 0.116\n",
      "  10% : 0.242\n",
      "  50% : 0.653\n",
      "  90% : 3.22\n",
      "  99% : 36.4\n",
      "  100% : 3.9e+03\n",
      "<chi^2/d.o.f.> = 1.09\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 57.54 s\n",
      "learning rate = 0.00024659695918671787\n",
      "setting learning rate to 0.00020189651799465538\n",
      "Iteration 9 of 20.\n",
      "Epoch 1/25\n",
      "2036/2038 [============================>.] - ETA: 0s - loss: 0.9153 - mse: 0.8952\n",
      "Epoch 1: val_loss improved from inf to 0.91888, saving model to checkpoints/ext_4h_l1n2_2hidden_it8.e001_vl0.919.h5\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9154 - mse: 0.8953 - val_loss: 0.9189 - val_mse: 0.8988\n",
      "Epoch 2/25\n",
      "2019/2038 [============================>.] - ETA: 0s - loss: 0.9149 - mse: 0.8949\n",
      "Epoch 2: val_loss improved from 0.91888 to 0.91746, saving model to checkpoints/ext_4h_l1n2_2hidden_it8.e002_vl0.917.h5\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9154 - mse: 0.8953 - val_loss: 0.9175 - val_mse: 0.8975\n",
      "Epoch 3/25\n",
      "2015/2038 [============================>.] - ETA: 0s - loss: 0.9152 - mse: 0.8952\n",
      "Epoch 3: val_loss improved from 0.91746 to 0.91542, saving model to checkpoints/ext_4h_l1n2_2hidden_it8.e003_vl0.915.h5\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9156 - mse: 0.8956 - val_loss: 0.9154 - val_mse: 0.8954\n",
      "Epoch 4/25\n",
      "2018/2038 [============================>.] - ETA: 0s - loss: 0.9151 - mse: 0.8951\n",
      "Epoch 4: val_loss did not improve from 0.91542\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9153 - mse: 0.8953 - val_loss: 0.9199 - val_mse: 0.8999\n",
      "Epoch 5/25\n",
      "2019/2038 [============================>.] - ETA: 0s - loss: 0.9151 - mse: 0.8951\n",
      "Epoch 5: val_loss did not improve from 0.91542\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9153 - mse: 0.8953 - val_loss: 0.9175 - val_mse: 0.8976\n",
      "Epoch 6/25\n",
      "2035/2038 [============================>.] - ETA: 0s - loss: 0.9153 - mse: 0.8954\n",
      "Epoch 6: val_loss did not improve from 0.91542\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9154 - mse: 0.8954 - val_loss: 0.9165 - val_mse: 0.8966\n",
      "Epoch 7/25\n",
      "2030/2038 [============================>.] - ETA: 0s - loss: 0.9159 - mse: 0.8960\n",
      "Epoch 7: val_loss improved from 0.91542 to 0.91534, saving model to checkpoints/ext_4h_l1n2_2hidden_it8.e007_vl0.915.h5\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9156 - mse: 0.8957 - val_loss: 0.9153 - val_mse: 0.8954\n",
      "Epoch 8/25\n",
      "2034/2038 [============================>.] - ETA: 0s - loss: 0.9154 - mse: 0.8955\n",
      "Epoch 8: val_loss did not improve from 0.91534\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9153 - mse: 0.8954 - val_loss: 0.9168 - val_mse: 0.8969\n",
      "Epoch 9/25\n",
      "2016/2038 [============================>.] - ETA: 0s - loss: 0.9152 - mse: 0.8953\n",
      "Epoch 9: val_loss did not improve from 0.91534\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9152 - mse: 0.8953 - val_loss: 0.9170 - val_mse: 0.8972\n",
      "Epoch 10/25\n",
      "2035/2038 [============================>.] - ETA: 0s - loss: 0.9151 - mse: 0.8953\n",
      "Epoch 10: val_loss improved from 0.91534 to 0.91517, saving model to checkpoints/ext_4h_l1n2_2hidden_it8.e010_vl0.915.h5\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9150 - mse: 0.8951 - val_loss: 0.9152 - val_mse: 0.8954\n",
      "Epoch 11/25\n",
      "2025/2038 [============================>.] - ETA: 0s - loss: 0.9151 - mse: 0.8953\n",
      "Epoch 11: val_loss did not improve from 0.91517\n",
      "2038/2038 [==============================] - 5s 3ms/step - loss: 0.9150 - mse: 0.8952 - val_loss: 0.9164 - val_mse: 0.8965\n",
      "Epoch 12/25\n",
      "2017/2038 [============================>.] - ETA: 0s - loss: 0.9157 - mse: 0.8959\n",
      "Epoch 12: val_loss improved from 0.91517 to 0.91288, saving model to checkpoints/ext_4h_l1n2_2hidden_it8.e012_vl0.913.h5\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9151 - mse: 0.8953 - val_loss: 0.9129 - val_mse: 0.8931\n",
      "Epoch 13/25\n",
      "2034/2038 [============================>.] - ETA: 0s - loss: 0.9152 - mse: 0.8954\n",
      "Epoch 13: val_loss did not improve from 0.91288\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9151 - mse: 0.8953 - val_loss: 0.9197 - val_mse: 0.9000\n",
      "Epoch 14/25\n",
      "2030/2038 [============================>.] - ETA: 0s - loss: 0.9146 - mse: 0.8949\n",
      "Epoch 14: val_loss did not improve from 0.91288\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9149 - mse: 0.8952 - val_loss: 0.9163 - val_mse: 0.8965\n",
      "Epoch 15/25\n",
      "2035/2038 [============================>.] - ETA: 0s - loss: 0.9148 - mse: 0.8950\n",
      "Epoch 15: val_loss did not improve from 0.91288\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9149 - mse: 0.8952 - val_loss: 0.9205 - val_mse: 0.9008\n",
      "Epoch 16/25\n",
      "2016/2038 [============================>.] - ETA: 0s - loss: 0.9147 - mse: 0.8950\n",
      "Epoch 16: val_loss did not improve from 0.91288\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9151 - mse: 0.8954 - val_loss: 0.9169 - val_mse: 0.8972\n",
      "Epoch 17/25\n",
      "2014/2038 [============================>.] - ETA: 0s - loss: 0.9151 - mse: 0.8954\n",
      "Epoch 17: val_loss did not improve from 0.91288\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9149 - mse: 0.8952 - val_loss: 0.9150 - val_mse: 0.8953\n",
      "Epoch 18/25\n",
      "2025/2038 [============================>.] - ETA: 0s - loss: 0.9145 - mse: 0.8949\n",
      "Epoch 18: val_loss did not improve from 0.91288\n",
      "2038/2038 [==============================] - 5s 3ms/step - loss: 0.9149 - mse: 0.8952 - val_loss: 0.9174 - val_mse: 0.8977\n",
      "Epoch 19/25\n",
      "2027/2038 [============================>.] - ETA: 0s - loss: 0.9152 - mse: 0.8955\n",
      "Epoch 19: val_loss did not improve from 0.91288\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9151 - mse: 0.8955 - val_loss: 0.9152 - val_mse: 0.8956\n",
      "Epoch 20/25\n",
      "2016/2038 [============================>.] - ETA: 0s - loss: 0.9151 - mse: 0.8955\n",
      "Epoch 20: val_loss did not improve from 0.91288\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9148 - mse: 0.8951 - val_loss: 0.9152 - val_mse: 0.8955\n",
      "Epoch 21/25\n",
      "2013/2038 [============================>.] - ETA: 0s - loss: 0.9141 - mse: 0.8945\n",
      "Epoch 21: val_loss did not improve from 0.91288\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9147 - mse: 0.8951 - val_loss: 0.9172 - val_mse: 0.8976\n",
      "Epoch 22/25\n",
      "2024/2038 [============================>.] - ETA: 0s - loss: 0.9148 - mse: 0.8952\n",
      "Epoch 22: val_loss did not improve from 0.91288\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9147 - mse: 0.8951 - val_loss: 0.9145 - val_mse: 0.8949\n",
      "Epoch 23/25\n",
      "2030/2038 [============================>.] - ETA: 0s - loss: 0.9145 - mse: 0.8949\n",
      "Epoch 23: val_loss did not improve from 0.91288\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9149 - mse: 0.8953 - val_loss: 0.9188 - val_mse: 0.8992\n",
      "Epoch 24/25\n",
      "2024/2038 [============================>.] - ETA: 0s - loss: 0.9150 - mse: 0.8954\n",
      "Epoch 24: val_loss did not improve from 0.91288\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9147 - mse: 0.8951 - val_loss: 0.9159 - val_mse: 0.8963\n",
      "Epoch 25/25\n",
      "2020/2038 [============================>.] - ETA: 0s - loss: 0.9140 - mse: 0.8945\n",
      "Epoch 25: val_loss did not improve from 0.91288\n",
      "2038/2038 [==============================] - 5s 2ms/step - loss: 0.9147 - mse: 0.8951 - val_loss: 0.9158 - val_mse: 0.8963\n",
      "Time elapsed to train: 121.50 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.660 3.460 1.857 3.845 2.699 1.963 1.431 1.123 0.689 0.327 0.146 0.055 0.000]\n",
      "<R> = [2.660 3.460 1.857 3.845 2.696 1.964 1.431 1.123 0.689 0.327 0.146 0.055 0.000]\n",
      "s_R = [0.034 0.006 0.002 0.058 0.069 0.003 0.001 0.001 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [5.4884996 4.379217  4.7197266 ... 3.6638107 3.4673586 5.705307 ]\n",
      "ri = [0.1566     0.11399937 0.09399986 ... 0.14400005 0.10769939 0.18040085]\n",
      "gr = [0.40940094 0.30720043 0.33909988 ... 0.39439964 0.3547001  0.54629993]\n",
      "gaia_g = [5.092581  4.0506763 4.3923035 ... 3.2777119 3.1194954 5.188401 ]\n",
      "bp_rp = [0.87466145 0.76038456 0.7539873  ... 0.8580713  0.80200386 1.0124731 ]\n",
      "mag_pred: [4.9459944 4.0823927 4.2984924 ... 3.4992995 3.6284604 4.964012 ]\n",
      "mag_pred: [4.9459944 4.0823927 4.2984924 ... 3.4992995 3.6284604 4.964012 ]\n",
      "Time elapsed to make plots: 16.35 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 183594 bad. Replacing with 14.76263.\n",
      "Band 1: 4 of 183594 bad. Replacing with 15.15992.\n",
      "Band 2: 4 of 183594 bad. Replacing with 14.19274.\n",
      "Band 3: 113 of 183594 bad. Replacing with 15.23890.\n",
      "Band 4: 216 of 183594 bad. Replacing with 14.74910.\n",
      "Band 5: 7858 of 183594 bad. Replacing with 14.61460.\n",
      "Band 6: 243 of 183594 bad. Replacing with 14.49620.\n",
      "Band 7: 71 of 183594 bad. Replacing with 14.44220.\n",
      "Band 8: 365 of 183594 bad. Replacing with 13.53800.\n",
      "Band 9: 383 of 183594 bad. Replacing with 13.15900.\n",
      "Band 10: 1558 of 183594 bad. Replacing with 13.07700.\n",
      "Band 11: 207 of 183594 bad. Replacing with 15.74246.\n",
      "Band 12: 227 of 183594 bad. Replacing with 16.41537.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 183591 of 183594 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [8.445663  7.378104  3.6805184 ... 9.656403  4.7020245 7.1363525]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0134\n",
      "  1% : 0.119\n",
      "  10% : 0.249\n",
      "  50% : 0.66\n",
      "  90% : 3.06\n",
      "  99% : 35.2\n",
      "  100% : 7.73e+03\n",
      "<chi^2/d.o.f.> = 1.09\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 3859 stars (2.1%) based on chi^2/dof > 15.8\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20400 bad. Replacing with 14.76272.\n",
      "Band 1: 1 of 20400 bad. Replacing with 15.16133.\n",
      "Band 2: 1 of 20400 bad. Replacing with 14.19002.\n",
      "Band 3: 12 of 20400 bad. Replacing with 15.23615.\n",
      "Band 4: 30 of 20400 bad. Replacing with 14.75020.\n",
      "Band 5: 901 of 20400 bad. Replacing with 14.62020.\n",
      "Band 6: 32 of 20400 bad. Replacing with 14.49545.\n",
      "Band 7: 8 of 20400 bad. Replacing with 14.43955.\n",
      "Band 8: 44 of 20400 bad. Replacing with 13.53900.\n",
      "Band 9: 38 of 20400 bad. Replacing with 13.16000.\n",
      "Band 10: 158 of 20400 bad. Replacing with 13.08300.\n",
      "Band 11: 12 of 20400 bad. Replacing with 15.74840.\n",
      "Band 12: 15 of 20400 bad. Replacing with 16.41809.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20400 of 20400 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 4.344151   6.2064567 12.286861  ... 11.043827   8.771233   3.3688343]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0489\n",
      "  1% : 0.12\n",
      "  10% : 0.255\n",
      "  50% : 0.668\n",
      "  90% : 3.19\n",
      "  99% : 36.8\n",
      "  100% : 3.9e+03\n",
      "<chi^2/d.o.f.> = 1.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 59.04 s\n",
      "learning rate = 0.00020189651695545763\n",
      "setting learning rate to 0.00016529888822158653\n",
      "Iteration 10 of 20.\n",
      "Epoch 1/25\n",
      "2003/2029 [============================>.] - ETA: 0s - loss: 0.8727 - mse: 0.8533\n",
      "Epoch 1: val_loss improved from inf to 0.87090, saving model to checkpoints/ext_4h_l1n2_2hidden_it9.e001_vl0.871.h5\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8733 - mse: 0.8538 - val_loss: 0.8709 - val_mse: 0.8514\n",
      "Epoch 2/25\n",
      "2014/2029 [============================>.] - ETA: 0s - loss: 0.8735 - mse: 0.8541\n",
      "Epoch 2: val_loss did not improve from 0.87090\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8736 - mse: 0.8542 - val_loss: 0.8727 - val_mse: 0.8531\n",
      "Epoch 3/25\n",
      "2027/2029 [============================>.] - ETA: 0s - loss: 0.8735 - mse: 0.8540\n",
      "Epoch 3: val_loss did not improve from 0.87090\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8734 - mse: 0.8540 - val_loss: 0.8711 - val_mse: 0.8517\n",
      "Epoch 4/25\n",
      "2011/2029 [============================>.] - ETA: 0s - loss: 0.8742 - mse: 0.8548\n",
      "Epoch 4: val_loss did not improve from 0.87090\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8736 - mse: 0.8542 - val_loss: 0.8779 - val_mse: 0.8585\n",
      "Epoch 5/25\n",
      "2004/2029 [============================>.] - ETA: 0s - loss: 0.8730 - mse: 0.8536\n",
      "Epoch 5: val_loss improved from 0.87090 to 0.87080, saving model to checkpoints/ext_4h_l1n2_2hidden_it9.e005_vl0.871.h5\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8735 - mse: 0.8541 - val_loss: 0.8708 - val_mse: 0.8513\n",
      "Epoch 6/25\n",
      "2008/2029 [============================>.] - ETA: 0s - loss: 0.8740 - mse: 0.8546\n",
      "Epoch 6: val_loss improved from 0.87080 to 0.87073, saving model to checkpoints/ext_4h_l1n2_2hidden_it9.e006_vl0.871.h5\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8735 - mse: 0.8541 - val_loss: 0.8707 - val_mse: 0.8514\n",
      "Epoch 7/25\n",
      "2028/2029 [============================>.] - ETA: 0s - loss: 0.8734 - mse: 0.8541\n",
      "Epoch 7: val_loss did not improve from 0.87073\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8733 - mse: 0.8540 - val_loss: 0.8710 - val_mse: 0.8516\n",
      "Epoch 8/25\n",
      "2004/2029 [============================>.] - ETA: 0s - loss: 0.8732 - mse: 0.8539\n",
      "Epoch 8: val_loss did not improve from 0.87073\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8733 - mse: 0.8540 - val_loss: 0.8713 - val_mse: 0.8520\n",
      "Epoch 9/25\n",
      "2019/2029 [============================>.] - ETA: 0s - loss: 0.8731 - mse: 0.8538\n",
      "Epoch 9: val_loss did not improve from 0.87073\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8733 - mse: 0.8540 - val_loss: 0.8723 - val_mse: 0.8530\n",
      "Epoch 10/25\n",
      "2022/2029 [============================>.] - ETA: 0s - loss: 0.8732 - mse: 0.8540\n",
      "Epoch 10: val_loss did not improve from 0.87073\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8733 - mse: 0.8540 - val_loss: 0.8719 - val_mse: 0.8526\n",
      "Epoch 11/25\n",
      "2011/2029 [============================>.] - ETA: 0s - loss: 0.8737 - mse: 0.8544\n",
      "Epoch 11: val_loss did not improve from 0.87073\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8736 - mse: 0.8543 - val_loss: 0.8744 - val_mse: 0.8551\n",
      "Epoch 12/25\n",
      "2008/2029 [============================>.] - ETA: 0s - loss: 0.8737 - mse: 0.8545\n",
      "Epoch 12: val_loss improved from 0.87073 to 0.87041, saving model to checkpoints/ext_4h_l1n2_2hidden_it9.e012_vl0.870.h5\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8733 - mse: 0.8541 - val_loss: 0.8704 - val_mse: 0.8512\n",
      "Epoch 13/25\n",
      "2006/2029 [============================>.] - ETA: 0s - loss: 0.8732 - mse: 0.8540\n",
      "Epoch 13: val_loss did not improve from 0.87041\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8730 - mse: 0.8538 - val_loss: 0.8735 - val_mse: 0.8544\n",
      "Epoch 14/25\n",
      "2007/2029 [============================>.] - ETA: 0s - loss: 0.8739 - mse: 0.8547\n",
      "Epoch 14: val_loss did not improve from 0.87041\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8733 - mse: 0.8541 - val_loss: 0.8708 - val_mse: 0.8516\n",
      "Epoch 15/25\n",
      "2010/2029 [============================>.] - ETA: 0s - loss: 0.8737 - mse: 0.8545\n",
      "Epoch 15: val_loss did not improve from 0.87041\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8732 - mse: 0.8540 - val_loss: 0.8710 - val_mse: 0.8518\n",
      "Epoch 16/25\n",
      "2018/2029 [============================>.] - ETA: 0s - loss: 0.8736 - mse: 0.8545\n",
      "Epoch 16: val_loss did not improve from 0.87041\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8734 - mse: 0.8542 - val_loss: 0.8715 - val_mse: 0.8524\n",
      "Epoch 17/25\n",
      "2019/2029 [============================>.] - ETA: 0s - loss: 0.8730 - mse: 0.8539\n",
      "Epoch 17: val_loss improved from 0.87041 to 0.87016, saving model to checkpoints/ext_4h_l1n2_2hidden_it9.e017_vl0.870.h5\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8732 - mse: 0.8541 - val_loss: 0.8702 - val_mse: 0.8511\n",
      "Epoch 18/25\n",
      "2020/2029 [============================>.] - ETA: 0s - loss: 0.8731 - mse: 0.8539\n",
      "Epoch 18: val_loss did not improve from 0.87016\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8732 - mse: 0.8541 - val_loss: 0.8704 - val_mse: 0.8513\n",
      "Epoch 19/25\n",
      "2004/2029 [============================>.] - ETA: 0s - loss: 0.8735 - mse: 0.8544\n",
      "Epoch 19: val_loss did not improve from 0.87016\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8735 - mse: 0.8543 - val_loss: 0.8714 - val_mse: 0.8524\n",
      "Epoch 20/25\n",
      "2022/2029 [============================>.] - ETA: 0s - loss: 0.8728 - mse: 0.8537\n",
      "Epoch 20: val_loss did not improve from 0.87016\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8730 - mse: 0.8540 - val_loss: 0.8756 - val_mse: 0.8565\n",
      "Epoch 21/25\n",
      "2021/2029 [============================>.] - ETA: 0s - loss: 0.8733 - mse: 0.8542\n",
      "Epoch 21: val_loss did not improve from 0.87016\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8731 - mse: 0.8540 - val_loss: 0.8707 - val_mse: 0.8516\n",
      "Epoch 22/25\n",
      "2017/2029 [============================>.] - ETA: 0s - loss: 0.8735 - mse: 0.8545\n",
      "Epoch 22: val_loss did not improve from 0.87016\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8732 - mse: 0.8541 - val_loss: 0.8739 - val_mse: 0.8549\n",
      "Epoch 23/25\n",
      "2019/2029 [============================>.] - ETA: 0s - loss: 0.8731 - mse: 0.8541\n",
      "Epoch 23: val_loss did not improve from 0.87016\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8730 - mse: 0.8540 - val_loss: 0.8709 - val_mse: 0.8519\n",
      "Epoch 24/25\n",
      "2021/2029 [============================>.] - ETA: 0s - loss: 0.8730 - mse: 0.8540\n",
      "Epoch 24: val_loss did not improve from 0.87016\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8730 - mse: 0.8540 - val_loss: 0.8719 - val_mse: 0.8529\n",
      "Epoch 25/25\n",
      "2017/2029 [============================>.] - ETA: 0s - loss: 0.8726 - mse: 0.8536\n",
      "Epoch 25: val_loss did not improve from 0.87016\n",
      "2029/2029 [==============================] - 5s 2ms/step - loss: 0.8730 - mse: 0.8540 - val_loss: 0.8720 - val_mse: 0.8530\n",
      "Time elapsed to train: 120.67 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.647 3.432 1.844 3.812 2.673 1.945 1.416 1.109 0.679 0.322 0.143 0.051 0.000]\n",
      "<R> = [2.647 3.432 1.844 3.812 2.671 1.945 1.416 1.109 0.679 0.322 0.143 0.051 0.000]\n",
      "s_R = [0.035 0.002 0.001 0.048 0.073 0.002 0.001 0.001 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [5.4884996 4.379217  4.7197266 ... 3.6638107 3.4673586 5.705307 ]\n",
      "ri = [0.1566     0.11399937 0.09399986 ... 0.14400005 0.10769939 0.18040085]\n",
      "gr = [0.40940094 0.30720043 0.33909988 ... 0.39439964 0.3547001  0.54629993]\n",
      "gaia_g = [5.092581  4.0506763 4.3923035 ... 3.2777119 3.1194954 5.188401 ]\n",
      "bp_rp = [0.87466145 0.76038456 0.7539873  ... 0.8580713  0.80200386 1.0124731 ]\n",
      "mag_pred: [4.9390006 4.0421643 4.2823095 ... 3.4299436 3.5736275 4.9263215]\n",
      "mag_pred: [4.9390006 4.0421643 4.2823095 ... 3.4299436 3.5736275 4.9263215]\n",
      "Time elapsed to make plots: 18.36 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 183594 bad. Replacing with 14.76263.\n",
      "Band 1: 4 of 183594 bad. Replacing with 15.15992.\n",
      "Band 2: 4 of 183594 bad. Replacing with 14.19274.\n",
      "Band 3: 113 of 183594 bad. Replacing with 15.23890.\n",
      "Band 4: 216 of 183594 bad. Replacing with 14.74910.\n",
      "Band 5: 7858 of 183594 bad. Replacing with 14.61460.\n",
      "Band 6: 243 of 183594 bad. Replacing with 14.49620.\n",
      "Band 7: 71 of 183594 bad. Replacing with 14.44220.\n",
      "Band 8: 365 of 183594 bad. Replacing with 13.53800.\n",
      "Band 9: 383 of 183594 bad. Replacing with 13.15900.\n",
      "Band 10: 1558 of 183594 bad. Replacing with 13.07700.\n",
      "Band 11: 207 of 183594 bad. Replacing with 15.74246.\n",
      "Band 12: 227 of 183594 bad. Replacing with 16.41537.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 183591 of 183594 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [8.773331  7.1486    3.8409376 ... 9.860515  5.6916018 7.6567707]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0142\n",
      "  1% : 0.112\n",
      "  10% : 0.241\n",
      "  50% : 0.654\n",
      "  90% : 3\n",
      "  99% : 35.2\n",
      "  100% : 7.74e+03\n",
      "<chi^2/d.o.f.> = 1.08\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 4792 stars (2.61%) based on chi^2/dof > 12.6\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20400 bad. Replacing with 14.76272.\n",
      "Band 1: 1 of 20400 bad. Replacing with 15.16133.\n",
      "Band 2: 1 of 20400 bad. Replacing with 14.19002.\n",
      "Band 3: 12 of 20400 bad. Replacing with 15.23615.\n",
      "Band 4: 30 of 20400 bad. Replacing with 14.75020.\n",
      "Band 5: 901 of 20400 bad. Replacing with 14.62020.\n",
      "Band 6: 32 of 20400 bad. Replacing with 14.49545.\n",
      "Band 7: 8 of 20400 bad. Replacing with 14.43955.\n",
      "Band 8: 44 of 20400 bad. Replacing with 13.53900.\n",
      "Band 9: 38 of 20400 bad. Replacing with 13.16000.\n",
      "Band 10: 158 of 20400 bad. Replacing with 13.08300.\n",
      "Band 11: 12 of 20400 bad. Replacing with 15.74840.\n",
      "Band 12: 15 of 20400 bad. Replacing with 16.41809.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20400 of 20400 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 4.694291   5.5704317 13.609353  ...  7.956999   7.53686    3.6693215]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0404\n",
      "  1% : 0.11\n",
      "  10% : 0.246\n",
      "  50% : 0.665\n",
      "  90% : 3.14\n",
      "  99% : 36.7\n",
      "  100% : 3.89e+03\n",
      "<chi^2/d.o.f.> = 1.09\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 57.94 s\n",
      "learning rate = 0.00016529888671357185\n",
      "setting learning rate to 0.0001353352832366127\n",
      "Iteration 11 of 20.\n",
      "Epoch 1/25\n",
      "2010/2018 [============================>.] - ETA: 0s - loss: 0.8159 - mse: 0.7969\n",
      "Epoch 1: val_loss improved from inf to 0.81397, saving model to checkpoints/ext_4h_l1n2_2hidden_it10.e001_vl0.814.h5\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8158 - mse: 0.7969 - val_loss: 0.8140 - val_mse: 0.7950\n",
      "Epoch 2/25\n",
      "1993/2018 [============================>.] - ETA: 0s - loss: 0.8156 - mse: 0.7967\n",
      "Epoch 2: val_loss did not improve from 0.81397\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8159 - mse: 0.7970 - val_loss: 0.8179 - val_mse: 0.7990\n",
      "Epoch 3/25\n",
      "2002/2018 [============================>.] - ETA: 0s - loss: 0.8157 - mse: 0.7968\n",
      "Epoch 3: val_loss did not improve from 0.81397\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8158 - mse: 0.7969 - val_loss: 0.8189 - val_mse: 0.8000\n",
      "Epoch 4/25\n",
      "2013/2018 [============================>.] - ETA: 0s - loss: 0.8155 - mse: 0.7967\n",
      "Epoch 4: val_loss did not improve from 0.81397\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8159 - mse: 0.7971 - val_loss: 0.8143 - val_mse: 0.7955\n",
      "Epoch 5/25\n",
      "2011/2018 [============================>.] - ETA: 0s - loss: 0.8158 - mse: 0.7969\n",
      "Epoch 5: val_loss did not improve from 0.81397\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8159 - mse: 0.7971 - val_loss: 0.8155 - val_mse: 0.7967\n",
      "Epoch 6/25\n",
      "2007/2018 [============================>.] - ETA: 0s - loss: 0.8160 - mse: 0.7972\n",
      "Epoch 6: val_loss did not improve from 0.81397\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8156 - mse: 0.7968 - val_loss: 0.8166 - val_mse: 0.7978\n",
      "Epoch 7/25\n",
      "2018/2018 [==============================] - ETA: 0s - loss: 0.8156 - mse: 0.7968\n",
      "Epoch 7: val_loss did not improve from 0.81397\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8156 - mse: 0.7968 - val_loss: 0.8142 - val_mse: 0.7955\n",
      "Epoch 8/25\n",
      "2000/2018 [============================>.] - ETA: 0s - loss: 0.8159 - mse: 0.7971\n",
      "Epoch 8: val_loss did not improve from 0.81397\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8158 - mse: 0.7971 - val_loss: 0.8160 - val_mse: 0.7973\n",
      "Epoch 9/25\n",
      "2005/2018 [============================>.] - ETA: 0s - loss: 0.8159 - mse: 0.7972\n",
      "Epoch 9: val_loss did not improve from 0.81397\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8157 - mse: 0.7970 - val_loss: 0.8169 - val_mse: 0.7982\n",
      "Epoch 10/25\n",
      "2017/2018 [============================>.] - ETA: 0s - loss: 0.8155 - mse: 0.7968\n",
      "Epoch 10: val_loss did not improve from 0.81397\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8155 - mse: 0.7968 - val_loss: 0.8158 - val_mse: 0.7971\n",
      "Epoch 11/25\n",
      "1995/2018 [============================>.] - ETA: 0s - loss: 0.8153 - mse: 0.7967\n",
      "Epoch 11: val_loss did not improve from 0.81397\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8157 - mse: 0.7970 - val_loss: 0.8159 - val_mse: 0.7973\n",
      "Epoch 12/25\n",
      "1994/2018 [============================>.] - ETA: 0s - loss: 0.8147 - mse: 0.7960\n",
      "Epoch 12: val_loss did not improve from 0.81397\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8156 - mse: 0.7969 - val_loss: 0.8154 - val_mse: 0.7967\n",
      "Epoch 13/25\n",
      "2004/2018 [============================>.] - ETA: 0s - loss: 0.8154 - mse: 0.7967\n",
      "Epoch 13: val_loss improved from 0.81397 to 0.81390, saving model to checkpoints/ext_4h_l1n2_2hidden_it10.e013_vl0.814.h5\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8157 - mse: 0.7971 - val_loss: 0.8139 - val_mse: 0.7953\n",
      "Epoch 14/25\n",
      "2016/2018 [============================>.] - ETA: 0s - loss: 0.8156 - mse: 0.7970\n",
      "Epoch 14: val_loss did not improve from 0.81390\n",
      "2018/2018 [==============================] - 5s 3ms/step - loss: 0.8157 - mse: 0.7970 - val_loss: 0.8183 - val_mse: 0.7997\n",
      "Epoch 15/25\n",
      "1998/2018 [============================>.] - ETA: 0s - loss: 0.8155 - mse: 0.7969\n",
      "Epoch 15: val_loss did not improve from 0.81390\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8154 - mse: 0.7968 - val_loss: 0.8173 - val_mse: 0.7987\n",
      "Epoch 16/25\n",
      "2003/2018 [============================>.] - ETA: 0s - loss: 0.8156 - mse: 0.7970\n",
      "Epoch 16: val_loss did not improve from 0.81390\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8154 - mse: 0.7968 - val_loss: 0.8149 - val_mse: 0.7963\n",
      "Epoch 17/25\n",
      "2012/2018 [============================>.] - ETA: 0s - loss: 0.8153 - mse: 0.7968\n",
      "Epoch 17: val_loss did not improve from 0.81390\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8155 - mse: 0.7969 - val_loss: 0.8143 - val_mse: 0.7957\n",
      "Epoch 18/25\n",
      "2004/2018 [============================>.] - ETA: 0s - loss: 0.8154 - mse: 0.7968\n",
      "Epoch 18: val_loss did not improve from 0.81390\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8154 - mse: 0.7968 - val_loss: 0.8151 - val_mse: 0.7965\n",
      "Epoch 19/25\n",
      "2011/2018 [============================>.] - ETA: 0s - loss: 0.8155 - mse: 0.7970\n",
      "Epoch 19: val_loss did not improve from 0.81390\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8154 - mse: 0.7969 - val_loss: 0.8188 - val_mse: 0.8003\n",
      "Epoch 20/25\n",
      "2000/2018 [============================>.] - ETA: 0s - loss: 0.8154 - mse: 0.7969\n",
      "Epoch 20: val_loss did not improve from 0.81390\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8153 - mse: 0.7968 - val_loss: 0.8141 - val_mse: 0.7956\n",
      "Epoch 21/25\n",
      "2013/2018 [============================>.] - ETA: 0s - loss: 0.8156 - mse: 0.7971\n",
      "Epoch 21: val_loss did not improve from 0.81390\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8154 - mse: 0.7970 - val_loss: 0.8188 - val_mse: 0.8003\n",
      "Epoch 22/25\n",
      "1997/2018 [============================>.] - ETA: 0s - loss: 0.8152 - mse: 0.7967\n",
      "Epoch 22: val_loss did not improve from 0.81390\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8153 - mse: 0.7968 - val_loss: 0.8140 - val_mse: 0.7955\n",
      "Epoch 23/25\n",
      "2002/2018 [============================>.] - ETA: 0s - loss: 0.8156 - mse: 0.7971\n",
      "Epoch 23: val_loss did not improve from 0.81390\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8152 - mse: 0.7968 - val_loss: 0.8144 - val_mse: 0.7959\n",
      "Epoch 24/25\n",
      "2004/2018 [============================>.] - ETA: 0s - loss: 0.8154 - mse: 0.7970\n",
      "Epoch 24: val_loss did not improve from 0.81390\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8151 - mse: 0.7967 - val_loss: 0.8152 - val_mse: 0.7968\n",
      "Epoch 25/25\n",
      "1999/2018 [============================>.] - ETA: 0s - loss: 0.8150 - mse: 0.7966\n",
      "Epoch 25: val_loss did not improve from 0.81390\n",
      "2018/2018 [==============================] - 5s 2ms/step - loss: 0.8153 - mse: 0.7969 - val_loss: 0.8150 - val_mse: 0.7966\n",
      "Time elapsed to train: 120.55 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.618 3.395 1.825 3.774 2.642 1.926 1.402 1.096 0.672 0.321 0.144 0.050 0.000]\n",
      "<R> = [2.618 3.394 1.825 3.774 2.641 1.926 1.402 1.096 0.672 0.321 0.144 0.050 0.000]\n",
      "s_R = [0.031 0.004 0.001 0.049 0.058 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [5.4884996 4.379217  4.7197266 ... 3.6638107 3.4673586 5.705307 ]\n",
      "ri = [0.1566     0.11399937 0.09399986 ... 0.14400005 0.10769939 0.18040085]\n",
      "gr = [0.40940094 0.30720043 0.33909988 ... 0.39439964 0.3547001  0.54629993]\n",
      "gaia_g = [5.092581  4.0506763 4.3923035 ... 3.2777119 3.1194954 5.188401 ]\n",
      "bp_rp = [0.87466145 0.76038456 0.7539873  ... 0.8580713  0.80200386 1.0124731 ]\n",
      "mag_pred: [4.9512315 4.0665183 4.306533  ... 3.4261546 3.59504   4.9389353]\n",
      "mag_pred: [4.9512315 4.0665183 4.306533  ... 3.4261546 3.59504   4.9389353]\n",
      "Time elapsed to make plots: 16.77 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 183594 bad. Replacing with 14.76263.\n",
      "Band 1: 4 of 183594 bad. Replacing with 15.15992.\n",
      "Band 2: 4 of 183594 bad. Replacing with 14.19274.\n",
      "Band 3: 113 of 183594 bad. Replacing with 15.23890.\n",
      "Band 4: 216 of 183594 bad. Replacing with 14.74910.\n",
      "Band 5: 7858 of 183594 bad. Replacing with 14.61460.\n",
      "Band 6: 243 of 183594 bad. Replacing with 14.49620.\n",
      "Band 7: 71 of 183594 bad. Replacing with 14.44220.\n",
      "Band 8: 365 of 183594 bad. Replacing with 13.53800.\n",
      "Band 9: 383 of 183594 bad. Replacing with 13.15900.\n",
      "Band 10: 1558 of 183594 bad. Replacing with 13.07700.\n",
      "Band 11: 207 of 183594 bad. Replacing with 15.74246.\n",
      "Band 12: 227 of 183594 bad. Replacing with 16.41537.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 183591 of 183594 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [8.657173  7.505     3.5788555 ... 9.889759  5.2084    7.256043 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0108\n",
      "  1% : 0.113\n",
      "  10% : 0.242\n",
      "  50% : 0.647\n",
      "  90% : 2.97\n",
      "  99% : 35.4\n",
      "  100% : 7.73e+03\n",
      "<chi^2/d.o.f.> = 1.07\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 5916 stars (3.22%) based on chi^2/dof > 10.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20400 bad. Replacing with 14.76272.\n",
      "Band 1: 1 of 20400 bad. Replacing with 15.16133.\n",
      "Band 2: 1 of 20400 bad. Replacing with 14.19002.\n",
      "Band 3: 12 of 20400 bad. Replacing with 15.23615.\n",
      "Band 4: 30 of 20400 bad. Replacing with 14.75020.\n",
      "Band 5: 901 of 20400 bad. Replacing with 14.62020.\n",
      "Band 6: 32 of 20400 bad. Replacing with 14.49545.\n",
      "Band 7: 8 of 20400 bad. Replacing with 14.43955.\n",
      "Band 8: 44 of 20400 bad. Replacing with 13.53900.\n",
      "Band 9: 38 of 20400 bad. Replacing with 13.16000.\n",
      "Band 10: 158 of 20400 bad. Replacing with 13.08300.\n",
      "Band 11: 12 of 20400 bad. Replacing with 15.74840.\n",
      "Band 12: 15 of 20400 bad. Replacing with 16.41809.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20400 of 20400 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 4.252117   5.528356  12.729679  ...  8.61502    7.4960275  3.5535603]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0465\n",
      "  1% : 0.114\n",
      "  10% : 0.248\n",
      "  50% : 0.656\n",
      "  90% : 3.1\n",
      "  99% : 36.9\n",
      "  100% : 3.87e+03\n",
      "<chi^2/d.o.f.> = 1.08\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 56.43 s\n",
      "learning rate = 0.00013533528544940054\n",
      "setting learning rate to 0.00011080315836233387\n",
      "Iteration 12 of 20.\n",
      "Epoch 1/25\n",
      "1997/2006 [============================>.] - ETA: 0s - loss: 0.7711 - mse: 0.7527\n",
      "Epoch 1: val_loss improved from inf to 0.76833, saving model to checkpoints/ext_4h_l1n2_2hidden_it11.e001_vl0.768.h5\n",
      "2006/2006 [==============================] - 5s 3ms/step - loss: 0.7712 - mse: 0.7529 - val_loss: 0.7683 - val_mse: 0.7500\n",
      "Epoch 2/25\n",
      "2006/2006 [==============================] - ETA: 0s - loss: 0.7713 - mse: 0.7530\n",
      "Epoch 2: val_loss did not improve from 0.76833\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7713 - mse: 0.7530 - val_loss: 0.7729 - val_mse: 0.7547\n",
      "Epoch 3/25\n",
      "1982/2006 [============================>.] - ETA: 0s - loss: 0.7711 - mse: 0.7528\n",
      "Epoch 3: val_loss did not improve from 0.76833\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7712 - mse: 0.7530 - val_loss: 0.7712 - val_mse: 0.7529\n",
      "Epoch 4/25\n",
      "1986/2006 [============================>.] - ETA: 0s - loss: 0.7712 - mse: 0.7529\n",
      "Epoch 4: val_loss did not improve from 0.76833\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7713 - mse: 0.7530 - val_loss: 0.7700 - val_mse: 0.7517\n",
      "Epoch 5/25\n",
      "1993/2006 [============================>.] - ETA: 0s - loss: 0.7712 - mse: 0.7530\n",
      "Epoch 5: val_loss did not improve from 0.76833\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7711 - mse: 0.7529 - val_loss: 0.7693 - val_mse: 0.7511\n",
      "Epoch 6/25\n",
      "1990/2006 [============================>.] - ETA: 0s - loss: 0.7714 - mse: 0.7531\n",
      "Epoch 6: val_loss did not improve from 0.76833\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7711 - mse: 0.7528 - val_loss: 0.7698 - val_mse: 0.7516\n",
      "Epoch 7/25\n",
      "1998/2006 [============================>.] - ETA: 0s - loss: 0.7712 - mse: 0.7530\n",
      "Epoch 7: val_loss did not improve from 0.76833\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7712 - mse: 0.7530 - val_loss: 0.7693 - val_mse: 0.7511\n",
      "Epoch 8/25\n",
      "1983/2006 [============================>.] - ETA: 0s - loss: 0.7712 - mse: 0.7530\n",
      "Epoch 8: val_loss did not improve from 0.76833\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7710 - mse: 0.7528 - val_loss: 0.7702 - val_mse: 0.7521\n",
      "Epoch 9/25\n",
      "1980/2006 [============================>.] - ETA: 0s - loss: 0.7710 - mse: 0.7528\n",
      "Epoch 9: val_loss did not improve from 0.76833\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7712 - mse: 0.7530 - val_loss: 0.7700 - val_mse: 0.7519\n",
      "Epoch 10/25\n",
      "1986/2006 [============================>.] - ETA: 0s - loss: 0.7715 - mse: 0.7533\n",
      "Epoch 10: val_loss did not improve from 0.76833\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7710 - mse: 0.7528 - val_loss: 0.7688 - val_mse: 0.7506\n",
      "Epoch 11/25\n",
      "1999/2006 [============================>.] - ETA: 0s - loss: 0.7707 - mse: 0.7526\n",
      "Epoch 11: val_loss did not improve from 0.76833\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7710 - mse: 0.7529 - val_loss: 0.7687 - val_mse: 0.7505\n",
      "Epoch 12/25\n",
      "1982/2006 [============================>.] - ETA: 0s - loss: 0.7707 - mse: 0.7526\n",
      "Epoch 12: val_loss did not improve from 0.76833\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7709 - mse: 0.7528 - val_loss: 0.7702 - val_mse: 0.7521\n",
      "Epoch 13/25\n",
      "2000/2006 [============================>.] - ETA: 0s - loss: 0.7713 - mse: 0.7531\n",
      "Epoch 13: val_loss did not improve from 0.76833\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7711 - mse: 0.7529 - val_loss: 0.7696 - val_mse: 0.7515\n",
      "Epoch 14/25\n",
      "1985/2006 [============================>.] - ETA: 0s - loss: 0.7708 - mse: 0.7527\n",
      "Epoch 14: val_loss did not improve from 0.76833\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7710 - mse: 0.7530 - val_loss: 0.7720 - val_mse: 0.7539\n",
      "Epoch 15/25\n",
      "1980/2006 [============================>.] - ETA: 0s - loss: 0.7715 - mse: 0.7534\n",
      "Epoch 15: val_loss improved from 0.76833 to 0.76762, saving model to checkpoints/ext_4h_l1n2_2hidden_it11.e015_vl0.768.h5\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7711 - mse: 0.7530 - val_loss: 0.7676 - val_mse: 0.7495\n",
      "Epoch 16/25\n",
      "1988/2006 [============================>.] - ETA: 0s - loss: 0.7708 - mse: 0.7527\n",
      "Epoch 16: val_loss did not improve from 0.76762\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7710 - mse: 0.7529 - val_loss: 0.7700 - val_mse: 0.7519\n",
      "Epoch 17/25\n",
      "1996/2006 [============================>.] - ETA: 0s - loss: 0.7708 - mse: 0.7528\n",
      "Epoch 17: val_loss did not improve from 0.76762\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7710 - mse: 0.7530 - val_loss: 0.7681 - val_mse: 0.7500\n",
      "Epoch 18/25\n",
      "1986/2006 [============================>.] - ETA: 0s - loss: 0.7708 - mse: 0.7527\n",
      "Epoch 18: val_loss did not improve from 0.76762\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7711 - mse: 0.7530 - val_loss: 0.7694 - val_mse: 0.7514\n",
      "Epoch 19/25\n",
      "1990/2006 [============================>.] - ETA: 0s - loss: 0.7706 - mse: 0.7526\n",
      "Epoch 19: val_loss did not improve from 0.76762\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7709 - mse: 0.7529 - val_loss: 0.7750 - val_mse: 0.7570\n",
      "Epoch 20/25\n",
      "1998/2006 [============================>.] - ETA: 0s - loss: 0.7708 - mse: 0.7528\n",
      "Epoch 20: val_loss did not improve from 0.76762\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7709 - mse: 0.7529 - val_loss: 0.7697 - val_mse: 0.7517\n",
      "Epoch 21/25\n",
      "1983/2006 [============================>.] - ETA: 0s - loss: 0.7710 - mse: 0.7530\n",
      "Epoch 21: val_loss did not improve from 0.76762\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7709 - mse: 0.7529 - val_loss: 0.7693 - val_mse: 0.7513\n",
      "Epoch 22/25\n",
      "1987/2006 [============================>.] - ETA: 0s - loss: 0.7716 - mse: 0.7536\n",
      "Epoch 22: val_loss did not improve from 0.76762\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7709 - mse: 0.7530 - val_loss: 0.7693 - val_mse: 0.7514\n",
      "Epoch 23/25\n",
      "1994/2006 [============================>.] - ETA: 0s - loss: 0.7705 - mse: 0.7526\n",
      "Epoch 23: val_loss did not improve from 0.76762\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7708 - mse: 0.7528 - val_loss: 0.7701 - val_mse: 0.7521\n",
      "Epoch 24/25\n",
      "1994/2006 [============================>.] - ETA: 0s - loss: 0.7704 - mse: 0.7524\n",
      "Epoch 24: val_loss did not improve from 0.76762\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7710 - mse: 0.7531 - val_loss: 0.7696 - val_mse: 0.7516\n",
      "Epoch 25/25\n",
      "1996/2006 [============================>.] - ETA: 0s - loss: 0.7707 - mse: 0.7528\n",
      "Epoch 25: val_loss did not improve from 0.76762\n",
      "2006/2006 [==============================] - 5s 2ms/step - loss: 0.7709 - mse: 0.7530 - val_loss: 0.7689 - val_mse: 0.7509\n",
      "Time elapsed to train: 118.08 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.578 3.343 1.796 3.720 2.607 1.899 1.380 1.078 0.661 0.319 0.145 0.050 0.000]\n",
      "<R> = [2.578 3.343 1.796 3.720 2.607 1.899 1.380 1.078 0.661 0.319 0.145 0.050 0.000]\n",
      "s_R = [0.036 0.004 0.000 0.045 0.056 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [5.4884996 4.379217  4.7197266 ... 3.6638107 3.4673586 5.705307 ]\n",
      "ri = [0.1566     0.11399937 0.09399986 ... 0.14400005 0.10769939 0.18040085]\n",
      "gr = [0.40940094 0.30720043 0.33909988 ... 0.39439964 0.3547001  0.54629993]\n",
      "gaia_g = [5.092581  4.0506763 4.3923035 ... 3.2777119 3.1194954 5.188401 ]\n",
      "bp_rp = [0.87466145 0.76038456 0.7539873  ... 0.8580713  0.80200386 1.0124731 ]\n",
      "mag_pred: [4.9555664 4.080457  4.319954  ... 3.4448304 3.6099591 4.9460287]\n",
      "mag_pred: [4.9555664 4.080457  4.319954  ... 3.4448304 3.6099591 4.9460287]\n",
      "Time elapsed to make plots: 18.90 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 183594 bad. Replacing with 14.76263.\n",
      "Band 1: 4 of 183594 bad. Replacing with 15.15992.\n",
      "Band 2: 4 of 183594 bad. Replacing with 14.19274.\n",
      "Band 3: 113 of 183594 bad. Replacing with 15.23890.\n",
      "Band 4: 216 of 183594 bad. Replacing with 14.74910.\n",
      "Band 5: 7858 of 183594 bad. Replacing with 14.61460.\n",
      "Band 6: 243 of 183594 bad. Replacing with 14.49620.\n",
      "Band 7: 71 of 183594 bad. Replacing with 14.44220.\n",
      "Band 8: 365 of 183594 bad. Replacing with 13.53800.\n",
      "Band 9: 383 of 183594 bad. Replacing with 13.15900.\n",
      "Band 10: 1558 of 183594 bad. Replacing with 13.07700.\n",
      "Band 11: 207 of 183594 bad. Replacing with 15.74246.\n",
      "Band 12: 227 of 183594 bad. Replacing with 16.41537.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 183591 of 183594 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [8.645161  7.7067146 3.8759599 ... 9.444889  5.68348   7.350169 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0152\n",
      "  1% : 0.11\n",
      "  10% : 0.236\n",
      "  50% : 0.639\n",
      "  90% : 2.95\n",
      "  99% : 35.7\n",
      "  100% : 7.73e+03\n",
      "<chi^2/d.o.f.> = 1.06\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 7370 stars (4.01%) based on chi^2/dof > 7.9\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20400 bad. Replacing with 14.76272.\n",
      "Band 1: 1 of 20400 bad. Replacing with 15.16133.\n",
      "Band 2: 1 of 20400 bad. Replacing with 14.19002.\n",
      "Band 3: 12 of 20400 bad. Replacing with 15.23615.\n",
      "Band 4: 30 of 20400 bad. Replacing with 14.75020.\n",
      "Band 5: 901 of 20400 bad. Replacing with 14.62020.\n",
      "Band 6: 32 of 20400 bad. Replacing with 14.49545.\n",
      "Band 7: 8 of 20400 bad. Replacing with 14.43955.\n",
      "Band 8: 44 of 20400 bad. Replacing with 13.53900.\n",
      "Band 9: 38 of 20400 bad. Replacing with 13.16000.\n",
      "Band 10: 158 of 20400 bad. Replacing with 13.08300.\n",
      "Band 11: 12 of 20400 bad. Replacing with 15.74840.\n",
      "Band 12: 15 of 20400 bad. Replacing with 16.41809.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20400 of 20400 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 4.154825   5.4153576 12.412704  ...  8.171002   7.7825937  3.5252695]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0316\n",
      "  1% : 0.108\n",
      "  10% : 0.242\n",
      "  50% : 0.648\n",
      "  90% : 3.07\n",
      "  99% : 37\n",
      "  100% : 3.88e+03\n",
      "<chi^2/d.o.f.> = 1.07\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 58.51 s\n",
      "learning rate = 0.00011080315744038671\n",
      "setting learning rate to 9.071795328941248e-05\n",
      "Iteration 13 of 20.\n",
      "Epoch 1/25\n",
      "1969/1989 [============================>.] - ETA: 0s - loss: 0.7239 - mse: 0.7060\n",
      "Epoch 1: val_loss improved from inf to 0.72667, saving model to checkpoints/ext_4h_l1n2_2hidden_it12.e001_vl0.727.h5\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7239 - mse: 0.7060 - val_loss: 0.7267 - val_mse: 0.7088\n",
      "Epoch 2/25\n",
      "1966/1989 [============================>.] - ETA: 0s - loss: 0.7238 - mse: 0.7059\n",
      "Epoch 2: val_loss improved from 0.72667 to 0.72359, saving model to checkpoints/ext_4h_l1n2_2hidden_it12.e002_vl0.724.h5\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7240 - mse: 0.7061 - val_loss: 0.7236 - val_mse: 0.7057\n",
      "Epoch 3/25\n",
      "1975/1989 [============================>.] - ETA: 0s - loss: 0.7238 - mse: 0.7060\n",
      "Epoch 3: val_loss did not improve from 0.72359\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7239 - mse: 0.7060 - val_loss: 0.7249 - val_mse: 0.7070\n",
      "Epoch 4/25\n",
      "1969/1989 [============================>.] - ETA: 0s - loss: 0.7240 - mse: 0.7062\n",
      "Epoch 4: val_loss improved from 0.72359 to 0.72278, saving model to checkpoints/ext_4h_l1n2_2hidden_it12.e004_vl0.723.h5\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7239 - mse: 0.7061 - val_loss: 0.7228 - val_mse: 0.7050\n",
      "Epoch 5/25\n",
      "1977/1989 [============================>.] - ETA: 0s - loss: 0.7239 - mse: 0.7061\n",
      "Epoch 5: val_loss did not improve from 0.72278\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7237 - mse: 0.7059 - val_loss: 0.7239 - val_mse: 0.7061\n",
      "Epoch 6/25\n",
      "1973/1989 [============================>.] - ETA: 0s - loss: 0.7238 - mse: 0.7060\n",
      "Epoch 6: val_loss did not improve from 0.72278\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7238 - mse: 0.7060 - val_loss: 0.7234 - val_mse: 0.7056\n",
      "Epoch 7/25\n",
      "1972/1989 [============================>.] - ETA: 0s - loss: 0.7236 - mse: 0.7058\n",
      "Epoch 7: val_loss did not improve from 0.72278\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7237 - mse: 0.7059 - val_loss: 0.7273 - val_mse: 0.7096\n",
      "Epoch 8/25\n",
      "1988/1989 [============================>.] - ETA: 0s - loss: 0.7238 - mse: 0.7060\n",
      "Epoch 8: val_loss did not improve from 0.72278\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7238 - mse: 0.7060 - val_loss: 0.7233 - val_mse: 0.7055\n",
      "Epoch 9/25\n",
      "1985/1989 [============================>.] - ETA: 0s - loss: 0.7236 - mse: 0.7058\n",
      "Epoch 9: val_loss did not improve from 0.72278\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7237 - mse: 0.7060 - val_loss: 0.7233 - val_mse: 0.7056\n",
      "Epoch 10/25\n",
      "1972/1989 [============================>.] - ETA: 0s - loss: 0.7237 - mse: 0.7060\n",
      "Epoch 10: val_loss did not improve from 0.72278\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7237 - mse: 0.7059 - val_loss: 0.7233 - val_mse: 0.7056\n",
      "Epoch 11/25\n",
      "1983/1989 [============================>.] - ETA: 0s - loss: 0.7238 - mse: 0.7061\n",
      "Epoch 11: val_loss did not improve from 0.72278\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7238 - mse: 0.7061 - val_loss: 0.7236 - val_mse: 0.7059\n",
      "Epoch 12/25\n",
      "1975/1989 [============================>.] - ETA: 0s - loss: 0.7236 - mse: 0.7059\n",
      "Epoch 12: val_loss did not improve from 0.72278\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7236 - mse: 0.7059 - val_loss: 0.7231 - val_mse: 0.7053\n",
      "Epoch 13/25\n",
      "1969/1989 [============================>.] - ETA: 0s - loss: 0.7234 - mse: 0.7057\n",
      "Epoch 13: val_loss improved from 0.72278 to 0.72258, saving model to checkpoints/ext_4h_l1n2_2hidden_it12.e013_vl0.723.h5\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7237 - mse: 0.7060 - val_loss: 0.7226 - val_mse: 0.7049\n",
      "Epoch 14/25\n",
      "1979/1989 [============================>.] - ETA: 0s - loss: 0.7235 - mse: 0.7058\n",
      "Epoch 14: val_loss did not improve from 0.72258\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7236 - mse: 0.7059 - val_loss: 0.7240 - val_mse: 0.7063\n",
      "Epoch 15/25\n",
      "1966/1989 [============================>.] - ETA: 0s - loss: 0.7236 - mse: 0.7060\n",
      "Epoch 15: val_loss did not improve from 0.72258\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7236 - mse: 0.7059 - val_loss: 0.7231 - val_mse: 0.7055\n",
      "Epoch 16/25\n",
      "1970/1989 [============================>.] - ETA: 0s - loss: 0.7239 - mse: 0.7062\n",
      "Epoch 16: val_loss did not improve from 0.72258\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7236 - mse: 0.7059 - val_loss: 0.7254 - val_mse: 0.7078\n",
      "Epoch 17/25\n",
      "1977/1989 [============================>.] - ETA: 0s - loss: 0.7237 - mse: 0.7061\n",
      "Epoch 17: val_loss did not improve from 0.72258\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7236 - mse: 0.7060 - val_loss: 0.7241 - val_mse: 0.7065\n",
      "Epoch 18/25\n",
      "1969/1989 [============================>.] - ETA: 0s - loss: 0.7239 - mse: 0.7063\n",
      "Epoch 18: val_loss did not improve from 0.72258\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7236 - mse: 0.7060 - val_loss: 0.7226 - val_mse: 0.7050\n",
      "Epoch 19/25\n",
      "1971/1989 [============================>.] - ETA: 0s - loss: 0.7236 - mse: 0.7060\n",
      "Epoch 19: val_loss did not improve from 0.72258\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7236 - mse: 0.7060 - val_loss: 0.7230 - val_mse: 0.7053\n",
      "Epoch 20/25\n",
      "1982/1989 [============================>.] - ETA: 0s - loss: 0.7237 - mse: 0.7061\n",
      "Epoch 20: val_loss did not improve from 0.72258\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7236 - mse: 0.7060 - val_loss: 0.7230 - val_mse: 0.7054\n",
      "Epoch 21/25\n",
      "1982/1989 [============================>.] - ETA: 0s - loss: 0.7237 - mse: 0.7061\n",
      "Epoch 21: val_loss did not improve from 0.72258\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7235 - mse: 0.7059 - val_loss: 0.7239 - val_mse: 0.7064\n",
      "Epoch 22/25\n",
      "1977/1989 [============================>.] - ETA: 0s - loss: 0.7231 - mse: 0.7056\n",
      "Epoch 22: val_loss did not improve from 0.72258\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7234 - mse: 0.7059 - val_loss: 0.7235 - val_mse: 0.7059\n",
      "Epoch 23/25\n",
      "1964/1989 [============================>.] - ETA: 0s - loss: 0.7236 - mse: 0.7060\n",
      "Epoch 23: val_loss did not improve from 0.72258\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7234 - mse: 0.7059 - val_loss: 0.7267 - val_mse: 0.7091\n",
      "Epoch 24/25\n",
      "1979/1989 [============================>.] - ETA: 0s - loss: 0.7240 - mse: 0.7065\n",
      "Epoch 24: val_loss did not improve from 0.72258\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7236 - mse: 0.7061 - val_loss: 0.7227 - val_mse: 0.7052\n",
      "Epoch 25/25\n",
      "1988/1989 [============================>.] - ETA: 0s - loss: 0.7234 - mse: 0.7059\n",
      "Epoch 25: val_loss did not improve from 0.72258\n",
      "1989/1989 [==============================] - 5s 2ms/step - loss: 0.7235 - mse: 0.7060 - val_loss: 0.7253 - val_mse: 0.7078\n",
      "Time elapsed to train: 118.38 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.536 3.287 1.768 3.654 2.561 1.868 1.356 1.055 0.647 0.313 0.145 0.052 0.000]\n",
      "<R> = [2.536 3.287 1.768 3.654 2.560 1.868 1.356 1.055 0.647 0.313 0.145 0.052 0.000]\n",
      "s_R = [0.040 0.001 0.000 0.042 0.051 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [5.4884996 4.379217  4.7197266 ... 3.6638107 3.4673586 5.705307 ]\n",
      "ri = [0.1566     0.11399937 0.09399986 ... 0.14400005 0.10769939 0.18040085]\n",
      "gr = [0.40940094 0.30720043 0.33909988 ... 0.39439964 0.3547001  0.54629993]\n",
      "gaia_g = [5.092581  4.0506763 4.3923035 ... 3.2777119 3.1194954 5.188401 ]\n",
      "bp_rp = [0.87466145 0.76038456 0.7539873  ... 0.8580713  0.80200386 1.0124731 ]\n",
      "mag_pred: [4.933486  4.048277  4.3080206 ... 3.401325  3.568663  4.9208226]\n",
      "mag_pred: [4.933486  4.048277  4.3080206 ... 3.401325  3.568663  4.9208226]\n",
      "Time elapsed to make plots: 16.50 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 183594 bad. Replacing with 14.76263.\n",
      "Band 1: 4 of 183594 bad. Replacing with 15.15992.\n",
      "Band 2: 4 of 183594 bad. Replacing with 14.19274.\n",
      "Band 3: 113 of 183594 bad. Replacing with 15.23890.\n",
      "Band 4: 216 of 183594 bad. Replacing with 14.74910.\n",
      "Band 5: 7858 of 183594 bad. Replacing with 14.61460.\n",
      "Band 6: 243 of 183594 bad. Replacing with 14.49620.\n",
      "Band 7: 71 of 183594 bad. Replacing with 14.44220.\n",
      "Band 8: 365 of 183594 bad. Replacing with 13.53800.\n",
      "Band 9: 383 of 183594 bad. Replacing with 13.15900.\n",
      "Band 10: 1558 of 183594 bad. Replacing with 13.07700.\n",
      "Band 11: 207 of 183594 bad. Replacing with 15.74246.\n",
      "Band 12: 227 of 183594 bad. Replacing with 16.41537.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 183591 of 183594 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [8.675962  7.557306  3.849493  ... 9.339577  5.5806456 6.6070995]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.019\n",
      "  1% : 0.111\n",
      "  10% : 0.236\n",
      "  50% : 0.635\n",
      "  90% : 2.9\n",
      "  99% : 35.6\n",
      "  100% : 7.75e+03\n",
      "<chi^2/d.o.f.> = 1.05\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 8943 stars (4.87%) based on chi^2/dof > 6.3\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20400 bad. Replacing with 14.76272.\n",
      "Band 1: 1 of 20400 bad. Replacing with 15.16133.\n",
      "Band 2: 1 of 20400 bad. Replacing with 14.19002.\n",
      "Band 3: 12 of 20400 bad. Replacing with 15.23615.\n",
      "Band 4: 30 of 20400 bad. Replacing with 14.75020.\n",
      "Band 5: 901 of 20400 bad. Replacing with 14.62020.\n",
      "Band 6: 32 of 20400 bad. Replacing with 14.49545.\n",
      "Band 7: 8 of 20400 bad. Replacing with 14.43955.\n",
      "Band 8: 44 of 20400 bad. Replacing with 13.53900.\n",
      "Band 9: 38 of 20400 bad. Replacing with 13.16000.\n",
      "Band 10: 158 of 20400 bad. Replacing with 13.08300.\n",
      "Band 11: 12 of 20400 bad. Replacing with 15.74840.\n",
      "Band 12: 15 of 20400 bad. Replacing with 16.41809.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20400 of 20400 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 3.850985   5.2102594 12.851344  ...  6.9039173  7.388569   3.596709 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0356\n",
      "  1% : 0.11\n",
      "  10% : 0.243\n",
      "  50% : 0.646\n",
      "  90% : 3.03\n",
      "  99% : 37.1\n",
      "  100% : 3.9e+03\n",
      "<chi^2/d.o.f.> = 1.06\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 56.58 s\n",
      "learning rate = 9.071795648196712e-05\n",
      "setting learning rate to 7.427357821433387e-05\n",
      "Iteration 14 of 20.\n",
      "Epoch 1/25\n",
      "1948/1971 [============================>.] - ETA: 0s - loss: 0.6803 - mse: 0.6628\n",
      "Epoch 1: val_loss improved from inf to 0.68235, saving model to checkpoints/ext_4h_l1n2_2hidden_it13.e001_vl0.682.h5\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6804 - mse: 0.6629 - val_loss: 0.6823 - val_mse: 0.6649\n",
      "Epoch 2/25\n",
      "1964/1971 [============================>.] - ETA: 0s - loss: 0.6801 - mse: 0.6627\n",
      "Epoch 2: val_loss did not improve from 0.68235\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6805 - mse: 0.6630 - val_loss: 0.6842 - val_mse: 0.6667\n",
      "Epoch 3/25\n",
      "1957/1971 [============================>.] - ETA: 0s - loss: 0.6802 - mse: 0.6628\n",
      "Epoch 3: val_loss improved from 0.68235 to 0.68218, saving model to checkpoints/ext_4h_l1n2_2hidden_it13.e003_vl0.682.h5\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6805 - mse: 0.6631 - val_loss: 0.6822 - val_mse: 0.6648\n",
      "Epoch 4/25\n",
      "1967/1971 [============================>.] - ETA: 0s - loss: 0.6803 - mse: 0.6629\n",
      "Epoch 4: val_loss improved from 0.68218 to 0.68176, saving model to checkpoints/ext_4h_l1n2_2hidden_it13.e004_vl0.682.h5\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6803 - mse: 0.6629 - val_loss: 0.6818 - val_mse: 0.6644\n",
      "Epoch 5/25\n",
      "1946/1971 [============================>.] - ETA: 0s - loss: 0.6798 - mse: 0.6624\n",
      "Epoch 5: val_loss did not improve from 0.68176\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6804 - mse: 0.6630 - val_loss: 0.6823 - val_mse: 0.6649\n",
      "Epoch 6/25\n",
      "1965/1971 [============================>.] - ETA: 0s - loss: 0.6804 - mse: 0.6630\n",
      "Epoch 6: val_loss did not improve from 0.68176\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6804 - mse: 0.6630 - val_loss: 0.6825 - val_mse: 0.6651\n",
      "Epoch 7/25\n",
      "1956/1971 [============================>.] - ETA: 0s - loss: 0.6806 - mse: 0.6633\n",
      "Epoch 7: val_loss did not improve from 0.68176\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6805 - mse: 0.6631 - val_loss: 0.6833 - val_mse: 0.6660\n",
      "Epoch 8/25\n",
      "1949/1971 [============================>.] - ETA: 0s - loss: 0.6804 - mse: 0.6630\n",
      "Epoch 8: val_loss improved from 0.68176 to 0.68163, saving model to checkpoints/ext_4h_l1n2_2hidden_it13.e008_vl0.682.h5\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6804 - mse: 0.6630 - val_loss: 0.6816 - val_mse: 0.6643\n",
      "Epoch 9/25\n",
      "1946/1971 [============================>.] - ETA: 0s - loss: 0.6806 - mse: 0.6633\n",
      "Epoch 9: val_loss did not improve from 0.68163\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6803 - mse: 0.6630 - val_loss: 0.6832 - val_mse: 0.6659\n",
      "Epoch 10/25\n",
      "1947/1971 [============================>.] - ETA: 0s - loss: 0.6806 - mse: 0.6633\n",
      "Epoch 10: val_loss did not improve from 0.68163\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6803 - mse: 0.6630 - val_loss: 0.6818 - val_mse: 0.6645\n",
      "Epoch 11/25\n",
      "1951/1971 [============================>.] - ETA: 0s - loss: 0.6800 - mse: 0.6627\n",
      "Epoch 11: val_loss did not improve from 0.68163\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6802 - mse: 0.6629 - val_loss: 0.6824 - val_mse: 0.6652\n",
      "Epoch 12/25\n",
      "1964/1971 [============================>.] - ETA: 0s - loss: 0.6801 - mse: 0.6628\n",
      "Epoch 12: val_loss did not improve from 0.68163\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6802 - mse: 0.6629 - val_loss: 0.6824 - val_mse: 0.6651\n",
      "Epoch 13/25\n",
      "1969/1971 [============================>.] - ETA: 0s - loss: 0.6803 - mse: 0.6631\n",
      "Epoch 13: val_loss did not improve from 0.68163\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6803 - mse: 0.6631 - val_loss: 0.6834 - val_mse: 0.6661\n",
      "Epoch 14/25\n",
      "1963/1971 [============================>.] - ETA: 0s - loss: 0.6804 - mse: 0.6632\n",
      "Epoch 14: val_loss did not improve from 0.68163\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6803 - mse: 0.6630 - val_loss: 0.6823 - val_mse: 0.6651\n",
      "Epoch 15/25\n",
      "1949/1971 [============================>.] - ETA: 0s - loss: 0.6803 - mse: 0.6631\n",
      "Epoch 15: val_loss did not improve from 0.68163\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6803 - mse: 0.6631 - val_loss: 0.6832 - val_mse: 0.6660\n",
      "Epoch 16/25\n",
      "1947/1971 [============================>.] - ETA: 0s - loss: 0.6797 - mse: 0.6625\n",
      "Epoch 16: val_loss did not improve from 0.68163\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6803 - mse: 0.6631 - val_loss: 0.6816 - val_mse: 0.6645\n",
      "Epoch 17/25\n",
      "1960/1971 [============================>.] - ETA: 0s - loss: 0.6803 - mse: 0.6631\n",
      "Epoch 17: val_loss did not improve from 0.68163\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6802 - mse: 0.6630 - val_loss: 0.6817 - val_mse: 0.6645\n",
      "Epoch 18/25\n",
      "1954/1971 [============================>.] - ETA: 0s - loss: 0.6800 - mse: 0.6628\n",
      "Epoch 18: val_loss did not improve from 0.68163\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6802 - mse: 0.6630 - val_loss: 0.6826 - val_mse: 0.6654\n",
      "Epoch 19/25\n",
      "1955/1971 [============================>.] - ETA: 0s - loss: 0.6801 - mse: 0.6629\n",
      "Epoch 19: val_loss did not improve from 0.68163\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6802 - mse: 0.6630 - val_loss: 0.6818 - val_mse: 0.6646\n",
      "Epoch 20/25\n",
      "1960/1971 [============================>.] - ETA: 0s - loss: 0.6801 - mse: 0.6629\n",
      "Epoch 20: val_loss did not improve from 0.68163\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6802 - mse: 0.6631 - val_loss: 0.6844 - val_mse: 0.6672\n",
      "Epoch 21/25\n",
      "1959/1971 [============================>.] - ETA: 0s - loss: 0.6801 - mse: 0.6630\n",
      "Epoch 21: val_loss did not improve from 0.68163\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6802 - mse: 0.6631 - val_loss: 0.6818 - val_mse: 0.6646\n",
      "Epoch 22/25\n",
      "1961/1971 [============================>.] - ETA: 0s - loss: 0.6802 - mse: 0.6631\n",
      "Epoch 22: val_loss did not improve from 0.68163\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6802 - mse: 0.6630 - val_loss: 0.6818 - val_mse: 0.6647\n",
      "Epoch 23/25\n",
      "1964/1971 [============================>.] - ETA: 0s - loss: 0.6803 - mse: 0.6632\n",
      "Epoch 23: val_loss did not improve from 0.68163\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6802 - mse: 0.6630 - val_loss: 0.6835 - val_mse: 0.6663\n",
      "Epoch 24/25\n",
      "1961/1971 [============================>.] - ETA: 0s - loss: 0.6800 - mse: 0.6629\n",
      "Epoch 24: val_loss improved from 0.68163 to 0.68144, saving model to checkpoints/ext_4h_l1n2_2hidden_it13.e024_vl0.681.h5\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6802 - mse: 0.6630 - val_loss: 0.6814 - val_mse: 0.6643\n",
      "Epoch 25/25\n",
      "1954/1971 [============================>.] - ETA: 0s - loss: 0.6803 - mse: 0.6632\n",
      "Epoch 25: val_loss did not improve from 0.68144\n",
      "1971/1971 [==============================] - 5s 2ms/step - loss: 0.6801 - mse: 0.6630 - val_loss: 0.6834 - val_mse: 0.6663\n",
      "Time elapsed to train: 117.18 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.500 3.239 1.743 3.600 2.524 1.839 1.333 1.037 0.636 0.311 0.145 0.053 0.000]\n",
      "<R> = [2.500 3.239 1.743 3.600 2.524 1.839 1.333 1.037 0.636 0.311 0.145 0.053 0.000]\n",
      "s_R = [0.041 0.001 0.000 0.038 0.045 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [5.4884996 4.379217  4.7197266 ... 3.6638107 3.4673586 5.705307 ]\n",
      "ri = [0.1566     0.11399937 0.09399986 ... 0.14400005 0.10769939 0.18040085]\n",
      "gr = [0.40940094 0.30720043 0.33909988 ... 0.39439964 0.3547001  0.54629993]\n",
      "gaia_g = [5.092581  4.0506763 4.3923035 ... 3.2777119 3.1194954 5.188401 ]\n",
      "bp_rp = [0.87466145 0.76038456 0.7539873  ... 0.8580713  0.80200386 1.0124731 ]\n",
      "mag_pred: [4.9817457 4.102423  4.3490534 ... 3.4476836 3.6284413 4.9611773]\n",
      "mag_pred: [4.9817457 4.102423  4.3490534 ... 3.4476836 3.6284413 4.9611773]\n",
      "Time elapsed to make plots: 19.96 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 183594 bad. Replacing with 14.76263.\n",
      "Band 1: 4 of 183594 bad. Replacing with 15.15992.\n",
      "Band 2: 4 of 183594 bad. Replacing with 14.19274.\n",
      "Band 3: 113 of 183594 bad. Replacing with 15.23890.\n",
      "Band 4: 216 of 183594 bad. Replacing with 14.74910.\n",
      "Band 5: 7858 of 183594 bad. Replacing with 14.61460.\n",
      "Band 6: 243 of 183594 bad. Replacing with 14.49620.\n",
      "Band 7: 71 of 183594 bad. Replacing with 14.44220.\n",
      "Band 8: 365 of 183594 bad. Replacing with 13.53800.\n",
      "Band 9: 383 of 183594 bad. Replacing with 13.15900.\n",
      "Band 10: 1558 of 183594 bad. Replacing with 13.07700.\n",
      "Band 11: 207 of 183594 bad. Replacing with 15.74246.\n",
      "Band 12: 227 of 183594 bad. Replacing with 16.41537.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 183591 of 183594 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [8.3291025 6.7534575 4.1945577 ... 8.629996  5.239614  5.9900017]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0115\n",
      "  1% : 0.109\n",
      "  10% : 0.23\n",
      "  50% : 0.615\n",
      "  90% : 2.96\n",
      "  99% : 36\n",
      "  100% : 7.76e+03\n",
      "<chi^2/d.o.f.> = 1.04\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 11257 stars (6.13%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20400 bad. Replacing with 14.76272.\n",
      "Band 1: 1 of 20400 bad. Replacing with 15.16133.\n",
      "Band 2: 1 of 20400 bad. Replacing with 14.19002.\n",
      "Band 3: 12 of 20400 bad. Replacing with 15.23615.\n",
      "Band 4: 30 of 20400 bad. Replacing with 14.75020.\n",
      "Band 5: 901 of 20400 bad. Replacing with 14.62020.\n",
      "Band 6: 32 of 20400 bad. Replacing with 14.49545.\n",
      "Band 7: 8 of 20400 bad. Replacing with 14.43955.\n",
      "Band 8: 44 of 20400 bad. Replacing with 13.53900.\n",
      "Band 9: 38 of 20400 bad. Replacing with 13.16000.\n",
      "Band 10: 158 of 20400 bad. Replacing with 13.08300.\n",
      "Band 11: 12 of 20400 bad. Replacing with 15.74840.\n",
      "Band 12: 15 of 20400 bad. Replacing with 16.41809.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20400 of 20400 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 3.2749815  5.642603  10.160614  ...  9.401568   8.508439   3.1200707]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.039\n",
      "  1% : 0.11\n",
      "  10% : 0.234\n",
      "  50% : 0.619\n",
      "  90% : 3.09\n",
      "  99% : 37.3\n",
      "  100% : 3.88e+03\n",
      "<chi^2/d.o.f.> = 1.05\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 57.54 s\n",
      "learning rate = 7.427357923006639e-05\n",
      "setting learning rate to 6.0810062625217954e-05\n",
      "Iteration 15 of 20.\n",
      "Epoch 1/25\n",
      "1925/1945 [============================>.] - ETA: 0s - loss: 0.6399 - mse: 0.6229\n",
      "Epoch 1: val_loss improved from inf to 0.64348, saving model to checkpoints/ext_4h_l1n2_2hidden_it14.e001_vl0.643.h5\n",
      "1945/1945 [==============================] - 5s 3ms/step - loss: 0.6399 - mse: 0.6228 - val_loss: 0.6435 - val_mse: 0.6264\n",
      "Epoch 2/25\n",
      "1942/1945 [============================>.] - ETA: 0s - loss: 0.6398 - mse: 0.6228\n",
      "Epoch 2: val_loss improved from 0.64348 to 0.64330, saving model to checkpoints/ext_4h_l1n2_2hidden_it14.e002_vl0.643.h5\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6398 - mse: 0.6228 - val_loss: 0.6433 - val_mse: 0.6263\n",
      "Epoch 3/25\n",
      "1945/1945 [==============================] - ETA: 0s - loss: 0.6398 - mse: 0.6228\n",
      "Epoch 3: val_loss did not improve from 0.64330\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6398 - mse: 0.6228 - val_loss: 0.6437 - val_mse: 0.6267\n",
      "Epoch 4/25\n",
      "1919/1945 [============================>.] - ETA: 0s - loss: 0.6393 - mse: 0.6223\n",
      "Epoch 4: val_loss improved from 0.64330 to 0.64316, saving model to checkpoints/ext_4h_l1n2_2hidden_it14.e004_vl0.643.h5\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6398 - mse: 0.6228 - val_loss: 0.6432 - val_mse: 0.6262\n",
      "Epoch 5/25\n",
      "1933/1945 [============================>.] - ETA: 0s - loss: 0.6397 - mse: 0.6227\n",
      "Epoch 5: val_loss improved from 0.64316 to 0.64298, saving model to checkpoints/ext_4h_l1n2_2hidden_it14.e005_vl0.643.h5\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6398 - mse: 0.6228 - val_loss: 0.6430 - val_mse: 0.6260\n",
      "Epoch 6/25\n",
      "1935/1945 [============================>.] - ETA: 0s - loss: 0.6399 - mse: 0.6229\n",
      "Epoch 6: val_loss did not improve from 0.64298\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6398 - mse: 0.6228 - val_loss: 0.6432 - val_mse: 0.6263\n",
      "Epoch 7/25\n",
      "1918/1945 [============================>.] - ETA: 0s - loss: 0.6395 - mse: 0.6225\n",
      "Epoch 7: val_loss improved from 0.64298 to 0.64284, saving model to checkpoints/ext_4h_l1n2_2hidden_it14.e007_vl0.643.h5\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6398 - mse: 0.6228 - val_loss: 0.6428 - val_mse: 0.6259\n",
      "Epoch 8/25\n",
      "1929/1945 [============================>.] - ETA: 0s - loss: 0.6397 - mse: 0.6228\n",
      "Epoch 8: val_loss did not improve from 0.64284\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6397 - mse: 0.6227 - val_loss: 0.6439 - val_mse: 0.6270\n",
      "Epoch 9/25\n",
      "1935/1945 [============================>.] - ETA: 0s - loss: 0.6398 - mse: 0.6229\n",
      "Epoch 9: val_loss did not improve from 0.64284\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6396 - mse: 0.6227 - val_loss: 0.6431 - val_mse: 0.6261\n",
      "Epoch 10/25\n",
      "1935/1945 [============================>.] - ETA: 0s - loss: 0.6398 - mse: 0.6229\n",
      "Epoch 10: val_loss improved from 0.64284 to 0.64234, saving model to checkpoints/ext_4h_l1n2_2hidden_it14.e010_vl0.642.h5\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6398 - mse: 0.6228 - val_loss: 0.6423 - val_mse: 0.6254\n",
      "Epoch 11/25\n",
      "1922/1945 [============================>.] - ETA: 0s - loss: 0.6398 - mse: 0.6229\n",
      "Epoch 11: val_loss did not improve from 0.64234\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6396 - mse: 0.6227 - val_loss: 0.6441 - val_mse: 0.6272\n",
      "Epoch 12/25\n",
      "1931/1945 [============================>.] - ETA: 0s - loss: 0.6398 - mse: 0.6229\n",
      "Epoch 12: val_loss did not improve from 0.64234\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6396 - mse: 0.6227 - val_loss: 0.6435 - val_mse: 0.6266\n",
      "Epoch 13/25\n",
      "1926/1945 [============================>.] - ETA: 0s - loss: 0.6396 - mse: 0.6227\n",
      "Epoch 13: val_loss did not improve from 0.64234\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6397 - mse: 0.6228 - val_loss: 0.6446 - val_mse: 0.6277\n",
      "Epoch 14/25\n",
      "1927/1945 [============================>.] - ETA: 0s - loss: 0.6397 - mse: 0.6229\n",
      "Epoch 14: val_loss did not improve from 0.64234\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6397 - mse: 0.6228 - val_loss: 0.6427 - val_mse: 0.6258\n",
      "Epoch 15/25\n",
      "1924/1945 [============================>.] - ETA: 0s - loss: 0.6395 - mse: 0.6226\n",
      "Epoch 15: val_loss did not improve from 0.64234\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6396 - mse: 0.6228 - val_loss: 0.6432 - val_mse: 0.6264\n",
      "Epoch 16/25\n",
      "1933/1945 [============================>.] - ETA: 0s - loss: 0.6397 - mse: 0.6229\n",
      "Epoch 16: val_loss did not improve from 0.64234\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6396 - mse: 0.6228 - val_loss: 0.6432 - val_mse: 0.6264\n",
      "Epoch 17/25\n",
      "1918/1945 [============================>.] - ETA: 0s - loss: 0.6394 - mse: 0.6226\n",
      "Epoch 17: val_loss did not improve from 0.64234\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6395 - mse: 0.6227 - val_loss: 0.6437 - val_mse: 0.6269\n",
      "Epoch 18/25\n",
      "1937/1945 [============================>.] - ETA: 0s - loss: 0.6397 - mse: 0.6229\n",
      "Epoch 18: val_loss did not improve from 0.64234\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6396 - mse: 0.6228 - val_loss: 0.6428 - val_mse: 0.6260\n",
      "Epoch 19/25\n",
      "1928/1945 [============================>.] - ETA: 0s - loss: 0.6395 - mse: 0.6227\n",
      "Epoch 19: val_loss did not improve from 0.64234\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6395 - mse: 0.6227 - val_loss: 0.6429 - val_mse: 0.6262\n",
      "Epoch 20/25\n",
      "1944/1945 [============================>.] - ETA: 0s - loss: 0.6395 - mse: 0.6227\n",
      "Epoch 20: val_loss did not improve from 0.64234\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6395 - mse: 0.6227 - val_loss: 0.6425 - val_mse: 0.6258\n",
      "Epoch 21/25\n",
      "1921/1945 [============================>.] - ETA: 0s - loss: 0.6396 - mse: 0.6228\n",
      "Epoch 21: val_loss did not improve from 0.64234\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6394 - mse: 0.6227 - val_loss: 0.6433 - val_mse: 0.6265\n",
      "Epoch 22/25\n",
      "1941/1945 [============================>.] - ETA: 0s - loss: 0.6394 - mse: 0.6227\n",
      "Epoch 22: val_loss did not improve from 0.64234\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6395 - mse: 0.6228 - val_loss: 0.6425 - val_mse: 0.6257\n",
      "Epoch 23/25\n",
      "1923/1945 [============================>.] - ETA: 0s - loss: 0.6393 - mse: 0.6225\n",
      "Epoch 23: val_loss did not improve from 0.64234\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6395 - mse: 0.6228 - val_loss: 0.6427 - val_mse: 0.6259\n",
      "Epoch 24/25\n",
      "1941/1945 [============================>.] - ETA: 0s - loss: 0.6396 - mse: 0.6229\n",
      "Epoch 24: val_loss did not improve from 0.64234\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6395 - mse: 0.6228 - val_loss: 0.6427 - val_mse: 0.6260\n",
      "Epoch 25/25\n",
      "1926/1945 [============================>.] - ETA: 0s - loss: 0.6394 - mse: 0.6227\n",
      "Epoch 25: val_loss improved from 0.64234 to 0.64220, saving model to checkpoints/ext_4h_l1n2_2hidden_it14.e025_vl0.642.h5\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6395 - mse: 0.6227 - val_loss: 0.6422 - val_mse: 0.6255\n",
      "Time elapsed to train: 116.63 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.460 3.186 1.714 3.544 2.484 1.811 1.310 1.017 0.624 0.307 0.144 0.054 0.000]\n",
      "<R> = [2.460 3.186 1.714 3.544 2.484 1.811 1.310 1.017 0.624 0.307 0.144 0.054 0.000]\n",
      "s_R = [0.042 0.002 0.000 0.030 0.039 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [5.4884996 4.379217  4.7197266 ... 3.6638107 3.4673586 5.705307 ]\n",
      "ri = [0.1566     0.11399937 0.09399986 ... 0.14400005 0.10769939 0.18040085]\n",
      "gr = [0.40940094 0.30720043 0.33909988 ... 0.39439964 0.3547001  0.54629993]\n",
      "gaia_g = [5.092581  4.0506763 4.3923035 ... 3.2777119 3.1194954 5.188401 ]\n",
      "bp_rp = [0.87466145 0.76038456 0.7539873  ... 0.8580713  0.80200386 1.0124731 ]\n",
      "mag_pred: [4.983675  4.0899324 4.360421  ... 3.4472656 3.6193705 4.941024 ]\n",
      "mag_pred: [4.983675  4.0899324 4.360421  ... 3.4472656 3.6193705 4.941024 ]\n",
      "Time elapsed to make plots: 16.54 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 183594 bad. Replacing with 14.76263.\n",
      "Band 1: 4 of 183594 bad. Replacing with 15.15992.\n",
      "Band 2: 4 of 183594 bad. Replacing with 14.19274.\n",
      "Band 3: 113 of 183594 bad. Replacing with 15.23890.\n",
      "Band 4: 216 of 183594 bad. Replacing with 14.74910.\n",
      "Band 5: 7858 of 183594 bad. Replacing with 14.61460.\n",
      "Band 6: 243 of 183594 bad. Replacing with 14.49620.\n",
      "Band 7: 71 of 183594 bad. Replacing with 14.44220.\n",
      "Band 8: 365 of 183594 bad. Replacing with 13.53800.\n",
      "Band 9: 383 of 183594 bad. Replacing with 13.15900.\n",
      "Band 10: 1558 of 183594 bad. Replacing with 13.07700.\n",
      "Band 11: 207 of 183594 bad. Replacing with 15.74246.\n",
      "Band 12: 227 of 183594 bad. Replacing with 16.41537.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 183591 of 183594 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [8.245928  7.1837826 3.53735   ... 8.95392   5.3214107 6.018049 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0168\n",
      "  1% : 0.107\n",
      "  10% : 0.228\n",
      "  50% : 0.607\n",
      "  90% : 2.9\n",
      "  99% : 36.2\n",
      "  100% : 7.77e+03\n",
      "<chi^2/d.o.f.> = 1.03\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 11100 stars (6.05%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20400 bad. Replacing with 14.76272.\n",
      "Band 1: 1 of 20400 bad. Replacing with 15.16133.\n",
      "Band 2: 1 of 20400 bad. Replacing with 14.19002.\n",
      "Band 3: 12 of 20400 bad. Replacing with 15.23615.\n",
      "Band 4: 30 of 20400 bad. Replacing with 14.75020.\n",
      "Band 5: 901 of 20400 bad. Replacing with 14.62020.\n",
      "Band 6: 32 of 20400 bad. Replacing with 14.49545.\n",
      "Band 7: 8 of 20400 bad. Replacing with 14.43955.\n",
      "Band 8: 44 of 20400 bad. Replacing with 13.53900.\n",
      "Band 9: 38 of 20400 bad. Replacing with 13.16000.\n",
      "Band 10: 158 of 20400 bad. Replacing with 13.08300.\n",
      "Band 11: 12 of 20400 bad. Replacing with 15.74840.\n",
      "Band 12: 15 of 20400 bad. Replacing with 16.41809.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20400 of 20400 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [3.0555425 5.797346  9.511322  ... 9.358     8.419387  3.193051 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0415\n",
      "  1% : 0.107\n",
      "  10% : 0.231\n",
      "  50% : 0.614\n",
      "  90% : 3\n",
      "  99% : 37\n",
      "  100% : 3.88e+03\n",
      "<chi^2/d.o.f.> = 1.03\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 55.96 s\n",
      "learning rate = 6.0810063587268814e-05\n",
      "setting learning rate to 4.9787068367863945e-05\n",
      "Iteration 16 of 20.\n",
      "Epoch 1/25\n",
      "1945/1947 [============================>.] - ETA: 0s - loss: 0.6379 - mse: 0.6212\n",
      "Epoch 1: val_loss improved from inf to 0.64103, saving model to checkpoints/ext_4h_l1n2_2hidden_it15.e001_vl0.641.h5\n",
      "1947/1947 [==============================] - 5s 2ms/step - loss: 0.6379 - mse: 0.6212 - val_loss: 0.6410 - val_mse: 0.6243\n",
      "Epoch 2/25\n",
      "1938/1947 [============================>.] - ETA: 0s - loss: 0.6379 - mse: 0.6211\n",
      "Epoch 2: val_loss did not improve from 0.64103\n",
      "1947/1947 [==============================] - 5s 2ms/step - loss: 0.6378 - mse: 0.6211 - val_loss: 0.6411 - val_mse: 0.6244\n",
      "Epoch 3/25\n",
      "1946/1947 [============================>.] - ETA: 0s - loss: 0.6378 - mse: 0.6211\n",
      "Epoch 3: val_loss did not improve from 0.64103\n",
      "1947/1947 [==============================] - 5s 2ms/step - loss: 0.6378 - mse: 0.6211 - val_loss: 0.6411 - val_mse: 0.6244\n",
      "Epoch 4/25\n",
      "1943/1947 [============================>.] - ETA: 0s - loss: 0.6379 - mse: 0.6212\n",
      "Epoch 4: val_loss improved from 0.64103 to 0.64093, saving model to checkpoints/ext_4h_l1n2_2hidden_it15.e004_vl0.641.h5\n",
      "1947/1947 [==============================] - 5s 2ms/step - loss: 0.6379 - mse: 0.6212 - val_loss: 0.6409 - val_mse: 0.6242\n",
      "Epoch 5/25\n",
      "1930/1947 [============================>.] - ETA: 0s - loss: 0.6377 - mse: 0.6210\n",
      "Epoch 5: val_loss did not improve from 0.64093\n",
      "1947/1947 [==============================] - 5s 2ms/step - loss: 0.6379 - mse: 0.6212 - val_loss: 0.6413 - val_mse: 0.6246\n",
      "Epoch 6/25\n",
      "1922/1947 [============================>.] - ETA: 0s - loss: 0.6376 - mse: 0.6209\n",
      "Epoch 6: val_loss did not improve from 0.64093\n",
      "1947/1947 [==============================] - 4s 2ms/step - loss: 0.6378 - mse: 0.6211 - val_loss: 0.6412 - val_mse: 0.6245\n",
      "Epoch 7/25\n",
      "1937/1947 [============================>.] - ETA: 0s - loss: 0.6377 - mse: 0.6210\n",
      "Epoch 7: val_loss did not improve from 0.64093\n",
      "1947/1947 [==============================] - 5s 2ms/step - loss: 0.6378 - mse: 0.6212 - val_loss: 0.6413 - val_mse: 0.6247\n",
      "Epoch 8/25\n",
      "1939/1947 [============================>.] - ETA: 0s - loss: 0.6378 - mse: 0.6211\n",
      "Epoch 8: val_loss did not improve from 0.64093\n",
      "1947/1947 [==============================] - 5s 2ms/step - loss: 0.6378 - mse: 0.6211 - val_loss: 0.6426 - val_mse: 0.6260\n",
      "Epoch 9/25\n",
      "1924/1947 [============================>.] - ETA: 0s - loss: 0.6376 - mse: 0.6209\n",
      "Epoch 9: val_loss did not improve from 0.64093\n",
      "1947/1947 [==============================] - 5s 2ms/step - loss: 0.6378 - mse: 0.6212 - val_loss: 0.6410 - val_mse: 0.6243\n",
      "Epoch 10/25\n",
      "1936/1947 [============================>.] - ETA: 0s - loss: 0.6377 - mse: 0.6211\n",
      "Epoch 10: val_loss improved from 0.64093 to 0.64084, saving model to checkpoints/ext_4h_l1n2_2hidden_it15.e010_vl0.641.h5\n",
      "1947/1947 [==============================] - 4s 2ms/step - loss: 0.6378 - mse: 0.6212 - val_loss: 0.6408 - val_mse: 0.6242\n",
      "Epoch 11/25\n",
      "1927/1947 [============================>.] - ETA: 0s - loss: 0.6377 - mse: 0.6211\n",
      "Epoch 11: val_loss improved from 0.64084 to 0.64062, saving model to checkpoints/ext_4h_l1n2_2hidden_it15.e011_vl0.641.h5\n",
      "1947/1947 [==============================] - 5s 2ms/step - loss: 0.6378 - mse: 0.6212 - val_loss: 0.6406 - val_mse: 0.6240\n",
      "Epoch 12/25\n",
      "1932/1947 [============================>.] - ETA: 0s - loss: 0.6376 - mse: 0.6210\n",
      "Epoch 12: val_loss did not improve from 0.64062\n",
      "1947/1947 [==============================] - 5s 2ms/step - loss: 0.6378 - mse: 0.6212 - val_loss: 0.6409 - val_mse: 0.6243\n",
      "Epoch 13/25\n",
      "1932/1947 [============================>.] - ETA: 0s - loss: 0.6379 - mse: 0.6213\n",
      "Epoch 13: val_loss did not improve from 0.64062\n",
      "1947/1947 [==============================] - 5s 2ms/step - loss: 0.6378 - mse: 0.6212 - val_loss: 0.6413 - val_mse: 0.6247\n",
      "Epoch 14/25\n",
      "1929/1947 [============================>.] - ETA: 0s - loss: 0.6376 - mse: 0.6210\n",
      "Epoch 14: val_loss did not improve from 0.64062\n",
      "1947/1947 [==============================] - 4s 2ms/step - loss: 0.6377 - mse: 0.6212 - val_loss: 0.6418 - val_mse: 0.6252\n",
      "Epoch 15/25\n",
      "1924/1947 [============================>.] - ETA: 0s - loss: 0.6374 - mse: 0.6209\n",
      "Epoch 15: val_loss did not improve from 0.64062\n",
      "1947/1947 [==============================] - 5s 2ms/step - loss: 0.6377 - mse: 0.6211 - val_loss: 0.6415 - val_mse: 0.6249\n",
      "Epoch 16/25\n",
      "1946/1947 [============================>.] - ETA: 0s - loss: 0.6376 - mse: 0.6211\n",
      "Epoch 16: val_loss did not improve from 0.64062\n",
      "1947/1947 [==============================] - 5s 2ms/step - loss: 0.6377 - mse: 0.6211 - val_loss: 0.6415 - val_mse: 0.6249\n",
      "Epoch 17/25\n",
      "1945/1947 [============================>.] - ETA: 0s - loss: 0.6377 - mse: 0.6211\n",
      "Epoch 17: val_loss did not improve from 0.64062\n",
      "1947/1947 [==============================] - 5s 2ms/step - loss: 0.6377 - mse: 0.6211 - val_loss: 0.6407 - val_mse: 0.6241\n",
      "Epoch 18/25\n",
      "1925/1947 [============================>.] - ETA: 0s - loss: 0.6375 - mse: 0.6209\n",
      "Epoch 18: val_loss did not improve from 0.64062\n",
      "1947/1947 [==============================] - 5s 2ms/step - loss: 0.6378 - mse: 0.6212 - val_loss: 0.6406 - val_mse: 0.6241\n",
      "Epoch 19/25\n",
      "1922/1947 [============================>.] - ETA: 0s - loss: 0.6379 - mse: 0.6213\n",
      "Epoch 19: val_loss did not improve from 0.64062\n",
      "1947/1947 [==============================] - 5s 2ms/step - loss: 0.6377 - mse: 0.6212 - val_loss: 0.6425 - val_mse: 0.6260\n",
      "Epoch 20/25\n",
      "1931/1947 [============================>.] - ETA: 0s - loss: 0.6376 - mse: 0.6211\n",
      "Epoch 20: val_loss did not improve from 0.64062\n",
      "1947/1947 [==============================] - 5s 2ms/step - loss: 0.6376 - mse: 0.6211 - val_loss: 0.6415 - val_mse: 0.6250\n",
      "Epoch 21/25\n",
      "1923/1947 [============================>.] - ETA: 0s - loss: 0.6377 - mse: 0.6212\n",
      "Epoch 21: val_loss did not improve from 0.64062\n",
      "1947/1947 [==============================] - 5s 2ms/step - loss: 0.6377 - mse: 0.6212 - val_loss: 0.6406 - val_mse: 0.6241\n",
      "Epoch 22/25\n",
      "1946/1947 [============================>.] - ETA: 0s - loss: 0.6377 - mse: 0.6212\n",
      "Epoch 22: val_loss did not improve from 0.64062\n",
      "1947/1947 [==============================] - 5s 2ms/step - loss: 0.6377 - mse: 0.6212 - val_loss: 0.6409 - val_mse: 0.6244\n",
      "Epoch 23/25\n",
      "1929/1947 [============================>.] - ETA: 0s - loss: 0.6380 - mse: 0.6214\n",
      "Epoch 23: val_loss did not improve from 0.64062\n",
      "1947/1947 [==============================] - 5s 2ms/step - loss: 0.6377 - mse: 0.6212 - val_loss: 0.6414 - val_mse: 0.6249\n",
      "Epoch 24/25\n",
      "1937/1947 [============================>.] - ETA: 0s - loss: 0.6376 - mse: 0.6211\n",
      "Epoch 24: val_loss did not improve from 0.64062\n",
      "1947/1947 [==============================] - 5s 2ms/step - loss: 0.6377 - mse: 0.6212 - val_loss: 0.6408 - val_mse: 0.6243\n",
      "Epoch 25/25\n",
      "1931/1947 [============================>.] - ETA: 0s - loss: 0.6375 - mse: 0.6211\n",
      "Epoch 25: val_loss did not improve from 0.64062\n",
      "1947/1947 [==============================] - 5s 2ms/step - loss: 0.6376 - mse: 0.6211 - val_loss: 0.6413 - val_mse: 0.6248\n",
      "Time elapsed to train: 115.07 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.439 3.158 1.699 3.508 2.462 1.794 1.298 1.006 0.617 0.305 0.144 0.054 0.000]\n",
      "<R> = [2.439 3.158 1.699 3.508 2.462 1.794 1.298 1.006 0.617 0.305 0.144 0.054 0.000]\n",
      "s_R = [0.043 0.002 0.000 0.026 0.036 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [5.4884996 4.379217  4.7197266 ... 3.6638107 3.4673586 5.705307 ]\n",
      "ri = [0.1566     0.11399937 0.09399986 ... 0.14400005 0.10769939 0.18040085]\n",
      "gr = [0.40940094 0.30720043 0.33909988 ... 0.39439964 0.3547001  0.54629993]\n",
      "gaia_g = [5.092581  4.0506763 4.3923035 ... 3.2777119 3.1194954 5.188401 ]\n",
      "bp_rp = [0.87466145 0.76038456 0.7539873  ... 0.8580713  0.80200386 1.0124731 ]\n",
      "mag_pred: [4.9847965 4.0946097 4.3690667 ... 3.4517834 3.6258438 4.950416 ]\n",
      "mag_pred: [4.9847965 4.0946097 4.3690667 ... 3.4517834 3.6258438 4.950416 ]\n",
      "Time elapsed to make plots: 16.10 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 183594 bad. Replacing with 14.76263.\n",
      "Band 1: 4 of 183594 bad. Replacing with 15.15992.\n",
      "Band 2: 4 of 183594 bad. Replacing with 14.19274.\n",
      "Band 3: 113 of 183594 bad. Replacing with 15.23890.\n",
      "Band 4: 216 of 183594 bad. Replacing with 14.74910.\n",
      "Band 5: 7858 of 183594 bad. Replacing with 14.61460.\n",
      "Band 6: 243 of 183594 bad. Replacing with 14.49620.\n",
      "Band 7: 71 of 183594 bad. Replacing with 14.44220.\n",
      "Band 8: 365 of 183594 bad. Replacing with 13.53800.\n",
      "Band 9: 383 of 183594 bad. Replacing with 13.15900.\n",
      "Band 10: 1558 of 183594 bad. Replacing with 13.07700.\n",
      "Band 11: 207 of 183594 bad. Replacing with 15.74246.\n",
      "Band 12: 227 of 183594 bad. Replacing with 16.41537.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 183591 of 183594 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [8.368163  7.123933  3.4827056 ... 8.918365  4.9564857 5.494407 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0183\n",
      "  1% : 0.108\n",
      "  10% : 0.228\n",
      "  50% : 0.605\n",
      "  90% : 2.92\n",
      "  99% : 36.2\n",
      "  100% : 7.77e+03\n",
      "<chi^2/d.o.f.> = 1.03\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 11222 stars (6.11%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20400 bad. Replacing with 14.76272.\n",
      "Band 1: 1 of 20400 bad. Replacing with 15.16133.\n",
      "Band 2: 1 of 20400 bad. Replacing with 14.19002.\n",
      "Band 3: 12 of 20400 bad. Replacing with 15.23615.\n",
      "Band 4: 30 of 20400 bad. Replacing with 14.75020.\n",
      "Band 5: 901 of 20400 bad. Replacing with 14.62020.\n",
      "Band 6: 32 of 20400 bad. Replacing with 14.49545.\n",
      "Band 7: 8 of 20400 bad. Replacing with 14.43955.\n",
      "Band 8: 44 of 20400 bad. Replacing with 13.53900.\n",
      "Band 9: 38 of 20400 bad. Replacing with 13.16000.\n",
      "Band 10: 158 of 20400 bad. Replacing with 13.08300.\n",
      "Band 11: 12 of 20400 bad. Replacing with 15.74840.\n",
      "Band 12: 15 of 20400 bad. Replacing with 16.41809.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20400 of 20400 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 2.8911357  5.5962257  9.157233  ... 10.040277   8.804962   3.1771464]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0381\n",
      "  1% : 0.107\n",
      "  10% : 0.233\n",
      "  50% : 0.614\n",
      "  90% : 3.03\n",
      "  99% : 37\n",
      "  100% : 3.88e+03\n",
      "<chi^2/d.o.f.> = 1.04\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 57.12 s\n",
      "learning rate = 4.978706783731468e-05\n",
      "setting learning rate to 4.0762203978366214e-05\n",
      "Iteration 17 of 20.\n",
      "Epoch 1/25\n",
      "1922/1946 [============================>.] - ETA: 0s - loss: 0.6368 - mse: 0.6203\n",
      "Epoch 1: val_loss improved from inf to 0.64013, saving model to checkpoints/ext_4h_l1n2_2hidden_it16.e001_vl0.640.h5\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6367 - mse: 0.6202 - val_loss: 0.6401 - val_mse: 0.6237\n",
      "Epoch 2/25\n",
      "1930/1946 [============================>.] - ETA: 0s - loss: 0.6364 - mse: 0.6200\n",
      "Epoch 2: val_loss improved from 0.64013 to 0.63931, saving model to checkpoints/ext_4h_l1n2_2hidden_it16.e002_vl0.639.h5\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6367 - mse: 0.6202 - val_loss: 0.6393 - val_mse: 0.6228\n",
      "Epoch 3/25\n",
      "1925/1946 [============================>.] - ETA: 0s - loss: 0.6370 - mse: 0.6205\n",
      "Epoch 3: val_loss improved from 0.63931 to 0.63930, saving model to checkpoints/ext_4h_l1n2_2hidden_it16.e003_vl0.639.h5\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6367 - mse: 0.6202 - val_loss: 0.6393 - val_mse: 0.6229\n",
      "Epoch 4/25\n",
      "1933/1946 [============================>.] - ETA: 0s - loss: 0.6366 - mse: 0.6201\n",
      "Epoch 4: val_loss improved from 0.63930 to 0.63927, saving model to checkpoints/ext_4h_l1n2_2hidden_it16.e004_vl0.639.h5\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6366 - mse: 0.6202 - val_loss: 0.6393 - val_mse: 0.6228\n",
      "Epoch 5/25\n",
      "1933/1946 [============================>.] - ETA: 0s - loss: 0.6366 - mse: 0.6202\n",
      "Epoch 5: val_loss did not improve from 0.63927\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6366 - mse: 0.6202 - val_loss: 0.6396 - val_mse: 0.6232\n",
      "Epoch 6/25\n",
      "1936/1946 [============================>.] - ETA: 0s - loss: 0.6367 - mse: 0.6203\n",
      "Epoch 6: val_loss improved from 0.63927 to 0.63909, saving model to checkpoints/ext_4h_l1n2_2hidden_it16.e006_vl0.639.h5\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6366 - mse: 0.6202 - val_loss: 0.6391 - val_mse: 0.6226\n",
      "Epoch 7/25\n",
      "1924/1946 [============================>.] - ETA: 0s - loss: 0.6367 - mse: 0.6202\n",
      "Epoch 7: val_loss improved from 0.63909 to 0.63904, saving model to checkpoints/ext_4h_l1n2_2hidden_it16.e007_vl0.639.h5\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6366 - mse: 0.6202 - val_loss: 0.6390 - val_mse: 0.6226\n",
      "Epoch 8/25\n",
      "1920/1946 [============================>.] - ETA: 0s - loss: 0.6362 - mse: 0.6198\n",
      "Epoch 8: val_loss did not improve from 0.63904\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6366 - mse: 0.6202 - val_loss: 0.6396 - val_mse: 0.6232\n",
      "Epoch 9/25\n",
      "1932/1946 [============================>.] - ETA: 0s - loss: 0.6365 - mse: 0.6201\n",
      "Epoch 9: val_loss did not improve from 0.63904\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6366 - mse: 0.6202 - val_loss: 0.6403 - val_mse: 0.6239\n",
      "Epoch 10/25\n",
      "1932/1946 [============================>.] - ETA: 0s - loss: 0.6365 - mse: 0.6201\n",
      "Epoch 10: val_loss did not improve from 0.63904\n",
      "1946/1946 [==============================] - 4s 2ms/step - loss: 0.6367 - mse: 0.6202 - val_loss: 0.6395 - val_mse: 0.6231\n",
      "Epoch 11/25\n",
      "1926/1946 [============================>.] - ETA: 0s - loss: 0.6365 - mse: 0.6201\n",
      "Epoch 11: val_loss did not improve from 0.63904\n",
      "1946/1946 [==============================] - 4s 2ms/step - loss: 0.6367 - mse: 0.6203 - val_loss: 0.6395 - val_mse: 0.6231\n",
      "Epoch 12/25\n",
      "1933/1946 [============================>.] - ETA: 0s - loss: 0.6365 - mse: 0.6201\n",
      "Epoch 12: val_loss did not improve from 0.63904\n",
      "1946/1946 [==============================] - 4s 2ms/step - loss: 0.6366 - mse: 0.6202 - val_loss: 0.6397 - val_mse: 0.6233\n",
      "Epoch 13/25\n",
      "1917/1946 [============================>.] - ETA: 0s - loss: 0.6366 - mse: 0.6202\n",
      "Epoch 13: val_loss improved from 0.63904 to 0.63891, saving model to checkpoints/ext_4h_l1n2_2hidden_it16.e013_vl0.639.h5\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6366 - mse: 0.6202 - val_loss: 0.6389 - val_mse: 0.6225\n",
      "Epoch 14/25\n",
      "1928/1946 [============================>.] - ETA: 0s - loss: 0.6366 - mse: 0.6202\n",
      "Epoch 14: val_loss did not improve from 0.63891\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6366 - mse: 0.6202 - val_loss: 0.6390 - val_mse: 0.6226\n",
      "Epoch 15/25\n",
      "1933/1946 [============================>.] - ETA: 0s - loss: 0.6364 - mse: 0.6201\n",
      "Epoch 15: val_loss did not improve from 0.63891\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6366 - mse: 0.6202 - val_loss: 0.6392 - val_mse: 0.6228\n",
      "Epoch 16/25\n",
      "1935/1946 [============================>.] - ETA: 0s - loss: 0.6364 - mse: 0.6200\n",
      "Epoch 16: val_loss did not improve from 0.63891\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6366 - mse: 0.6202 - val_loss: 0.6397 - val_mse: 0.6234\n",
      "Epoch 17/25\n",
      "1934/1946 [============================>.] - ETA: 0s - loss: 0.6366 - mse: 0.6203\n",
      "Epoch 17: val_loss did not improve from 0.63891\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6366 - mse: 0.6202 - val_loss: 0.6394 - val_mse: 0.6230\n",
      "Epoch 18/25\n",
      "1938/1946 [============================>.] - ETA: 0s - loss: 0.6366 - mse: 0.6202\n",
      "Epoch 18: val_loss did not improve from 0.63891\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6366 - mse: 0.6202 - val_loss: 0.6405 - val_mse: 0.6241\n",
      "Epoch 19/25\n",
      "1932/1946 [============================>.] - ETA: 0s - loss: 0.6365 - mse: 0.6201\n",
      "Epoch 19: val_loss did not improve from 0.63891\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6366 - mse: 0.6202 - val_loss: 0.6392 - val_mse: 0.6228\n",
      "Epoch 20/25\n",
      "1923/1946 [============================>.] - ETA: 0s - loss: 0.6367 - mse: 0.6204\n",
      "Epoch 20: val_loss did not improve from 0.63891\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6366 - mse: 0.6203 - val_loss: 0.6393 - val_mse: 0.6229\n",
      "Epoch 21/25\n",
      "1942/1946 [============================>.] - ETA: 0s - loss: 0.6366 - mse: 0.6203\n",
      "Epoch 21: val_loss improved from 0.63891 to 0.63889, saving model to checkpoints/ext_4h_l1n2_2hidden_it16.e021_vl0.639.h5\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6366 - mse: 0.6202 - val_loss: 0.6389 - val_mse: 0.6226\n",
      "Epoch 22/25\n",
      "1931/1946 [============================>.] - ETA: 0s - loss: 0.6365 - mse: 0.6202\n",
      "Epoch 22: val_loss did not improve from 0.63889\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6366 - mse: 0.6202 - val_loss: 0.6396 - val_mse: 0.6233\n",
      "Epoch 23/25\n",
      "1939/1946 [============================>.] - ETA: 0s - loss: 0.6366 - mse: 0.6203\n",
      "Epoch 23: val_loss did not improve from 0.63889\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6366 - mse: 0.6203 - val_loss: 0.6390 - val_mse: 0.6227\n",
      "Epoch 24/25\n",
      "1943/1946 [============================>.] - ETA: 0s - loss: 0.6366 - mse: 0.6202\n",
      "Epoch 24: val_loss did not improve from 0.63889\n",
      "1946/1946 [==============================] - 4s 2ms/step - loss: 0.6366 - mse: 0.6203 - val_loss: 0.6395 - val_mse: 0.6232\n",
      "Epoch 25/25\n",
      "1920/1946 [============================>.] - ETA: 0s - loss: 0.6366 - mse: 0.6203\n",
      "Epoch 25: val_loss did not improve from 0.63889\n",
      "1946/1946 [==============================] - 4s 2ms/step - loss: 0.6366 - mse: 0.6202 - val_loss: 0.6390 - val_mse: 0.6227\n",
      "Time elapsed to train: 115.82 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.428 3.143 1.690 3.493 2.449 1.785 1.290 0.999 0.613 0.303 0.143 0.054 0.000]\n",
      "<R> = [2.428 3.143 1.690 3.493 2.449 1.785 1.290 0.999 0.613 0.303 0.143 0.054 0.000]\n",
      "s_R = [0.042 0.005 0.000 0.022 0.035 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [5.4884996 4.379217  4.7197266 ... 3.6638107 3.4673586 5.705307 ]\n",
      "ri = [0.1566     0.11399937 0.09399986 ... 0.14400005 0.10769939 0.18040085]\n",
      "gr = [0.40940094 0.30720043 0.33909988 ... 0.39439964 0.3547001  0.54629993]\n",
      "gaia_g = [5.092581  4.0506763 4.3923035 ... 3.2777119 3.1194954 5.188401 ]\n",
      "bp_rp = [0.87466145 0.76038456 0.7539873  ... 0.8580713  0.80200386 1.0124731 ]\n",
      "mag_pred: [4.9852614 4.1033497 4.37957   ... 3.4782047 3.640926  4.9555173]\n",
      "mag_pred: [4.9852614 4.1033497 4.37957   ... 3.4782047 3.640926  4.9555173]\n",
      "Time elapsed to make plots: 20.06 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 183594 bad. Replacing with 14.76263.\n",
      "Band 1: 4 of 183594 bad. Replacing with 15.15992.\n",
      "Band 2: 4 of 183594 bad. Replacing with 14.19274.\n",
      "Band 3: 113 of 183594 bad. Replacing with 15.23890.\n",
      "Band 4: 216 of 183594 bad. Replacing with 14.74910.\n",
      "Band 5: 7858 of 183594 bad. Replacing with 14.61460.\n",
      "Band 6: 243 of 183594 bad. Replacing with 14.49620.\n",
      "Band 7: 71 of 183594 bad. Replacing with 14.44220.\n",
      "Band 8: 365 of 183594 bad. Replacing with 13.53800.\n",
      "Band 9: 383 of 183594 bad. Replacing with 13.15900.\n",
      "Band 10: 1558 of 183594 bad. Replacing with 13.07700.\n",
      "Band 11: 207 of 183594 bad. Replacing with 15.74246.\n",
      "Band 12: 227 of 183594 bad. Replacing with 16.41537.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 183591 of 183594 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [8.315998  7.180797  3.6852074 ... 8.794061  5.2056627 5.2595277]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0135\n",
      "  1% : 0.108\n",
      "  10% : 0.228\n",
      "  50% : 0.606\n",
      "  90% : 2.92\n",
      "  99% : 36.3\n",
      "  100% : 7.76e+03\n",
      "<chi^2/d.o.f.> = 1.03\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 11232 stars (6.12%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20400 bad. Replacing with 14.76272.\n",
      "Band 1: 1 of 20400 bad. Replacing with 15.16133.\n",
      "Band 2: 1 of 20400 bad. Replacing with 14.19002.\n",
      "Band 3: 12 of 20400 bad. Replacing with 15.23615.\n",
      "Band 4: 30 of 20400 bad. Replacing with 14.75020.\n",
      "Band 5: 901 of 20400 bad. Replacing with 14.62020.\n",
      "Band 6: 32 of 20400 bad. Replacing with 14.49545.\n",
      "Band 7: 8 of 20400 bad. Replacing with 14.43955.\n",
      "Band 8: 44 of 20400 bad. Replacing with 13.53900.\n",
      "Band 9: 38 of 20400 bad. Replacing with 13.16000.\n",
      "Band 10: 158 of 20400 bad. Replacing with 13.08300.\n",
      "Band 11: 12 of 20400 bad. Replacing with 15.74840.\n",
      "Band 12: 15 of 20400 bad. Replacing with 16.41809.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20400 of 20400 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 2.9268405  5.4963737  9.146951  ... 10.366413   9.516837   3.1412377]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0409\n",
      "  1% : 0.107\n",
      "  10% : 0.232\n",
      "  50% : 0.614\n",
      "  90% : 3.03\n",
      "  99% : 37\n",
      "  100% : 3.89e+03\n",
      "<chi^2/d.o.f.> = 1.04\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 58.76 s\n",
      "learning rate = 4.076220284332521e-05\n",
      "setting learning rate to 3.337326996032607e-05\n",
      "Iteration 18 of 20.\n",
      "Epoch 1/25\n",
      "1927/1946 [============================>.] - ETA: 0s - loss: 0.6381 - mse: 0.6218\n",
      "Epoch 1: val_loss improved from inf to 0.64146, saving model to checkpoints/ext_4h_l1n2_2hidden_it17.e001_vl0.641.h5\n",
      "1946/1946 [==============================] - 5s 3ms/step - loss: 0.6383 - mse: 0.6220 - val_loss: 0.6415 - val_mse: 0.6252\n",
      "Epoch 2/25\n",
      "1945/1946 [============================>.] - ETA: 0s - loss: 0.6383 - mse: 0.6220\n",
      "Epoch 2: val_loss did not improve from 0.64146\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6383 - mse: 0.6220 - val_loss: 0.6419 - val_mse: 0.6256\n",
      "Epoch 3/25\n",
      "1931/1946 [============================>.] - ETA: 0s - loss: 0.6383 - mse: 0.6220\n",
      "Epoch 3: val_loss improved from 0.64146 to 0.64134, saving model to checkpoints/ext_4h_l1n2_2hidden_it17.e003_vl0.641.h5\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6383 - mse: 0.6220 - val_loss: 0.6413 - val_mse: 0.6250\n",
      "Epoch 4/25\n",
      "1927/1946 [============================>.] - ETA: 0s - loss: 0.6384 - mse: 0.6221\n",
      "Epoch 4: val_loss did not improve from 0.64134\n",
      "1946/1946 [==============================] - 4s 2ms/step - loss: 0.6383 - mse: 0.6220 - val_loss: 0.6419 - val_mse: 0.6256\n",
      "Epoch 5/25\n",
      "1921/1946 [============================>.] - ETA: 0s - loss: 0.6386 - mse: 0.6223\n",
      "Epoch 5: val_loss did not improve from 0.64134\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6383 - mse: 0.6220 - val_loss: 0.6415 - val_mse: 0.6252\n",
      "Epoch 6/25\n",
      "1946/1946 [==============================] - ETA: 0s - loss: 0.6383 - mse: 0.6220\n",
      "Epoch 6: val_loss improved from 0.64134 to 0.64125, saving model to checkpoints/ext_4h_l1n2_2hidden_it17.e006_vl0.641.h5\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6383 - mse: 0.6220 - val_loss: 0.6413 - val_mse: 0.6250\n",
      "Epoch 7/25\n",
      "1937/1946 [============================>.] - ETA: 0s - loss: 0.6383 - mse: 0.6220\n",
      "Epoch 7: val_loss did not improve from 0.64125\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6383 - mse: 0.6221 - val_loss: 0.6420 - val_mse: 0.6257\n",
      "Epoch 8/25\n",
      "1921/1946 [============================>.] - ETA: 0s - loss: 0.6384 - mse: 0.6221\n",
      "Epoch 8: val_loss did not improve from 0.64125\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6383 - mse: 0.6220 - val_loss: 0.6417 - val_mse: 0.6254\n",
      "Epoch 9/25\n",
      "1940/1946 [============================>.] - ETA: 0s - loss: 0.6382 - mse: 0.6219\n",
      "Epoch 9: val_loss did not improve from 0.64125\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6382 - mse: 0.6220 - val_loss: 0.6415 - val_mse: 0.6253\n",
      "Epoch 10/25\n",
      "1946/1946 [==============================] - ETA: 0s - loss: 0.6383 - mse: 0.6220\n",
      "Epoch 10: val_loss did not improve from 0.64125\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6383 - mse: 0.6220 - val_loss: 0.6416 - val_mse: 0.6254\n",
      "Epoch 11/25\n",
      "1932/1946 [============================>.] - ETA: 0s - loss: 0.6380 - mse: 0.6218\n",
      "Epoch 11: val_loss did not improve from 0.64125\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6383 - mse: 0.6220 - val_loss: 0.6416 - val_mse: 0.6253\n",
      "Epoch 12/25\n",
      "1943/1946 [============================>.] - ETA: 0s - loss: 0.6382 - mse: 0.6219\n",
      "Epoch 12: val_loss did not improve from 0.64125\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6382 - mse: 0.6219 - val_loss: 0.6423 - val_mse: 0.6261\n",
      "Epoch 13/25\n",
      "1940/1946 [============================>.] - ETA: 0s - loss: 0.6382 - mse: 0.6219\n",
      "Epoch 13: val_loss did not improve from 0.64125\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6382 - mse: 0.6220 - val_loss: 0.6420 - val_mse: 0.6257\n",
      "Epoch 14/25\n",
      "1928/1946 [============================>.] - ETA: 0s - loss: 0.6381 - mse: 0.6219\n",
      "Epoch 14: val_loss did not improve from 0.64125\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6383 - mse: 0.6220 - val_loss: 0.6414 - val_mse: 0.6252\n",
      "Epoch 15/25\n",
      "1935/1946 [============================>.] - ETA: 0s - loss: 0.6383 - mse: 0.6220\n",
      "Epoch 15: val_loss did not improve from 0.64125\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6383 - mse: 0.6220 - val_loss: 0.6413 - val_mse: 0.6251\n",
      "Epoch 16/25\n",
      "1933/1946 [============================>.] - ETA: 0s - loss: 0.6380 - mse: 0.6218\n",
      "Epoch 16: val_loss improved from 0.64125 to 0.64122, saving model to checkpoints/ext_4h_l1n2_2hidden_it17.e016_vl0.641.h5\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6382 - mse: 0.6220 - val_loss: 0.6412 - val_mse: 0.6250\n",
      "Epoch 17/25\n",
      "1941/1946 [============================>.] - ETA: 0s - loss: 0.6383 - mse: 0.6221\n",
      "Epoch 17: val_loss did not improve from 0.64122\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6382 - mse: 0.6220 - val_loss: 0.6416 - val_mse: 0.6254\n",
      "Epoch 18/25\n",
      "1920/1946 [============================>.] - ETA: 0s - loss: 0.6380 - mse: 0.6218\n",
      "Epoch 18: val_loss did not improve from 0.64122\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6382 - mse: 0.6220 - val_loss: 0.6416 - val_mse: 0.6254\n",
      "Epoch 19/25\n",
      "1932/1946 [============================>.] - ETA: 0s - loss: 0.6381 - mse: 0.6219\n",
      "Epoch 19: val_loss did not improve from 0.64122\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6382 - mse: 0.6220 - val_loss: 0.6416 - val_mse: 0.6254\n",
      "Epoch 20/25\n",
      "1942/1946 [============================>.] - ETA: 0s - loss: 0.6382 - mse: 0.6220\n",
      "Epoch 20: val_loss did not improve from 0.64122\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6382 - mse: 0.6220 - val_loss: 0.6421 - val_mse: 0.6259\n",
      "Epoch 21/25\n",
      "1932/1946 [============================>.] - ETA: 0s - loss: 0.6381 - mse: 0.6218\n",
      "Epoch 21: val_loss did not improve from 0.64122\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6382 - mse: 0.6219 - val_loss: 0.6418 - val_mse: 0.6256\n",
      "Epoch 22/25\n",
      "1928/1946 [============================>.] - ETA: 0s - loss: 0.6381 - mse: 0.6219\n",
      "Epoch 22: val_loss improved from 0.64122 to 0.64117, saving model to checkpoints/ext_4h_l1n2_2hidden_it17.e022_vl0.641.h5\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6382 - mse: 0.6220 - val_loss: 0.6412 - val_mse: 0.6249\n",
      "Epoch 23/25\n",
      "1926/1946 [============================>.] - ETA: 0s - loss: 0.6382 - mse: 0.6220\n",
      "Epoch 23: val_loss did not improve from 0.64117\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6382 - mse: 0.6220 - val_loss: 0.6412 - val_mse: 0.6250\n",
      "Epoch 24/25\n",
      "1925/1946 [============================>.] - ETA: 0s - loss: 0.6382 - mse: 0.6220\n",
      "Epoch 24: val_loss did not improve from 0.64117\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6382 - mse: 0.6220 - val_loss: 0.6414 - val_mse: 0.6252\n",
      "Epoch 25/25\n",
      "1944/1946 [============================>.] - ETA: 0s - loss: 0.6382 - mse: 0.6220\n",
      "Epoch 25: val_loss did not improve from 0.64117\n",
      "1946/1946 [==============================] - 5s 2ms/step - loss: 0.6382 - mse: 0.6220 - val_loss: 0.6420 - val_mse: 0.6258\n",
      "Time elapsed to train: 117.45 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.421 3.135 1.684 3.485 2.442 1.779 1.285 0.995 0.610 0.302 0.142 0.053 0.000]\n",
      "<R> = [2.421 3.135 1.684 3.485 2.443 1.779 1.285 0.995 0.610 0.302 0.142 0.053 0.000]\n",
      "s_R = [0.043 0.006 0.000 0.024 0.036 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [5.4884996 4.379217  4.7197266 ... 3.6638107 3.4673586 5.705307 ]\n",
      "ri = [0.1566     0.11399937 0.09399986 ... 0.14400005 0.10769939 0.18040085]\n",
      "gr = [0.40940094 0.30720043 0.33909988 ... 0.39439964 0.3547001  0.54629993]\n",
      "gaia_g = [5.092581  4.0506763 4.3923035 ... 3.2777119 3.1194954 5.188401 ]\n",
      "bp_rp = [0.87466145 0.76038456 0.7539873  ... 0.8580713  0.80200386 1.0124731 ]\n",
      "mag_pred: [4.988204  4.102195  4.3776937 ... 3.4953387 3.6466246 4.954255 ]\n",
      "mag_pred: [4.988204  4.102195  4.3776937 ... 3.4953387 3.6466246 4.954255 ]\n",
      "Time elapsed to make plots: 16.43 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 183594 bad. Replacing with 14.76263.\n",
      "Band 1: 4 of 183594 bad. Replacing with 15.15992.\n",
      "Band 2: 4 of 183594 bad. Replacing with 14.19274.\n",
      "Band 3: 113 of 183594 bad. Replacing with 15.23890.\n",
      "Band 4: 216 of 183594 bad. Replacing with 14.74910.\n",
      "Band 5: 7858 of 183594 bad. Replacing with 14.61460.\n",
      "Band 6: 243 of 183594 bad. Replacing with 14.49620.\n",
      "Band 7: 71 of 183594 bad. Replacing with 14.44220.\n",
      "Band 8: 365 of 183594 bad. Replacing with 13.53800.\n",
      "Band 9: 383 of 183594 bad. Replacing with 13.15900.\n",
      "Band 10: 1558 of 183594 bad. Replacing with 13.07700.\n",
      "Band 11: 207 of 183594 bad. Replacing with 15.74246.\n",
      "Band 12: 227 of 183594 bad. Replacing with 16.41537.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 183591 of 183594 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [8.091883  7.2754645 3.456701  ... 9.027347  5.110178  5.795067 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0157\n",
      "  1% : 0.107\n",
      "  10% : 0.228\n",
      "  50% : 0.608\n",
      "  90% : 2.95\n",
      "  99% : 36.5\n",
      "  100% : 7.77e+03\n",
      "<chi^2/d.o.f.> = 1.03\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 11307 stars (6.16%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20400 bad. Replacing with 14.76272.\n",
      "Band 1: 1 of 20400 bad. Replacing with 15.16133.\n",
      "Band 2: 1 of 20400 bad. Replacing with 14.19002.\n",
      "Band 3: 12 of 20400 bad. Replacing with 15.23615.\n",
      "Band 4: 30 of 20400 bad. Replacing with 14.75020.\n",
      "Band 5: 901 of 20400 bad. Replacing with 14.62020.\n",
      "Band 6: 32 of 20400 bad. Replacing with 14.49545.\n",
      "Band 7: 8 of 20400 bad. Replacing with 14.43955.\n",
      "Band 8: 44 of 20400 bad. Replacing with 13.53900.\n",
      "Band 9: 38 of 20400 bad. Replacing with 13.16000.\n",
      "Band 10: 158 of 20400 bad. Replacing with 13.08300.\n",
      "Band 11: 12 of 20400 bad. Replacing with 15.74840.\n",
      "Band 12: 15 of 20400 bad. Replacing with 16.41809.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20400 of 20400 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 3.0179863  5.9422636  9.306705  ... 10.548925   9.977206   3.2716918]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0365\n",
      "  1% : 0.106\n",
      "  10% : 0.232\n",
      "  50% : 0.614\n",
      "  90% : 3.06\n",
      "  99% : 37.9\n",
      "  100% : 3.9e+03\n",
      "<chi^2/d.o.f.> = 1.04\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 56.16 s\n",
      "learning rate = 3.337327143526636e-05\n",
      "setting learning rate to 2.732372244729256e-05\n",
      "Iteration 19 of 20.\n",
      "Epoch 1/25\n",
      "1944/1945 [============================>.] - ETA: 0s - loss: 0.6400 - mse: 0.6238\n",
      "Epoch 1: val_loss improved from inf to 0.64299, saving model to checkpoints/ext_4h_l1n2_2hidden_it18.e001_vl0.643.h5\n",
      "1945/1945 [==============================] - 5s 3ms/step - loss: 0.6400 - mse: 0.6238 - val_loss: 0.6430 - val_mse: 0.6268\n",
      "Epoch 2/25\n",
      "1926/1945 [============================>.] - ETA: 0s - loss: 0.6396 - mse: 0.6234\n",
      "Epoch 2: val_loss did not improve from 0.64299\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6400 - mse: 0.6238 - val_loss: 0.6434 - val_mse: 0.6272\n",
      "Epoch 3/25\n",
      "1923/1945 [============================>.] - ETA: 0s - loss: 0.6399 - mse: 0.6237\n",
      "Epoch 3: val_loss did not improve from 0.64299\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6400 - mse: 0.6238 - val_loss: 0.6432 - val_mse: 0.6270\n",
      "Epoch 4/25\n",
      "1927/1945 [============================>.] - ETA: 0s - loss: 0.6401 - mse: 0.6239\n",
      "Epoch 4: val_loss did not improve from 0.64299\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 0.6400 - mse: 0.6238 - val_loss: 0.6432 - val_mse: 0.6270\n",
      "Epoch 5/25\n",
      "1920/1945 [============================>.] - ETA: 0s - loss: 0.6402 - mse: 0.6241\n",
      "Epoch 5: val_loss improved from 0.64299 to 0.64296, saving model to checkpoints/ext_4h_l1n2_2hidden_it18.e005_vl0.643.h5\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6400 - mse: 0.6238 - val_loss: 0.6430 - val_mse: 0.6268\n",
      "Epoch 6/25\n",
      "1944/1945 [============================>.] - ETA: 0s - loss: 0.6399 - mse: 0.6238\n",
      "Epoch 6: val_loss did not improve from 0.64296\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 0.6399 - mse: 0.6238 - val_loss: 0.6431 - val_mse: 0.6269\n",
      "Epoch 7/25\n",
      "1918/1945 [============================>.] - ETA: 0s - loss: 0.6400 - mse: 0.6238\n",
      "Epoch 7: val_loss did not improve from 0.64296\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 0.6400 - mse: 0.6238 - val_loss: 0.6432 - val_mse: 0.6270\n",
      "Epoch 8/25\n",
      "1934/1945 [============================>.] - ETA: 0s - loss: 0.6401 - mse: 0.6239\n",
      "Epoch 8: val_loss improved from 0.64296 to 0.64285, saving model to checkpoints/ext_4h_l1n2_2hidden_it18.e008_vl0.643.h5\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 0.6399 - mse: 0.6238 - val_loss: 0.6429 - val_mse: 0.6267\n",
      "Epoch 9/25\n",
      "1927/1945 [============================>.] - ETA: 0s - loss: 0.6401 - mse: 0.6239\n",
      "Epoch 9: val_loss did not improve from 0.64285\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 0.6400 - mse: 0.6238 - val_loss: 0.6430 - val_mse: 0.6268\n",
      "Epoch 10/25\n",
      "1938/1945 [============================>.] - ETA: 0s - loss: 0.6400 - mse: 0.6238\n",
      "Epoch 10: val_loss did not improve from 0.64285\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6399 - mse: 0.6237 - val_loss: 0.6431 - val_mse: 0.6270\n",
      "Epoch 11/25\n",
      "1932/1945 [============================>.] - ETA: 0s - loss: 0.6401 - mse: 0.6239\n",
      "Epoch 11: val_loss improved from 0.64285 to 0.64272, saving model to checkpoints/ext_4h_l1n2_2hidden_it18.e011_vl0.643.h5\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6400 - mse: 0.6238 - val_loss: 0.6427 - val_mse: 0.6265\n",
      "Epoch 12/25\n",
      "1925/1945 [============================>.] - ETA: 0s - loss: 0.6402 - mse: 0.6241\n",
      "Epoch 12: val_loss did not improve from 0.64272\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6400 - mse: 0.6238 - val_loss: 0.6437 - val_mse: 0.6276\n",
      "Epoch 13/25\n",
      "1927/1945 [============================>.] - ETA: 0s - loss: 0.6400 - mse: 0.6239\n",
      "Epoch 13: val_loss did not improve from 0.64272\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6400 - mse: 0.6238 - val_loss: 0.6438 - val_mse: 0.6277\n",
      "Epoch 14/25\n",
      "1935/1945 [============================>.] - ETA: 0s - loss: 0.6399 - mse: 0.6237\n",
      "Epoch 14: val_loss did not improve from 0.64272\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6400 - mse: 0.6239 - val_loss: 0.6430 - val_mse: 0.6268\n",
      "Epoch 15/25\n",
      "1932/1945 [============================>.] - ETA: 0s - loss: 0.6399 - mse: 0.6238\n",
      "Epoch 15: val_loss did not improve from 0.64272\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6400 - mse: 0.6238 - val_loss: 0.6431 - val_mse: 0.6269\n",
      "Epoch 16/25\n",
      "1928/1945 [============================>.] - ETA: 0s - loss: 0.6399 - mse: 0.6238\n",
      "Epoch 16: val_loss did not improve from 0.64272\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6399 - mse: 0.6237 - val_loss: 0.6430 - val_mse: 0.6268\n",
      "Epoch 17/25\n",
      "1919/1945 [============================>.] - ETA: 0s - loss: 0.6398 - mse: 0.6236\n",
      "Epoch 17: val_loss did not improve from 0.64272\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6399 - mse: 0.6238 - val_loss: 0.6430 - val_mse: 0.6269\n",
      "Epoch 18/25\n",
      "1923/1945 [============================>.] - ETA: 0s - loss: 0.6399 - mse: 0.6238\n",
      "Epoch 18: val_loss did not improve from 0.64272\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6399 - mse: 0.6238 - val_loss: 0.6433 - val_mse: 0.6271\n",
      "Epoch 19/25\n",
      "1922/1945 [============================>.] - ETA: 0s - loss: 0.6400 - mse: 0.6238\n",
      "Epoch 19: val_loss did not improve from 0.64272\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6399 - mse: 0.6238 - val_loss: 0.6431 - val_mse: 0.6269\n",
      "Epoch 20/25\n",
      "1929/1945 [============================>.] - ETA: 0s - loss: 0.6399 - mse: 0.6237\n",
      "Epoch 20: val_loss did not improve from 0.64272\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6399 - mse: 0.6238 - val_loss: 0.6432 - val_mse: 0.6270\n",
      "Epoch 21/25\n",
      "1925/1945 [============================>.] - ETA: 0s - loss: 0.6397 - mse: 0.6236\n",
      "Epoch 21: val_loss did not improve from 0.64272\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6400 - mse: 0.6238 - val_loss: 0.6430 - val_mse: 0.6269\n",
      "Epoch 22/25\n",
      "1933/1945 [============================>.] - ETA: 0s - loss: 0.6401 - mse: 0.6240\n",
      "Epoch 22: val_loss did not improve from 0.64272\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6399 - mse: 0.6238 - val_loss: 0.6430 - val_mse: 0.6269\n",
      "Epoch 23/25\n",
      "1941/1945 [============================>.] - ETA: 0s - loss: 0.6399 - mse: 0.6238\n",
      "Epoch 23: val_loss did not improve from 0.64272\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 0.6399 - mse: 0.6238 - val_loss: 0.6431 - val_mse: 0.6270\n",
      "Epoch 24/25\n",
      "1940/1945 [============================>.] - ETA: 0s - loss: 0.6399 - mse: 0.6238\n",
      "Epoch 24: val_loss did not improve from 0.64272\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6399 - mse: 0.6238 - val_loss: 0.6431 - val_mse: 0.6270\n",
      "Epoch 25/25\n",
      "1940/1945 [============================>.] - ETA: 0s - loss: 0.6398 - mse: 0.6236\n",
      "Epoch 25: val_loss did not improve from 0.64272\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6399 - mse: 0.6238 - val_loss: 0.6432 - val_mse: 0.6271\n",
      "Time elapsed to train: 115.52 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.417 3.129 1.681 3.477 2.438 1.776 1.282 0.993 0.608 0.301 0.142 0.053 0.000]\n",
      "<R> = [2.417 3.129 1.681 3.477 2.438 1.776 1.282 0.993 0.608 0.301 0.142 0.053 0.000]\n",
      "s_R = [0.042 0.005 0.000 0.023 0.034 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [5.4884996 4.379217  4.7197266 ... 3.6638107 3.4673586 5.705307 ]\n",
      "ri = [0.1566     0.11399937 0.09399986 ... 0.14400005 0.10769939 0.18040085]\n",
      "gr = [0.40940094 0.30720043 0.33909988 ... 0.39439964 0.3547001  0.54629993]\n",
      "gaia_g = [5.092581  4.0506763 4.3923035 ... 3.2777119 3.1194954 5.188401 ]\n",
      "bp_rp = [0.87466145 0.76038456 0.7539873  ... 0.8580713  0.80200386 1.0124731 ]\n",
      "mag_pred: [4.9902344 4.101046  4.3820586 ... 3.5002701 3.6444733 4.954834 ]\n",
      "mag_pred: [4.9902344 4.101046  4.3820586 ... 3.5002701 3.6444733 4.954834 ]\n",
      "Time elapsed to make plots: 16.37 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 183594 bad. Replacing with 14.76263.\n",
      "Band 1: 4 of 183594 bad. Replacing with 15.15992.\n",
      "Band 2: 4 of 183594 bad. Replacing with 14.19274.\n",
      "Band 3: 113 of 183594 bad. Replacing with 15.23890.\n",
      "Band 4: 216 of 183594 bad. Replacing with 14.74910.\n",
      "Band 5: 7858 of 183594 bad. Replacing with 14.61460.\n",
      "Band 6: 243 of 183594 bad. Replacing with 14.49620.\n",
      "Band 7: 71 of 183594 bad. Replacing with 14.44220.\n",
      "Band 8: 365 of 183594 bad. Replacing with 13.53800.\n",
      "Band 9: 383 of 183594 bad. Replacing with 13.15900.\n",
      "Band 10: 1558 of 183594 bad. Replacing with 13.07700.\n",
      "Band 11: 207 of 183594 bad. Replacing with 15.74246.\n",
      "Band 12: 227 of 183594 bad. Replacing with 16.41537.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 183591 of 183594 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [8.597347  7.18705   3.7325091 ... 8.860004  5.178639  5.3138456]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0119\n",
      "  1% : 0.108\n",
      "  10% : 0.228\n",
      "  50% : 0.607\n",
      "  90% : 2.93\n",
      "  99% : 36.4\n",
      "  100% : 7.76e+03\n",
      "<chi^2/d.o.f.> = 1.03\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 11283 stars (6.15%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20400 bad. Replacing with 14.76272.\n",
      "Band 1: 1 of 20400 bad. Replacing with 15.16133.\n",
      "Band 2: 1 of 20400 bad. Replacing with 14.19002.\n",
      "Band 3: 12 of 20400 bad. Replacing with 15.23615.\n",
      "Band 4: 30 of 20400 bad. Replacing with 14.75020.\n",
      "Band 5: 901 of 20400 bad. Replacing with 14.62020.\n",
      "Band 6: 32 of 20400 bad. Replacing with 14.49545.\n",
      "Band 7: 8 of 20400 bad. Replacing with 14.43955.\n",
      "Band 8: 44 of 20400 bad. Replacing with 13.53900.\n",
      "Band 9: 38 of 20400 bad. Replacing with 13.16000.\n",
      "Band 10: 158 of 20400 bad. Replacing with 13.08300.\n",
      "Band 11: 12 of 20400 bad. Replacing with 15.74840.\n",
      "Band 12: 15 of 20400 bad. Replacing with 16.41809.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20400 of 20400 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 2.8918014  5.4255195  9.395153  ... 10.1255    10.044543   3.2325177]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0386\n",
      "  1% : 0.106\n",
      "  10% : 0.234\n",
      "  50% : 0.615\n",
      "  90% : 3.04\n",
      "  99% : 38.2\n",
      "  100% : 3.91e+03\n",
      "<chi^2/d.o.f.> = 1.04\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 56.41 s\n",
      "learning rate = 2.732372195168864e-05\n",
      "setting learning rate to 2.2370771856165592e-05\n",
      "Iteration 20 of 20.\n",
      "Epoch 1/25\n",
      "1940/1945 [============================>.] - ETA: 0s - loss: 0.6391 - mse: 0.6230\n",
      "Epoch 1: val_loss improved from inf to 0.64194, saving model to checkpoints/ext_4h_l1n2_2hidden_it19.e001_vl0.642.h5\n",
      "1945/1945 [==============================] - 5s 3ms/step - loss: 0.6391 - mse: 0.6230 - val_loss: 0.6419 - val_mse: 0.6258\n",
      "Epoch 2/25\n",
      "1941/1945 [============================>.] - ETA: 0s - loss: 0.6390 - mse: 0.6228\n",
      "Epoch 2: val_loss improved from 0.64194 to 0.64192, saving model to checkpoints/ext_4h_l1n2_2hidden_it19.e002_vl0.642.h5\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6391 - mse: 0.6230 - val_loss: 0.6419 - val_mse: 0.6258\n",
      "Epoch 3/25\n",
      "1939/1945 [============================>.] - ETA: 0s - loss: 0.6389 - mse: 0.6228\n",
      "Epoch 3: val_loss improved from 0.64192 to 0.64169, saving model to checkpoints/ext_4h_l1n2_2hidden_it19.e003_vl0.642.h5\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6391 - mse: 0.6230 - val_loss: 0.6417 - val_mse: 0.6256\n",
      "Epoch 4/25\n",
      "1933/1945 [============================>.] - ETA: 0s - loss: 0.6392 - mse: 0.6231\n",
      "Epoch 4: val_loss did not improve from 0.64169\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6391 - mse: 0.6230 - val_loss: 0.6418 - val_mse: 0.6257\n",
      "Epoch 5/25\n",
      "1922/1945 [============================>.] - ETA: 0s - loss: 0.6390 - mse: 0.6229\n",
      "Epoch 5: val_loss did not improve from 0.64169\n",
      "1945/1945 [==============================] - 4s 2ms/step - loss: 0.6391 - mse: 0.6230 - val_loss: 0.6417 - val_mse: 0.6256\n",
      "Epoch 6/25\n",
      "1944/1945 [============================>.] - ETA: 0s - loss: 0.6391 - mse: 0.6230\n",
      "Epoch 6: val_loss improved from 0.64169 to 0.64153, saving model to checkpoints/ext_4h_l1n2_2hidden_it19.e006_vl0.642.h5\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6391 - mse: 0.6230 - val_loss: 0.6415 - val_mse: 0.6254\n",
      "Epoch 7/25\n",
      "1927/1945 [============================>.] - ETA: 0s - loss: 0.6392 - mse: 0.6231\n",
      "Epoch 7: val_loss improved from 0.64153 to 0.64148, saving model to checkpoints/ext_4h_l1n2_2hidden_it19.e007_vl0.641.h5\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6391 - mse: 0.6230 - val_loss: 0.6415 - val_mse: 0.6254\n",
      "Epoch 8/25\n",
      "1945/1945 [==============================] - ETA: 0s - loss: 0.6391 - mse: 0.6230\n",
      "Epoch 8: val_loss improved from 0.64148 to 0.64141, saving model to checkpoints/ext_4h_l1n2_2hidden_it19.e008_vl0.641.h5\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6391 - mse: 0.6230 - val_loss: 0.6414 - val_mse: 0.6253\n",
      "Epoch 9/25\n",
      "1926/1945 [============================>.] - ETA: 0s - loss: 0.6387 - mse: 0.6226\n",
      "Epoch 9: val_loss did not improve from 0.64141\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6391 - mse: 0.6230 - val_loss: 0.6414 - val_mse: 0.6253\n",
      "Epoch 10/25\n",
      "1921/1945 [============================>.] - ETA: 0s - loss: 0.6390 - mse: 0.6230\n",
      "Epoch 10: val_loss did not improve from 0.64141\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6391 - mse: 0.6230 - val_loss: 0.6417 - val_mse: 0.6256\n",
      "Epoch 11/25\n",
      "1944/1945 [============================>.] - ETA: 0s - loss: 0.6391 - mse: 0.6230\n",
      "Epoch 11: val_loss did not improve from 0.64141\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6391 - mse: 0.6230 - val_loss: 0.6417 - val_mse: 0.6257\n",
      "Epoch 12/25\n",
      "1919/1945 [============================>.] - ETA: 0s - loss: 0.6387 - mse: 0.6226\n",
      "Epoch 12: val_loss did not improve from 0.64141\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6391 - mse: 0.6230 - val_loss: 0.6417 - val_mse: 0.6256\n",
      "Epoch 13/25\n",
      "1928/1945 [============================>.] - ETA: 0s - loss: 0.6389 - mse: 0.6228\n",
      "Epoch 13: val_loss did not improve from 0.64141\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6391 - mse: 0.6230 - val_loss: 0.6420 - val_mse: 0.6260\n",
      "Epoch 14/25\n",
      "1938/1945 [============================>.] - ETA: 0s - loss: 0.6392 - mse: 0.6232\n",
      "Epoch 14: val_loss did not improve from 0.64141\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6391 - mse: 0.6230 - val_loss: 0.6416 - val_mse: 0.6255\n",
      "Epoch 15/25\n",
      "1937/1945 [============================>.] - ETA: 0s - loss: 0.6391 - mse: 0.6230\n",
      "Epoch 15: val_loss did not improve from 0.64141\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6391 - mse: 0.6230 - val_loss: 0.6416 - val_mse: 0.6255\n",
      "Epoch 16/25\n",
      "1929/1945 [============================>.] - ETA: 0s - loss: 0.6393 - mse: 0.6232\n",
      "Epoch 16: val_loss did not improve from 0.64141\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6391 - mse: 0.6230 - val_loss: 0.6418 - val_mse: 0.6258\n",
      "Epoch 17/25\n",
      "1941/1945 [============================>.] - ETA: 0s - loss: 0.6391 - mse: 0.6230\n",
      "Epoch 17: val_loss did not improve from 0.64141\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6391 - mse: 0.6230 - val_loss: 0.6420 - val_mse: 0.6260\n",
      "Epoch 18/25\n",
      "1939/1945 [============================>.] - ETA: 0s - loss: 0.6390 - mse: 0.6229\n",
      "Epoch 18: val_loss did not improve from 0.64141\n",
      "1945/1945 [==============================] - 5s 3ms/step - loss: 0.6391 - mse: 0.6230 - val_loss: 0.6417 - val_mse: 0.6257\n",
      "Epoch 19/25\n",
      "1939/1945 [============================>.] - ETA: 0s - loss: 0.6390 - mse: 0.6230\n",
      "Epoch 19: val_loss did not improve from 0.64141\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6390 - mse: 0.6230 - val_loss: 0.6416 - val_mse: 0.6256\n",
      "Epoch 20/25\n",
      "1936/1945 [============================>.] - ETA: 0s - loss: 0.6390 - mse: 0.6229\n",
      "Epoch 20: val_loss did not improve from 0.64141\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6391 - mse: 0.6230 - val_loss: 0.6417 - val_mse: 0.6257\n",
      "Epoch 21/25\n",
      "1944/1945 [============================>.] - ETA: 0s - loss: 0.6390 - mse: 0.6230\n",
      "Epoch 21: val_loss did not improve from 0.64141\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6390 - mse: 0.6230 - val_loss: 0.6417 - val_mse: 0.6256\n",
      "Epoch 22/25\n",
      "1931/1945 [============================>.] - ETA: 0s - loss: 0.6390 - mse: 0.6229\n",
      "Epoch 22: val_loss improved from 0.64141 to 0.64138, saving model to checkpoints/ext_4h_l1n2_2hidden_it19.e022_vl0.641.h5\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6391 - mse: 0.6230 - val_loss: 0.6414 - val_mse: 0.6253\n",
      "Epoch 23/25\n",
      "1923/1945 [============================>.] - ETA: 0s - loss: 0.6392 - mse: 0.6231\n",
      "Epoch 23: val_loss did not improve from 0.64138\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6390 - mse: 0.6230 - val_loss: 0.6416 - val_mse: 0.6256\n",
      "Epoch 24/25\n",
      "1944/1945 [============================>.] - ETA: 0s - loss: 0.6390 - mse: 0.6230\n",
      "Epoch 24: val_loss did not improve from 0.64138\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6391 - mse: 0.6230 - val_loss: 0.6414 - val_mse: 0.6254\n",
      "Epoch 25/25\n",
      "1930/1945 [============================>.] - ETA: 0s - loss: 0.6392 - mse: 0.6231\n",
      "Epoch 25: val_loss did not improve from 0.64138\n",
      "1945/1945 [==============================] - 5s 2ms/step - loss: 0.6390 - mse: 0.6230 - val_loss: 0.6418 - val_mse: 0.6257\n",
      "Time elapsed to train: 116.88 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.413 3.125 1.680 3.474 2.436 1.774 1.281 0.992 0.607 0.300 0.141 0.052 0.000]\n",
      "<R> = [2.413 3.125 1.680 3.474 2.436 1.774 1.281 0.992 0.607 0.300 0.141 0.052 0.000]\n",
      "s_R = [0.042 0.005 0.000 0.022 0.035 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [5.4884996 4.379217  4.7197266 ... 3.6638107 3.4673586 5.705307 ]\n",
      "ri = [0.1566     0.11399937 0.09399986 ... 0.14400005 0.10769939 0.18040085]\n",
      "gr = [0.40940094 0.30720043 0.33909988 ... 0.39439964 0.3547001  0.54629993]\n",
      "gaia_g = [5.092581  4.0506763 4.3923035 ... 3.2777119 3.1194954 5.188401 ]\n",
      "bp_rp = [0.87466145 0.76038456 0.7539873  ... 0.8580713  0.80200386 1.0124731 ]\n",
      "mag_pred: [4.9811487 4.0937824 4.3798995 ... 3.4899507 3.6333954 4.9488797]\n",
      "mag_pred: [4.9811487 4.0937824 4.3798995 ... 3.4899507 3.6333954 4.9488797]\n",
      "Time elapsed to make plots: 16.33 s\n"
     ]
    }
   ],
   "source": [
    "for k in range(0, n_iterations):\n",
    "    # Transform data to inputs and outputs\n",
    "    # On subsequent iterations, inflate errors using\n",
    "    # gradients dM/dtheta from trained model, and derive new\n",
    "    # estimates of the reddenings of the stars.\n",
    "    t0 = time()\n",
    "    io_train = get_inputs_outputs(\n",
    "        d_train,\n",
    "        pretrained_model=None if k == 0 else nn_model,\n",
    "        recalc_reddening=True,\n",
    "        rchisq_max=rchisq_max[k]\n",
    "    )                                                                         \n",
    "    io_test = get_inputs_outputs(\n",
    "        d_test,\n",
    "        pretrained_model=None if k == 0 else nn_model,\n",
    "        recalc_reddening=True,\n",
    "    )                                                                        \n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to prepare data: {t1-t0:.2f} s')\n",
    "    # Set learning rate based on the iteration\n",
    "    lr = 0.001 * np.exp(-0.2*k)\n",
    "    print('learning rate = {}'.format(K.get_value(nn_model.optimizer.lr)))\n",
    "    print('setting learning rate to {}'.format(lr))\n",
    "    K.set_value(nn_model.optimizer.lr, lr)\n",
    "\n",
    "    # Train the model\n",
    "    print('Iteration {} of {}.'.format(k+1, n_iterations))\n",
    "    t0 = time()\n",
    "    train_model(\n",
    "        nn_model,\n",
    "        io_train,\n",
    "        k,\n",
    "        n_iterations,\n",
    "        epochs=25,\n",
    "        checkpoint_fn='{:s}_{:d}hidden_it{:d}'.format(\n",
    "            nn_name, n_hidden, k\n",
    "        ),\n",
    "        batch_size=batch_size,\n",
    "        suff='{:s}_{:d}hidden_it{:d}'.format(nn_name, n_hidden, k)\n",
    "    )\n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to train: {t1-t0:.2f} s')\n",
    "    nn_model.save(\n",
    "        'models/{:s}_{:d}hidden_it{:d}.h5'.format(\n",
    "            nn_name, n_hidden, k\n",
    "        )\n",
    "    )\n",
    "    nn_model = keras.models.load_model(\n",
    "       'models/{:s}_{:d}hidden_it{:d}.h5'.format(nn_name, n_hidden, k)\n",
    "    )\n",
    "\n",
    "    # Plot results on test set\n",
    "    print('Diagnostic plots ...')\n",
    "    t0 = time()\n",
    "    diagnostic_plots(\n",
    "       nn_model,\n",
    "       io_test,\n",
    "       d_test,\n",
    "       #io_train,\n",
    "       #d_train,\n",
    "       suffix='{:s}_{:d}hidden_it{:d}'.format(nn_name, n_hidden, k)\n",
    "    )\n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to make plots: {t1-t0:.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1d8de09-5d9d-43a1-b6ad-5aa70393a40a",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating covariances and reddening estimates of test dataset ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20400 bad. Replacing with 14.76272.\n",
      "Band 1: 1 of 20400 bad. Replacing with 15.16133.\n",
      "Band 2: 1 of 20400 bad. Replacing with 14.19002.\n",
      "Band 3: 12 of 20400 bad. Replacing with 15.23615.\n",
      "Band 4: 30 of 20400 bad. Replacing with 14.75020.\n",
      "Band 5: 901 of 20400 bad. Replacing with 14.62020.\n",
      "Band 6: 32 of 20400 bad. Replacing with 14.49545.\n",
      "Band 7: 8 of 20400 bad. Replacing with 14.43955.\n",
      "Band 8: 44 of 20400 bad. Replacing with 13.53900.\n",
      "Band 9: 38 of 20400 bad. Replacing with 13.16000.\n",
      "Band 10: 158 of 20400 bad. Replacing with 13.08300.\n",
      "Band 11: 12 of 20400 bad. Replacing with 15.74840.\n",
      "Band 12: 15 of 20400 bad. Replacing with 16.41809.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20400 of 20400 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [2.8457003 5.307616  9.030081  ... 9.746163  9.925603  3.0540438]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0394\n",
      "  1% : 0.105\n",
      "  10% : 0.232\n",
      "  50% : 0.611\n",
      "  90% : 3.03\n",
      "  99% : 38.1\n",
      "  100% : 3.92e+03\n",
      "<chi^2/d.o.f.> = 1.04\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to update covariances and reddenings: 5.95 s\n"
     ]
    }
   ],
   "source": [
    "print('Updating covariances and reddening estimates of test dataset ...')\n",
    "t0 = time()\n",
    "io_test = get_inputs_outputs(\n",
    "    d_test,\n",
    "    pretrained_model=nn_model,\n",
    "    recalc_reddening=True\n",
    ")\n",
    "t1 = time()\n",
    "print(f'Time elapsed to update covariances and reddenings: {t1-t0:.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fe20ad0-6076-42e4-b5fa-0a8b44b55833",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: [0.6361275315284729, 0.6200906038284302]\n",
      "train loss: [0.6397904753684998, 0.6237534284591675]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance on (train, validation and test sets)\n",
    "loss = {}\n",
    "for n,io_eval in (('test',io_test), ('train',io_train)):\n",
    "    loss[n] = evaluate_model(\n",
    "        nn_model,\n",
    "        io_eval,\n",
    "        batch_size=batch_size,\n",
    "        rchisq_max=rchisq_max[-1]\n",
    "    )\n",
    "    print(f'{n} loss: {loss[n]}')\n",
    "fname = 'loss_{:s}_{:d}hidden_it{:d}.json'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "with open(fname, 'w') as f:\n",
    "    json.dump(loss, f, indent=2, sort_keys=True)\n",
    "\n",
    "fname = 'predictions_{:s}_{:d}hidden_it{:d}.h5'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "save_predictions(fname, nn_model, d_test, io_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ef83a49-55d7-41f4-be9e-87606f86734e",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving covariance components for small subset of test dataset ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 1000 bad. Replacing with 14.71998.\n",
      "Band 1: 0 of 1000 bad. Replacing with 15.10560.\n",
      "Band 2: 0 of 1000 bad. Replacing with 14.16390.\n",
      "Band 3: 0 of 1000 bad. Replacing with 15.20465.\n",
      "Band 4: 0 of 1000 bad. Replacing with 14.70285.\n",
      "Band 5: 42 of 1000 bad. Replacing with 14.57920.\n",
      "Band 6: 0 of 1000 bad. Replacing with 14.46040.\n",
      "Band 7: 0 of 1000 bad. Replacing with 14.40905.\n",
      "Band 8: 1 of 1000 bad. Replacing with 13.51600.\n",
      "Band 9: 2 of 1000 bad. Replacing with 13.14500.\n",
      "Band 10: 2 of 1000 bad. Replacing with 13.06950.\n",
      "Band 11: 0 of 1000 bad. Replacing with 15.72575.\n",
      "Band 12: 0 of 1000 bad. Replacing with 16.40207.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 1000 of 1000 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [8.91418552e+00 8.93860912e+00 3.82765865e+00 1.83189144e+01\n",
      " 1.32545975e+02 2.31003308e+00 6.85216141e+00 3.83733773e+00\n",
      " 8.82768822e+00 2.37251320e+01 1.88914013e+01 3.43310428e+00\n",
      " 1.17153320e+01 6.06505127e+01 9.06700516e+00 1.00866451e+01\n",
      " 2.93618660e+01 2.31544018e+00 9.57108116e+00 3.12431407e+00\n",
      " 6.72435570e+00 9.16121864e+00 3.85487127e+00 2.02065372e+00\n",
      " 2.29200888e+00 2.80805826e+00 2.10241203e+01 9.03558826e+00\n",
      " 4.49795914e+00 4.71040649e+01 7.27652931e+00 4.01893759e+00\n",
      " 2.92339706e+00 2.84799743e+00 1.79442251e+00 1.20843935e+01\n",
      " 5.75543594e+00 5.88201427e+00 1.12309666e+01 5.11254072e-01\n",
      " 2.23569584e+01 2.08171387e+01 9.91602135e+00 8.19170189e+00\n",
      " 4.41557837e+00 1.28955860e+01 2.28094745e+00 1.24874563e+01\n",
      " 2.45918045e+01 1.52903261e+01 1.49741840e+01 7.16289520e+00\n",
      " 2.89162016e+00 6.72435236e+00 5.24828863e+00 4.35919285e+00\n",
      " 4.75572157e+00 8.49527264e+00 3.93293309e+00 1.81479950e+01\n",
      " 1.17736566e+00 5.03263760e+00 8.41077328e+00 4.55299044e+00\n",
      " 7.87169075e+00 6.30647039e+00 6.25706244e+00 3.15294313e+00\n",
      " 1.05755157e+01 7.15360928e+00 3.81511450e+00 6.16180182e+00\n",
      " 1.65161114e+01 6.71262169e+00 8.40888214e+00 1.60314293e+01\n",
      " 9.82446289e+00 1.11130142e+01 4.21934366e+00 6.69357910e+01\n",
      " 1.23451061e+01 6.61411428e+00 5.60180712e+00 3.56417961e+01\n",
      " 1.42230911e+01 4.81096840e+00 1.08343086e+02 1.72252502e+01\n",
      " 5.76247835e+00 2.36814260e+00 8.33759594e+00 5.74926615e+00\n",
      " 4.85277843e+00 5.94279957e+00 1.01512537e+01 4.62436829e+01\n",
      " 1.42702169e+01 3.61054111e+00 2.46100044e+01 1.38852215e+01\n",
      " 8.16151142e+00 3.42886200e+01 5.61805992e+01 1.93180099e+02\n",
      " 1.09859014e+00 1.01011717e+00 1.54089251e+01 2.12232170e+01\n",
      " 3.40493584e+00 5.23764467e+00 2.08409691e+00 2.59230614e+00\n",
      " 3.30505991e+00 1.39554977e+01 2.21273375e+00 5.11277676e+00\n",
      " 1.18264141e+01 1.65844512e+00 1.28480358e+01 5.34034634e+00\n",
      " 3.82449055e+00 2.27902050e+01 1.04713039e+01 2.33731556e+00\n",
      " 8.49926472e+00 4.38805389e+00 7.74113846e+00 6.39458179e+00\n",
      " 1.28034792e+01 1.29528484e+01 3.13976078e+01 4.70664940e+01\n",
      " 3.51345420e+00 2.62011790e+00 5.26847935e+00 6.52216110e+01\n",
      " 2.74307251e+00 9.72016716e+00 2.88808727e+00 5.92901993e+00\n",
      " 7.70690441e+00 7.87510681e+00 6.21898079e+00 1.35989428e+00\n",
      " 6.10527658e+00 3.99964905e+00 6.81433058e+00 9.17899990e+00\n",
      " 1.02858934e+01 6.17516613e+00 4.86882448e+00 8.42707634e+00\n",
      " 1.18856883e+00 8.54125977e+00 3.85502458e+00 4.65476131e+00\n",
      " 1.24459057e+01 1.46365156e+01 1.01573582e+01 1.23925156e+02\n",
      " 2.67774963e+00 6.35339737e+00 2.35874939e+00 8.24793549e+01\n",
      " 4.62555456e+00 2.56697392e+00 8.80658245e+00 3.41333318e+00\n",
      " 1.61571121e+01 1.85633719e+00 8.83995914e+00 1.16088875e+02\n",
      " 1.46204519e+01 6.29926109e+00 6.20404339e+00 5.46469784e+00\n",
      " 6.53053761e+00 1.44100006e+02 1.02851280e+02 5.55075264e+00\n",
      " 1.68770456e+00 1.49735092e+02 5.32562017e+00 2.45056534e+00\n",
      " 1.24605598e+01 6.74456787e+00 7.17126226e+00 2.23186378e+01\n",
      " 1.89506245e+01 8.38366222e+00 5.52813530e+00 1.09603357e+01\n",
      " 1.66582413e+02 7.89273500e+00 3.52571201e+00 8.62461472e+00\n",
      " 1.47635860e+01 4.80340767e+00 1.33752317e+01 1.60593760e+00\n",
      " 9.28279018e+00 2.02963257e+00 9.65997601e+00 4.43036556e+00\n",
      " 8.28928375e+00 1.22849245e+01 4.84723663e+00 6.82139492e+00\n",
      " 8.02726364e+01 2.55754757e+00 2.36130524e+01 3.43555522e+00\n",
      " 7.04851770e+00 3.91396618e+00 7.66538334e+00 2.80117202e+00\n",
      " 1.16311371e+00 1.26406517e+01 4.26573706e+00 1.71299350e+00\n",
      " 1.00476770e+03 4.43991518e+00 5.76082611e+00 3.49777818e+00\n",
      " 1.98144493e+01 2.63637781e+00 3.78576684e+00 1.61717682e+01\n",
      " 5.05996513e+00 9.73880482e+00 9.79946804e+00 1.14862881e+01\n",
      " 1.11197624e+01 3.38352585e+00 4.67055845e+00 2.69601536e+00\n",
      " 2.40828943e+00 1.43419495e+01 6.32210445e+00 4.09063530e+00\n",
      " 1.65551865e+00 2.02473392e+01 2.12252140e+00 5.90618515e+00\n",
      " 2.96582718e+01 8.83485985e+00 2.87320065e+00 1.74223633e+01\n",
      " 5.47567511e+00 7.58456612e+00 9.85427570e+00 2.04172211e+01\n",
      " 2.28765988e+00 1.70190697e+01 6.01599503e+00 1.50141850e+01\n",
      " 7.82905655e+01 1.96401620e+00 1.17898884e+01 1.74393368e+00\n",
      " 8.42877865e+00 4.92589235e+00 3.58602676e+01 1.28977165e+01\n",
      " 2.18044138e+00 1.15169506e+01 9.58816814e+00 5.74884701e+00\n",
      " 3.29865265e+00 2.60980082e+00 6.66754246e+00 9.82977962e+00\n",
      " 2.00218334e+01 4.81191730e+00 4.38824177e+00 1.45848780e+01\n",
      " 3.90254211e+00 4.21162510e+00 2.49646149e+01 4.86363125e+00\n",
      " 6.68844986e+00 5.22441711e+01 3.99820256e+00 1.92329617e+01\n",
      " 1.80896902e+00 1.20918369e+01 2.82861567e+00 3.33599377e+00\n",
      " 5.37166166e+00 9.90529060e+00 2.44603043e+01 5.16003132e+00\n",
      " 1.09199562e+01 3.37167096e+00 2.66649284e+01 1.86222339e+00\n",
      " 7.10175943e+00 1.60770741e+01 2.26072121e+01 6.61768112e+01\n",
      " 3.60688248e+01 3.36417007e+00 4.50165796e+00 3.05787802e+00\n",
      " 9.52648354e+00 5.82482243e+00 1.02794123e+01 7.51390886e+00\n",
      " 1.57342672e+01 3.63456154e+00 1.87192745e+01 3.11170101e+00\n",
      " 4.97831106e+00 7.92949247e+00 7.05104351e+00 1.13101997e+01\n",
      " 9.98008919e+00 5.20285797e+00 1.20575066e+01 4.58107471e+00\n",
      " 3.65748787e+01 1.41500568e+01 7.38586712e+00 4.63124390e+01\n",
      " 4.69658375e+00 7.02230530e+01 1.63142242e+01 4.69665003e+00\n",
      " 3.34812408e+02 7.19385862e+00 9.04745865e+00 5.23073578e+00\n",
      " 7.25499344e+00 1.49849510e+00 1.16146774e+01 1.30357790e+01\n",
      " 6.11039352e+00 1.35928364e+01 5.42766905e+00 2.92392874e+00\n",
      " 4.80620146e+00 5.37643089e+01 7.47211075e+00 4.27476959e+01\n",
      " 6.07438660e+00 1.78646431e+01 5.62359428e+00 1.65463120e+02\n",
      " 2.23430977e+01 1.11864500e+01 7.40123844e+00 5.28142548e+00\n",
      " 2.12043495e+01 4.74862976e+01 5.08477592e+00 3.98273730e+00\n",
      " 7.91184139e+00 8.37358761e+00 4.00559139e+00 1.31979551e+01\n",
      " 8.27924728e+00 4.98573074e+01 2.90537310e+00 5.87262487e+00\n",
      " 3.10886860e+00 3.16016698e+00 6.15523529e+00 7.11986685e+00\n",
      " 7.87643313e-01 2.88937521e+00 2.76307702e+00 5.63429260e+00\n",
      " 8.11657047e+00 1.16752510e+01 5.36987782e+00 8.46416473e+00\n",
      " 3.36795306e+00 3.19196153e+00 6.31308556e+00 1.51203346e+01\n",
      " 8.76791191e+00 1.06431398e+01 2.57347832e+01 1.30709133e+01\n",
      " 4.48017836e+00 2.95249939e+01 1.49578428e+00 4.91933441e+00\n",
      " 1.11628494e+01 1.37886963e+01 2.21841073e+00 1.01636610e+01\n",
      " 7.35581350e+00 7.22119217e+01 7.57016087e+00 4.30084133e+00\n",
      " 3.56710091e+01 2.54898143e+00 3.26956391e+00 7.97891617e+00\n",
      " 3.13416958e+00 2.08795810e+00 3.25708818e+00 2.59168510e+01\n",
      " 2.29765205e+01 3.01704121e+00 8.02512360e+00 1.37949057e+01\n",
      " 7.58891106e+00 4.98656273e+00 1.25222502e+01 6.86566448e+00\n",
      " 4.25456467e+01 4.81714249e+00 1.07132816e+01 1.56291742e+01\n",
      " 4.88534279e+01 8.90161133e+00 7.54403496e+00 2.31923652e+00\n",
      " 1.30452557e+01 3.82996416e+00 3.88338900e+00 1.50658302e+01\n",
      " 9.53097057e+00 8.66781998e+00 1.17249317e+01 5.08989000e+00\n",
      " 3.16901779e+00 7.49199219e+01 1.76920700e+02 8.60520363e+00\n",
      " 5.19653893e+00 4.03530788e+00 4.10089836e+01 1.28952627e+01\n",
      " 5.33183146e+00 4.65156317e+00 3.49158955e+00 2.78995442e+00\n",
      " 3.22978783e+00 2.81131673e+00 7.66044044e+00 1.10706955e+02\n",
      " 1.99592340e+00 3.52639437e+00 1.35364838e+02 3.55292416e+00\n",
      " 2.89569497e+00 4.45029402e+00 4.20284348e+01 1.30827236e+01\n",
      " 1.61993158e+00 3.55550909e+00 5.15021706e+00 1.46882334e+01\n",
      " 1.02131748e+01 6.90186405e+00 5.63319111e+00 6.02101707e+00\n",
      " 6.53675270e+00 6.99146080e+00 4.50951004e+00 4.37699127e+00\n",
      " 3.05429435e+00 4.91532040e+00 1.27942657e+01 4.03756285e+00\n",
      " 3.47872124e+01 1.34689312e+01 3.74219513e+00 8.73964691e+00\n",
      " 9.83368492e+00 6.22151470e+00 5.61714268e+00 4.89721203e+00\n",
      " 1.30800772e+01 1.18211250e+01 4.27195072e+00 1.42652016e+01\n",
      " 1.05331297e+01 9.19359303e+00 6.51348972e+00 1.61013851e+01\n",
      " 4.07820320e+00 2.23084831e+01 4.14684391e+00 7.33716736e+01\n",
      " 2.23365474e+00 7.78422356e+00 1.06857729e+01 6.47733116e+00\n",
      " 5.94973564e+00 2.77909889e+01 4.49928932e+01 1.64751072e+01\n",
      " 1.09754662e+02 1.30512180e+01 1.65458393e+01 5.62258339e+00\n",
      " 1.14305134e+01 8.40218544e+00 3.38530993e+00 1.05869942e+01\n",
      " 2.46868195e+02 4.04925652e+01 1.13930998e+01 5.71356726e+00\n",
      " 4.61216736e+00 1.65872502e+00 3.92597923e+01 8.96600246e+00\n",
      " 1.49548874e+01 1.30596533e+03 6.67577219e+00 2.11964726e+00\n",
      " 8.93830681e+00 3.93984675e+00 2.00443792e+00 3.32032871e+00\n",
      " 5.86881256e+00 2.99855828e+00 1.35773270e+02 5.74598122e+00\n",
      " 5.83267212e+00 8.41521645e+00 3.35849524e+00 4.55776453e+00\n",
      " 1.98141384e+01 4.35853291e+00 1.64826107e+01 1.22173014e+01\n",
      " 1.38713531e+01 2.88679218e+01 2.90389490e+00 9.54484653e+00\n",
      " 3.68476105e+00 1.33719006e+01 5.30960655e+00 3.40984082e+00\n",
      " 3.54617143e+00 8.63929749e+00 1.11607666e+01 5.39406204e+00\n",
      " 1.86417246e+00 1.54426861e+01 6.25246572e+00 1.52983487e+00\n",
      " 4.74234428e+01 5.68865776e+00 3.47986197e+00 1.49260254e+01\n",
      " 1.85106339e+02 2.54766045e+01 3.64689980e+01 2.61481619e+00\n",
      " 4.24746418e+00 8.65293884e+00 1.01452503e+01 4.64235973e+00\n",
      " 1.45857407e+02 3.13361549e+00 1.72627945e+01 6.78339386e+00\n",
      " 2.45982018e+01 6.54640675e+00 3.80534458e+00 1.77663441e+01\n",
      " 5.69405508e+00 1.88030319e+01 3.36911082e+00 5.13758755e+00\n",
      " 8.40942097e+00 8.16228333e+01 2.87071919e+00 2.10329498e+02\n",
      " 7.12388468e+00 8.74345112e+00 2.39210606e+00 3.49696231e+00\n",
      " 2.28507690e+01 7.85329866e+00 7.84832306e+01 5.33766747e+00\n",
      " 3.20512748e+00 2.75716362e+01 2.94516158e+00 1.23989677e+02\n",
      " 2.36189747e+00 4.99764585e+00 1.89107239e+00 1.83910408e+01\n",
      " 7.77823591e+00 3.45811105e+00 3.56888866e+00 2.38017416e+00\n",
      " 9.36628056e+00 1.45887537e+01 7.46080017e+00 1.69105649e+00\n",
      " 1.46956360e+00 4.59770298e+00 1.06458359e+01 9.27053070e+01\n",
      " 1.08018560e+01 1.20617466e+01 2.16612778e+01 3.11865950e+00\n",
      " 4.77860546e+00 2.19494572e+01 1.94531035e+00 4.43182802e+00\n",
      " 1.76933937e+01 5.58011341e+00 5.59567547e+00 4.04180098e+00\n",
      " 3.28763819e+00 1.14822769e+00 3.29123592e+00 6.20997047e+00\n",
      " 1.82364440e+00 1.01119642e+01 2.17914915e+00 5.60676765e+00\n",
      " 4.44264555e+00 1.56957569e+01 7.48969507e+00 5.49537277e+00\n",
      " 8.72551250e+00 2.91317320e+00 2.95910263e+00 8.62078953e+00\n",
      " 1.12851887e+01 7.52938414e+00 2.80941463e+00 2.02764678e+00\n",
      " 1.89181538e+01 5.95191383e+00 5.04801273e+00 1.37617569e+01\n",
      " 1.35977468e+01 9.24742508e+00 5.90255976e+00 5.01315117e+00\n",
      " 8.03614616e+00 2.12240658e+01 1.55366983e+01 6.72754908e+00\n",
      " 1.77770531e+00 7.85268664e-01 2.31013727e+00 1.02124414e+01\n",
      " 1.93993521e+00 2.79695964e+00 1.89433403e+01 5.01406670e+00\n",
      " 2.69221187e+00 3.98801041e+00 5.80707121e+00 7.16544342e+00\n",
      " 3.96960083e+02 1.46424316e+02 3.29706979e+00 1.48686874e+00\n",
      " 1.51530380e+01 8.39016056e+00 3.19430828e+00 7.26442383e+02\n",
      " 1.05349846e+01 1.22237720e+01 8.05479507e+01 5.64804554e+00\n",
      " 1.04131441e+01 4.87868595e+00 1.38881054e+01 1.38016090e+01\n",
      " 5.86859608e+00 7.90717926e+01 7.09213829e+00 6.07020855e+00\n",
      " 3.54239559e+00 2.63793716e+01 1.46939850e+00 4.96968985e+00\n",
      " 5.39225006e+01 4.87777039e+02 2.21441765e+01 2.25982628e+01\n",
      " 1.30830994e+02 5.31459141e+00 6.15203209e+01 9.52717400e+00\n",
      " 6.31624126e+00 1.11759491e+01 1.00817089e+01 5.00605249e+00\n",
      " 3.21322441e+00 5.31348610e+00 6.68105698e+00 7.98315430e+00\n",
      " 7.68454647e+00 1.75994034e+01 6.16034794e+00 5.88291693e+00\n",
      " 1.84108047e+01 4.34049177e+00 3.54627728e+00 7.01674461e+00\n",
      " 2.26137047e+01 7.26130342e+00 4.75570679e+00 9.46303272e+00\n",
      " 8.34359360e+00 8.05038379e+03 3.21410465e+00 4.22244263e+01\n",
      " 2.51981354e+01 1.01423126e+02 1.43375120e+01 1.01010094e+01\n",
      " 9.26229095e+00 3.37409935e+01 3.93149018e+00 5.80640888e+00\n",
      " 3.45293808e+01 5.08676834e+01 1.00131626e+01 1.57850170e+00\n",
      " 5.27943850e+00 2.78032017e+00 7.61504555e+00 7.10293865e+00\n",
      " 4.27637329e+01 3.84453988e+00 2.42988434e+01 5.76250362e+00\n",
      " 4.92798090e+00 1.68688011e+01 6.04297018e+00 4.02565289e+00\n",
      " 4.02275562e+00 3.32844424e+00 1.87329502e+01 6.62861347e+00\n",
      " 4.99636364e+00 5.96712112e+00 1.02018509e+01 1.12215290e+01\n",
      " 5.24044180e+00 7.75688782e+01 8.86973572e+00 9.51277161e+00\n",
      " 5.46370888e+00 3.91304436e+01 1.57805271e+01 4.38136005e+00\n",
      " 2.48715897e+01 1.26428429e+02 2.83912048e+01 5.27712011e+00\n",
      " 7.16403961e+00 9.46271038e+00 5.19615841e+00 3.20517612e+00\n",
      " 2.88897920e+00 2.16794052e+01 7.96631241e+00 1.37738142e+01\n",
      " 7.27750349e+00 1.93237152e+01 2.28321195e+00 1.74377880e+01\n",
      " 5.66021061e+00 5.86384106e+00 6.82001019e+00 7.82616282e+00\n",
      " 1.15209332e+01 3.80077744e+00 9.11232758e+00 8.44372845e+00\n",
      " 1.08294973e+01 2.77551985e+00 2.38243771e+00 7.15400219e+00\n",
      " 3.68322134e+00 2.98892927e+00 1.31411247e+01 2.33091812e+01\n",
      " 9.39501762e+00 1.01187029e+01 3.38596392e+00 5.65078783e+00\n",
      " 7.34791613e+00 2.42072601e+01 9.67074890e+01 9.08798599e+00\n",
      " 8.56862259e+00 2.34713793e+00 2.55418434e+01 2.62150049e+00\n",
      " 5.13905678e+01 9.34498501e+00 7.40456486e+00 1.15629692e+01\n",
      " 3.05526328e+00 2.62963080e+00 5.70186663e+00 4.21083355e+00\n",
      " 2.43481312e+01 5.77772980e+01 7.93412590e+00 2.70839005e+01\n",
      " 1.52144127e+01 4.94971371e+00 8.93505478e+00 1.14056072e+01\n",
      " 1.41520634e+01 1.15045538e+01 2.44181085e+00 2.18955040e+00\n",
      " 7.46147251e+00 4.26654339e+00 6.18559551e+00 1.04020987e+01\n",
      " 1.74691734e+01 3.27469420e+00 2.11439371e+00 8.61623077e+01\n",
      " 2.80582952e+00 2.46802092e+00 2.54402399e+00 2.69082212e+00\n",
      " 6.19970226e+00 8.58815384e+00 3.26825809e+00 4.34093285e+01\n",
      " 4.14632320e+00 1.54666939e+01 4.98799324e+00 1.28298054e+01\n",
      " 1.04780235e+01 3.85430193e+00 6.92473269e+00 6.50168533e+01\n",
      " 1.02086182e+01 1.00394499e+00 6.44542313e+00 3.44723587e+01\n",
      " 6.55764246e+00 1.94060135e+00 4.04078817e+00 2.61573148e+00\n",
      " 3.87455273e+00 7.20789528e+00 1.01676659e+02 1.97547226e+01\n",
      " 5.43575382e+00 7.27209244e+01 1.13636694e+01 3.67664957e+00\n",
      " 3.26912193e+01 2.26866722e+01 1.02916479e+01 1.54267025e+01\n",
      " 2.87799025e+00 7.30276299e+00 5.00991249e+00 2.57083368e+00\n",
      " 4.37747526e+00 1.10790720e+01 1.23019104e+01 3.83130693e+00\n",
      " 2.64976454e+00 1.48796787e+01 9.46060944e+00 5.07602348e+01\n",
      " 2.54832196e+00 2.50097427e+01 9.92663956e+00 3.34970856e+01\n",
      " 1.23049564e+01 8.18043327e+00 1.39380894e+01 4.58577156e+00\n",
      " 7.10995674e+00 6.65466595e+00 1.42771111e+01 3.02868867e+00\n",
      " 9.46188259e+00 1.97933912e+00 2.47159004e+00 4.24431572e+01\n",
      " 1.07610588e+01 1.68728123e+01 5.27790976e+00 1.41287346e+01\n",
      " 3.39173393e+01 5.31254883e+01 6.84501362e+00 2.66568069e+01\n",
      " 3.94357944e+00 1.08746166e+01 1.65980988e+01 3.04320812e+00\n",
      " 1.98721695e+00 1.54220886e+01 2.09621453e+00 1.44140816e+01\n",
      " 6.12584591e+00 8.11345100e+00 7.16286469e+00 1.43212147e+01\n",
      " 3.95830107e+00 6.07266140e+00 1.30577450e+01 1.15507154e+01\n",
      " 5.81210899e+00 3.07730198e+00 9.07884884e+00 3.01821089e+00\n",
      " 1.41299683e+02 6.93740797e+00 3.93435860e+00 7.04665375e+00\n",
      " 4.24794436e+00 1.86226692e+01 3.16292667e+00 4.08187199e+00\n",
      " 2.40870285e+00 3.56527591e+00 3.20213842e+00 5.70684910e+00\n",
      " 7.23079910e+01 3.55751300e+00 5.94783211e+00 3.03660798e+00\n",
      " 4.36522789e+01 1.22878418e+01 5.06944733e+01 4.48949814e+00\n",
      " 4.99868774e+00 2.32167077e+00 4.62847137e+00 3.07807159e+00\n",
      " 4.08636141e+00 1.62598457e+01 9.11269684e+01 6.43590403e+00\n",
      " 2.31461668e+00 7.00061893e+00 6.18594313e+00 1.63965523e+00\n",
      " 1.20025425e+01 6.06544495e+00 9.00160789e+00 1.35836649e+01\n",
      " 3.01755667e+00 4.85117102e+00 4.34439516e+00 5.71802378e+00\n",
      " 2.87642193e+00 1.27286682e+01 1.45069923e+01 7.16032028e+00\n",
      " 6.04952850e+01 2.79946041e+00 3.11419630e+00 3.18058643e+01\n",
      " 8.38366318e+00 1.08043804e+01 3.61680746e+00 1.82995338e+01\n",
      " 5.74964046e+00 2.81278563e+00 7.57846975e+00 4.23279047e+00\n",
      " 3.09968472e+00 8.29477596e+00 1.01935730e+01 1.47674561e+01\n",
      " 3.84404182e+00 5.66518593e+00 3.89931870e+00 3.05272055e+00\n",
      " 4.93612003e+00 4.58182383e+00 2.22403011e+01 6.98385715e+00\n",
      " 1.91025722e+00 6.45772409e+00 4.29259729e+00 1.24600639e+01\n",
      " 4.84864899e+02 1.74570656e+01 5.16545582e+00 2.13988686e+00\n",
      " 1.28379345e+01 7.87817669e+00 8.30380535e+00 7.94758415e+00]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0426\n",
      "  1% : 0.113\n",
      "  10% : 0.224\n",
      "  50% : 0.596\n",
      "  90% : 2.86\n",
      "  99% : 16.1\n",
      "  100% : 671\n",
      "<chi^2/d.o.f.> = 1.03\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n"
     ]
    }
   ],
   "source": [
    "print('Saving covariance components for small subset of test dataset ...')\n",
    "# Fix random seed (same subset every run)\n",
    "np.random.seed(3)\n",
    "idx = np.arange(d_test.size)\n",
    "np.random.shuffle(idx)\n",
    "idx = idx[:1000]\n",
    "d_comp = d_test[idx]\n",
    "io_comp = get_inputs_outputs(\n",
    "    d_comp,\n",
    "    pretrained_model=nn_model,\n",
    "    recalc_reddening=True,\n",
    "    return_cov_components=True\n",
    ")\n",
    "fname = 'predictions_{:s}_{:d}hidden_it{:d}_comp.h5'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "save_predictions(fname, nn_model, d_comp, io_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bf3ec27-6103-4713-9c21-1222e68e39f1",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data and reddening estimates of subset of test dataset ...\n"
     ]
    }
   ],
   "source": [
    "print('Saving data and reddening estimates of subset of test dataset ...')\n",
    "np.random.seed(5)\n",
    "idx = np.arange(d_test.size)\n",
    "np.random.shuffle(idx)\n",
    "idx = idx[:10000]\n",
    "d_small = d_test[idx]\n",
    "r_fit_small = io_test['r'][idx]\n",
    "r_var_small = io_test['r_var'][idx]\n",
    "fname = 'test_data_small_{:s}_{:d}hidden.h5'.format(\n",
    "    nn_name, n_hidden\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82da0ebc-697f-4f8b-ae07-05ba4f0e7217",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving subset to test_data_small_ext_4h_l1n2_2hidden.h5 ...\n"
     ]
    }
   ],
   "source": [
    "print(f'Saving subset to {fname} ...')\n",
    "with h5py.File(fname, 'w') as f:\n",
    "    dset = f.create_dataset(\n",
    "        'data',\n",
    "        data=d_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )\n",
    "    for key in d_attrs:\n",
    "        dset.attrs[key] = d_attrs[key]\n",
    "\n",
    "    # Store updated reddening estimates\n",
    "    dset = f.create_dataset(\n",
    "        'r_fit',\n",
    "        data=r_fit_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )\n",
    "    dset = f.create_dataset(\n",
    "        'r_var',\n",
    "        data=r_var_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 2,
      "defaultCellHeight": 40,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
