{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b43db49-f88d-44af-8188-9c546a2bb2e1",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "source": [
    "Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12337364-915d-45e0-aa68-ff9ad349e998",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "# # Tell Tensorflow not to allocate all GPU memory right away.\n",
    "# # This is very important in shared environments!\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU') \n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from glob import glob\n",
    "from time import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b0b4d-d609-4535-82f4-76f5979bb893",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### The dataloder used by Green+2020 which will be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f39968a5-1090-448f-a6dc-b53829db1f41",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def load_data(fname, return_attrs=False):\n",
    "    print(f'Loading {fname} ...')\n",
    "    attrs = {}\n",
    "    with h5py.File(fname, 'r') as f:\n",
    "        dset = f['io_data']\n",
    "        for key in dset.attrs.keys():\n",
    "            attrs[key] = dset.attrs[key]\n",
    "        d = dset[:]\n",
    "    \n",
    "    if return_attrs:\n",
    "        return d, attrs\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a7c2e5-f232-46ff-b235-d6604c1b5d35",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Obtaining a correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e0eccc-4ffd-4904-a210-7b430692c477",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def get_corr_matrix(cov):\n",
    "    rho = cov.copy()\n",
    "    sqrt_cov_diag = np.sqrt(cov[np.diag_indices(cov.shape[0])])\n",
    "    rho /= sqrt_cov_diag[:,None]\n",
    "    rho /= sqrt_cov_diag[None,:]\n",
    "    rho[np.diag_indices(cov.shape[0])] = sqrt_cov_diag\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f2ec3-9dba-4970-ab73-494dddd61534",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Cannot be explained in one markdown cell above, need to look through it more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72257ca9-2c06-4d52-9589-9b9086876356",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def get_inputs_outputs(d, pretrained_model=None,\n",
    "                          recalc_reddening=False,\n",
    "                          rchisq_max=None,\n",
    "                          return_cov_components=False):\n",
    "    n_bands = 13 # Gaia (G, BP, RP), PS1 (grizy), 2MASS (JHK), unWISE (W1,W2)\n",
    "    n_atm_params = 3 # (T_eff, logg, [M/H])\n",
    "    \n",
    "    large_err = 999.\n",
    "\n",
    "    # Stellar spectroscopic parameters\n",
    "    print('Fill in stellar atmospheric parameters ...')\n",
    "    x = np.empty((d.size,3), dtype='f4')\n",
    "    x[:] = d['atm_param'][:]\n",
    "\n",
    "    x_p = np.empty((d.size,3), dtype='f4')\n",
    "    x_p = d['atm_param_p'][:]\n",
    "\n",
    "    # Magnitudes\n",
    "    print('Fill in stellar magnitudes ...')\n",
    "    y = np.empty((d.size,n_bands), dtype='f4')\n",
    "    y[:] = d['mag'][:]\n",
    "\n",
    "    # Covariance of y\n",
    "    print('Empty covariance matrix ...')\n",
    "    cov_y = np.zeros((d.size,n_bands,n_bands), dtype='f4')\n",
    "\n",
    "    # \\delta m\n",
    "    print('Covariance: \\delta m ...')\n",
    "    for i in range(n_bands):\n",
    "        cov_y[:,i,i] = d['mag_err'][:,i]**2\n",
    "\n",
    "    # Replace NaN magnitudes with median (in each band).\n",
    "    # Also set corresponding variances to large number.\n",
    "    print('Replace NaN magnitudes ...')\n",
    "    for b in range(n_bands):\n",
    "        idx = (\n",
    "              ~np.isfinite(y[:,b])\n",
    "            | ~np.isfinite(cov_y[:,b,b])\n",
    "        )\n",
    "        n_bad = np.count_nonzero(idx)\n",
    "        n_tot = idx.size\n",
    "        y0 = np.median(y[~idx,b])\n",
    "        if np.isnan(y0):\n",
    "            y0 = 0.\n",
    "        print(f'Band {b}: {n_bad} of {n_tot} bad. Replacing with {y0:.5f}.')\n",
    "        y[idx,b] = y0\n",
    "        cov_y[idx,b,b] = large_err**2.\n",
    "\n",
    "    # Transform both y and its covariance\n",
    "    B = np.identity(n_bands, dtype='f4')\n",
    "    B[1:,0] = -1.\n",
    "    \n",
    "    print('Transform y -> B y ...')\n",
    "    y = np.einsum('ij,nj->ni', B, y) # y' = B y\n",
    "    print('Transform C -> B C B^T ...')\n",
    "    #cov_y = np.einsum('ik,nkl,jl->nij', B, cov_y, B) # C' = B C B^T\n",
    "    cov_y = np.einsum('nik,jk->nij', cov_y, B)\n",
    "    cov_y = np.einsum('ik,nkj->nij', B, cov_y)\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp = {\n",
    "            'delta_m': cov_y.copy()\n",
    "        }\n",
    "    \n",
    "    # Add in dM/dtheta and dR/dtheta terms\n",
    "    if pretrained_model is not None:\n",
    "        print('Calculate J = dM/dtheta ...')\n",
    "        J_M = calc_dmag_color_dtheta(pretrained_model, x_p)\n",
    "        cov_x = d['atm_param_cov_p']\n",
    "        print('Covariance: J C_theta J^T ...')\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_M)\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['dM/dtheta'] = np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_M)\n",
    "\n",
    "    # If pretrained model provided, could calculate reduced chi^2\n",
    "    # with maximum-likelihood (mu, E) here.\n",
    "\n",
    "    # \\delta \\mu (must be added in after transformation,\n",
    "    #             due to possibly infinite terms).\n",
    "    print('{:d} NaN parallaxes'.format(\n",
    "        np.count_nonzero(np.isnan(d['parallax']))\n",
    "    ))\n",
    "    err_over_plx = d['parallax_err'] / d['parallax']\n",
    "    print('Covariance: DM uncertainty term ...')\n",
    "    cov_y[:,0,0] += (5./np.log(10.) * err_over_plx)**2.\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp['dm'] = np.zeros_like(cov_y)\n",
    "        cov_comp['dm'][:,0,0] = (5./np.log(10.) * err_over_plx)**2.\n",
    "\n",
    "    # Subtract distance modulus from m_G\n",
    "    #dm = -5. * (np.log10(d['parallax']) - 2.)\n",
    "    #dm_corr = 0.5 * err_over_plx**2 + 0.75 * err_over_plx**4\n",
    "    #dm_corr_pct = np.percentile(dm_corr, [1., 5., 10., 50., 90., 95., 99.])\n",
    "    #print(dm_corr_pct)\n",
    "\n",
    "    print('Estimate DM ...')\n",
    "    dm = 10. - 5.*np.log10(d['parallax'])# + 5./np.log(10.)*dm_corr\n",
    "    y[:,0] -= dm\n",
    "\n",
    "    # Don't attempt to predict M_G for poor plx/err or when plx < 0\n",
    "    print('Filter out M_G for poor parallax measurements ...')\n",
    "    idx = (\n",
    "          (err_over_plx > 0.2)\n",
    "        | (d['parallax'] < 1.e-8)\n",
    "        | ~np.isfinite(d['parallax'])\n",
    "        | ~np.isfinite(d['parallax_err'])\n",
    "    )\n",
    "    n_use = idx.size - np.count_nonzero(idx)\n",
    "    print(r'Using {:d} of {:d} ({:.3f}%) of stellar parallaxes.'.format(\n",
    "        n_use, idx.size, n_use/idx.size*100.\n",
    "    ))\n",
    "    cov_y[idx,0,0] = large_err**2\n",
    "    y[idx,0] = np.nanmedian(y[:,0])\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp['dm'][idx,0,0] = large_err**2\n",
    "\n",
    "    # Reddenings\n",
    "    print('Copy reddenings ...')\n",
    "    r = np.empty((d.size,), dtype='f4')\n",
    "    r[:] = d['r'][:]\n",
    "    \n",
    "    if pretrained_model is None:\n",
    "        # If R has not yet been estimated, then\n",
    "        # cut out stars with sigma_r > 0.2 mag.\n",
    "        idx = (d['r_err'] > 0.2)\n",
    "        print(f'Cutting {np.count_nonzero(idx)} stars with large sigma_r.')\n",
    "        for k in range(cov_y.shape[1]):\n",
    "            cov_y[idx,k,k] += large_err**2\n",
    "\n",
    "    if pretrained_model is not None:\n",
    "        # Update reddenings, based on vector R and (y_obs - y_pred).\n",
    "        # Use provided reddenings as a prior.\n",
    "\n",
    "        # First, need to calculate inv_cov_y\n",
    "        print('Invert C_y matrices ...')\n",
    "        inv_cov_y = np.stack([np.linalg.inv(c) for c in cov_y])\n",
    "\n",
    "        # Predict M & R for each star based on atm. params\n",
    "        M_pred = predict_M(pretrained_model, x_p)\n",
    "        R = predict_R(pretrained_model, x_p)\n",
    "        \n",
    "        r_var = d['r_err']**2\n",
    "        \n",
    "        # Calculate posterior on reddening\n",
    "        if recalc_reddening:\n",
    "            print('Calculate posterior on reddening ...')\n",
    "            r_pred, r_var = update_reddenings(\n",
    "                M_pred, R, y,\n",
    "                inv_cov_y,\n",
    "                r, r_var\n",
    "            )\n",
    "            \n",
    "            # Clip mean and variance of reddenings\n",
    "            print('Clip reddenings and reddening variances ...')\n",
    "            r[:] = np.clip(r_pred, 0., 10.) # TODO: Update upper limit?\n",
    "        \n",
    "        # TODO: Different lower bounds on error for different sources?\n",
    "        r_var[:] = np.clip(r_var, 0.02**2 + (0.1*r)**2, 10.**2)\n",
    "        \n",
    "        # Reddening uncertainty term in covariance of y\n",
    "        print('Covariance: reddening uncertainty term ...')\n",
    "        cov_y += r_var[:,None,None] * R[:,:,None]*R[:,None,:]\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['r'] = r_var[:,None,None] * R[:,:,None]*R[:,None,:]\n",
    "        \n",
    "        # Propagate uncertainty in theta to uncertainty in R\n",
    "        print('Calculate J = dA/dtheta ...')\n",
    "        J_A = calc_dext_red_dtheta(pretrained_model, x_p, r)\n",
    "        cov_x = d['atm_param_cov_p']\n",
    "        print('Covariance: J C_theta J^T ...')\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_A)\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_A)\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_M)\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['dA/dtheta'] = np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_A)\n",
    "            cov_comp['dMA/dtheta'] = np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_A)\n",
    "            cov_comp['dAM/dtheta'] = np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_M)\n",
    "        \n",
    "        # Calculate chi^2 for each star\n",
    "        chisq = calc_chisq(M_pred+r[:,None]*R-y, inv_cov_y)\n",
    "        print('chisq =', chisq)\n",
    "\n",
    "        # Calculate d.o.f. of each star\n",
    "        print('Calculate d.o.f. of each star ...')\n",
    "        n_dof = np.zeros(d.size, dtype='i4')\n",
    "        for k in range(n_bands):\n",
    "            n_dof += (cov_y[:,k,k] < (large_err-1.)**2).astype('i4')\n",
    "        #print('n_dof =', n_dof)\n",
    "\n",
    "        # Calculate reduced chi^2 for each star\n",
    "        print('Calculate chi^2/d.o.f. for each star ...')\n",
    "        rchisq = chisq / (n_dof - 1.)\n",
    "        pct = (0., 1., 10., 50., 90., 99., 100.)\n",
    "        rchisq_pct = np.percentile(rchisq[np.isfinite(rchisq)], pct)\n",
    "        print('chi^2/dof percentiles:')\n",
    "        for p,rc in zip(pct,rchisq_pct):\n",
    "            print(rf'  {p:.0f}% : {rc:.3g}')\n",
    "        idx_rchisq = (rchisq < 10.)\n",
    "        print(f'<chi^2/d.o.f.> = {np.mean(rchisq[idx_rchisq]):.3g}')\n",
    "        \n",
    "        # Filter on reduced chi^2\n",
    "        if rchisq_max is not None:\n",
    "            print('Filter on chi^2/d.o.f. ...')\n",
    "            idx = np.isfinite(rchisq) & (rchisq > 0.) & (rchisq < rchisq_max)\n",
    "            n_filt = np.count_nonzero(~idx)\n",
    "            pct_filt = 100. * n_filt / idx.size\n",
    "            print(\n",
    "                rf'Filtering {n_filt:d} stars ({pct_filt:.3g}%) ' +\n",
    "                rf'based on chi^2/dof > {rchisq_max:.1f}'\n",
    "            )\n",
    "            x = x[idx]\n",
    "            x_p = x_p[idx]\n",
    "            r = r[idx]\n",
    "            y = y[idx]\n",
    "            cov_y = cov_y[idx]\n",
    "            r_var = r_var[idx]\n",
    "            rchisq = rchisq[idx]\n",
    "            \n",
    "            if return_cov_components:\n",
    "                for key in cov_comp:\n",
    "                    cov_comp[key] = cov_comp[key][idx]\n",
    "\n",
    "    # Cholesky transform of inverse covariance: L L^T = C^(-1).\n",
    "    print('Cholesky transform of each stellar covariance matrix ...')\n",
    "    LT = np.empty_like(cov_y)\n",
    "    inv_cov_y = np.empty_like(cov_y)\n",
    "    for k,c in enumerate(cov_y):\n",
    "        try:\n",
    "            # Inflate diagonal of cov slightly, to ensure\n",
    "            # positive-definiteness\n",
    "            c_diag = c[np.diag_indices_from(c)]\n",
    "            c[np.diag_indices_from(c)] += 1.e-4 + 1.e-3 * c_diag\n",
    "            \n",
    "            inv_cov_y[k] = np.linalg.inv(c)\n",
    "            LT[k] = np.linalg.cholesky(inv_cov_y[k]).T\n",
    "            #ic = np.linalg.inv(c)\n",
    "            #LT.append(np.linalg.cholesky(ic).T)\n",
    "            #inv_cov_y.append(ic)\n",
    "        except np.linalg.LinAlgError as e:\n",
    "            rho = get_corr_matrix(c)\n",
    "            print('Offending correlation matrix:')\n",
    "            print(np.array2string(\n",
    "                rho[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >7.4f}'.format(z)}\n",
    "            ))\n",
    "            print('Offending covariance matrix:')\n",
    "            print(np.array2string(\n",
    "                c[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >9.6f}'.format(z)}\n",
    "            ))\n",
    "            print('Covariance matrix of (normed) atmospheric parameters:')\n",
    "            print(d['atm_param_cov_p'][k])\n",
    "            if pretrained_model is not None:\n",
    "                print(f'Variance of r: {r_var[k]:.8f}')\n",
    "            \n",
    "            # Inflate errors along the diagonal and try again\n",
    "            c_diag = c[np.diag_indices_from(c)]\n",
    "            c[np.diag_indices_from(c)] += 0.02 + 0.02 * c_diag\n",
    "            rho = get_corr_matrix(c)\n",
    "            print('Inflated correlation matrix:')\n",
    "            print(np.array2string(\n",
    "                rho[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >7.4f}'.format(z)}\n",
    "            ))\n",
    "            \n",
    "            inv_cov_y[k] = np.linalg.inv(c)\n",
    "            LT[k] = np.linalg.cholesky(inv_cov_y[k]).T\n",
    "            #raise e\n",
    "\n",
    "    #print('Stack L^T matrices ...')\n",
    "    #LT = np.stack(LT)\n",
    "    #print('Stack C^(-1) matrices ...')\n",
    "    #inv_cov_y = np.stack(inv_cov_y)\n",
    "\n",
    "    # L^T y\n",
    "    print('Calculate L^T y ...')\n",
    "    LTy = np.einsum('nij,nj->ni', LT, y)\n",
    "\n",
    "    print('Gather inputs and outputs and return ...')\n",
    "    inputs_outputs = {\n",
    "        'x':x, 'x_p':x_p, 'r':r, 'y':y,\n",
    "        'LT':LT, 'LTy':LTy,\n",
    "        'cov_y':cov_y, 'inv_cov_y':inv_cov_y,\n",
    "    }\n",
    "    \n",
    "    if return_cov_components:\n",
    "        inputs_outputs['cov_comp'] = cov_comp\n",
    "    \n",
    "    if pretrained_model is not None:\n",
    "        inputs_outputs['r_var'] = r_var\n",
    "        inputs_outputs['rchisq'] = rchisq\n",
    "\n",
    "    # Check that there are no NaNs or Infs in results\n",
    "    for key in inputs_outputs:\n",
    "        if isinstance(inputs_outputs[key], dict):\n",
    "            continue\n",
    "        if key == 'rchisq': # Infs appear when d.o.f. = 1\n",
    "            continue\n",
    "        if np.any(~np.isfinite(inputs_outputs[key])):\n",
    "            raise ValueError(f'NaNs or Infs detected in {key}.')\n",
    "\n",
    "    return inputs_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caad35d-51ad-4e5f-8e27-57ac56e80468",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Predicts the absolute magnitude in the Gaia G-band and the colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb5329ec-4d17-4a14-9ec3-936b60844ca9",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def predict_M(nn_model, x_p):\n",
    "    \"\"\"\n",
    "    Predicts (absmag0,color1,color2,...) for input\n",
    "    normalized stellar parameters.\n",
    "\n",
    "    Inputs:\n",
    "        nn_model (keras.Model): Neural network model.\n",
    "        x_p (np.ndarray): Normalized stellar parameters.\n",
    "            Shape = (n_stars, 3).\n",
    "    \n",
    "    Outputs:\n",
    "        M (np.ndarray): Shape = (n_stars, n_bands).\n",
    "    \"\"\"\n",
    "    inputs = nn_model.get_layer(name='theta').input\n",
    "    outputs = nn_model.get_layer(name='BM').output\n",
    "    mag_color_model = keras.Model(inputs, outputs)\n",
    "    M = mag_color_model.predict(x_p)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14482c31-4986-4451-b4f7-295c2b3530b0",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Predicting the redenning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b36fc92-d995-4531-a1e4-994b63a9a954",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def predict_R(nn_model, x_p=None):\n",
    "    inputs = nn_model.get_layer(name='theta').input\n",
    "    outputs = nn_model.get_layer(name='R').output\n",
    "    R_model = keras.Model(inputs, outputs)\n",
    "    if x_p is None:\n",
    "        R = R_model.predict(np.array([[0.,0.,0.]]))[0]\n",
    "        R[1:] -= R[0]\n",
    "    else:\n",
    "        R = R_model.predict(x_p)\n",
    "        R[:,1:] -= R[:,0][:,None]\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2cab63-a66c-4c34-a7f1-50cb9568337b",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Saving the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52ee4e30-e866-45c2-a60f-37f5d8996b9f",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def save_predictions(fname, nn_model, d_test, io_test):\n",
    "    M_pred = predict_M(nn_model, io_test['x_p'])\n",
    "    R_pred = predict_R(nn_model, io_test['x_p'])\n",
    "    R0 = predict_R(nn_model)\n",
    "    \n",
    "    with h5py.File(fname, 'w') as f:\n",
    "        f.create_dataset('/data', data=d_test, chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/y_obs', data=io_test['y'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/cov_y', data=io_test['cov_y'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/r_fit', data=io_test['r'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/M_pred', data=M_pred, chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/R_pred', data=R_pred, chunks=True,\n",
    "                        compression='gzip', compression_opts=3)\n",
    "        f.attrs['R0'] = R0\n",
    "        \n",
    "        if 'cov_comp' in io_test:\n",
    "            for key in io_test['cov_comp']:\n",
    "                f.create_dataset(\n",
    "                    f'/cov_comp/{key.replace(r\"/\",\"_\")}',\n",
    "                    data=io_test['cov_comp'][key],\n",
    "                    chunks=True,\n",
    "                    compression='gzip',\n",
    "                    compression_opts=3\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9dbfb5-0fa8-47b6-b59e-5507d8182916",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Updates the redenning, as in the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12ce532d-8584-46ea-b538-a65837b35597",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def update_reddenings(M_pred, R, y_obs, inv_cov_y, r0, r_var0):\n",
    "    \"\"\"\n",
    "    Updates the posterior on reddening of each star, given\n",
    "    the predicted absolute magnitudes, reddening vector,\n",
    "    observed magnitudes, inverse covariance matrix, and priors on\n",
    "    reddening.\n",
    "    \n",
    "    The model is given by\n",
    "    \n",
    "        y_obs = M_pred + R r,\n",
    "    \n",
    "    with the uncertainties in y_obs described by inv_cov_y, and\n",
    "    with a prior on r described by (r0, r_var0). We solve for\n",
    "    the Gaussian posterior on r: p(r|y_obs,M_pred,R,r0,r_var0).\n",
    "    \n",
    "    Let n = # of bands, k = # of stars.\n",
    "\n",
    "    Inputs:\n",
    "        M_pred (np.ndarray): Shape-(k,n) array containing predicted\n",
    "            zero-reddening asbolute magnitude & colors for each star.\n",
    "        R (np.ndarray): Shape-(k,n) array containing reddening vector\n",
    "            for each star.\n",
    "        inv_cov_y (np.ndarray): Shape-(k,n,n) array containing\n",
    "            covariance matrix of y_obs-y_pred for each star.\n",
    "        y_obs (np.ndarray): Shape-(k,n) array containing observed\n",
    "            magnitude (minus distance modulus) & colors for each star.\n",
    "        r0 (np.ndarray): Shape-(k,) array containing mean of prior on\n",
    "            reddening for each star.\n",
    "        r_var0 (np.ndarray): Shape-(k,) array containing variance of\n",
    "            prior on reddening for each star.\n",
    "\n",
    "    Outputs:\n",
    "        r_mean (np.ndarray): Shape-(k,) array containing mean posterior\n",
    "            reddening of each star.\n",
    "        r_var (np.ndarray): Shape-(k,) array containing variance of\n",
    "            reddening posterior for each star.\n",
    "    \"\"\"\n",
    "    print('Updating reddenings:')\n",
    "    print('  * R^T C_y^(-1) ...')\n",
    "    RT_Cinv = np.einsum('ni,nij->nj', R, inv_cov_y)\n",
    "    print('  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...')\n",
    "    num = r0/r_var0 + np.einsum('ni,ni->n', RT_Cinv, y_obs - M_pred)\n",
    "    print('  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...')\n",
    "    den = np.einsum('ni,ni->n', RT_Cinv, R) + 1./r_var0\n",
    "    print('  * r_mean, r_var ...')\n",
    "    r_mean = num / den\n",
    "    r_var = 1. / den\n",
    "\n",
    "    return r_mean, r_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d6a72-37ab-4d7a-bfb3-cd329804a9ca",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### calculates the chi^2, as in docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c76cf577-6ee4-41db-a3ea-bada40e97afb",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def calc_chisq(dy, inv_cov_y):\n",
    "    \"\"\"\n",
    "    Returns the chi^2 for each observation, given\n",
    "    an array of residuals and inverse covariance matrices.\n",
    "    \n",
    "        chi^2 = dy^T C^{-1} dy.\n",
    "    \n",
    "    Inputs:\n",
    "        dy (np.ndarray): Residual values. Shape = (n_obs, n_dim),\n",
    "            where n_obs is the number of observations, and n_dim is\n",
    "            the dimensionality of the vector space.\n",
    "        inv_cov_y (np.ndarray): Inverse covariance matrices.\n",
    "            Shape = (n_obs, n_dim, n_dim).\n",
    "    \n",
    "    Returns:\n",
    "        chisq (np.ndarray): Chi^2 for each observation. Shape=(n_obs,).\n",
    "    \"\"\"\n",
    "    C_inv_dy = np.einsum('nij,nj->ni', inv_cov_y, dy)\n",
    "    chisq = np.einsum('ni,ni->n', dy, C_inv_dy)\n",
    "    return chisq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50c262-4e28-419e-83d5-8b75ec32470b",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Creates the architecture of the NN as described in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45204db0-8dfb-448f-879b-11102036d543",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def get_nn_model(n_hidden_layers=1, hidden_size=32, l1=1.e0, l2=1.e-4, n_bands=13):\n",
    "    # Stellar model: B M(theta)\n",
    "    atm = keras.Input(shape=(3,), name='theta')\n",
    "    x = atm\n",
    "    for i in range(n_hidden_layers):\n",
    "        x = keras.layers.Dense(\n",
    "            hidden_size,\n",
    "            activation='sigmoid',\n",
    "            kernel_regularizer=keras.regularizers.l2(l=l2),\n",
    "            name=f'stellar_model_hidden_{i+1}'\n",
    "        )(x)\n",
    "    mag_color = keras.layers.Dense(n_bands, name='BM')(x)\n",
    "\n",
    "    # Reddening measurement E\n",
    "    red = keras.Input(shape=(1,), name='E')\n",
    "    \n",
    "    # Extinction vector: R(theta)\n",
    "    r = atm\n",
    "    #for i in range(n_hidden_layers):\n",
    "    #    r = keras.layers.Dense(\n",
    "    #        6,\n",
    "    #        use_bias=True,\n",
    "    #        activation='sigmoid',\n",
    "    #        kernel_regularizer=keras.regularizers.l2(l=l2),\n",
    "    #        name=f'extinction_model_hidden_{i+1}'\n",
    "    #    )(r)\n",
    "    ext_vec = keras.layers.Dense(\n",
    "        n_bands,\n",
    "        use_bias=True,\n",
    "        activation='exponential',\n",
    "        #kernel_regularizer=keras.regularizers.l1_l2(l1=1.e0, l2=1.e0),\n",
    "        kernel_regularizer=keras.regularizers.l1(l=l1),\n",
    "        name='R'\n",
    "    )(r)\n",
    "    \n",
    "    # Extinction A = ER\n",
    "    ext = keras.layers.Multiply(name='A')([red, ext_vec])\n",
    "    \n",
    "    # Transform extinction to extinction,reddening using B: BA\n",
    "    B = np.identity(n_bands, dtype='f4')\n",
    "    B[1:,0] = -1.\n",
    "    ext_red = keras.layers.Dense(\n",
    "        n_bands,\n",
    "        use_bias=False,\n",
    "        trainable=False,\n",
    "        weights=[B.T],\n",
    "        name='BA'\n",
    "    )(ext)\n",
    "\n",
    "    # Predicted mag,color, B(M+A)\n",
    "    y = keras.layers.Add(name='B_M_plus_A')([mag_color, ext_red])\n",
    "\n",
    "    # Cholesky decomposition of inverse covariance matrix, L L^T = C^(-1)\n",
    "    LT = keras.Input(shape=(n_bands,n_bands), name='LT')\n",
    "\n",
    "    # Multiply y_pred by L^T, since loss is given by |L^T (y_pred - y_obs)|^2,\n",
    "    # where y_pred = B(M+A), and y_obs = B(m-mu).\n",
    "    LTy = keras.layers.Dot((2,1), name='LT_B_M_plus_A')([LT, y])\n",
    "\n",
    "    # Compile model\n",
    "    model = keras.Model(\n",
    "        inputs=[atm,red,LT],\n",
    "        outputs=LTy,\n",
    "        name='stellar_photometry_model'\n",
    "    )\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer='Adam',\n",
    "        metrics=['mse']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c98052-09ff-4591-830a-446eedd1c701",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### splits the dataset according to a fraction selected by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f096cf60-242d-4eef-8d91-59430a2672dc",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def split_dataset(frac, *args):\n",
    "    assert len(args) != 0\n",
    "\n",
    "    n_tot = args[0].shape[0]\n",
    "    idx = np.arange(n_tot)\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    n = int(frac * n_tot)\n",
    "    idx_left = idx[:n]\n",
    "    idx_right = idx[n:]\n",
    "\n",
    "    left, right = [], []\n",
    "\n",
    "    for x in args:\n",
    "        left.append(x[idx_left])\n",
    "        right.append(x[idx_right])\n",
    "    \n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a650c5-2ed5-4cfd-bd99-92ff0587e213",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d4f6eac-a9dd-4e9d-9d27-f9995997b7a2",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def train_model(nn_model, io_train, epochs=100,\n",
    "                checkpoint_fn='checkpoint', batch_size=32):\n",
    "    checkpoint_fn = (\n",
    "          'checkpoints/'\n",
    "        + checkpoint_fn\n",
    "        + '.e{epoch:03d}_vl{val_loss:.3f}.h5'\n",
    "    )\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_fn,\n",
    "            save_best_only=True,\n",
    "            monitor='val_loss',\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    inputs = [io_train['x_p'], io_train['r'], io_train['LT']]\n",
    "    outputs = io_train['LTy']\n",
    "    nn_model.fit(\n",
    "        inputs, outputs,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.25/0.9,\n",
    "        callbacks=callbacks,\n",
    "        batch_size=batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d76b11-59a7-41ca-a531-13411c1a6ce9",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### tests and makes sure the loss is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eb14a0f-a62d-4d46-ab6d-4b33476566da",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(nn_model, io_eval, batch_size=32, rchisq_max=None):\n",
    "    \"\"\"\n",
    "    Runs the model on the given inputs and outputs, and returns the\n",
    "    MSE and loss.\n",
    "    \n",
    "    Inputs:\n",
    "        nn_model (keras.Model): The neural network model.\n",
    "        io_eval (dict): A dictionary containing, among other things,\n",
    "            x_p, r, LT and LTy. If rchisq_max is provided, then the\n",
    "            dictionary must also contain rchisq.\n",
    "        batch_size (int): Defaults to 32.\n",
    "        rchisq_max (float): Stars with greater than this reduced chi^2\n",
    "            will not be included in the calculation. Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "        A list containing the MSE and loss.\n",
    "    \"\"\"\n",
    "    inputs = [io_eval['x_p'], io_eval['r'], io_eval['LT']]\n",
    "    outputs = io_eval['LTy']\n",
    "    \n",
    "    if rchisq_max is not None:\n",
    "        idx = (io_eval['rchisq'] < rchisq_max)\n",
    "        inputs = [x[idx] for x in inputs]\n",
    "        outputs = outputs[idx]\n",
    "    \n",
    "    loss = nn_model.evaluate(\n",
    "        inputs,\n",
    "        outputs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    loss = [float(x) for x in loss] # Make JSON serializable\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd030e3e-55e6-419d-9a07-ce0a6baeb62c",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### plots? follow up here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d65e396c-7677-41d8-b229-8c3b2377a7b6",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def diagnostic_plots(nn_model, io_test, d_test, suffix=None):\n",
    "    if suffix is None:\n",
    "        suff = ''\n",
    "    else:\n",
    "        suff = '_' + suffix\n",
    "    \n",
    "    inputs = [\n",
    "        nn_model.get_layer(name='theta').input,\n",
    "        nn_model.get_layer(name='E').input\n",
    "    ]\n",
    "    outputs = nn_model.get_layer(name='B_M_plus_A').output\n",
    "    absmag_model = keras.Model(inputs, outputs)\n",
    "\n",
    "    # Predict y for the test dataset\n",
    "    test_pred = {\n",
    "        'y': absmag_model.predict([\n",
    "            io_test['x_p'],\n",
    "            io_test['r']\n",
    "        ]),\n",
    "        'y_dered': absmag_model.predict([\n",
    "            io_test['x_p'],\n",
    "            np.zeros_like(io_test['r'])\n",
    "        ])\n",
    "    }\n",
    "    test_pred['y_resid'] = io_test['y'] - test_pred['y']\n",
    "\n",
    "    # Get the extinction vector\n",
    "    R = predict_R(nn_model)\n",
    "    R[1:] += R[0]\n",
    "    print(\n",
    "          'R(<theta>) = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,R)))\n",
    "        + ']'\n",
    "    )\n",
    "    R_all = predict_R(nn_model, io_test['x_p'])\n",
    "    R_all[:,1:] += R_all[:,0][:,None]\n",
    "    print(\n",
    "          '<R> = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,np.median(R_all,axis=0))))\n",
    "        + ']'\n",
    "    )\n",
    "    print(\n",
    "          's_R = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,np.std(R_all,axis=0))))\n",
    "        + ']'\n",
    "    )\n",
    "\n",
    "    # Read out colors, magnitudes\n",
    "    g = io_test['y'][:,3] + io_test['y'][:,0]\n",
    "    ri = io_test['y'][:,4] - io_test['y'][:,5]\n",
    "    gr = io_test['y'][:,3] - io_test['y'][:,4]\n",
    "    g_pred = test_pred['y'][:,3] + test_pred['y'][:,0]\n",
    "    ri_pred = test_pred['y'][:,4] - test_pred['y'][:,5]\n",
    "    gr_pred = test_pred['y'][:,3] - test_pred['y'][:,4]\n",
    "    g_pred_dered = test_pred['y_dered'][:,3] + test_pred['y_dered'][:,0]\n",
    "    ri_pred_dered = test_pred['y_dered'][:,4] - test_pred['y_dered'][:,5]\n",
    "    gr_pred_dered = test_pred['y_dered'][:,3] - test_pred['y_dered'][:,4]\n",
    "    A_g = 0.25 * R[3]\n",
    "    E_ri = 0.25 * (R[4] - R[5])\n",
    "    E_gr = 0.25 * (R[3] - R[4])\n",
    "\n",
    "    gaia_g = io_test['y'][:,0]\n",
    "    bp_rp = io_test['y'][:,1] - io_test['y'][:,2]\n",
    "    gaia_g_pred = test_pred['y'][:,0]\n",
    "    bp_rp_pred = test_pred['y'][:,1] - test_pred['y'][:,2]\n",
    "    gaia_g_pred_dered = test_pred['y_dered'][:,0]\n",
    "    gaia_bp_rp_pred_dered = test_pred['y_dered'][:,1] - test_pred['y_dered'][:,2]\n",
    "    A_gaia_g = 0.25 * R[0]\n",
    "    E_bp_rp = 0.25 * (R[1] - R[2])\n",
    "\n",
    "    print('g =', g)\n",
    "    print('ri =', ri)\n",
    "    print('gr =', gr)\n",
    "    print('gaia_g =', gaia_g)\n",
    "    print('bp_rp =', bp_rp)\n",
    "\n",
    "    # Plot HRD\n",
    "    params = {\n",
    "        'density': (None, r'$N$', (None, None)),\n",
    "        'teff': (d_test['atm_param'][:,0], r'$T_{\\mathrm{eff}}$', (4000., 8000.)),\n",
    "        'logg': (d_test['atm_param'][:,1], r'$\\log \\left( g \\right)$', (0., 5.)),\n",
    "        'mh': (d_test['atm_param'][:,2], r'$\\left[ \\mathrm{M} / \\mathrm{H} \\right]$', (-2.5, 0.5))\n",
    "    }\n",
    "\n",
    "    plot_spec = [\n",
    "        {\n",
    "            'colors': [(1,2), (4,5)],\n",
    "            'mag': 0\n",
    "        },\n",
    "        {\n",
    "            'colors': [(3,4), (4,5)],\n",
    "            'mag': 0\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    idx_goodobs = np.isfinite(d_test['mag_err'])\n",
    "    idx_goodobs &= (np.abs(io_test['cov_y'][:,0,0]) < 90.)[:,None]\n",
    "    idx_goodobs = idx_goodobs.T\n",
    "\n",
    "    def scatter_or_hexbin(ax, x, y, c, vmin, vmax, extent):\n",
    "        if p == 'density':\n",
    "            im = ax.hexbin(\n",
    "                x, y,\n",
    "                extent=extent,\n",
    "                bins='log',\n",
    "                rasterized=True\n",
    "            )\n",
    "        else:\n",
    "            im = ax.scatter(\n",
    "                x,\n",
    "                y,\n",
    "                c=c,\n",
    "                edgecolors='none',\n",
    "                alpha=0.1,\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "                rasterized=True\n",
    "            )\n",
    "        return im\n",
    "\n",
    "    def get_lim(*args, **kwargs):\n",
    "        expand = kwargs.get('expand', 0.4)\n",
    "        expand_low = kwargs.get('expand_low', expand)\n",
    "        expand_high = kwargs.get('expand_high', expand)\n",
    "        pct = kwargs.get('pct', 1.)\n",
    "        lim = [np.inf, -np.inf]\n",
    "        for a in args:\n",
    "            a0,a1 = np.nanpercentile(a, [pct, 100.-pct])\n",
    "            lim[0] = min(a0, lim[0])\n",
    "            lim[1] = max(a1, lim[1])\n",
    "        w = lim[1] - lim[0]\n",
    "        lim[0] -= expand_low * w\n",
    "        lim[1] += expand_high * w\n",
    "        return lim\n",
    "\n",
    "    labels = ['G', 'BP', 'RP', 'g', 'r', 'i', 'z', 'y']\n",
    "\n",
    "    for ps in plot_spec:\n",
    "        mag_label = r'$M_{{ {} }}$'.format(labels[ps['mag']])\n",
    "        mag_obs = io_test['y'][:,ps['mag']]\n",
    "        mag_pred = test_pred['y'][:,ps['mag']]\n",
    "        mag_pred_dered = test_pred['y_dered'][:,ps['mag']]\n",
    "        A_vec = 0.25 * R[ps['mag']]\n",
    "        print('mag_pred:',mag_pred)\n",
    "\n",
    "        if ps['mag'] != 0:\n",
    "            mag_obs += io_test['y'][:,0]\n",
    "            mag_pred += io_test['y'][:,0]\n",
    "            mag_pred_dered += io_test['y'][:,0]\n",
    "            A_vec += 0.25 * R[0]\n",
    "\n",
    "        color_labels = []\n",
    "        colors_obs = []\n",
    "        colors_pred = []\n",
    "        colors_pred_dered = []\n",
    "        idx_colors_obs = []\n",
    "        E_vec = []\n",
    "        for i1,i2 in ps['colors']:\n",
    "            color_labels.append(r'${} - {}$'.format(labels[i1], labels[i2]))\n",
    "            colors_obs.append(io_test['y'][:,i1] - io_test['y'][:,i2])\n",
    "            colors_pred.append(test_pred['y'][:,i1] - test_pred['y'][:,i2])\n",
    "            colors_pred_dered.append(\n",
    "                test_pred['y_dered'][:,i1] - test_pred['y_dered'][:,i2]\n",
    "            )\n",
    "            idx_colors_obs.append(idx_goodobs[i1] & idx_goodobs[i2])\n",
    "            E_vec.append(0.25 * (R[i1] - R[i2]))\n",
    "\n",
    "        mag_lim = get_lim(\n",
    "            mag_obs[idx_goodobs[ps['mag']]],\n",
    "            pct=2.\n",
    "        )[::-1]\n",
    "        color_lim = [\n",
    "            get_lim(c[idx_colors_obs[k]], expand_low=0.5, expand_high=0.4)\n",
    "            for k,c in enumerate(colors_obs)\n",
    "        ]\n",
    "        \n",
    "        for p in params.keys():\n",
    "            c, label, (vmin,vmax) = params[p]\n",
    "            \n",
    "            fig = plt.figure(figsize=(14,4.5), dpi=150)\n",
    "            fig.patch.set_alpha(0.)\n",
    "            gs = GridSpec(\n",
    "                1,4,\n",
    "                width_ratios=[1,1,1,0.1],\n",
    "                left=0.07, right=0.93,\n",
    "                bottom=0.10, top=0.92\n",
    "            )\n",
    "            ax_obs = fig.add_subplot(gs[0,0], facecolor='gray')\n",
    "            ax_pred = fig.add_subplot(gs[0,1], facecolor='gray')\n",
    "            ax_dered = fig.add_subplot(gs[0,2], facecolor='gray')\n",
    "            cax = fig.add_subplot(gs[0,3], facecolor='w')\n",
    "\n",
    "            extent = color_lim[0] + mag_lim\n",
    "\n",
    "            idx = (\n",
    "                  idx_goodobs[ps['mag']]\n",
    "                & idx_goodobs[ps['colors'][0][0]]\n",
    "                & idx_goodobs[ps['colors'][0][1]]\n",
    "            )\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_obs,\n",
    "                colors_obs[0][idx],\n",
    "                mag_obs[idx],\n",
    "                c if c is None else c[idx],\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "                #(-0.3,1.0,11.5,-2.0)\n",
    "            )\n",
    "\n",
    "            ax_obs.set_xlim(color_lim[0])\n",
    "            ax_obs.set_ylim(mag_lim)\n",
    "            ax_obs.set_xlabel(color_labels[0])\n",
    "            ax_obs.set_ylabel(mag_label)\n",
    "            ax_obs.grid('on', alpha=0.3)\n",
    "            ax_obs.set_title(r'$\\mathrm{Observed}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_pred,\n",
    "                colors_pred[0],\n",
    "                mag_pred,\n",
    "                c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "\n",
    "            ax_pred.set_xlim(color_lim[0])\n",
    "            ax_pred.set_ylim(mag_lim)\n",
    "            ax_pred.set_xlabel(color_labels[0])\n",
    "            ax_pred.grid('on', alpha=0.3)\n",
    "            ax_pred.set_title(r'$\\mathrm{Predicted}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_dered,\n",
    "                colors_pred_dered[0],\n",
    "                mag_pred_dered,\n",
    "                c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "\n",
    "            ax_dered.set_xlim(color_lim[0])\n",
    "            ax_dered.set_ylim(mag_lim)\n",
    "            ax_dered.set_xlabel(color_labels[0])\n",
    "            ax_dered.grid('on', alpha=0.3)\n",
    "            ax_dered.set_title(r'$\\mathrm{Predicted+Dereddened}$')\n",
    "\n",
    "            ax_dered.annotate(\n",
    "                '',\n",
    "                xy=(0.35+E_vec[0], 1.+A_vec),\n",
    "                xytext=(0.35, 1.),\n",
    "                arrowprops=dict(color='r', width=1., headwidth=5., headlength=5.)\n",
    "            )\n",
    "\n",
    "            cb = fig.colorbar(im, cax=cax)\n",
    "            cb.set_label(label)\n",
    "            cb.set_alpha(1.)\n",
    "            cb.draw_all()\n",
    "\n",
    "            cm_desc = '{}_vs_{}{}'.format(\n",
    "                labels[ps['mag']],\n",
    "                labels[ps['colors'][0][0]],\n",
    "                labels[ps['colors'][0][1]]\n",
    "            )\n",
    "            fig.savefig(\n",
    "                '/arc/home/aydanmckay/networkplots/nn_predictions_'+cm_desc+'_'+p+suff+'.svg',\n",
    "                dpi=150,\n",
    "                facecolor=fig.get_facecolor(),\n",
    "                edgecolor='none'\n",
    "            )\n",
    "            plt.close(fig)\n",
    "\n",
    "            # Color-color diagrams\n",
    "            fig = plt.figure(figsize=(14,4.5), dpi=150)\n",
    "            fig.patch.set_alpha(0.)\n",
    "            gs = GridSpec(\n",
    "                1,4,\n",
    "                width_ratios=[1,1,1,0.1],\n",
    "                left=0.07, right=0.93,\n",
    "                bottom=0.10, top=0.92\n",
    "            )\n",
    "            ax_obs = fig.add_subplot(gs[0,0], facecolor='gray')\n",
    "            ax_pred = fig.add_subplot(gs[0,1], facecolor='gray')\n",
    "            ax_dered = fig.add_subplot(gs[0,2], facecolor='gray')\n",
    "            cax = fig.add_subplot(gs[0,3], facecolor='w')\n",
    "\n",
    "            extent = color_lim[0] + color_lim[1]\n",
    "\n",
    "            idx = (\n",
    "                  idx_goodobs[ps['colors'][0][0]]\n",
    "                & idx_goodobs[ps['colors'][0][1]]\n",
    "                & idx_goodobs[ps['colors'][1][0]]\n",
    "                & idx_goodobs[ps['colors'][1][1]]\n",
    "            )\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_obs,\n",
    "                colors_obs[0][idx],\n",
    "                colors_obs[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "                #(-0.2,1.5,-0.15,0.8)\n",
    "            )\n",
    "            ax_obs.set_xlim(color_lim[0])\n",
    "            ax_obs.set_ylim(color_lim[1])\n",
    "            ax_obs.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_obs.set_ylabel(color_labels[1], fontsize=14)\n",
    "            ax_obs.grid('on', alpha=0.3)\n",
    "            ax_obs.set_title(r'$\\mathrm{Observed}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_pred,\n",
    "                colors_pred[0][idx],\n",
    "                colors_pred[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                #c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "            ax_pred.set_xlim(color_lim[0])\n",
    "            ax_pred.set_ylim(color_lim[1])\n",
    "            ax_pred.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_pred.grid('on', alpha=0.3)\n",
    "            ax_pred.set_title(r'$\\mathrm{Predicted}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_dered,\n",
    "                colors_pred_dered[0][idx],\n",
    "                colors_pred_dered[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                #c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "            ax_dered.set_xlim(color_lim[0])\n",
    "            ax_dered.set_ylim(color_lim[1])\n",
    "            ax_dered.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_dered.grid('on', alpha=0.3)\n",
    "            ax_dered.set_title(r'$\\mathrm{Predicted+Dereddened}$')\n",
    "\n",
    "            ax_dered.annotate(\n",
    "                '',\n",
    "                xy=(0.4+E_vec[0], 0.3+E_vec[1]),\n",
    "                xytext=(0.4, 0.3),\n",
    "                arrowprops=dict(color='r', width=1., headwidth=5., headlength=5.)\n",
    "            )\n",
    "\n",
    "            cb = fig.colorbar(im, cax=cax)\n",
    "            cb.set_label(label, fontsize=14)\n",
    "            cb.set_alpha(1.)\n",
    "            cb.draw_all()\n",
    "\n",
    "            cc_desc = '{}{}_vs_{}{}'.format(\n",
    "                labels[ps['colors'][0][0]],\n",
    "                labels[ps['colors'][0][1]],\n",
    "                labels[ps['colors'][1][0]],\n",
    "                labels[ps['colors'][1][1]]\n",
    "            )\n",
    "            fig.savefig(\n",
    "                '/arc/home/aydanmckay/networkplots/test_'+cc_desc+'_'+p+suff+'.svg',\n",
    "                dpi=150,\n",
    "                facecolor=fig.get_facecolor(),\n",
    "                edgecolor='none'\n",
    "            )\n",
    "            plt.close(fig)\n",
    "    \n",
    "    # Plot histograms of residuals\n",
    "    dr = (io_test['r'] - d_test['r'])/np.hypot(np.nanstd(d_test['r']),.01)\n",
    "    # dmag = (io_test['LTy'] - d_test['mag'])\n",
    "    # dm1,dm2,dm3,dm4,dm5,dm6,dm7,dm8,dm9,dm10,dm11,dm12,dm13 = dmag.T\n",
    "    names = ['G','(BP-G)','(RP-G)','(g-G)','(r-G)','(i-G)','(z-G)','(y-G)','(J-G)','(H-G)','(K_s-G)','(W_1-G)','(W_2-G)']\n",
    "    # ds = [dm1,dm2,dm3,dm4,dm5,dm6,dm7,dm8,dm9,dm10,dm11,dm12,dm13]\n",
    "    fig = plt.figure(figsize=(12,18))\n",
    "    ax = fig.add_subplot(5,3,1)\n",
    "    dr_mean = np.nanmean(dr)\n",
    "    dr_std = np.nanstd(dr)\n",
    "    ax.hist(dr, bins=50)\n",
    "    dr_skew = scipy.stats.moment(dr, moment=3, nan_policy='omit')\n",
    "    dr_txt = r'$\\Delta E = {:+.3f} \\pm {:.3f}$'.format(dr_mean, dr_std)\n",
    "    dr_skew /= (dr_std**1.5 + 1.e-5)\n",
    "    dr_txt += '\\n' + r'$\\tilde{{\\mu}}_3 = {:+.3f}$'.format(dr_skew)\n",
    "    ax.text(0.05, 0.95, dr_txt, ha='left', va='top', transform=ax.transAxes)\n",
    "    ax.set_xlabel(r'$\\Delta E \\ \\left( \\mathrm{estimated} - \\mathrm{Bayestar19} \\right)$',fontsize=10)\n",
    "    for it,(io,dm,name) in enumerate(zip(io_test['LTy'].T,d_test['mag'].T,names)):\n",
    "        dd = (io - dm)/np.hypot(np.nanstd(dm),.01)\n",
    "        ax = fig.add_subplot(5,3,it+2)\n",
    "        dd_mean = np.nanmean(dd)\n",
    "        dd_std = np.nanstd(dd)\n",
    "        ax.hist(dd, bins=50)\n",
    "        dd_skew = scipy.stats.moment(dd, moment=3, nan_policy='omit')\n",
    "        dd_txt = r'$\\Delta '+name+r' = {:+.3f} \\pm {:.3f}$'.format(dd_mean, dd_std)\n",
    "        dd_skew /= (dd_std**1.5 + 1.e-5)\n",
    "        dd_txt += '\\n' + r'$\\tilde{{\\mu}}_3 = {:+.3f}$'.format(dd_skew)\n",
    "        ax.text(0.05, 0.95, dd_txt, ha='left', va='top', transform=ax.transAxes)\n",
    "        ax.set_xlabel(r'$\\Delta '+name+r'\\ \\left( \\mathrm{estimated} - \\mathrm{observed} \\right)$',fontsize=10)\n",
    "    fig.savefig('/arc/home/aydanmckay/networkplots/test_z-score_dE'+suff+'.svg', dpi=150)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc50d23-d49f-4732-87e4-a7e1ec8fc816",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Calculates the derivative of the stellar model portion for gradient descent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8c296da-d523-4953-87b3-738be2e038fe",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def calc_dmag_color_dtheta(nn_model, x_p):\n",
    "    m = keras.Model(\n",
    "        inputs=nn_model.get_layer(name='theta').input,\n",
    "        outputs=nn_model.get_layer(name='BM').output\n",
    "    )\n",
    "    with tf.GradientTape() as g:\n",
    "        x_p = tf.constant(x_p)\n",
    "        g.watch(x_p)\n",
    "        mag_color = m(x_p)\n",
    "    J = g.batch_jacobian(mag_color, x_p).numpy()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb05c4c2-5d82-4311-b6f2-b46532797a41",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Calculates the derivative of the extinction model portion for gradient descent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2af63500-d06a-4ba6-bcc1-5fd5c3df6247",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def calc_dext_red_dtheta(nn_model, x_p, r):\n",
    "    A_model = keras.Model(\n",
    "        inputs=[\n",
    "            nn_model.get_layer(name='theta').input,\n",
    "            nn_model.get_layer(name='E').input\n",
    "        ],\n",
    "        outputs=nn_model.get_layer(name='BA').output\n",
    "    )\n",
    "    r = tf.constant(np.reshape(r, (r.size,1)))\n",
    "    #r = tf.reshape(r, (tf.size(r), 1))\n",
    "    with tf.GradientTape() as g:\n",
    "        x_p = tf.constant(x_p)\n",
    "        g.watch(x_p)\n",
    "        A = A_model([x_p, r])\n",
    "    J = g.batch_jacobian(A, x_p).numpy()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fb7f2c-5df5-4b99-aae0-39035aa43797",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Saves the normalizations, which seen in the tutorial is useful for scaling and shifting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86cef280-6cca-48f4-93ce-a8f4b7336300",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def save_theta_norm(d_attrs, fname):\n",
    "    d = {\n",
    "        'theta_med': d_attrs['atm_param_med'].tolist(),\n",
    "        'theta_std': d_attrs['atm_param_std'].tolist()\n",
    "    }\n",
    "    with open(fname, 'w') as f:\n",
    "        json.dump(d, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab8ecb-d1c9-438d-8794-1ff0b7eceef3",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### start of main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b834ddb7-6836-4e26-b7d7-81ce6cf146fd",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"stellar_photometry_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " theta (InputLayer)             [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " stellar_model_hidden_1 (Dense)  (None, 32)          128         ['theta[0][0]']                  \n",
      "                                                                                                  \n",
      " E (InputLayer)                 [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " R (Dense)                      (None, 13)           52          ['theta[0][0]']                  \n",
      "                                                                                                  \n",
      " stellar_model_hidden_2 (Dense)  (None, 32)          1056        ['stellar_model_hidden_1[0][0]'] \n",
      "                                                                                                  \n",
      " A (Multiply)                   (None, 13)           0           ['E[0][0]',                      \n",
      "                                                                  'R[0][0]']                      \n",
      "                                                                                                  \n",
      " BM (Dense)                     (None, 13)           429         ['stellar_model_hidden_2[0][0]'] \n",
      "                                                                                                  \n",
      " BA (Dense)                     (None, 13)           169         ['A[0][0]']                      \n",
      "                                                                                                  \n",
      " LT (InputLayer)                [(None, 13, 13)]     0           []                               \n",
      "                                                                                                  \n",
      " B_M_plus_A (Add)               (None, 13)           0           ['BM[0][0]',                     \n",
      "                                                                  'BA[0][0]']                     \n",
      "                                                                                                  \n",
      " LT_B_M_plus_A (Dot)            (None, 13)           0           ['LT[0][0]',                     \n",
      "                                                                  'B_M_plus_A[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,834\n",
      "Trainable params: 1,665\n",
      "Non-trainable params: 169\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load/create neural network\n",
    "nn_name = 'ext_0h_l1n2'\n",
    "n_hidden = 2\n",
    "nn_model = get_nn_model(n_hidden_layers=n_hidden, l2=1.e-4, l1=1.e-2)\n",
    "#nn_model = keras.models.load_model(\n",
    "#    'models/{:s}_{:d}hidden_it14.h5'.format(nn_name, n_hidden)\n",
    "#)\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07e4514b-44a8-4a5c-8512-e7feaa15e94e",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Loading /arc/home/aydanmckay/ml/network/datav2.h5 ...\n"
     ]
    }
   ],
   "source": [
    "# Load stellar data\n",
    "print('Loading data ...')\n",
    "fname = '/arc/home/aydanmckay/ml/network/datav2.h5'\n",
    "d, d_attrs = load_data(fname, return_attrs=True)\n",
    "#d = d[::25]\n",
    "save_theta_norm(d_attrs, 'theta_normalization.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d54baa9f-60d9-4fc0-acb7-e4c49cd83a66",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    253053 training/validation stars.\n",
      "     28118 test stars.\n"
     ]
    }
   ],
   "source": [
    "# (training+validation) / test split\n",
    "# Fix random seed (same split every run)\n",
    "np.random.seed(7)\n",
    "(d_train,), (d_test,) = split_dataset(0.9, d)\n",
    "np.random.shuffle(d_train) # Want d_train to be in random order\n",
    "print(f'{d_train.size: >10d} training/validation stars.')\n",
    "print(f'{d_test.size: >10d} test stars.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa8b04a6-3b93-4b72-9d3f-8855c3111e8c",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi^2/dof = [None, 100.00000000000004, 79.41833348134496, 63.07271692954115, 50.09130066684769, 39.78167620874025, 31.593944275926187, 25.091384024965357, 19.927159040031896, 15.825817619770502, 12.56860061341878, 9.981773149103292, 7.927357886906197, 6.295775522882865, 4.999999999999999, 5.0, 5.0, 5.0, 5.0, 5.0]\n"
     ]
    }
   ],
   "source": [
    "# Iteratively update dM/dtheta contribution to uncertainties,\n",
    "# reddening estimates and reduced chi^2 cut, and retrain.\n",
    "n_iterations = 20\n",
    "\n",
    "# On GPU, use large batch sizes for memory transfer efficiency\n",
    "batch_size = 1024\n",
    "\n",
    "rchisq_max_init = 100.\n",
    "rchisq_max_final = 5.\n",
    "rchisq_max = np.exp(np.linspace(\n",
    "    np.log(rchisq_max_init),\n",
    "    np.log(rchisq_max_final),\n",
    "    n_iterations-6\n",
    "))\n",
    "rchisq_max = [None] + rchisq_max.tolist() + 5*[rchisq_max_final]\n",
    "print('chi^2/dof = {}'.format(rchisq_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b3ee798-6cee-458d-b5e3-e6f014c0c873",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Cutting 0 stars with large sigma_r.\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Cutting 0 stars with large sigma_r.\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 37.65 s\n",
      "learning rate = 0.0010000000474974513\n",
      "setting learning rate to 0.001\n",
      "Iteration 1 of 20.\n",
      "Epoch 1/25\n",
      "173/179 [===========================>..] - ETA: 0s - loss: 1589.7825 - mse: 1589.6667\n",
      "Epoch 1: val_loss improved from inf to 11665.43555, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e001_vl11665.436.h5\n",
      "179/179 [==============================] - 2s 8ms/step - loss: 1554.6049 - mse: 1554.4889 - val_loss: 11665.4355 - val_mse: 11665.3193\n",
      "Epoch 2/25\n",
      "171/179 [===========================>..] - ETA: 0s - loss: 783.9544 - mse: 783.8405\n",
      "Epoch 2: val_loss improved from 11665.43555 to 7707.92676, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e002_vl7707.927.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 762.4650 - mse: 762.3511 - val_loss: 7707.9268 - val_mse: 7707.8140\n",
      "Epoch 3/25\n",
      "179/179 [==============================] - ETA: 0s - loss: 539.1719 - mse: 539.0598\n",
      "Epoch 3: val_loss improved from 7707.92676 to 5096.93994, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e003_vl5096.940.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 539.1719 - mse: 539.0598 - val_loss: 5096.9399 - val_mse: 5096.8271\n",
      "Epoch 4/25\n",
      "179/179 [==============================] - ETA: 0s - loss: 384.4382 - mse: 384.3275\n",
      "Epoch 4: val_loss improved from 5096.93994 to 3585.05469, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e004_vl3585.055.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 384.4382 - mse: 384.3275 - val_loss: 3585.0547 - val_mse: 3584.9441\n",
      "Epoch 5/25\n",
      "176/179 [============================>.] - ETA: 0s - loss: 291.4708 - mse: 291.3606\n",
      "Epoch 5: val_loss improved from 3585.05469 to 2684.67578, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e005_vl2684.676.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 288.5951 - mse: 288.4849 - val_loss: 2684.6758 - val_mse: 2684.5667\n",
      "Epoch 6/25\n",
      "169/179 [===========================>..] - ETA: 0s - loss: 237.4460 - mse: 237.3374\n",
      "Epoch 6: val_loss improved from 2684.67578 to 2110.23340, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e006_vl2110.233.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 228.0756 - mse: 227.9671 - val_loss: 2110.2334 - val_mse: 2110.1252\n",
      "Epoch 7/25\n",
      "178/179 [============================>.] - ETA: 0s - loss: 187.4456 - mse: 187.3385\n",
      "Epoch 7: val_loss improved from 2110.23340 to 1691.56348, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e007_vl1691.563.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 187.0791 - mse: 186.9720 - val_loss: 1691.5635 - val_mse: 1691.4575\n",
      "Epoch 8/25\n",
      "169/179 [===========================>..] - ETA: 0s - loss: 162.1203 - mse: 162.0147\n",
      "Epoch 8: val_loss improved from 1691.56348 to 1385.07495, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e008_vl1385.075.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 157.1513 - mse: 157.0457 - val_loss: 1385.0750 - val_mse: 1384.9706\n",
      "Epoch 9/25\n",
      "179/179 [==============================] - ETA: 0s - loss: 134.4251 - mse: 134.3209\n",
      "Epoch 9: val_loss improved from 1385.07495 to 1147.99792, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e009_vl1147.998.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 134.4251 - mse: 134.3209 - val_loss: 1147.9979 - val_mse: 1147.8947\n",
      "Epoch 10/25\n",
      "175/179 [============================>.] - ETA: 0s - loss: 118.3495 - mse: 118.2470\n",
      "Epoch 10: val_loss improved from 1147.99792 to 959.94751, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e010_vl959.948.h5\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 116.5773 - mse: 116.4749 - val_loss: 959.9475 - val_mse: 959.8459\n",
      "Epoch 11/25\n",
      "175/179 [============================>.] - ETA: 0s - loss: 103.4918 - mse: 103.3907\n",
      "Epoch 11: val_loss improved from 959.94751 to 805.34088, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e011_vl805.341.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 102.6543 - mse: 102.5533 - val_loss: 805.3409 - val_mse: 805.2409\n",
      "Epoch 12/25\n",
      "173/179 [===========================>..] - ETA: 0s - loss: 93.2471 - mse: 93.1475 \n",
      "Epoch 12: val_loss improved from 805.34088 to 688.43475, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e012_vl688.435.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 91.2435 - mse: 91.1439 - val_loss: 688.4348 - val_mse: 688.3353\n",
      "Epoch 13/25\n",
      "174/179 [============================>.] - ETA: 0s - loss: 83.0717 - mse: 82.9728\n",
      "Epoch 13: val_loss improved from 688.43475 to 589.98151, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e013_vl589.982.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 81.7778 - mse: 81.6789 - val_loss: 589.9815 - val_mse: 589.8832\n",
      "Epoch 14/25\n",
      "169/179 [===========================>..] - ETA: 0s - loss: 76.7351 - mse: 76.6373\n",
      "Epoch 14: val_loss improved from 589.98151 to 511.89969, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e014_vl511.900.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 74.1993 - mse: 74.1015 - val_loss: 511.8997 - val_mse: 511.8024\n",
      "Epoch 15/25\n",
      "171/179 [===========================>..] - ETA: 0s - loss: 69.1553 - mse: 69.0585\n",
      "Epoch 15: val_loss improved from 511.89969 to 449.48425, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e015_vl449.484.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 67.7478 - mse: 67.6510 - val_loss: 449.4843 - val_mse: 449.3875\n",
      "Epoch 16/25\n",
      "174/179 [============================>.] - ETA: 0s - loss: 63.2384 - mse: 63.1422\n",
      "Epoch 16: val_loss improved from 449.48425 to 392.50665, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e016_vl392.507.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 62.2736 - mse: 62.1774 - val_loss: 392.5067 - val_mse: 392.4110\n",
      "Epoch 17/25\n",
      "174/179 [============================>.] - ETA: 0s - loss: 58.1896 - mse: 58.0943\n",
      "Epoch 17: val_loss improved from 392.50665 to 345.86200, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e017_vl345.862.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 57.6202 - mse: 57.5249 - val_loss: 345.8620 - val_mse: 345.7672\n",
      "Epoch 18/25\n",
      "170/179 [===========================>..] - ETA: 0s - loss: 55.0894 - mse: 54.9951\n",
      "Epoch 18: val_loss improved from 345.86200 to 306.32785, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e018_vl306.328.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 53.6970 - mse: 53.6028 - val_loss: 306.3279 - val_mse: 306.2340\n",
      "Epoch 19/25\n",
      "177/179 [============================>.] - ETA: 0s - loss: 50.3815 - mse: 50.2881\n",
      "Epoch 19: val_loss improved from 306.32785 to 272.60345, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e019_vl272.603.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 50.1573 - mse: 50.0639 - val_loss: 272.6035 - val_mse: 272.5107\n",
      "Epoch 20/25\n",
      "173/179 [===========================>..] - ETA: 0s - loss: 47.9477 - mse: 47.8553\n",
      "Epoch 20: val_loss improved from 272.60345 to 243.18216, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e020_vl243.182.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 47.2585 - mse: 47.1661 - val_loss: 243.1822 - val_mse: 243.0904\n",
      "Epoch 21/25\n",
      "169/179 [===========================>..] - ETA: 0s - loss: 45.3242 - mse: 45.2327\n",
      "Epoch 21: val_loss improved from 243.18216 to 218.85374, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e021_vl218.854.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 44.5076 - mse: 44.4162 - val_loss: 218.8537 - val_mse: 218.7630\n",
      "Epoch 22/25\n",
      "179/179 [==============================] - ETA: 0s - loss: 42.2606 - mse: 42.1705\n",
      "Epoch 22: val_loss improved from 218.85374 to 196.94012, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e022_vl196.940.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 42.2606 - mse: 42.1705 - val_loss: 196.9401 - val_mse: 196.8506\n",
      "Epoch 23/25\n",
      "170/179 [===========================>..] - ETA: 0s - loss: 40.8505 - mse: 40.7615\n",
      "Epoch 23: val_loss improved from 196.94012 to 178.30923, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e023_vl178.309.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 40.2180 - mse: 40.1289 - val_loss: 178.3092 - val_mse: 178.2209\n",
      "Epoch 24/25\n",
      "175/179 [============================>.] - ETA: 0s - loss: 38.7283 - mse: 38.6403\n",
      "Epoch 24: val_loss improved from 178.30923 to 161.90718, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e024_vl161.907.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 38.3953 - mse: 38.3074 - val_loss: 161.9072 - val_mse: 161.8198\n",
      "Epoch 25/25\n",
      "169/179 [===========================>..] - ETA: 0s - loss: 37.5446 - mse: 37.4578\n",
      "Epoch 25: val_loss improved from 161.90718 to 146.42334, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e025_vl146.423.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 36.8045 - mse: 36.7177 - val_loss: 146.4233 - val_mse: 146.3370\n",
      "Time elapsed to train: 27.92 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [1.616 1.018 0.841 1.969 1.701 0.870 0.834 0.769 0.795 0.802 0.540 0.541 0.770]\n",
      "<R> = [1.614 1.016 0.846 1.966 1.727 0.856 0.832 0.771 0.772 0.783 0.538 0.538 0.757]\n",
      "s_R = [0.407 0.378 0.737 0.374 0.404 29.248 1.167 0.311 0.952 0.819 0.270 0.288 0.421]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6639009 2.9277067 6.5711813 ... 3.160048  4.168663  4.472575 ]\n",
      "mag_pred: [3.6639009 2.9277067 6.5711813 ... 3.160048  4.168663  4.472575 ]\n",
      "Time elapsed to make plots: 19.01 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [59.83286  40.006706 17.00357  ...  3.506168 39.5393   18.460316]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0361\n",
      "  1% : 0.233\n",
      "  10% : 0.482\n",
      "  50% : 1.16\n",
      "  90% : 5.67\n",
      "  99% : 112\n",
      "  100% : 6.68e+03\n",
      "<chi^2/d.o.f.> = 1.65\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 2750 stars (1.09%) based on chi^2/dof > 100.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [19.09105  47.47658  17.771496 ... 13.153782  8.904013 13.167376]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0597\n",
      "  1% : 0.236\n",
      "  10% : 0.482\n",
      "  50% : 1.17\n",
      "  90% : 5.66\n",
      "  99% : 118\n",
      "  100% : 5.12e+03\n",
      "<chi^2/d.o.f.> = 1.67\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 77.34 s\n",
      "learning rate = 0.0010000000474974513\n",
      "setting learning rate to 0.0008187307530779819\n",
      "Iteration 2 of 20.\n",
      "Epoch 1/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.9642 - mse: 1.8781\n",
      "Epoch 1: val_loss improved from inf to 1.91778, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e001_vl1.918.h5\n",
      "177/177 [==============================] - 2s 7ms/step - loss: 1.9621 - mse: 1.8760 - val_loss: 1.9178 - val_mse: 1.8319\n",
      "Epoch 2/25\n",
      "166/177 [===========================>..] - ETA: 0s - loss: 1.9135 - mse: 1.8278\n",
      "Epoch 2: val_loss improved from 1.91778 to 1.88859, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e002_vl1.889.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.9107 - mse: 1.8250 - val_loss: 1.8886 - val_mse: 1.8031\n",
      "Epoch 3/25\n",
      "168/177 [===========================>..] - ETA: 0s - loss: 1.8874 - mse: 1.8021\n",
      "Epoch 3: val_loss improved from 1.88859 to 1.86569, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e003_vl1.866.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.8844 - mse: 1.7991 - val_loss: 1.8657 - val_mse: 1.7806\n",
      "Epoch 4/25\n",
      "177/177 [==============================] - ETA: 0s - loss: 1.8631 - mse: 1.7782\n",
      "Epoch 4: val_loss improved from 1.86569 to 1.84675, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e004_vl1.847.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.8631 - mse: 1.7782 - val_loss: 1.8467 - val_mse: 1.7621\n",
      "Epoch 5/25\n",
      "169/177 [===========================>..] - ETA: 0s - loss: 1.8483 - mse: 1.7638\n",
      "Epoch 5: val_loss improved from 1.84675 to 1.82903, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e005_vl1.829.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.8442 - mse: 1.7597 - val_loss: 1.8290 - val_mse: 1.7448\n",
      "Epoch 6/25\n",
      "173/177 [============================>.] - ETA: 0s - loss: 1.8261 - mse: 1.7420\n",
      "Epoch 6: val_loss improved from 1.82903 to 1.81323, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e006_vl1.813.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.8276 - mse: 1.7435 - val_loss: 1.8132 - val_mse: 1.7294\n",
      "Epoch 7/25\n",
      "167/177 [===========================>..] - ETA: 0s - loss: 1.8103 - mse: 1.7267\n",
      "Epoch 7: val_loss improved from 1.81323 to 1.80052, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e007_vl1.801.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.8123 - mse: 1.7286 - val_loss: 1.8005 - val_mse: 1.7171\n",
      "Epoch 8/25\n",
      "169/177 [===========================>..] - ETA: 0s - loss: 1.7966 - mse: 1.7134\n",
      "Epoch 8: val_loss improved from 1.80052 to 1.78436, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e008_vl1.784.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.7980 - mse: 1.7147 - val_loss: 1.7844 - val_mse: 1.7013\n",
      "Epoch 9/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.7868 - mse: 1.7039\n",
      "Epoch 9: val_loss improved from 1.78436 to 1.77232, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e009_vl1.772.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.7846 - mse: 1.7017 - val_loss: 1.7723 - val_mse: 1.6896\n",
      "Epoch 10/25\n",
      "167/177 [===========================>..] - ETA: 0s - loss: 1.7746 - mse: 1.6920\n",
      "Epoch 10: val_loss improved from 1.77232 to 1.76009, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e010_vl1.760.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.7726 - mse: 1.6900 - val_loss: 1.7601 - val_mse: 1.6776\n",
      "Epoch 11/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.7626 - mse: 1.6802\n",
      "Epoch 11: val_loss improved from 1.76009 to 1.74858, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e011_vl1.749.h5\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 1.7609 - mse: 1.6786 - val_loss: 1.7486 - val_mse: 1.6664\n",
      "Epoch 12/25\n",
      "171/177 [===========================>..] - ETA: 0s - loss: 1.7500 - mse: 1.6679\n",
      "Epoch 12: val_loss improved from 1.74858 to 1.73786, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e012_vl1.738.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.7492 - mse: 1.6671 - val_loss: 1.7379 - val_mse: 1.6560\n",
      "Epoch 13/25\n",
      "167/177 [===========================>..] - ETA: 0s - loss: 1.7337 - mse: 1.6520\n",
      "Epoch 13: val_loss improved from 1.73786 to 1.72700, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e013_vl1.727.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.7381 - mse: 1.6564 - val_loss: 1.7270 - val_mse: 1.6454\n",
      "Epoch 14/25\n",
      "175/177 [============================>.] - ETA: 0s - loss: 1.7298 - mse: 1.6484\n",
      "Epoch 14: val_loss improved from 1.72700 to 1.72048, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e014_vl1.720.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.7278 - mse: 1.6464 - val_loss: 1.7205 - val_mse: 1.6393\n",
      "Epoch 15/25\n",
      "176/177 [============================>.] - ETA: 0s - loss: 1.7171 - mse: 1.6361\n",
      "Epoch 15: val_loss improved from 1.72048 to 1.70810, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e015_vl1.708.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.7173 - mse: 1.6362 - val_loss: 1.7081 - val_mse: 1.6273\n",
      "Epoch 16/25\n",
      "168/177 [===========================>..] - ETA: 0s - loss: 1.7049 - mse: 1.6243\n",
      "Epoch 16: val_loss improved from 1.70810 to 1.69677, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e016_vl1.697.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.7069 - mse: 1.6263 - val_loss: 1.6968 - val_mse: 1.6163\n",
      "Epoch 17/25\n",
      "173/177 [============================>.] - ETA: 0s - loss: 1.6986 - mse: 1.6183\n",
      "Epoch 17: val_loss improved from 1.69677 to 1.68924, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e017_vl1.689.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.6975 - mse: 1.6172 - val_loss: 1.6892 - val_mse: 1.6092\n",
      "Epoch 18/25\n",
      "174/177 [============================>.] - ETA: 0s - loss: 1.6876 - mse: 1.6077\n",
      "Epoch 18: val_loss improved from 1.68924 to 1.67886, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e018_vl1.679.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.6880 - mse: 1.6081 - val_loss: 1.6789 - val_mse: 1.5991\n",
      "Epoch 19/25\n",
      "176/177 [============================>.] - ETA: 0s - loss: 1.6793 - mse: 1.5998\n",
      "Epoch 19: val_loss improved from 1.67886 to 1.67289, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e019_vl1.673.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.6790 - mse: 1.5995 - val_loss: 1.6729 - val_mse: 1.5936\n",
      "Epoch 20/25\n",
      "170/177 [===========================>..] - ETA: 0s - loss: 1.6745 - mse: 1.5954\n",
      "Epoch 20: val_loss improved from 1.67289 to 1.66039, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e020_vl1.660.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.6704 - mse: 1.5913 - val_loss: 1.6604 - val_mse: 1.5815\n",
      "Epoch 21/25\n",
      "170/177 [===========================>..] - ETA: 0s - loss: 1.6591 - mse: 1.5804\n",
      "Epoch 21: val_loss improved from 1.66039 to 1.65642, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e021_vl1.656.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.6616 - mse: 1.5829 - val_loss: 1.6564 - val_mse: 1.5779\n",
      "Epoch 22/25\n",
      "173/177 [============================>.] - ETA: 0s - loss: 1.6561 - mse: 1.5778\n",
      "Epoch 22: val_loss improved from 1.65642 to 1.64610, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e022_vl1.646.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.6538 - mse: 1.5754 - val_loss: 1.6461 - val_mse: 1.5678\n",
      "Epoch 23/25\n",
      "166/177 [===========================>..] - ETA: 0s - loss: 1.6403 - mse: 1.5622\n",
      "Epoch 23: val_loss improved from 1.64610 to 1.63786, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e023_vl1.638.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.6453 - mse: 1.5672 - val_loss: 1.6379 - val_mse: 1.5599\n",
      "Epoch 24/25\n",
      "168/177 [===========================>..] - ETA: 0s - loss: 1.6402 - mse: 1.5624\n",
      "Epoch 24: val_loss improved from 1.63786 to 1.62899, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e024_vl1.629.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.6383 - mse: 1.5605 - val_loss: 1.6290 - val_mse: 1.5513\n",
      "Epoch 25/25\n",
      "171/177 [===========================>..] - ETA: 0s - loss: 1.6289 - mse: 1.5514\n",
      "Epoch 25: val_loss improved from 1.62899 to 1.62334, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e025_vl1.623.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.6314 - mse: 1.5539 - val_loss: 1.6233 - val_mse: 1.5460\n",
      "Time elapsed to train: 26.59 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [1.466 1.347 0.843 1.899 1.616 0.870 0.774 0.659 0.693 0.785 0.593 0.554 0.592]\n",
      "<R> = [1.469 1.344 0.849 1.896 1.627 0.856 0.773 0.659 0.675 0.767 0.594 0.556 0.585]\n",
      "s_R = [0.344 0.472 0.730 0.346 0.204 29.211 0.647 0.204 0.612 0.783 0.134 0.358 0.363]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.643606  2.9253173 6.454121  ... 2.8958817 4.148314  4.4762106]\n",
      "mag_pred: [3.643606  2.9253173 6.454121  ... 2.8958817 4.148314  4.4762106]\n",
      "Time elapsed to make plots: 18.90 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7f30e5833160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7f30e578b3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [46.407578  34.120064  33.421143  ...  3.2674284 33.160934  31.153572 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0257\n",
      "  1% : 0.147\n",
      "  10% : 0.326\n",
      "  50% : 0.883\n",
      "  90% : 3.87\n",
      "  99% : 88.4\n",
      "  100% : 6.74e+03\n",
      "<chi^2/d.o.f.> = 1.31\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 2749 stars (1.09%) based on chi^2/dof > 79.4\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [14.96958   24.86204   13.739298  ...  3.756539   4.3694186 11.797344 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0499\n",
      "  1% : 0.148\n",
      "  10% : 0.326\n",
      "  50% : 0.888\n",
      "  90% : 3.79\n",
      "  99% : 96.9\n",
      "  100% : 5.15e+03\n",
      "<chi^2/d.o.f.> = 1.3\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 80.93 s\n",
      "learning rate = 0.0008187307394109666\n",
      "setting learning rate to 0.0006703200460356394\n",
      "Iteration 3 of 20.\n",
      "Epoch 1/25\n",
      "171/177 [===========================>..] - ETA: 0s - loss: 1.5575 - mse: 1.4802\n",
      "Epoch 1: val_loss improved from inf to 1.54063, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e001_vl1.541.h5\n",
      "177/177 [==============================] - 2s 7ms/step - loss: 1.5578 - mse: 1.4804 - val_loss: 1.5406 - val_mse: 1.4632\n",
      "Epoch 2/25\n",
      "168/177 [===========================>..] - ETA: 0s - loss: 1.5454 - mse: 1.4680\n",
      "Epoch 2: val_loss improved from 1.54063 to 1.53109, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e002_vl1.531.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.5436 - mse: 1.4662 - val_loss: 1.5311 - val_mse: 1.4537\n",
      "Epoch 3/25\n",
      "176/177 [============================>.] - ETA: 0s - loss: 1.5331 - mse: 1.4557\n",
      "Epoch 3: val_loss improved from 1.53109 to 1.52309, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e003_vl1.523.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.5333 - mse: 1.4560 - val_loss: 1.5231 - val_mse: 1.4458\n",
      "Epoch 4/25\n",
      "174/177 [============================>.] - ETA: 0s - loss: 1.5259 - mse: 1.4488\n",
      "Epoch 4: val_loss improved from 1.52309 to 1.51267, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e004_vl1.513.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.5244 - mse: 1.4473 - val_loss: 1.5127 - val_mse: 1.4357\n",
      "Epoch 5/25\n",
      "170/177 [===========================>..] - ETA: 0s - loss: 1.5191 - mse: 1.4423\n",
      "Epoch 5: val_loss improved from 1.51267 to 1.50377, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e005_vl1.504.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.5168 - mse: 1.4400 - val_loss: 1.5038 - val_mse: 1.4271\n",
      "Epoch 6/25\n",
      "176/177 [============================>.] - ETA: 0s - loss: 1.5088 - mse: 1.4324\n",
      "Epoch 6: val_loss improved from 1.50377 to 1.49944, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e006_vl1.499.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.5083 - mse: 1.4319 - val_loss: 1.4994 - val_mse: 1.4232\n",
      "Epoch 7/25\n",
      "166/177 [===========================>..] - ETA: 0s - loss: 1.5026 - mse: 1.4267\n",
      "Epoch 7: val_loss improved from 1.49944 to 1.49141, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e007_vl1.491.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.5019 - mse: 1.4260 - val_loss: 1.4914 - val_mse: 1.4157\n",
      "Epoch 8/25\n",
      "170/177 [===========================>..] - ETA: 0s - loss: 1.4985 - mse: 1.4231\n",
      "Epoch 8: val_loss improved from 1.49141 to 1.48602, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e008_vl1.486.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4951 - mse: 1.4197 - val_loss: 1.4860 - val_mse: 1.4110\n",
      "Epoch 9/25\n",
      "177/177 [==============================] - ETA: 0s - loss: 1.4881 - mse: 1.4134\n",
      "Epoch 9: val_loss improved from 1.48602 to 1.48135, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e009_vl1.481.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4881 - mse: 1.4134 - val_loss: 1.4814 - val_mse: 1.4070\n",
      "Epoch 10/25\n",
      "169/177 [===========================>..] - ETA: 0s - loss: 1.4805 - mse: 1.4064\n",
      "Epoch 10: val_loss improved from 1.48135 to 1.47596, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e010_vl1.476.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4823 - mse: 1.4083 - val_loss: 1.4760 - val_mse: 1.4023\n",
      "Epoch 11/25\n",
      "175/177 [============================>.] - ETA: 0s - loss: 1.4766 - mse: 1.4033\n",
      "Epoch 11: val_loss improved from 1.47596 to 1.46987, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e011_vl1.470.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4766 - mse: 1.4033 - val_loss: 1.4699 - val_mse: 1.3969\n",
      "Epoch 12/25\n",
      "165/177 [==========================>...] - ETA: 0s - loss: 1.4711 - mse: 1.3986\n",
      "Epoch 12: val_loss improved from 1.46987 to 1.46468, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e012_vl1.465.h5\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 1.4707 - mse: 1.3981 - val_loss: 1.4647 - val_mse: 1.3925\n",
      "Epoch 13/25\n",
      "170/177 [===========================>..] - ETA: 0s - loss: 1.4651 - mse: 1.3933\n",
      "Epoch 13: val_loss improved from 1.46468 to 1.45629, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e013_vl1.456.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4649 - mse: 1.3931 - val_loss: 1.4563 - val_mse: 1.3849\n",
      "Epoch 14/25\n",
      "173/177 [============================>.] - ETA: 0s - loss: 1.4594 - mse: 1.3885\n",
      "Epoch 14: val_loss improved from 1.45629 to 1.45244, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e014_vl1.452.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4592 - mse: 1.3883 - val_loss: 1.4524 - val_mse: 1.3820\n",
      "Epoch 15/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.4551 - mse: 1.3851\n",
      "Epoch 15: val_loss improved from 1.45244 to 1.44447, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e015_vl1.444.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4538 - mse: 1.3838 - val_loss: 1.4445 - val_mse: 1.3750\n",
      "Epoch 16/25\n",
      "169/177 [===========================>..] - ETA: 0s - loss: 1.4448 - mse: 1.3759\n",
      "Epoch 16: val_loss improved from 1.44447 to 1.43893, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e016_vl1.439.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4480 - mse: 1.3790 - val_loss: 1.4389 - val_mse: 1.3704\n",
      "Epoch 17/25\n",
      "167/177 [===========================>..] - ETA: 0s - loss: 1.4438 - mse: 1.3757\n",
      "Epoch 17: val_loss did not improve from 1.43893\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 1.4426 - mse: 1.3746 - val_loss: 1.4396 - val_mse: 1.3720\n",
      "Epoch 18/25\n",
      "169/177 [===========================>..] - ETA: 0s - loss: 1.4353 - mse: 1.3682\n",
      "Epoch 18: val_loss improved from 1.43893 to 1.43187, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e018_vl1.432.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4375 - mse: 1.3705 - val_loss: 1.4319 - val_mse: 1.3652\n",
      "Epoch 19/25\n",
      "169/177 [===========================>..] - ETA: 0s - loss: 1.4289 - mse: 1.3628\n",
      "Epoch 19: val_loss improved from 1.43187 to 1.42852, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e019_vl1.429.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4325 - mse: 1.3665 - val_loss: 1.4285 - val_mse: 1.3629\n",
      "Epoch 20/25\n",
      "171/177 [===========================>..] - ETA: 0s - loss: 1.4285 - mse: 1.3633\n",
      "Epoch 20: val_loss improved from 1.42852 to 1.42661, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e020_vl1.427.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4278 - mse: 1.3627 - val_loss: 1.4266 - val_mse: 1.3620\n",
      "Epoch 21/25\n",
      "166/177 [===========================>..] - ETA: 0s - loss: 1.4257 - mse: 1.3616\n",
      "Epoch 21: val_loss improved from 1.42661 to 1.41554, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e021_vl1.416.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4232 - mse: 1.3590 - val_loss: 1.4155 - val_mse: 1.3520\n",
      "Epoch 22/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.4192 - mse: 1.3562\n",
      "Epoch 22: val_loss improved from 1.41554 to 1.41411, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e022_vl1.414.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4172 - mse: 1.3542 - val_loss: 1.4141 - val_mse: 1.3517\n",
      "Epoch 23/25\n",
      "171/177 [===========================>..] - ETA: 0s - loss: 1.4082 - mse: 1.3464\n",
      "Epoch 23: val_loss improved from 1.41411 to 1.40567, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e023_vl1.406.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4121 - mse: 1.3503 - val_loss: 1.4057 - val_mse: 1.3445\n",
      "Epoch 24/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.4075 - mse: 1.3469\n",
      "Epoch 24: val_loss did not improve from 1.40567\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4079 - mse: 1.3473 - val_loss: 1.4061 - val_mse: 1.3462\n",
      "Epoch 25/25\n",
      "177/177 [==============================] - ETA: 0s - loss: 1.4024 - mse: 1.3431\n",
      "Epoch 25: val_loss improved from 1.40567 to 1.39812, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e025_vl1.398.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4024 - mse: 1.3431 - val_loss: 1.3981 - val_mse: 1.3394\n",
      "Time elapsed to train: 26.28 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [1.574 1.927 0.874 2.212 1.647 0.870 0.775 0.559 0.468 0.662 0.332 0.280 0.276]\n",
      "<R> = [1.575 1.927 0.879 2.210 1.662 0.856 0.775 0.560 0.464 0.649 0.332 0.281 0.277]\n",
      "s_R = [0.089 0.212 0.696 0.221 0.364 29.060 0.070 0.029 0.128 0.557 0.000 0.156 0.203]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7438452 2.9398212 6.5004706 ... 2.832917  4.0359936 4.430693 ]\n",
      "mag_pred: [3.7438452 2.9398212 6.5004706 ... 2.832917  4.0359936 4.430693 ]\n",
      "Time elapsed to make plots: 19.12 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [43.251358  30.02301   27.364864  ...  3.2596164 32.241222  30.48486  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0213\n",
      "  1% : 0.133\n",
      "  10% : 0.297\n",
      "  50% : 0.793\n",
      "  90% : 3.48\n",
      "  99% : 77.2\n",
      "  100% : 6.86e+03\n",
      "<chi^2/d.o.f.> = 1.21\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 2883 stars (1.14%) based on chi^2/dof > 63.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [13.582407  22.054733  14.675617  ...  5.0840836  4.03971   14.845865 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0341\n",
      "  1% : 0.136\n",
      "  10% : 0.294\n",
      "  50% : 0.8\n",
      "  90% : 3.46\n",
      "  99% : 84.2\n",
      "  100% : 5.18e+03\n",
      "<chi^2/d.o.f.> = 1.21\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 79.84 s\n",
      "learning rate = 0.0006703200633637607\n",
      "setting learning rate to 0.0005488116360940264\n",
      "Iteration 4 of 20.\n",
      "Epoch 1/25\n",
      "173/177 [============================>.] - ETA: 0s - loss: 1.3460 - mse: 1.2881\n",
      "Epoch 1: val_loss improved from inf to 1.33585, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e001_vl1.336.h5\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.3468 - mse: 1.2890 - val_loss: 1.3358 - val_mse: 1.2787\n",
      "Epoch 2/25\n",
      "174/177 [============================>.] - ETA: 0s - loss: 1.3405 - mse: 1.2841\n",
      "Epoch 2: val_loss improved from 1.33585 to 1.33256, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e002_vl1.333.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.3409 - mse: 1.2844 - val_loss: 1.3326 - val_mse: 1.2768\n",
      "Epoch 3/25\n",
      "174/177 [============================>.] - ETA: 0s - loss: 1.3362 - mse: 1.2811\n",
      "Epoch 3: val_loss improved from 1.33256 to 1.32721, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e003_vl1.327.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.3362 - mse: 1.2811 - val_loss: 1.3272 - val_mse: 1.2727\n",
      "Epoch 4/25\n",
      "167/177 [===========================>..] - ETA: 0s - loss: 1.3314 - mse: 1.2773\n",
      "Epoch 4: val_loss did not improve from 1.32721\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.3315 - mse: 1.2775 - val_loss: 1.3283 - val_mse: 1.2747\n",
      "Epoch 5/25\n",
      "174/177 [============================>.] - ETA: 0s - loss: 1.3272 - mse: 1.2741\n",
      "Epoch 5: val_loss improved from 1.32721 to 1.32116, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e005_vl1.321.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.3276 - mse: 1.2745 - val_loss: 1.3212 - val_mse: 1.2686\n",
      "Epoch 6/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.3231 - mse: 1.2709\n",
      "Epoch 6: val_loss improved from 1.32116 to 1.31703, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e006_vl1.317.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.3237 - mse: 1.2715 - val_loss: 1.3170 - val_mse: 1.2654\n",
      "Epoch 7/25\n",
      "167/177 [===========================>..] - ETA: 0s - loss: 1.3209 - mse: 1.2696\n",
      "Epoch 7: val_loss improved from 1.31703 to 1.31046, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e007_vl1.310.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.3203 - mse: 1.2691 - val_loss: 1.3105 - val_mse: 1.2597\n",
      "Epoch 8/25\n",
      "169/177 [===========================>..] - ETA: 0s - loss: 1.3163 - mse: 1.2660\n",
      "Epoch 8: val_loss improved from 1.31046 to 1.30640, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e008_vl1.306.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.3161 - mse: 1.2658 - val_loss: 1.3064 - val_mse: 1.2566\n",
      "Epoch 9/25\n",
      "168/177 [===========================>..] - ETA: 0s - loss: 1.3111 - mse: 1.2617\n",
      "Epoch 9: val_loss did not improve from 1.30640\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.3118 - mse: 1.2625 - val_loss: 1.3077 - val_mse: 1.2588\n",
      "Epoch 10/25\n",
      "167/177 [===========================>..] - ETA: 0s - loss: 1.3093 - mse: 1.2608\n",
      "Epoch 10: val_loss improved from 1.30640 to 1.29946, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e010_vl1.299.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.3086 - mse: 1.2602 - val_loss: 1.2995 - val_mse: 1.2515\n",
      "Epoch 11/25\n",
      "174/177 [============================>.] - ETA: 0s - loss: 1.3054 - mse: 1.2579\n",
      "Epoch 11: val_loss improved from 1.29946 to 1.29763, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e011_vl1.298.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.3052 - mse: 1.2577 - val_loss: 1.2976 - val_mse: 1.2507\n",
      "Epoch 12/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.2998 - mse: 1.2533\n",
      "Epoch 12: val_loss improved from 1.29763 to 1.29523, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e012_vl1.295.h5\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 1.3014 - mse: 1.2550 - val_loss: 1.2952 - val_mse: 1.2492\n",
      "Epoch 13/25\n",
      "175/177 [============================>.] - ETA: 0s - loss: 1.2986 - mse: 1.2529\n",
      "Epoch 13: val_loss improved from 1.29523 to 1.29137, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e013_vl1.291.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2987 - mse: 1.2531 - val_loss: 1.2914 - val_mse: 1.2461\n",
      "Epoch 14/25\n",
      "175/177 [============================>.] - ETA: 0s - loss: 1.2961 - mse: 1.2510\n",
      "Epoch 14: val_loss improved from 1.29137 to 1.28865, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e014_vl1.289.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2958 - mse: 1.2507 - val_loss: 1.2886 - val_mse: 1.2439\n",
      "Epoch 15/25\n",
      "177/177 [==============================] - ETA: 0s - loss: 1.2935 - mse: 1.2490\n",
      "Epoch 15: val_loss improved from 1.28865 to 1.28605, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e015_vl1.286.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2935 - mse: 1.2490 - val_loss: 1.2860 - val_mse: 1.2419\n",
      "Epoch 16/25\n",
      "177/177 [==============================] - ETA: 0s - loss: 1.2906 - mse: 1.2468\n",
      "Epoch 16: val_loss improved from 1.28605 to 1.28226, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e016_vl1.282.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2906 - mse: 1.2468 - val_loss: 1.2823 - val_mse: 1.2386\n",
      "Epoch 17/25\n",
      "175/177 [============================>.] - ETA: 0s - loss: 1.2882 - mse: 1.2447\n",
      "Epoch 17: val_loss improved from 1.28226 to 1.27860, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e017_vl1.279.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2874 - mse: 1.2440 - val_loss: 1.2786 - val_mse: 1.2354\n",
      "Epoch 18/25\n",
      "169/177 [===========================>..] - ETA: 0s - loss: 1.2867 - mse: 1.2437\n",
      "Epoch 18: val_loss did not improve from 1.27860\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 1.2857 - mse: 1.2427 - val_loss: 1.2795 - val_mse: 1.2367\n",
      "Epoch 19/25\n",
      "170/177 [===========================>..] - ETA: 0s - loss: 1.2838 - mse: 1.2412\n",
      "Epoch 19: val_loss improved from 1.27860 to 1.27474, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e019_vl1.275.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2832 - mse: 1.2406 - val_loss: 1.2747 - val_mse: 1.2322\n",
      "Epoch 20/25\n",
      "174/177 [============================>.] - ETA: 0s - loss: 1.2784 - mse: 1.2361\n",
      "Epoch 20: val_loss did not improve from 1.27474\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2808 - mse: 1.2384 - val_loss: 1.2750 - val_mse: 1.2329\n",
      "Epoch 21/25\n",
      "174/177 [============================>.] - ETA: 0s - loss: 1.2781 - mse: 1.2361\n",
      "Epoch 21: val_loss improved from 1.27474 to 1.27078, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e021_vl1.271.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2788 - mse: 1.2369 - val_loss: 1.2708 - val_mse: 1.2291\n",
      "Epoch 22/25\n",
      "176/177 [============================>.] - ETA: 0s - loss: 1.2765 - mse: 1.2350\n",
      "Epoch 22: val_loss did not improve from 1.27078\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 1.2766 - mse: 1.2351 - val_loss: 1.2739 - val_mse: 1.2327\n",
      "Epoch 23/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.2748 - mse: 1.2338\n",
      "Epoch 23: val_loss improved from 1.27078 to 1.26480, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e023_vl1.265.h5\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 1.2748 - mse: 1.2337 - val_loss: 1.2648 - val_mse: 1.2240\n",
      "Epoch 24/25\n",
      "176/177 [============================>.] - ETA: 0s - loss: 1.2724 - mse: 1.2319\n",
      "Epoch 24: val_loss improved from 1.26480 to 1.26418, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e024_vl1.264.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2723 - mse: 1.2318 - val_loss: 1.2642 - val_mse: 1.2239\n",
      "Epoch 25/25\n",
      "174/177 [============================>.] - ETA: 0s - loss: 1.2703 - mse: 1.2303\n",
      "Epoch 25: val_loss improved from 1.26418 to 1.26175, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e025_vl1.262.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2698 - mse: 1.2298 - val_loss: 1.2617 - val_mse: 1.2221\n",
      "Time elapsed to train: 26.10 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [1.619 2.125 1.021 2.365 1.666 0.875 0.754 0.526 0.335 0.378 0.183 0.106 0.095]\n",
      "<R> = [1.619 2.125 1.025 2.365 1.658 0.861 0.754 0.526 0.335 0.375 0.183 0.106 0.095]\n",
      "s_R = [0.060 0.030 0.542 0.023 0.115 27.880 0.018 0.000 0.000 0.140 0.000 0.000 0.010]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.730321  2.6180375 6.3689137 ... 2.6576853 3.9755147 4.394324 ]\n",
      "mag_pred: [3.730321  2.6180375 6.3689137 ... 2.6576853 3.9755147 4.394324 ]\n",
      "Time elapsed to make plots: 19.11 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [43.482735  34.08779   21.330479  ...  2.8710861 32.496376  24.22017  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0136\n",
      "  1% : 0.121\n",
      "  10% : 0.271\n",
      "  50% : 0.722\n",
      "  90% : 3.33\n",
      "  99% : 72.1\n",
      "  100% : 6.99e+03\n",
      "<chi^2/d.o.f.> = 1.14\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 3213 stars (1.27%) based on chi^2/dof > 50.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [11.693024  28.92899   12.166353  ...  3.3081374  4.8843412 12.948969 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0152\n",
      "  1% : 0.126\n",
      "  10% : 0.271\n",
      "  50% : 0.728\n",
      "  90% : 3.29\n",
      "  99% : 78.4\n",
      "  100% : 5.16e+03\n",
      "<chi^2/d.o.f.> = 1.14\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 79.88 s\n",
      "learning rate = 0.0005488116294145584\n",
      "setting learning rate to 0.0004493289641172216\n",
      "Iteration 5 of 20.\n",
      "Epoch 1/25\n",
      "166/177 [===========================>..] - ETA: 0s - loss: 1.2002 - mse: 1.1607\n",
      "Epoch 1: val_loss improved from inf to 1.19201, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e001_vl1.192.h5\n",
      "177/177 [==============================] - 2s 7ms/step - loss: 1.1994 - mse: 1.1599 - val_loss: 1.1920 - val_mse: 1.1525\n",
      "Epoch 2/25\n",
      "173/177 [============================>.] - ETA: 0s - loss: 1.1967 - mse: 1.1573\n",
      "Epoch 2: val_loss improved from 1.19201 to 1.18946, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e002_vl1.189.h5\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.1972 - mse: 1.1578 - val_loss: 1.1895 - val_mse: 1.1502\n",
      "Epoch 3/25\n",
      "174/177 [============================>.] - ETA: 0s - loss: 1.1946 - mse: 1.1555\n",
      "Epoch 3: val_loss improved from 1.18946 to 1.18475, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e003_vl1.185.h5\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.1947 - mse: 1.1556 - val_loss: 1.1848 - val_mse: 1.1459\n",
      "Epoch 4/25\n",
      "171/177 [===========================>..] - ETA: 0s - loss: 1.1926 - mse: 1.1537\n",
      "Epoch 4: val_loss did not improve from 1.18475\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1929 - mse: 1.1540 - val_loss: 1.1851 - val_mse: 1.1462\n",
      "Epoch 5/25\n",
      "167/177 [===========================>..] - ETA: 0s - loss: 1.1910 - mse: 1.1521\n",
      "Epoch 5: val_loss improved from 1.18475 to 1.18414, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e005_vl1.184.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1915 - mse: 1.1527 - val_loss: 1.1841 - val_mse: 1.1454\n",
      "Epoch 6/25\n",
      "174/177 [============================>.] - ETA: 0s - loss: 1.1903 - mse: 1.1517\n",
      "Epoch 6: val_loss improved from 1.18414 to 1.18059, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e006_vl1.181.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1905 - mse: 1.1519 - val_loss: 1.1806 - val_mse: 1.1420\n",
      "Epoch 7/25\n",
      "174/177 [============================>.] - ETA: 0s - loss: 1.1869 - mse: 1.1484\n",
      "Epoch 7: val_loss improved from 1.18059 to 1.18015, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e007_vl1.180.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1877 - mse: 1.1492 - val_loss: 1.1802 - val_mse: 1.1417\n",
      "Epoch 8/25\n",
      "166/177 [===========================>..] - ETA: 0s - loss: 1.1873 - mse: 1.1489\n",
      "Epoch 8: val_loss improved from 1.18015 to 1.17767, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e008_vl1.178.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1870 - mse: 1.1487 - val_loss: 1.1777 - val_mse: 1.1395\n",
      "Epoch 9/25\n",
      "175/177 [============================>.] - ETA: 0s - loss: 1.1851 - mse: 1.1471\n",
      "Epoch 9: val_loss improved from 1.17767 to 1.17553, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e009_vl1.176.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1847 - mse: 1.1467 - val_loss: 1.1755 - val_mse: 1.1377\n",
      "Epoch 10/25\n",
      "171/177 [===========================>..] - ETA: 0s - loss: 1.1827 - mse: 1.1451\n",
      "Epoch 10: val_loss improved from 1.17553 to 1.17420, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e010_vl1.174.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1829 - mse: 1.1453 - val_loss: 1.1742 - val_mse: 1.1367\n",
      "Epoch 11/25\n",
      "174/177 [============================>.] - ETA: 0s - loss: 1.1830 - mse: 1.1457\n",
      "Epoch 11: val_loss did not improve from 1.17420\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1824 - mse: 1.1452 - val_loss: 1.1754 - val_mse: 1.1383\n",
      "Epoch 12/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.1796 - mse: 1.1427\n",
      "Epoch 12: val_loss improved from 1.17420 to 1.17106, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e012_vl1.171.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1793 - mse: 1.1424 - val_loss: 1.1711 - val_mse: 1.1344\n",
      "Epoch 13/25\n",
      "171/177 [===========================>..] - ETA: 0s - loss: 1.1807 - mse: 1.1443\n",
      "Epoch 13: val_loss improved from 1.17106 to 1.16983, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e013_vl1.170.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1782 - mse: 1.1419 - val_loss: 1.1698 - val_mse: 1.1336\n",
      "Epoch 14/25\n",
      "171/177 [===========================>..] - ETA: 0s - loss: 1.1754 - mse: 1.1395\n",
      "Epoch 14: val_loss improved from 1.16983 to 1.16802, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e014_vl1.168.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1767 - mse: 1.1408 - val_loss: 1.1680 - val_mse: 1.1322\n",
      "Epoch 15/25\n",
      "168/177 [===========================>..] - ETA: 0s - loss: 1.1764 - mse: 1.1409\n",
      "Epoch 15: val_loss improved from 1.16802 to 1.16706, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e015_vl1.167.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1746 - mse: 1.1391 - val_loss: 1.1671 - val_mse: 1.1317\n",
      "Epoch 16/25\n",
      "173/177 [============================>.] - ETA: 0s - loss: 1.1745 - mse: 1.1393\n",
      "Epoch 16: val_loss improved from 1.16706 to 1.16619, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e016_vl1.166.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1732 - mse: 1.1380 - val_loss: 1.1662 - val_mse: 1.1312\n",
      "Epoch 17/25\n",
      "174/177 [============================>.] - ETA: 0s - loss: 1.1728 - mse: 1.1381\n",
      "Epoch 17: val_loss did not improve from 1.16619\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1717 - mse: 1.1370 - val_loss: 1.1689 - val_mse: 1.1345\n",
      "Epoch 18/25\n",
      "174/177 [============================>.] - ETA: 0s - loss: 1.1705 - mse: 1.1364\n",
      "Epoch 18: val_loss improved from 1.16619 to 1.16168, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e018_vl1.162.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1698 - mse: 1.1356 - val_loss: 1.1617 - val_mse: 1.1277\n",
      "Epoch 19/25\n",
      "176/177 [============================>.] - ETA: 0s - loss: 1.1682 - mse: 1.1345\n",
      "Epoch 19: val_loss improved from 1.16168 to 1.16031, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e019_vl1.160.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1678 - mse: 1.1341 - val_loss: 1.1603 - val_mse: 1.1268\n",
      "Epoch 20/25\n",
      "169/177 [===========================>..] - ETA: 0s - loss: 1.1669 - mse: 1.1337\n",
      "Epoch 20: val_loss improved from 1.16031 to 1.15790, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e020_vl1.158.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1661 - mse: 1.1330 - val_loss: 1.1579 - val_mse: 1.1250\n",
      "Epoch 21/25\n",
      "169/177 [===========================>..] - ETA: 0s - loss: 1.1630 - mse: 1.1304\n",
      "Epoch 21: val_loss did not improve from 1.15790\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1645 - mse: 1.1319 - val_loss: 1.1585 - val_mse: 1.1262\n",
      "Epoch 22/25\n",
      "171/177 [===========================>..] - ETA: 0s - loss: 1.1624 - mse: 1.1303\n",
      "Epoch 22: val_loss improved from 1.15790 to 1.15426, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e022_vl1.154.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1631 - mse: 1.1311 - val_loss: 1.1543 - val_mse: 1.1224\n",
      "Epoch 23/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.1626 - mse: 1.1309\n",
      "Epoch 23: val_loss did not improve from 1.15426\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1619 - mse: 1.1302 - val_loss: 1.1554 - val_mse: 1.1237\n",
      "Epoch 24/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.1595 - mse: 1.1280\n",
      "Epoch 24: val_loss did not improve from 1.15426\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1603 - mse: 1.1288 - val_loss: 1.1552 - val_mse: 1.1238\n",
      "Epoch 25/25\n",
      "167/177 [===========================>..] - ETA: 0s - loss: 1.1609 - mse: 1.1296\n",
      "Epoch 25: val_loss improved from 1.15426 to 1.14941, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e025_vl1.149.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1593 - mse: 1.1280 - val_loss: 1.1494 - val_mse: 1.1183\n",
      "Time elapsed to train: 27.73 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [1.681 2.219 1.171 2.477 1.723 0.917 0.788 0.563 0.326 0.229 0.113 0.046 0.033]\n",
      "<R> = [1.680 2.219 1.171 2.478 1.715 0.903 0.788 0.563 0.326 0.229 0.113 0.046 0.033]\n",
      "s_R = [0.054 0.055 0.088 0.036 0.124 19.830 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7305293 2.6023998 6.3132973 ... 2.6685379 4.011095  4.4199033]\n",
      "mag_pred: [3.7305293 2.6023998 6.3132973 ... 2.6685379 4.011095  4.4199033]\n",
      "Time elapsed to make plots: 19.13 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [44.080307 34.130352 17.150986 ...  2.551801 34.39691  21.49533 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0128\n",
      "  1% : 0.111\n",
      "  10% : 0.251\n",
      "  50% : 0.678\n",
      "  90% : 3.27\n",
      "  99% : 68.8\n",
      "  100% : 7.02e+03\n",
      "<chi^2/d.o.f.> = 1.1\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 3635 stars (1.44%) based on chi^2/dof > 39.8\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [10.68851   39.16138   13.102191  ...  3.2737937  4.917303  13.190264 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0197\n",
      "  1% : 0.116\n",
      "  10% : 0.251\n",
      "  50% : 0.682\n",
      "  90% : 3.22\n",
      "  99% : 75.8\n",
      "  100% : 5.15e+03\n",
      "<chi^2/d.o.f.> = 1.11\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 82.69 s\n",
      "learning rate = 0.0004493289743550122\n",
      "setting learning rate to 0.00036787944117144236\n",
      "Iteration 6 of 20.\n",
      "Epoch 1/25\n",
      "172/176 [============================>.] - ETA: 0s - loss: 1.0905 - mse: 1.0596\n",
      "Epoch 1: val_loss improved from inf to 1.07829, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e001_vl1.078.h5\n",
      "176/176 [==============================] - 2s 7ms/step - loss: 1.0895 - mse: 1.0585 - val_loss: 1.0783 - val_mse: 1.0475\n",
      "Epoch 2/25\n",
      "167/176 [===========================>..] - ETA: 0s - loss: 1.0894 - mse: 1.0586\n",
      "Epoch 2: val_loss improved from 1.07829 to 1.07784, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e002_vl1.078.h5\n",
      "176/176 [==============================] - 1s 7ms/step - loss: 1.0881 - mse: 1.0573 - val_loss: 1.0778 - val_mse: 1.0472\n",
      "Epoch 3/25\n",
      "168/176 [===========================>..] - ETA: 0s - loss: 1.0881 - mse: 1.0576\n",
      "Epoch 3: val_loss improved from 1.07784 to 1.07627, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e003_vl1.076.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0871 - mse: 1.0565 - val_loss: 1.0763 - val_mse: 1.0459\n",
      "Epoch 4/25\n",
      "167/176 [===========================>..] - ETA: 0s - loss: 1.0847 - mse: 1.0544\n",
      "Epoch 4: val_loss improved from 1.07627 to 1.07533, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e004_vl1.075.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0862 - mse: 1.0558 - val_loss: 1.0753 - val_mse: 1.0451\n",
      "Epoch 5/25\n",
      "165/176 [===========================>..] - ETA: 0s - loss: 1.0850 - mse: 1.0549\n",
      "Epoch 5: val_loss did not improve from 1.07533\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0851 - mse: 1.0549 - val_loss: 1.0763 - val_mse: 1.0462\n",
      "Epoch 6/25\n",
      "171/176 [============================>.] - ETA: 0s - loss: 1.0847 - mse: 1.0547\n",
      "Epoch 6: val_loss improved from 1.07533 to 1.07301, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e006_vl1.073.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0841 - mse: 1.0540 - val_loss: 1.0730 - val_mse: 1.0431\n",
      "Epoch 7/25\n",
      "175/176 [============================>.] - ETA: 0s - loss: 1.0832 - mse: 1.0533\n",
      "Epoch 7: val_loss improved from 1.07301 to 1.07256, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e007_vl1.073.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0834 - mse: 1.0535 - val_loss: 1.0726 - val_mse: 1.0428\n",
      "Epoch 8/25\n",
      "175/176 [============================>.] - ETA: 0s - loss: 1.0832 - mse: 1.0534\n",
      "Epoch 8: val_loss improved from 1.07256 to 1.07172, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e008_vl1.072.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0828 - mse: 1.0530 - val_loss: 1.0717 - val_mse: 1.0420\n",
      "Epoch 9/25\n",
      "175/176 [============================>.] - ETA: 0s - loss: 1.0821 - mse: 1.0525\n",
      "Epoch 9: val_loss improved from 1.07172 to 1.07137, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e009_vl1.071.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0816 - mse: 1.0519 - val_loss: 1.0714 - val_mse: 1.0418\n",
      "Epoch 10/25\n",
      "168/176 [===========================>..] - ETA: 0s - loss: 1.0817 - mse: 1.0521\n",
      "Epoch 10: val_loss did not improve from 1.07137\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0810 - mse: 1.0515 - val_loss: 1.0716 - val_mse: 1.0421\n",
      "Epoch 11/25\n",
      "170/176 [===========================>..] - ETA: 0s - loss: 1.0818 - mse: 1.0523\n",
      "Epoch 11: val_loss improved from 1.07137 to 1.07095, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e011_vl1.071.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0799 - mse: 1.0504 - val_loss: 1.0709 - val_mse: 1.0416\n",
      "Epoch 12/25\n",
      "166/176 [===========================>..] - ETA: 0s - loss: 1.0776 - mse: 1.0482\n",
      "Epoch 12: val_loss improved from 1.07095 to 1.06886, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e012_vl1.069.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0790 - mse: 1.0496 - val_loss: 1.0689 - val_mse: 1.0396\n",
      "Epoch 13/25\n",
      "166/176 [===========================>..] - ETA: 0s - loss: 1.0782 - mse: 1.0489\n",
      "Epoch 13: val_loss improved from 1.06886 to 1.06825, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e013_vl1.068.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0782 - mse: 1.0490 - val_loss: 1.0683 - val_mse: 1.0391\n",
      "Epoch 14/25\n",
      "168/176 [===========================>..] - ETA: 0s - loss: 1.0779 - mse: 1.0488\n",
      "Epoch 14: val_loss improved from 1.06825 to 1.06705, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e014_vl1.067.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0776 - mse: 1.0485 - val_loss: 1.0671 - val_mse: 1.0380\n",
      "Epoch 15/25\n",
      "169/176 [===========================>..] - ETA: 0s - loss: 1.0742 - mse: 1.0453\n",
      "Epoch 15: val_loss did not improve from 1.06705\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0762 - mse: 1.0473 - val_loss: 1.0689 - val_mse: 1.0401\n",
      "Epoch 16/25\n",
      "171/176 [============================>.] - ETA: 0s - loss: 1.0754 - mse: 1.0466\n",
      "Epoch 16: val_loss improved from 1.06705 to 1.06405, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e016_vl1.064.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0751 - mse: 1.0463 - val_loss: 1.0640 - val_mse: 1.0354\n",
      "Epoch 17/25\n",
      "164/176 [==========================>...] - ETA: 0s - loss: 1.0732 - mse: 1.0447\n",
      "Epoch 17: val_loss improved from 1.06405 to 1.06319, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e017_vl1.063.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0741 - mse: 1.0456 - val_loss: 1.0632 - val_mse: 1.0347\n",
      "Epoch 18/25\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.0728 - mse: 1.0444\n",
      "Epoch 18: val_loss improved from 1.06319 to 1.06317, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e018_vl1.063.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0728 - mse: 1.0444 - val_loss: 1.0632 - val_mse: 1.0349\n",
      "Epoch 19/25\n",
      "171/176 [============================>.] - ETA: 0s - loss: 1.0709 - mse: 1.0428\n",
      "Epoch 19: val_loss improved from 1.06317 to 1.06069, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e019_vl1.061.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0719 - mse: 1.0437 - val_loss: 1.0607 - val_mse: 1.0326\n",
      "Epoch 20/25\n",
      "173/176 [============================>.] - ETA: 0s - loss: 1.0699 - mse: 1.0420\n",
      "Epoch 20: val_loss improved from 1.06069 to 1.06043, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e020_vl1.060.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0706 - mse: 1.0426 - val_loss: 1.0604 - val_mse: 1.0326\n",
      "Epoch 21/25\n",
      "169/176 [===========================>..] - ETA: 0s - loss: 1.0692 - mse: 1.0415\n",
      "Epoch 21: val_loss improved from 1.06043 to 1.05973, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e021_vl1.060.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0693 - mse: 1.0416 - val_loss: 1.0597 - val_mse: 1.0322\n",
      "Epoch 22/25\n",
      "169/176 [===========================>..] - ETA: 0s - loss: 1.0679 - mse: 1.0405\n",
      "Epoch 22: val_loss improved from 1.05973 to 1.05800, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e022_vl1.058.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0686 - mse: 1.0412 - val_loss: 1.0580 - val_mse: 1.0307\n",
      "Epoch 23/25\n",
      "174/176 [============================>.] - ETA: 0s - loss: 1.0668 - mse: 1.0396\n",
      "Epoch 23: val_loss improved from 1.05800 to 1.05729, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e023_vl1.057.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0669 - mse: 1.0397 - val_loss: 1.0573 - val_mse: 1.0302\n",
      "Epoch 24/25\n",
      "169/176 [===========================>..] - ETA: 0s - loss: 1.0664 - mse: 1.0395\n",
      "Epoch 24: val_loss improved from 1.05729 to 1.05465, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e024_vl1.055.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0659 - mse: 1.0390 - val_loss: 1.0547 - val_mse: 1.0280\n",
      "Epoch 25/25\n",
      "173/176 [============================>.] - ETA: 0s - loss: 1.0652 - mse: 1.0386\n",
      "Epoch 25: val_loss improved from 1.05465 to 1.05338, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e025_vl1.053.h5\n",
      "176/176 [==============================] - 1s 7ms/step - loss: 1.0642 - mse: 1.0376 - val_loss: 1.0534 - val_mse: 1.0270\n",
      "Time elapsed to train: 27.33 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [1.808 2.383 1.224 2.659 1.843 1.165 0.874 0.638 0.363 0.204 0.086 0.024 0.014]\n",
      "<R> = [1.808 2.383 1.224 2.660 1.835 1.152 0.874 0.638 0.363 0.204 0.086 0.024 0.014]\n",
      "s_R = [0.025 0.026 0.001 0.017 0.101 1.861 0.001 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7254875 2.5649118 6.3116484 ... 2.6728525 4.0252085 4.4352403]\n",
      "mag_pred: [3.7254875 2.5649118 6.3116484 ... 2.6728525 4.0252085 4.4352403]\n",
      "Time elapsed to make plots: 18.22 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [43.076607  35.77473   15.689616  ...  2.3454452 36.52743   19.984201 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0137\n",
      "  1% : 0.105\n",
      "  10% : 0.236\n",
      "  50% : 0.641\n",
      "  90% : 3.21\n",
      "  99% : 67.7\n",
      "  100% : 7.06e+03\n",
      "<chi^2/d.o.f.> = 1.07\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 4177 stars (1.65%) based on chi^2/dof > 31.6\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.815262  45.4373    12.503635  ...  3.5655851  5.02432   12.7215   ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0178\n",
      "  1% : 0.107\n",
      "  10% : 0.237\n",
      "  50% : 0.646\n",
      "  90% : 3.12\n",
      "  99% : 76\n",
      "  100% : 5.16e+03\n",
      "<chi^2/d.o.f.> = 1.07\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 81.03 s\n",
      "learning rate = 0.0003678794309962541\n",
      "setting learning rate to 0.00030119421191220205\n",
      "Iteration 7 of 20.\n",
      "Epoch 1/25\n",
      "173/176 [============================>.] - ETA: 0s - loss: 0.9951 - mse: 0.9688\n",
      "Epoch 1: val_loss improved from inf to 0.99883, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e001_vl0.999.h5\n",
      "176/176 [==============================] - 3s 7ms/step - loss: 0.9948 - mse: 0.9685 - val_loss: 0.9988 - val_mse: 0.9727\n",
      "Epoch 2/25\n",
      "170/176 [===========================>..] - ETA: 0s - loss: 0.9913 - mse: 0.9653\n",
      "Epoch 2: val_loss improved from 0.99883 to 0.99713, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e002_vl0.997.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9931 - mse: 0.9671 - val_loss: 0.9971 - val_mse: 0.9713\n",
      "Epoch 3/25\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.9921 - mse: 0.9664\n",
      "Epoch 3: val_loss improved from 0.99713 to 0.99410, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e003_vl0.994.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9921 - mse: 0.9664 - val_loss: 0.9941 - val_mse: 0.9686\n",
      "Epoch 4/25\n",
      "175/176 [============================>.] - ETA: 0s - loss: 0.9905 - mse: 0.9652\n",
      "Epoch 4: val_loss did not improve from 0.99410\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9904 - mse: 0.9651 - val_loss: 0.9954 - val_mse: 0.9703\n",
      "Epoch 5/25\n",
      "167/176 [===========================>..] - ETA: 0s - loss: 0.9897 - mse: 0.9648\n",
      "Epoch 5: val_loss improved from 0.99410 to 0.99257, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e005_vl0.993.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9888 - mse: 0.9639 - val_loss: 0.9926 - val_mse: 0.9679\n",
      "Epoch 6/25\n",
      "172/176 [============================>.] - ETA: 0s - loss: 0.9872 - mse: 0.9627\n",
      "Epoch 6: val_loss improved from 0.99257 to 0.99031, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e006_vl0.990.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9873 - mse: 0.9628 - val_loss: 0.9903 - val_mse: 0.9661\n",
      "Epoch 7/25\n",
      "168/176 [===========================>..] - ETA: 0s - loss: 0.9872 - mse: 0.9631\n",
      "Epoch 7: val_loss improved from 0.99031 to 0.98966, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e007_vl0.990.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9859 - mse: 0.9618 - val_loss: 0.9897 - val_mse: 0.9658\n",
      "Epoch 8/25\n",
      "171/176 [============================>.] - ETA: 0s - loss: 0.9842 - mse: 0.9605\n",
      "Epoch 8: val_loss did not improve from 0.98966\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9845 - mse: 0.9608 - val_loss: 0.9898 - val_mse: 0.9663\n",
      "Epoch 9/25\n",
      "174/176 [============================>.] - ETA: 0s - loss: 0.9839 - mse: 0.9606\n",
      "Epoch 9: val_loss improved from 0.98966 to 0.98604, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e009_vl0.986.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9834 - mse: 0.9601 - val_loss: 0.9860 - val_mse: 0.9629\n",
      "Epoch 10/25\n",
      "166/176 [===========================>..] - ETA: 0s - loss: 0.9828 - mse: 0.9599\n",
      "Epoch 10: val_loss improved from 0.98604 to 0.98477, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e010_vl0.985.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9821 - mse: 0.9592 - val_loss: 0.9848 - val_mse: 0.9621\n",
      "Epoch 11/25\n",
      "169/176 [===========================>..] - ETA: 0s - loss: 0.9817 - mse: 0.9592\n",
      "Epoch 11: val_loss did not improve from 0.98477\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9810 - mse: 0.9584 - val_loss: 0.9862 - val_mse: 0.9639\n",
      "Epoch 12/25\n",
      "174/176 [============================>.] - ETA: 0s - loss: 0.9798 - mse: 0.9576\n",
      "Epoch 12: val_loss improved from 0.98477 to 0.98286, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e012_vl0.983.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9795 - mse: 0.9573 - val_loss: 0.9829 - val_mse: 0.9608\n",
      "Epoch 13/25\n",
      "171/176 [============================>.] - ETA: 0s - loss: 0.9782 - mse: 0.9563\n",
      "Epoch 13: val_loss improved from 0.98286 to 0.98167, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e013_vl0.982.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9785 - mse: 0.9567 - val_loss: 0.9817 - val_mse: 0.9600\n",
      "Epoch 14/25\n",
      "172/176 [============================>.] - ETA: 0s - loss: 0.9787 - mse: 0.9571\n",
      "Epoch 14: val_loss improved from 0.98167 to 0.98106, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e014_vl0.981.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9775 - mse: 0.9559 - val_loss: 0.9811 - val_mse: 0.9597\n",
      "Epoch 15/25\n",
      "169/176 [===========================>..] - ETA: 0s - loss: 0.9769 - mse: 0.9557\n",
      "Epoch 15: val_loss improved from 0.98106 to 0.97995, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e015_vl0.980.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9768 - mse: 0.9556 - val_loss: 0.9799 - val_mse: 0.9589\n",
      "Epoch 16/25\n",
      "169/176 [===========================>..] - ETA: 0s - loss: 0.9765 - mse: 0.9556\n",
      "Epoch 16: val_loss improved from 0.97995 to 0.97844, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e016_vl0.978.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9753 - mse: 0.9544 - val_loss: 0.9784 - val_mse: 0.9578\n",
      "Epoch 17/25\n",
      "173/176 [============================>.] - ETA: 0s - loss: 0.9754 - mse: 0.9548\n",
      "Epoch 17: val_loss did not improve from 0.97844\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9750 - mse: 0.9544 - val_loss: 0.9787 - val_mse: 0.9583\n",
      "Epoch 18/25\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.9739 - mse: 0.9537\n",
      "Epoch 18: val_loss improved from 0.97844 to 0.97757, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e018_vl0.978.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9739 - mse: 0.9537 - val_loss: 0.9776 - val_mse: 0.9575\n",
      "Epoch 19/25\n",
      "166/176 [===========================>..] - ETA: 0s - loss: 0.9740 - mse: 0.9540\n",
      "Epoch 19: val_loss did not improve from 0.97757\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.9735 - mse: 0.9535 - val_loss: 0.9779 - val_mse: 0.9580\n",
      "Epoch 20/25\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.9730 - mse: 0.9532\n",
      "Epoch 20: val_loss improved from 0.97757 to 0.97648, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e020_vl0.976.h5\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.9730 - mse: 0.9532 - val_loss: 0.9765 - val_mse: 0.9567\n",
      "Epoch 21/25\n",
      "171/176 [============================>.] - ETA: 0s - loss: 0.9715 - mse: 0.9518\n",
      "Epoch 21: val_loss did not improve from 0.97648\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9726 - mse: 0.9529 - val_loss: 0.9767 - val_mse: 0.9570\n",
      "Epoch 22/25\n",
      "172/176 [============================>.] - ETA: 0s - loss: 0.9731 - mse: 0.9534\n",
      "Epoch 22: val_loss did not improve from 0.97648\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.9723 - mse: 0.9526 - val_loss: 0.9766 - val_mse: 0.9570\n",
      "Epoch 23/25\n",
      "173/176 [============================>.] - ETA: 0s - loss: 0.9726 - mse: 0.9529\n",
      "Epoch 23: val_loss improved from 0.97648 to 0.97637, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e023_vl0.976.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9722 - mse: 0.9525 - val_loss: 0.9764 - val_mse: 0.9567\n",
      "Epoch 24/25\n",
      "167/176 [===========================>..] - ETA: 0s - loss: 0.9726 - mse: 0.9530\n",
      "Epoch 24: val_loss improved from 0.97637 to 0.97535, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e024_vl0.975.h5\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.9717 - mse: 0.9520 - val_loss: 0.9754 - val_mse: 0.9557\n",
      "Epoch 25/25\n",
      "166/176 [===========================>..] - ETA: 0s - loss: 0.9712 - mse: 0.9515\n",
      "Epoch 25: val_loss improved from 0.97535 to 0.97476, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e025_vl0.975.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9714 - mse: 0.9517 - val_loss: 0.9748 - val_mse: 0.9550\n",
      "Time elapsed to train: 27.67 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.031 2.663 1.387 2.958 2.061 1.443 1.029 0.774 0.453 0.227 0.089 0.018 0.007]\n",
      "<R> = [2.031 2.662 1.387 2.958 2.061 1.443 1.029 0.774 0.453 0.227 0.089 0.018 0.007]\n",
      "s_R = [0.026 0.001 0.000 0.027 0.076 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.720442  2.5363271 6.3295035 ... 2.6766665 4.008405  4.4331512]\n",
      "mag_pred: [3.720442  2.5363271 6.3295035 ... 2.6766665 4.008405  4.4331512]\n",
      "Time elapsed to make plots: 18.35 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [42.240738 34.563667 15.208286 ...  2.497808 38.462017 20.091637]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0104\n",
      "  1% : 0.101\n",
      "  10% : 0.227\n",
      "  50% : 0.621\n",
      "  90% : 3.11\n",
      "  99% : 66.2\n",
      "  100% : 7.17e+03\n",
      "<chi^2/d.o.f.> = 1.05\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 4801 stars (1.9%) based on chi^2/dof > 25.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.719049  45.33733   12.008117  ...  3.5860307  5.293998  13.371464 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0161\n",
      "  1% : 0.101\n",
      "  10% : 0.228\n",
      "  50% : 0.626\n",
      "  90% : 3.01\n",
      "  99% : 73.9\n",
      "  100% : 5.17e+03\n",
      "<chi^2/d.o.f.> = 1.04\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 80.90 s\n",
      "learning rate = 0.0003011942026205361\n",
      "setting learning rate to 0.00024659696394160646\n",
      "Iteration 8 of 20.\n",
      "Epoch 1/25\n",
      "168/176 [===========================>..] - ETA: 0s - loss: 0.9001 - mse: 0.8805\n",
      "Epoch 1: val_loss improved from inf to 0.90336, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e001_vl0.903.h5\n",
      "176/176 [==============================] - 1s 7ms/step - loss: 0.9006 - mse: 0.8809 - val_loss: 0.9034 - val_mse: 0.8838\n",
      "Epoch 2/25\n",
      "175/176 [============================>.] - ETA: 0s - loss: 0.9003 - mse: 0.8808\n",
      "Epoch 2: val_loss improved from 0.90336 to 0.90328, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e002_vl0.903.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9003 - mse: 0.8807 - val_loss: 0.9033 - val_mse: 0.8838\n",
      "Epoch 3/25\n",
      "175/176 [============================>.] - ETA: 0s - loss: 0.9002 - mse: 0.8807\n",
      "Epoch 3: val_loss did not improve from 0.90328\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9003 - mse: 0.8807 - val_loss: 0.9042 - val_mse: 0.8847\n",
      "Epoch 4/25\n",
      "170/176 [===========================>..] - ETA: 0s - loss: 0.8995 - mse: 0.8800\n",
      "Epoch 4: val_loss improved from 0.90328 to 0.90322, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e004_vl0.903.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9001 - mse: 0.8806 - val_loss: 0.9032 - val_mse: 0.8837\n",
      "Epoch 5/25\n",
      "169/176 [===========================>..] - ETA: 0s - loss: 0.8989 - mse: 0.8794\n",
      "Epoch 5: val_loss did not improve from 0.90322\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8998 - mse: 0.8803 - val_loss: 0.9047 - val_mse: 0.8852\n",
      "Epoch 6/25\n",
      "175/176 [============================>.] - ETA: 0s - loss: 0.8996 - mse: 0.8800\n",
      "Epoch 6: val_loss did not improve from 0.90322\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8995 - mse: 0.8800 - val_loss: 0.9034 - val_mse: 0.8839\n",
      "Epoch 7/25\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.8994 - mse: 0.8799\n",
      "Epoch 7: val_loss did not improve from 0.90322\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8994 - mse: 0.8799 - val_loss: 0.9043 - val_mse: 0.8847\n",
      "Epoch 8/25\n",
      "166/176 [===========================>..] - ETA: 0s - loss: 0.8992 - mse: 0.8797\n",
      "Epoch 8: val_loss did not improve from 0.90322\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8992 - mse: 0.8797 - val_loss: 0.9033 - val_mse: 0.8838\n",
      "Epoch 9/25\n",
      "171/176 [============================>.] - ETA: 0s - loss: 0.8997 - mse: 0.8802\n",
      "Epoch 9: val_loss improved from 0.90322 to 0.90220, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e009_vl0.902.h5\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.8992 - mse: 0.8797 - val_loss: 0.9022 - val_mse: 0.8827\n",
      "Epoch 10/25\n",
      "168/176 [===========================>..] - ETA: 0s - loss: 0.8979 - mse: 0.8784\n",
      "Epoch 10: val_loss improved from 0.90220 to 0.90113, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e010_vl0.901.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8987 - mse: 0.8792 - val_loss: 0.9011 - val_mse: 0.8816\n",
      "Epoch 11/25\n",
      "173/176 [============================>.] - ETA: 0s - loss: 0.8991 - mse: 0.8796\n",
      "Epoch 11: val_loss did not improve from 0.90113\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8984 - mse: 0.8789 - val_loss: 0.9011 - val_mse: 0.8816\n",
      "Epoch 12/25\n",
      "171/176 [============================>.] - ETA: 0s - loss: 0.8992 - mse: 0.8797\n",
      "Epoch 12: val_loss did not improve from 0.90113\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8987 - mse: 0.8792 - val_loss: 0.9016 - val_mse: 0.8821\n",
      "Epoch 13/25\n",
      "163/176 [==========================>...] - ETA: 0s - loss: 0.8990 - mse: 0.8795\n",
      "Epoch 13: val_loss did not improve from 0.90113\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8983 - mse: 0.8788 - val_loss: 0.9023 - val_mse: 0.8829\n",
      "Epoch 14/25\n",
      "166/176 [===========================>..] - ETA: 0s - loss: 0.8989 - mse: 0.8793\n",
      "Epoch 14: val_loss did not improve from 0.90113\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8981 - mse: 0.8786 - val_loss: 0.9027 - val_mse: 0.8831\n",
      "Epoch 15/25\n",
      "169/176 [===========================>..] - ETA: 0s - loss: 0.8981 - mse: 0.8786\n",
      "Epoch 15: val_loss did not improve from 0.90113\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8981 - mse: 0.8785 - val_loss: 0.9012 - val_mse: 0.8817\n",
      "Epoch 16/25\n",
      "167/176 [===========================>..] - ETA: 0s - loss: 0.8979 - mse: 0.8784\n",
      "Epoch 16: val_loss improved from 0.90113 to 0.90065, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e016_vl0.901.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8978 - mse: 0.8783 - val_loss: 0.9006 - val_mse: 0.8811\n",
      "Epoch 17/25\n",
      "173/176 [============================>.] - ETA: 0s - loss: 0.8980 - mse: 0.8785\n",
      "Epoch 17: val_loss improved from 0.90065 to 0.90045, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e017_vl0.900.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8979 - mse: 0.8784 - val_loss: 0.9004 - val_mse: 0.8809\n",
      "Epoch 18/25\n",
      "168/176 [===========================>..] - ETA: 0s - loss: 0.8998 - mse: 0.8802\n",
      "Epoch 18: val_loss improved from 0.90045 to 0.90012, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e018_vl0.900.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8973 - mse: 0.8778 - val_loss: 0.9001 - val_mse: 0.8806\n",
      "Epoch 19/25\n",
      "167/176 [===========================>..] - ETA: 0s - loss: 0.8966 - mse: 0.8770\n",
      "Epoch 19: val_loss did not improve from 0.90012\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8971 - mse: 0.8775 - val_loss: 0.9017 - val_mse: 0.8821\n",
      "Epoch 20/25\n",
      "170/176 [===========================>..] - ETA: 0s - loss: 0.8979 - mse: 0.8784\n",
      "Epoch 20: val_loss did not improve from 0.90012\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8974 - mse: 0.8778 - val_loss: 0.9008 - val_mse: 0.8812\n",
      "Epoch 21/25\n",
      "169/176 [===========================>..] - ETA: 0s - loss: 0.8990 - mse: 0.8794\n",
      "Epoch 21: val_loss improved from 0.90012 to 0.90001, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e021_vl0.900.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8973 - mse: 0.8777 - val_loss: 0.9000 - val_mse: 0.8805\n",
      "Epoch 22/25\n",
      "165/176 [===========================>..] - ETA: 0s - loss: 0.8967 - mse: 0.8771\n",
      "Epoch 22: val_loss did not improve from 0.90001\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8970 - mse: 0.8775 - val_loss: 0.9013 - val_mse: 0.8817\n",
      "Epoch 23/25\n",
      "166/176 [===========================>..] - ETA: 0s - loss: 0.8969 - mse: 0.8773\n",
      "Epoch 23: val_loss did not improve from 0.90001\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.8967 - mse: 0.8771 - val_loss: 0.9007 - val_mse: 0.8811\n",
      "Epoch 24/25\n",
      "168/176 [===========================>..] - ETA: 0s - loss: 0.8961 - mse: 0.8765\n",
      "Epoch 24: val_loss did not improve from 0.90001\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8967 - mse: 0.8772 - val_loss: 0.9003 - val_mse: 0.8807\n",
      "Epoch 25/25\n",
      "171/176 [============================>.] - ETA: 0s - loss: 0.8964 - mse: 0.8768\n",
      "Epoch 25: val_loss improved from 0.90001 to 0.89938, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e025_vl0.899.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8965 - mse: 0.8769 - val_loss: 0.8994 - val_mse: 0.8798\n",
      "Time elapsed to train: 26.09 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.155 2.821 1.480 3.137 2.187 1.562 1.109 0.846 0.506 0.249 0.100 0.018 0.004]\n",
      "<R> = [2.155 2.821 1.480 3.137 2.187 1.562 1.109 0.846 0.506 0.249 0.100 0.018 0.004]\n",
      "s_R = [0.030 0.000 0.001 0.027 0.062 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.730279  2.5186946 6.3468933 ... 2.7268982 4.0076733 4.4373116]\n",
      "mag_pred: [3.730279  2.5186946 6.3468933 ... 2.7268982 4.0076733 4.4373116]\n",
      "Time elapsed to make plots: 19.95 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [41.157066  33.56214   14.457697  ...  2.7422352 37.68188   18.967785 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0116\n",
      "  1% : 0.102\n",
      "  10% : 0.228\n",
      "  50% : 0.62\n",
      "  90% : 3.1\n",
      "  99% : 66\n",
      "  100% : 7.2e+03\n",
      "<chi^2/d.o.f.> = 1.04\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 5590 stars (2.21%) based on chi^2/dof > 19.9\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.698506 47.93366  13.360384 ...  3.891202  5.12446  14.058777]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0223\n",
      "  1% : 0.102\n",
      "  10% : 0.228\n",
      "  50% : 0.625\n",
      "  90% : 3.02\n",
      "  99% : 72.7\n",
      "  100% : 5.17e+03\n",
      "<chi^2/d.o.f.> = 1.04\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 77.78 s\n",
      "learning rate = 0.00024659695918671787\n",
      "setting learning rate to 0.00020189651799465538\n",
      "Iteration 9 of 20.\n",
      "Epoch 1/25\n",
      "166/175 [===========================>..] - ETA: 0s - loss: 0.8485 - mse: 0.8290\n",
      "Epoch 1: val_loss improved from inf to 0.84765, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e001_vl0.848.h5\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.8490 - mse: 0.8294 - val_loss: 0.8476 - val_mse: 0.8281\n",
      "Epoch 2/25\n",
      "168/175 [===========================>..] - ETA: 0s - loss: 0.8485 - mse: 0.8290\n",
      "Epoch 2: val_loss improved from 0.84765 to 0.84688, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e002_vl0.847.h5\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8488 - mse: 0.8292 - val_loss: 0.8469 - val_mse: 0.8273\n",
      "Epoch 3/25\n",
      "169/175 [===========================>..] - ETA: 0s - loss: 0.8493 - mse: 0.8298\n",
      "Epoch 3: val_loss improved from 0.84688 to 0.84664, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e003_vl0.847.h5\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8487 - mse: 0.8292 - val_loss: 0.8466 - val_mse: 0.8271\n",
      "Epoch 4/25\n",
      "169/175 [===========================>..] - ETA: 0s - loss: 0.8481 - mse: 0.8285\n",
      "Epoch 4: val_loss did not improve from 0.84664\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8485 - mse: 0.8290 - val_loss: 0.8469 - val_mse: 0.8274\n",
      "Epoch 5/25\n",
      "172/175 [============================>.] - ETA: 0s - loss: 0.8491 - mse: 0.8296\n",
      "Epoch 5: val_loss improved from 0.84664 to 0.84619, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e005_vl0.846.h5\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8487 - mse: 0.8292 - val_loss: 0.8462 - val_mse: 0.8267\n",
      "Epoch 6/25\n",
      "167/175 [===========================>..] - ETA: 0s - loss: 0.8486 - mse: 0.8290\n",
      "Epoch 6: val_loss did not improve from 0.84619\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8484 - mse: 0.8289 - val_loss: 0.8468 - val_mse: 0.8273\n",
      "Epoch 7/25\n",
      "170/175 [============================>.] - ETA: 0s - loss: 0.8488 - mse: 0.8293\n",
      "Epoch 7: val_loss did not improve from 0.84619\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8486 - mse: 0.8290 - val_loss: 0.8468 - val_mse: 0.8273\n",
      "Epoch 8/25\n",
      "172/175 [============================>.] - ETA: 0s - loss: 0.8487 - mse: 0.8292\n",
      "Epoch 8: val_loss did not improve from 0.84619\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8480 - mse: 0.8284 - val_loss: 0.8464 - val_mse: 0.8269\n",
      "Epoch 9/25\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.8482 - mse: 0.8286\n",
      "Epoch 9: val_loss improved from 0.84619 to 0.84591, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e009_vl0.846.h5\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8482 - mse: 0.8286 - val_loss: 0.8459 - val_mse: 0.8264\n",
      "Epoch 10/25\n",
      "173/175 [============================>.] - ETA: 0s - loss: 0.8476 - mse: 0.8280\n",
      "Epoch 10: val_loss did not improve from 0.84591\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8479 - mse: 0.8283 - val_loss: 0.8466 - val_mse: 0.8270\n",
      "Epoch 11/25\n",
      "166/175 [===========================>..] - ETA: 0s - loss: 0.8479 - mse: 0.8284\n",
      "Epoch 11: val_loss improved from 0.84591 to 0.84567, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e011_vl0.846.h5\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8480 - mse: 0.8285 - val_loss: 0.8457 - val_mse: 0.8261\n",
      "Epoch 12/25\n",
      "169/175 [===========================>..] - ETA: 0s - loss: 0.8488 - mse: 0.8292\n",
      "Epoch 12: val_loss improved from 0.84567 to 0.84540, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e012_vl0.845.h5\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8477 - mse: 0.8282 - val_loss: 0.8454 - val_mse: 0.8259\n",
      "Epoch 13/25\n",
      "167/175 [===========================>..] - ETA: 0s - loss: 0.8475 - mse: 0.8280\n",
      "Epoch 13: val_loss improved from 0.84540 to 0.84532, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e013_vl0.845.h5\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8477 - mse: 0.8282 - val_loss: 0.8453 - val_mse: 0.8258\n",
      "Epoch 14/25\n",
      "173/175 [============================>.] - ETA: 0s - loss: 0.8467 - mse: 0.8272\n",
      "Epoch 14: val_loss did not improve from 0.84532\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8474 - mse: 0.8279 - val_loss: 0.8457 - val_mse: 0.8262\n",
      "Epoch 15/25\n",
      "164/175 [===========================>..] - ETA: 0s - loss: 0.8460 - mse: 0.8265\n",
      "Epoch 15: val_loss did not improve from 0.84532\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8472 - mse: 0.8276 - val_loss: 0.8457 - val_mse: 0.8262\n",
      "Epoch 16/25\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.8471 - mse: 0.8275\n",
      "Epoch 16: val_loss improved from 0.84532 to 0.84497, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e016_vl0.845.h5\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8471 - mse: 0.8275 - val_loss: 0.8450 - val_mse: 0.8254\n",
      "Epoch 17/25\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.8472 - mse: 0.8277\n",
      "Epoch 17: val_loss did not improve from 0.84497\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8472 - mse: 0.8277 - val_loss: 0.8450 - val_mse: 0.8254\n",
      "Epoch 18/25\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.8471 - mse: 0.8275\n",
      "Epoch 18: val_loss did not improve from 0.84497\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8470 - mse: 0.8274 - val_loss: 0.8451 - val_mse: 0.8255\n",
      "Epoch 19/25\n",
      "170/175 [============================>.] - ETA: 0s - loss: 0.8475 - mse: 0.8279\n",
      "Epoch 19: val_loss did not improve from 0.84497\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8471 - mse: 0.8276 - val_loss: 0.8455 - val_mse: 0.8259\n",
      "Epoch 20/25\n",
      "170/175 [============================>.] - ETA: 0s - loss: 0.8485 - mse: 0.8289\n",
      "Epoch 20: val_loss did not improve from 0.84497\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8473 - mse: 0.8277 - val_loss: 0.8467 - val_mse: 0.8271\n",
      "Epoch 21/25\n",
      "173/175 [============================>.] - ETA: 0s - loss: 0.8474 - mse: 0.8279\n",
      "Epoch 21: val_loss did not improve from 0.84497\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8470 - mse: 0.8275 - val_loss: 0.8450 - val_mse: 0.8255\n",
      "Epoch 22/25\n",
      "167/175 [===========================>..] - ETA: 0s - loss: 0.8466 - mse: 0.8270\n",
      "Epoch 22: val_loss did not improve from 0.84497\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8468 - mse: 0.8273 - val_loss: 0.8457 - val_mse: 0.8261\n",
      "Epoch 23/25\n",
      "163/175 [==========================>...] - ETA: 0s - loss: 0.8476 - mse: 0.8280\n",
      "Epoch 23: val_loss improved from 0.84497 to 0.84487, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e023_vl0.845.h5\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8468 - mse: 0.8272 - val_loss: 0.8449 - val_mse: 0.8253\n",
      "Epoch 24/25\n",
      "173/175 [============================>.] - ETA: 0s - loss: 0.8466 - mse: 0.8271\n",
      "Epoch 24: val_loss did not improve from 0.84487\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.8467 - mse: 0.8272 - val_loss: 0.8450 - val_mse: 0.8254\n",
      "Epoch 25/25\n",
      "168/175 [===========================>..] - ETA: 0s - loss: 0.8461 - mse: 0.8265\n",
      "Epoch 25: val_loss improved from 0.84487 to 0.84452, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e025_vl0.845.h5\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8463 - mse: 0.8268 - val_loss: 0.8445 - val_mse: 0.8250\n",
      "Time elapsed to train: 26.41 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.224 2.904 1.531 3.230 2.255 1.615 1.152 0.882 0.532 0.260 0.109 0.019 0.003]\n",
      "<R> = [2.224 2.904 1.531 3.230 2.255 1.615 1.152 0.882 0.532 0.260 0.109 0.019 0.003]\n",
      "s_R = [0.032 0.001 0.000 0.028 0.060 0.000 0.001 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7303433 2.4995737 6.356862  ... 2.767946  3.9974625 4.428505 ]\n",
      "mag_pred: [3.7303433 2.4995737 6.356862  ... 2.767946  3.9974625 4.428505 ]\n",
      "Time elapsed to make plots: 17.81 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [40.985893  34.040462  14.566343  ...  2.6887188 37.552555  19.332472 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00992\n",
      "  1% : 0.0997\n",
      "  10% : 0.227\n",
      "  50% : 0.621\n",
      "  90% : 3.09\n",
      "  99% : 65.8\n",
      "  100% : 7.21e+03\n",
      "<chi^2/d.o.f.> = 1.05\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 6570 stars (2.6%) based on chi^2/dof > 15.8\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.650155  49.87219   14.004373  ...  3.7123494  5.510965  13.600262 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0213\n",
      "  1% : 0.0995\n",
      "  10% : 0.226\n",
      "  50% : 0.627\n",
      "  90% : 3.01\n",
      "  99% : 72.3\n",
      "  100% : 5.17e+03\n",
      "<chi^2/d.o.f.> = 1.04\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 78.12 s\n",
      "learning rate = 0.00020189651695545763\n",
      "setting learning rate to 0.00016529888822158653\n",
      "Iteration 10 of 20.\n",
      "Epoch 1/25\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.8005 - mse: 0.7810\n",
      "Epoch 1: val_loss improved from inf to 0.79979, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e001_vl0.800.h5\n",
      "174/174 [==============================] - 2s 7ms/step - loss: 0.8003 - mse: 0.7808 - val_loss: 0.7998 - val_mse: 0.7803\n",
      "Epoch 2/25\n",
      "172/174 [============================>.] - ETA: 0s - loss: 0.8004 - mse: 0.7809\n",
      "Epoch 2: val_loss improved from 0.79979 to 0.79975, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e002_vl0.800.h5\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.8005 - mse: 0.7811 - val_loss: 0.7997 - val_mse: 0.7803\n",
      "Epoch 3/25\n",
      "174/174 [==============================] - ETA: 0s - loss: 0.8002 - mse: 0.7808\n",
      "Epoch 3: val_loss improved from 0.79975 to 0.79941, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e003_vl0.799.h5\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.8002 - mse: 0.7808 - val_loss: 0.7994 - val_mse: 0.7799\n",
      "Epoch 4/25\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.7999 - mse: 0.7804\n",
      "Epoch 4: val_loss improved from 0.79941 to 0.79938, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e004_vl0.799.h5\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.8002 - mse: 0.7807 - val_loss: 0.7994 - val_mse: 0.7799\n",
      "Epoch 5/25\n",
      "169/174 [============================>.] - ETA: 0s - loss: 0.7994 - mse: 0.7799\n",
      "Epoch 5: val_loss did not improve from 0.79938\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.8002 - mse: 0.7807 - val_loss: 0.7994 - val_mse: 0.7800\n",
      "Epoch 6/25\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.8001 - mse: 0.7806\n",
      "Epoch 6: val_loss improved from 0.79938 to 0.79897, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e006_vl0.799.h5\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.8002 - mse: 0.7807 - val_loss: 0.7990 - val_mse: 0.7795\n",
      "Epoch 7/25\n",
      "165/174 [===========================>..] - ETA: 0s - loss: 0.8013 - mse: 0.7819\n",
      "Epoch 7: val_loss did not improve from 0.79897\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.8000 - mse: 0.7806 - val_loss: 0.7994 - val_mse: 0.7800\n",
      "Epoch 8/25\n",
      "166/174 [===========================>..] - ETA: 0s - loss: 0.7991 - mse: 0.7797\n",
      "Epoch 8: val_loss did not improve from 0.79897\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.8002 - mse: 0.7807 - val_loss: 0.7996 - val_mse: 0.7801\n",
      "Epoch 9/25\n",
      "164/174 [===========================>..] - ETA: 0s - loss: 0.7999 - mse: 0.7804\n",
      "Epoch 9: val_loss did not improve from 0.79897\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7999 - mse: 0.7805 - val_loss: 0.8000 - val_mse: 0.7805\n",
      "Epoch 10/25\n",
      "167/174 [===========================>..] - ETA: 0s - loss: 0.7992 - mse: 0.7798\n",
      "Epoch 10: val_loss did not improve from 0.79897\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7998 - mse: 0.7804 - val_loss: 0.8004 - val_mse: 0.7809\n",
      "Epoch 11/25\n",
      "162/174 [==========================>...] - ETA: 0s - loss: 0.8002 - mse: 0.7808\n",
      "Epoch 11: val_loss did not improve from 0.79897\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7997 - mse: 0.7803 - val_loss: 0.7995 - val_mse: 0.7801\n",
      "Epoch 12/25\n",
      "163/174 [===========================>..] - ETA: 0s - loss: 0.8001 - mse: 0.7806\n",
      "Epoch 12: val_loss did not improve from 0.79897\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7997 - mse: 0.7802 - val_loss: 0.7996 - val_mse: 0.7802\n",
      "Epoch 13/25\n",
      "164/174 [===========================>..] - ETA: 0s - loss: 0.8010 - mse: 0.7816\n",
      "Epoch 13: val_loss did not improve from 0.79897\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.7998 - mse: 0.7803 - val_loss: 0.7990 - val_mse: 0.7796\n",
      "Epoch 14/25\n",
      "170/174 [============================>.] - ETA: 0s - loss: 0.7993 - mse: 0.7799\n",
      "Epoch 14: val_loss improved from 0.79897 to 0.79897, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e014_vl0.799.h5\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7996 - mse: 0.7802 - val_loss: 0.7990 - val_mse: 0.7795\n",
      "Epoch 15/25\n",
      "167/174 [===========================>..] - ETA: 0s - loss: 0.7993 - mse: 0.7799\n",
      "Epoch 15: val_loss did not improve from 0.79897\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7995 - mse: 0.7801 - val_loss: 0.7995 - val_mse: 0.7801\n",
      "Epoch 16/25\n",
      "165/174 [===========================>..] - ETA: 0s - loss: 0.7995 - mse: 0.7801\n",
      "Epoch 16: val_loss did not improve from 0.79897\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7994 - mse: 0.7799 - val_loss: 0.7992 - val_mse: 0.7798\n",
      "Epoch 17/25\n",
      "171/174 [============================>.] - ETA: 0s - loss: 0.7994 - mse: 0.7800\n",
      "Epoch 17: val_loss did not improve from 0.79897\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7996 - mse: 0.7802 - val_loss: 0.7995 - val_mse: 0.7800\n",
      "Epoch 18/25\n",
      "166/174 [===========================>..] - ETA: 0s - loss: 0.7997 - mse: 0.7803\n",
      "Epoch 18: val_loss improved from 0.79897 to 0.79831, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e018_vl0.798.h5\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7995 - mse: 0.7801 - val_loss: 0.7983 - val_mse: 0.7789\n",
      "Epoch 19/25\n",
      "172/174 [============================>.] - ETA: 0s - loss: 0.7992 - mse: 0.7797\n",
      "Epoch 19: val_loss did not improve from 0.79831\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.7993 - mse: 0.7799 - val_loss: 0.7989 - val_mse: 0.7794\n",
      "Epoch 20/25\n",
      "165/174 [===========================>..] - ETA: 0s - loss: 0.7991 - mse: 0.7796\n",
      "Epoch 20: val_loss improved from 0.79831 to 0.79830, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e020_vl0.798.h5\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.7992 - mse: 0.7798 - val_loss: 0.7983 - val_mse: 0.7789\n",
      "Epoch 21/25\n",
      "169/174 [============================>.] - ETA: 0s - loss: 0.8003 - mse: 0.7809\n",
      "Epoch 21: val_loss did not improve from 0.79830\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.7993 - mse: 0.7798 - val_loss: 0.7987 - val_mse: 0.7793\n",
      "Epoch 22/25\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.7987 - mse: 0.7793\n",
      "Epoch 22: val_loss improved from 0.79830 to 0.79829, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e022_vl0.798.h5\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7989 - mse: 0.7795 - val_loss: 0.7983 - val_mse: 0.7789\n",
      "Epoch 23/25\n",
      "166/174 [===========================>..] - ETA: 0s - loss: 0.7987 - mse: 0.7793\n",
      "Epoch 23: val_loss improved from 0.79829 to 0.79811, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e023_vl0.798.h5\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7990 - mse: 0.7796 - val_loss: 0.7981 - val_mse: 0.7787\n",
      "Epoch 24/25\n",
      "166/174 [===========================>..] - ETA: 0s - loss: 0.7999 - mse: 0.7805\n",
      "Epoch 24: val_loss did not improve from 0.79811\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7991 - mse: 0.7797 - val_loss: 0.7987 - val_mse: 0.7793\n",
      "Epoch 25/25\n",
      "169/174 [============================>.] - ETA: 0s - loss: 0.7986 - mse: 0.7792\n",
      "Epoch 25: val_loss improved from 0.79811 to 0.79808, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e025_vl0.798.h5\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7988 - mse: 0.7794 - val_loss: 0.7981 - val_mse: 0.7787\n",
      "Time elapsed to train: 25.38 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.262 2.948 1.559 3.278 2.290 1.644 1.176 0.903 0.548 0.268 0.115 0.020 0.002]\n",
      "<R> = [2.262 2.948 1.559 3.278 2.290 1.644 1.176 0.903 0.548 0.268 0.115 0.020 0.002]\n",
      "s_R = [0.033 0.001 0.000 0.026 0.056 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7262204 2.4639075 6.383215  ... 2.767935  3.9972448 4.4289374]\n",
      "mag_pred: [3.7262204 2.4639075 6.383215  ... 2.767935  3.9972448 4.4289374]\n",
      "Time elapsed to make plots: 20.11 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [40.223156 33.832737 14.755889 ...  2.797261 37.102257 18.853775]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00993\n",
      "  1% : 0.0989\n",
      "  10% : 0.224\n",
      "  50% : 0.615\n",
      "  90% : 3.06\n",
      "  99% : 65.9\n",
      "  100% : 7.21e+03\n",
      "<chi^2/d.o.f.> = 1.04\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 7819 stars (3.09%) based on chi^2/dof > 12.6\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.864623  51.501236  14.014622  ...  3.4335618  5.303658  13.619093 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0168\n",
      "  1% : 0.0989\n",
      "  10% : 0.224\n",
      "  50% : 0.621\n",
      "  90% : 2.96\n",
      "  99% : 72.3\n",
      "  100% : 5.17e+03\n",
      "<chi^2/d.o.f.> = 1.04\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 82.24 s\n",
      "learning rate = 0.00016529888671357185\n",
      "setting learning rate to 0.0001353352832366127\n",
      "Iteration 11 of 20.\n",
      "Epoch 1/25\n",
      "167/173 [===========================>..] - ETA: 0s - loss: 0.7511 - mse: 0.7317\n",
      "Epoch 1: val_loss improved from inf to 0.74925, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e001_vl0.749.h5\n",
      "173/173 [==============================] - 1s 7ms/step - loss: 0.7512 - mse: 0.7319 - val_loss: 0.7493 - val_mse: 0.7299\n",
      "Epoch 2/25\n",
      "169/173 [============================>.] - ETA: 0s - loss: 0.7516 - mse: 0.7322\n",
      "Epoch 2: val_loss did not improve from 0.74925\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7512 - mse: 0.7319 - val_loss: 0.7502 - val_mse: 0.7308\n",
      "Epoch 3/25\n",
      "168/173 [============================>.] - ETA: 0s - loss: 0.7513 - mse: 0.7320\n",
      "Epoch 3: val_loss improved from 0.74925 to 0.74915, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e003_vl0.749.h5\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7512 - mse: 0.7318 - val_loss: 0.7491 - val_mse: 0.7298\n",
      "Epoch 4/25\n",
      "171/173 [============================>.] - ETA: 0s - loss: 0.7510 - mse: 0.7317\n",
      "Epoch 4: val_loss did not improve from 0.74915\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.7511 - mse: 0.7318 - val_loss: 0.7495 - val_mse: 0.7302\n",
      "Epoch 5/25\n",
      "167/173 [===========================>..] - ETA: 0s - loss: 0.7520 - mse: 0.7327\n",
      "Epoch 5: val_loss did not improve from 0.74915\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7512 - mse: 0.7319 - val_loss: 0.7492 - val_mse: 0.7299\n",
      "Epoch 6/25\n",
      "170/173 [============================>.] - ETA: 0s - loss: 0.7510 - mse: 0.7317\n",
      "Epoch 6: val_loss improved from 0.74915 to 0.74914, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e006_vl0.749.h5\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7510 - mse: 0.7317 - val_loss: 0.7491 - val_mse: 0.7298\n",
      "Epoch 7/25\n",
      "165/173 [===========================>..] - ETA: 0s - loss: 0.7511 - mse: 0.7318\n",
      "Epoch 7: val_loss did not improve from 0.74914\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7511 - mse: 0.7318 - val_loss: 0.7502 - val_mse: 0.7309\n",
      "Epoch 8/25\n",
      "168/173 [============================>.] - ETA: 0s - loss: 0.7509 - mse: 0.7316\n",
      "Epoch 8: val_loss improved from 0.74914 to 0.74909, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e008_vl0.749.h5\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7510 - mse: 0.7317 - val_loss: 0.7491 - val_mse: 0.7298\n",
      "Epoch 9/25\n",
      "168/173 [============================>.] - ETA: 0s - loss: 0.7512 - mse: 0.7319\n",
      "Epoch 9: val_loss improved from 0.74909 to 0.74872, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e009_vl0.749.h5\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7510 - mse: 0.7317 - val_loss: 0.7487 - val_mse: 0.7294\n",
      "Epoch 10/25\n",
      "162/173 [===========================>..] - ETA: 0s - loss: 0.7507 - mse: 0.7314\n",
      "Epoch 10: val_loss did not improve from 0.74872\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7508 - mse: 0.7315 - val_loss: 0.7489 - val_mse: 0.7296\n",
      "Epoch 11/25\n",
      "164/173 [===========================>..] - ETA: 0s - loss: 0.7504 - mse: 0.7311\n",
      "Epoch 11: val_loss did not improve from 0.74872\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7509 - mse: 0.7316 - val_loss: 0.7494 - val_mse: 0.7301\n",
      "Epoch 12/25\n",
      "169/173 [============================>.] - ETA: 0s - loss: 0.7506 - mse: 0.7314\n",
      "Epoch 12: val_loss did not improve from 0.74872\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7509 - mse: 0.7316 - val_loss: 0.7488 - val_mse: 0.7296\n",
      "Epoch 13/25\n",
      "163/173 [===========================>..] - ETA: 0s - loss: 0.7510 - mse: 0.7317\n",
      "Epoch 13: val_loss did not improve from 0.74872\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7507 - mse: 0.7314 - val_loss: 0.7488 - val_mse: 0.7296\n",
      "Epoch 14/25\n",
      "167/173 [===========================>..] - ETA: 0s - loss: 0.7503 - mse: 0.7311\n",
      "Epoch 14: val_loss did not improve from 0.74872\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7506 - mse: 0.7314 - val_loss: 0.7495 - val_mse: 0.7303\n",
      "Epoch 15/25\n",
      "170/173 [============================>.] - ETA: 0s - loss: 0.7512 - mse: 0.7320\n",
      "Epoch 15: val_loss improved from 0.74872 to 0.74866, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e015_vl0.749.h5\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7506 - mse: 0.7313 - val_loss: 0.7487 - val_mse: 0.7294\n",
      "Epoch 16/25\n",
      "164/173 [===========================>..] - ETA: 0s - loss: 0.7503 - mse: 0.7311\n",
      "Epoch 16: val_loss improved from 0.74866 to 0.74852, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e016_vl0.749.h5\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7506 - mse: 0.7314 - val_loss: 0.7485 - val_mse: 0.7293\n",
      "Epoch 17/25\n",
      "169/173 [============================>.] - ETA: 0s - loss: 0.7500 - mse: 0.7308\n",
      "Epoch 17: val_loss did not improve from 0.74852\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.7505 - mse: 0.7313 - val_loss: 0.7486 - val_mse: 0.7293\n",
      "Epoch 18/25\n",
      "164/173 [===========================>..] - ETA: 0s - loss: 0.7501 - mse: 0.7309\n",
      "Epoch 18: val_loss did not improve from 0.74852\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7505 - mse: 0.7312 - val_loss: 0.7489 - val_mse: 0.7296\n",
      "Epoch 19/25\n",
      "170/173 [============================>.] - ETA: 0s - loss: 0.7502 - mse: 0.7309\n",
      "Epoch 19: val_loss did not improve from 0.74852\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.7504 - mse: 0.7312 - val_loss: 0.7488 - val_mse: 0.7296\n",
      "Epoch 20/25\n",
      "170/173 [============================>.] - ETA: 0s - loss: 0.7503 - mse: 0.7311\n",
      "Epoch 20: val_loss improved from 0.74852 to 0.74845, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e020_vl0.748.h5\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7504 - mse: 0.7312 - val_loss: 0.7484 - val_mse: 0.7292\n",
      "Epoch 21/25\n",
      "172/173 [============================>.] - ETA: 0s - loss: 0.7505 - mse: 0.7313\n",
      "Epoch 21: val_loss improved from 0.74845 to 0.74810, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e021_vl0.748.h5\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.7504 - mse: 0.7312 - val_loss: 0.7481 - val_mse: 0.7289\n",
      "Epoch 22/25\n",
      "166/173 [===========================>..] - ETA: 0s - loss: 0.7504 - mse: 0.7311\n",
      "Epoch 22: val_loss did not improve from 0.74810\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.7503 - mse: 0.7311 - val_loss: 0.7484 - val_mse: 0.7292\n",
      "Epoch 23/25\n",
      "171/173 [============================>.] - ETA: 0s - loss: 0.7503 - mse: 0.7311\n",
      "Epoch 23: val_loss improved from 0.74810 to 0.74803, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e023_vl0.748.h5\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7503 - mse: 0.7311 - val_loss: 0.7480 - val_mse: 0.7288\n",
      "Epoch 24/25\n",
      "172/173 [============================>.] - ETA: 0s - loss: 0.7504 - mse: 0.7312\n",
      "Epoch 24: val_loss did not improve from 0.74803\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7503 - mse: 0.7311 - val_loss: 0.7490 - val_mse: 0.7298\n",
      "Epoch 25/25\n",
      "167/173 [===========================>..] - ETA: 0s - loss: 0.7513 - mse: 0.7321\n",
      "Epoch 25: val_loss did not improve from 0.74803\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7503 - mse: 0.7311 - val_loss: 0.7486 - val_mse: 0.7294\n",
      "Time elapsed to train: 25.56 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.277 2.967 1.573 3.302 2.305 1.659 1.189 0.914 0.556 0.273 0.120 0.022 0.002]\n",
      "<R> = [2.278 2.967 1.573 3.302 2.305 1.659 1.189 0.914 0.556 0.273 0.120 0.022 0.002]\n",
      "s_R = [0.035 0.001 0.000 0.026 0.050 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7358954 2.4714448 6.4124203 ... 2.800575  4.0049667 4.435061 ]\n",
      "mag_pred: [3.7358954 2.4714448 6.4124203 ... 2.800575  4.0049667 4.435061 ]\n",
      "Time elapsed to make plots: 18.06 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [39.69886   33.869694  13.526233  ...  2.6977115 37.768955  17.52531  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00643\n",
      "  1% : 0.0972\n",
      "  10% : 0.221\n",
      "  50% : 0.607\n",
      "  90% : 3.07\n",
      "  99% : 65.6\n",
      "  100% : 7.2e+03\n",
      "<chi^2/d.o.f.> = 1.03\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 9395 stars (3.71%) based on chi^2/dof > 10.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.431132  52.31434   14.866297  ...  3.5754104  5.518223  13.4384985]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0168\n",
      "  1% : 0.0979\n",
      "  10% : 0.221\n",
      "  50% : 0.612\n",
      "  90% : 2.97\n",
      "  99% : 71.5\n",
      "  100% : 5.17e+03\n",
      "<chi^2/d.o.f.> = 1.03\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 79.62 s\n",
      "learning rate = 0.00013533528544940054\n",
      "setting learning rate to 0.00011080315836233387\n",
      "Iteration 12 of 20.\n",
      "Epoch 1/25\n",
      "170/172 [============================>.] - ETA: 0s - loss: 0.7081 - mse: 0.6889\n",
      "Epoch 1: val_loss improved from inf to 0.70822, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e001_vl0.708.h5\n",
      "172/172 [==============================] - 1s 7ms/step - loss: 0.7082 - mse: 0.6891 - val_loss: 0.7082 - val_mse: 0.6891\n",
      "Epoch 2/25\n",
      "162/172 [===========================>..] - ETA: 0s - loss: 0.7080 - mse: 0.6888\n",
      "Epoch 2: val_loss improved from 0.70822 to 0.70818, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e002_vl0.708.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7080 - mse: 0.6889 - val_loss: 0.7082 - val_mse: 0.6890\n",
      "Epoch 3/25\n",
      "169/172 [============================>.] - ETA: 0s - loss: 0.7084 - mse: 0.6892\n",
      "Epoch 3: val_loss improved from 0.70818 to 0.70743, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e003_vl0.707.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7081 - mse: 0.6889 - val_loss: 0.7074 - val_mse: 0.6883\n",
      "Epoch 4/25\n",
      "169/172 [============================>.] - ETA: 0s - loss: 0.7078 - mse: 0.6887\n",
      "Epoch 4: val_loss did not improve from 0.70743\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7081 - mse: 0.6890 - val_loss: 0.7082 - val_mse: 0.6890\n",
      "Epoch 5/25\n",
      "165/172 [===========================>..] - ETA: 0s - loss: 0.7085 - mse: 0.6894\n",
      "Epoch 5: val_loss did not improve from 0.70743\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7080 - mse: 0.6889 - val_loss: 0.7077 - val_mse: 0.6886\n",
      "Epoch 6/25\n",
      "172/172 [==============================] - ETA: 0s - loss: 0.7080 - mse: 0.6889\n",
      "Epoch 6: val_loss did not improve from 0.70743\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7080 - mse: 0.6889 - val_loss: 0.7083 - val_mse: 0.6892\n",
      "Epoch 7/25\n",
      "172/172 [==============================] - ETA: 0s - loss: 0.7080 - mse: 0.6889\n",
      "Epoch 7: val_loss did not improve from 0.70743\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7080 - mse: 0.6889 - val_loss: 0.7076 - val_mse: 0.6885\n",
      "Epoch 8/25\n",
      "167/172 [============================>.] - ETA: 0s - loss: 0.7084 - mse: 0.6893\n",
      "Epoch 8: val_loss did not improve from 0.70743\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7080 - mse: 0.6889 - val_loss: 0.7075 - val_mse: 0.6883\n",
      "Epoch 9/25\n",
      "167/172 [============================>.] - ETA: 0s - loss: 0.7084 - mse: 0.6893\n",
      "Epoch 9: val_loss did not improve from 0.70743\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7079 - mse: 0.6888 - val_loss: 0.7089 - val_mse: 0.6898\n",
      "Epoch 10/25\n",
      "163/172 [===========================>..] - ETA: 0s - loss: 0.7082 - mse: 0.6891\n",
      "Epoch 10: val_loss did not improve from 0.70743\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7080 - mse: 0.6889 - val_loss: 0.7079 - val_mse: 0.6889\n",
      "Epoch 11/25\n",
      "164/172 [===========================>..] - ETA: 0s - loss: 0.7084 - mse: 0.6893\n",
      "Epoch 11: val_loss did not improve from 0.70743\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7079 - mse: 0.6888 - val_loss: 0.7077 - val_mse: 0.6886\n",
      "Epoch 12/25\n",
      "163/172 [===========================>..] - ETA: 0s - loss: 0.7078 - mse: 0.6887\n",
      "Epoch 12: val_loss did not improve from 0.70743\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7079 - mse: 0.6888 - val_loss: 0.7079 - val_mse: 0.6888\n",
      "Epoch 13/25\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.7075 - mse: 0.6884\n",
      "Epoch 13: val_loss improved from 0.70743 to 0.70724, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e013_vl0.707.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7078 - mse: 0.6888 - val_loss: 0.7072 - val_mse: 0.6882\n",
      "Epoch 14/25\n",
      "165/172 [===========================>..] - ETA: 0s - loss: 0.7074 - mse: 0.6883\n",
      "Epoch 14: val_loss did not improve from 0.70724\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7078 - mse: 0.6887 - val_loss: 0.7073 - val_mse: 0.6882\n",
      "Epoch 15/25\n",
      "164/172 [===========================>..] - ETA: 0s - loss: 0.7085 - mse: 0.6894\n",
      "Epoch 15: val_loss did not improve from 0.70724\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7077 - mse: 0.6886 - val_loss: 0.7073 - val_mse: 0.6883\n",
      "Epoch 16/25\n",
      "167/172 [============================>.] - ETA: 0s - loss: 0.7085 - mse: 0.6894\n",
      "Epoch 16: val_loss did not improve from 0.70724\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7077 - mse: 0.6887 - val_loss: 0.7082 - val_mse: 0.6892\n",
      "Epoch 17/25\n",
      "166/172 [===========================>..] - ETA: 0s - loss: 0.7079 - mse: 0.6888\n",
      "Epoch 17: val_loss did not improve from 0.70724\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7078 - mse: 0.6887 - val_loss: 0.7075 - val_mse: 0.6885\n",
      "Epoch 18/25\n",
      "162/172 [===========================>..] - ETA: 0s - loss: 0.7081 - mse: 0.6891\n",
      "Epoch 18: val_loss did not improve from 0.70724\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7076 - mse: 0.6885 - val_loss: 0.7075 - val_mse: 0.6885\n",
      "Epoch 19/25\n",
      "163/172 [===========================>..] - ETA: 0s - loss: 0.7071 - mse: 0.6880\n",
      "Epoch 19: val_loss improved from 0.70724 to 0.70713, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e019_vl0.707.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7076 - mse: 0.6886 - val_loss: 0.7071 - val_mse: 0.6881\n",
      "Epoch 20/25\n",
      "172/172 [==============================] - ETA: 0s - loss: 0.7076 - mse: 0.6886\n",
      "Epoch 20: val_loss did not improve from 0.70713\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7076 - mse: 0.6886 - val_loss: 0.7078 - val_mse: 0.6887\n",
      "Epoch 21/25\n",
      "169/172 [============================>.] - ETA: 0s - loss: 0.7076 - mse: 0.6886\n",
      "Epoch 21: val_loss did not improve from 0.70713\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7076 - mse: 0.6886 - val_loss: 0.7074 - val_mse: 0.6884\n",
      "Epoch 22/25\n",
      "160/172 [==========================>...] - ETA: 0s - loss: 0.7076 - mse: 0.6886\n",
      "Epoch 22: val_loss did not improve from 0.70713\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7075 - mse: 0.6885 - val_loss: 0.7072 - val_mse: 0.6882\n",
      "Epoch 23/25\n",
      "164/172 [===========================>..] - ETA: 0s - loss: 0.7078 - mse: 0.6888\n",
      "Epoch 23: val_loss improved from 0.70713 to 0.70706, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e023_vl0.707.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7075 - mse: 0.6885 - val_loss: 0.7071 - val_mse: 0.6881\n",
      "Epoch 24/25\n",
      "169/172 [============================>.] - ETA: 0s - loss: 0.7068 - mse: 0.6878\n",
      "Epoch 24: val_loss did not improve from 0.70706\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7075 - mse: 0.6885 - val_loss: 0.7074 - val_mse: 0.6885\n",
      "Epoch 25/25\n",
      "163/172 [===========================>..] - ETA: 0s - loss: 0.7081 - mse: 0.6891\n",
      "Epoch 25: val_loss improved from 0.70706 to 0.70705, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e025_vl0.707.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7074 - mse: 0.6884 - val_loss: 0.7070 - val_mse: 0.6881\n",
      "Time elapsed to train: 26.26 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.287 2.977 1.579 3.311 2.312 1.665 1.195 0.918 0.561 0.275 0.123 0.024 0.002]\n",
      "<R> = [2.287 2.977 1.579 3.311 2.311 1.665 1.195 0.918 0.561 0.275 0.123 0.024 0.002]\n",
      "s_R = [0.037 0.001 0.000 0.022 0.049 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7272398 2.4426713 6.426101  ... 2.7995126 4.0017753 4.428658 ]\n",
      "mag_pred: [3.7272398 2.4426713 6.426101  ... 2.7995126 4.0017753 4.428658 ]\n",
      "Time elapsed to make plots: 20.40 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [40.079483  33.604008  13.0688305 ...  2.8017938 37.00868   17.099232 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00904\n",
      "  1% : 0.0965\n",
      "  10% : 0.22\n",
      "  50% : 0.603\n",
      "  90% : 3.03\n",
      "  99% : 65.9\n",
      "  100% : 7.21e+03\n",
      "<chi^2/d.o.f.> = 1.02\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 11243 stars (4.44%) based on chi^2/dof > 7.9\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.832051  54.18707   14.895131  ...  3.3222535  5.475881  13.733231 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0144\n",
      "  1% : 0.0972\n",
      "  10% : 0.22\n",
      "  50% : 0.607\n",
      "  90% : 2.94\n",
      "  99% : 71.4\n",
      "  100% : 5.17e+03\n",
      "<chi^2/d.o.f.> = 1.02\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 78.72 s\n",
      "learning rate = 0.00011080315744038671\n",
      "setting learning rate to 9.071795328941248e-05\n",
      "Iteration 13 of 20.\n",
      "Epoch 1/25\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.6659 - mse: 0.6470\n",
      "Epoch 1: val_loss improved from inf to 0.66546, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e001_vl0.665.h5\n",
      "171/171 [==============================] - 2s 7ms/step - loss: 0.6664 - mse: 0.6475 - val_loss: 0.6655 - val_mse: 0.6465\n",
      "Epoch 2/25\n",
      "170/171 [============================>.] - ETA: 0s - loss: 0.6665 - mse: 0.6476\n",
      "Epoch 2: val_loss did not improve from 0.66546\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6664 - mse: 0.6475 - val_loss: 0.6655 - val_mse: 0.6466\n",
      "Epoch 3/25\n",
      "164/171 [===========================>..] - ETA: 0s - loss: 0.6665 - mse: 0.6476\n",
      "Epoch 3: val_loss did not improve from 0.66546\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6664 - mse: 0.6475 - val_loss: 0.6655 - val_mse: 0.6466\n",
      "Epoch 4/25\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.6665 - mse: 0.6476\n",
      "Epoch 4: val_loss improved from 0.66546 to 0.66539, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e004_vl0.665.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6665 - mse: 0.6476 - val_loss: 0.6654 - val_mse: 0.6465\n",
      "Epoch 5/25\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.6664 - mse: 0.6474\n",
      "Epoch 5: val_loss did not improve from 0.66539\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6664 - mse: 0.6475 - val_loss: 0.6657 - val_mse: 0.6468\n",
      "Epoch 6/25\n",
      "164/171 [===========================>..] - ETA: 0s - loss: 0.6668 - mse: 0.6479\n",
      "Epoch 6: val_loss did not improve from 0.66539\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6663 - mse: 0.6474 - val_loss: 0.6655 - val_mse: 0.6466\n",
      "Epoch 7/25\n",
      "163/171 [===========================>..] - ETA: 0s - loss: 0.6660 - mse: 0.6471\n",
      "Epoch 7: val_loss improved from 0.66539 to 0.66530, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e007_vl0.665.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6663 - mse: 0.6474 - val_loss: 0.6653 - val_mse: 0.6464\n",
      "Epoch 8/25\n",
      "167/171 [============================>.] - ETA: 0s - loss: 0.6666 - mse: 0.6477\n",
      "Epoch 8: val_loss did not improve from 0.66530\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.6663 - mse: 0.6475 - val_loss: 0.6656 - val_mse: 0.6467\n",
      "Epoch 9/25\n",
      "166/171 [============================>.] - ETA: 0s - loss: 0.6663 - mse: 0.6474\n",
      "Epoch 9: val_loss did not improve from 0.66530\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6662 - mse: 0.6473 - val_loss: 0.6654 - val_mse: 0.6466\n",
      "Epoch 10/25\n",
      "163/171 [===========================>..] - ETA: 0s - loss: 0.6666 - mse: 0.6478\n",
      "Epoch 10: val_loss did not improve from 0.66530\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6663 - mse: 0.6475 - val_loss: 0.6654 - val_mse: 0.6466\n",
      "Epoch 11/25\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.6663 - mse: 0.6474\n",
      "Epoch 11: val_loss improved from 0.66530 to 0.66528, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e011_vl0.665.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6662 - mse: 0.6474 - val_loss: 0.6653 - val_mse: 0.6464\n",
      "Epoch 12/25\n",
      "162/171 [===========================>..] - ETA: 0s - loss: 0.6663 - mse: 0.6474\n",
      "Epoch 12: val_loss did not improve from 0.66528\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6661 - mse: 0.6473 - val_loss: 0.6653 - val_mse: 0.6464\n",
      "Epoch 13/25\n",
      "170/171 [============================>.] - ETA: 0s - loss: 0.6660 - mse: 0.6471\n",
      "Epoch 13: val_loss improved from 0.66528 to 0.66511, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e013_vl0.665.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6661 - mse: 0.6473 - val_loss: 0.6651 - val_mse: 0.6463\n",
      "Epoch 14/25\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 0.6655 - mse: 0.6467\n",
      "Epoch 14: val_loss did not improve from 0.66511\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6661 - mse: 0.6472 - val_loss: 0.6655 - val_mse: 0.6467\n",
      "Epoch 15/25\n",
      "168/171 [============================>.] - ETA: 0s - loss: 0.6662 - mse: 0.6474\n",
      "Epoch 15: val_loss did not improve from 0.66511\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6660 - mse: 0.6472 - val_loss: 0.6653 - val_mse: 0.6465\n",
      "Epoch 16/25\n",
      "167/171 [============================>.] - ETA: 0s - loss: 0.6663 - mse: 0.6475\n",
      "Epoch 16: val_loss did not improve from 0.66511\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.6661 - mse: 0.6473 - val_loss: 0.6655 - val_mse: 0.6466\n",
      "Epoch 17/25\n",
      "161/171 [===========================>..] - ETA: 0s - loss: 0.6661 - mse: 0.6473\n",
      "Epoch 17: val_loss did not improve from 0.66511\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6661 - mse: 0.6473 - val_loss: 0.6653 - val_mse: 0.6465\n",
      "Epoch 18/25\n",
      "162/171 [===========================>..] - ETA: 0s - loss: 0.6657 - mse: 0.6469\n",
      "Epoch 18: val_loss did not improve from 0.66511\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.6659 - mse: 0.6471 - val_loss: 0.6656 - val_mse: 0.6467\n",
      "Epoch 19/25\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 0.6659 - mse: 0.6471\n",
      "Epoch 19: val_loss improved from 0.66511 to 0.66511, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e019_vl0.665.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6660 - mse: 0.6472 - val_loss: 0.6651 - val_mse: 0.6463\n",
      "Epoch 20/25\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 0.6662 - mse: 0.6474\n",
      "Epoch 20: val_loss improved from 0.66511 to 0.66503, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e020_vl0.665.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6660 - mse: 0.6472 - val_loss: 0.6650 - val_mse: 0.6462\n",
      "Epoch 21/25\n",
      "169/171 [============================>.] - ETA: 0s - loss: 0.6661 - mse: 0.6473\n",
      "Epoch 21: val_loss improved from 0.66503 to 0.66486, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e021_vl0.665.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6660 - mse: 0.6472 - val_loss: 0.6649 - val_mse: 0.6461\n",
      "Epoch 22/25\n",
      "168/171 [============================>.] - ETA: 0s - loss: 0.6658 - mse: 0.6470\n",
      "Epoch 22: val_loss improved from 0.66486 to 0.66484, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e022_vl0.665.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6659 - mse: 0.6471 - val_loss: 0.6648 - val_mse: 0.6461\n",
      "Epoch 23/25\n",
      "162/171 [===========================>..] - ETA: 0s - loss: 0.6652 - mse: 0.6465\n",
      "Epoch 23: val_loss did not improve from 0.66484\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6658 - mse: 0.6471 - val_loss: 0.6650 - val_mse: 0.6462\n",
      "Epoch 24/25\n",
      "167/171 [============================>.] - ETA: 0s - loss: 0.6659 - mse: 0.6472\n",
      "Epoch 24: val_loss did not improve from 0.66484\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6658 - mse: 0.6471 - val_loss: 0.6649 - val_mse: 0.6461\n",
      "Epoch 25/25\n",
      "167/171 [============================>.] - ETA: 0s - loss: 0.6653 - mse: 0.6465\n",
      "Epoch 25: val_loss improved from 0.66484 to 0.66470, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e025_vl0.665.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6658 - mse: 0.6470 - val_loss: 0.6647 - val_mse: 0.6460\n",
      "Time elapsed to train: 25.48 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.286 2.974 1.580 3.309 2.312 1.666 1.196 0.918 0.563 0.277 0.125 0.026 0.001]\n",
      "<R> = [2.287 2.974 1.580 3.309 2.311 1.666 1.196 0.918 0.563 0.277 0.125 0.026 0.001]\n",
      "s_R = [0.039 0.001 0.000 0.021 0.041 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.726186  2.4163876 6.442615  ... 2.7937584 4.006418  4.431144 ]\n",
      "mag_pred: [3.726186  2.4163876 6.442615  ... 2.7937584 4.006418  4.431144 ]\n",
      "Time elapsed to make plots: 17.79 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [39.368187  32.95085   12.614156  ...  2.8296373 36.287357  15.678883 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0106\n",
      "  1% : 0.0956\n",
      "  10% : 0.218\n",
      "  50% : 0.596\n",
      "  90% : 3\n",
      "  99% : 65.6\n",
      "  100% : 7.21e+03\n",
      "<chi^2/d.o.f.> = 1.01\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 13525 stars (5.34%) based on chi^2/dof > 6.3\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.854858  55.5926    14.723104  ...  3.2094865  5.595221  13.410222 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0143\n",
      "  1% : 0.0953\n",
      "  10% : 0.218\n",
      "  50% : 0.601\n",
      "  90% : 2.92\n",
      "  99% : 70.7\n",
      "  100% : 5.17e+03\n",
      "<chi^2/d.o.f.> = 1.01\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 80.61 s\n",
      "learning rate = 9.071795648196712e-05\n",
      "setting learning rate to 7.427357821433387e-05\n",
      "Iteration 14 of 20.\n",
      "Epoch 1/25\n",
      "166/169 [============================>.] - ETA: 0s - loss: 0.6265 - mse: 0.6077\n",
      "Epoch 1: val_loss improved from inf to 0.62324, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e001_vl0.623.h5\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.6261 - mse: 0.6073 - val_loss: 0.6232 - val_mse: 0.6045\n",
      "Epoch 2/25\n",
      "165/169 [============================>.] - ETA: 0s - loss: 0.6260 - mse: 0.6073\n",
      "Epoch 2: val_loss did not improve from 0.62324\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6259 - mse: 0.6072 - val_loss: 0.6233 - val_mse: 0.6046\n",
      "Epoch 3/25\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.6260 - mse: 0.6073\n",
      "Epoch 3: val_loss improved from 0.62324 to 0.62313, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e003_vl0.623.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6260 - mse: 0.6073 - val_loss: 0.6231 - val_mse: 0.6044\n",
      "Epoch 4/25\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.6260 - mse: 0.6073\n",
      "Epoch 4: val_loss did not improve from 0.62313\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6260 - mse: 0.6073 - val_loss: 0.6233 - val_mse: 0.6046\n",
      "Epoch 5/25\n",
      "161/169 [===========================>..] - ETA: 0s - loss: 0.6256 - mse: 0.6069\n",
      "Epoch 5: val_loss did not improve from 0.62313\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6260 - mse: 0.6073 - val_loss: 0.6234 - val_mse: 0.6047\n",
      "Epoch 6/25\n",
      "161/169 [===========================>..] - ETA: 0s - loss: 0.6256 - mse: 0.6069\n",
      "Epoch 6: val_loss improved from 0.62313 to 0.62310, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e006_vl0.623.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6260 - mse: 0.6073 - val_loss: 0.6231 - val_mse: 0.6044\n",
      "Epoch 7/25\n",
      "164/169 [============================>.] - ETA: 0s - loss: 0.6260 - mse: 0.6074\n",
      "Epoch 7: val_loss improved from 0.62310 to 0.62302, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e007_vl0.623.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6259 - mse: 0.6072 - val_loss: 0.6230 - val_mse: 0.6043\n",
      "Epoch 8/25\n",
      "166/169 [============================>.] - ETA: 0s - loss: 0.6259 - mse: 0.6072\n",
      "Epoch 8: val_loss improved from 0.62302 to 0.62297, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e008_vl0.623.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6259 - mse: 0.6072 - val_loss: 0.6230 - val_mse: 0.6043\n",
      "Epoch 9/25\n",
      "161/169 [===========================>..] - ETA: 0s - loss: 0.6253 - mse: 0.6067\n",
      "Epoch 9: val_loss did not improve from 0.62297\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6258 - mse: 0.6071 - val_loss: 0.6232 - val_mse: 0.6046\n",
      "Epoch 10/25\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.6258 - mse: 0.6072\n",
      "Epoch 10: val_loss did not improve from 0.62297\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6258 - mse: 0.6072 - val_loss: 0.6231 - val_mse: 0.6044\n",
      "Epoch 11/25\n",
      "159/169 [===========================>..] - ETA: 0s - loss: 0.6255 - mse: 0.6068\n",
      "Epoch 11: val_loss did not improve from 0.62297\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6258 - mse: 0.6072 - val_loss: 0.6234 - val_mse: 0.6047\n",
      "Epoch 12/25\n",
      "165/169 [============================>.] - ETA: 0s - loss: 0.6257 - mse: 0.6070\n",
      "Epoch 12: val_loss did not improve from 0.62297\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6258 - mse: 0.6071 - val_loss: 0.6230 - val_mse: 0.6044\n",
      "Epoch 13/25\n",
      "164/169 [============================>.] - ETA: 0s - loss: 0.6254 - mse: 0.6067\n",
      "Epoch 13: val_loss did not improve from 0.62297\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6258 - mse: 0.6072 - val_loss: 0.6234 - val_mse: 0.6047\n",
      "Epoch 14/25\n",
      "164/169 [============================>.] - ETA: 0s - loss: 0.6258 - mse: 0.6072\n",
      "Epoch 14: val_loss did not improve from 0.62297\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6257 - mse: 0.6071 - val_loss: 0.6232 - val_mse: 0.6046\n",
      "Epoch 15/25\n",
      "163/169 [===========================>..] - ETA: 0s - loss: 0.6262 - mse: 0.6076\n",
      "Epoch 15: val_loss did not improve from 0.62297\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6257 - mse: 0.6071 - val_loss: 0.6232 - val_mse: 0.6046\n",
      "Epoch 16/25\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.6259 - mse: 0.6073\n",
      "Epoch 16: val_loss improved from 0.62297 to 0.62295, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e016_vl0.623.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6256 - mse: 0.6070 - val_loss: 0.6230 - val_mse: 0.6044\n",
      "Epoch 17/25\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.6256 - mse: 0.6070\n",
      "Epoch 17: val_loss did not improve from 0.62295\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6257 - mse: 0.6071 - val_loss: 0.6231 - val_mse: 0.6045\n",
      "Epoch 18/25\n",
      "163/169 [===========================>..] - ETA: 0s - loss: 0.6252 - mse: 0.6066\n",
      "Epoch 18: val_loss improved from 0.62295 to 0.62290, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e018_vl0.623.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6257 - mse: 0.6071 - val_loss: 0.6229 - val_mse: 0.6043\n",
      "Epoch 19/25\n",
      "159/169 [===========================>..] - ETA: 0s - loss: 0.6256 - mse: 0.6070\n",
      "Epoch 19: val_loss improved from 0.62290 to 0.62281, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e019_vl0.623.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6256 - mse: 0.6070 - val_loss: 0.6228 - val_mse: 0.6042\n",
      "Epoch 20/25\n",
      "164/169 [============================>.] - ETA: 0s - loss: 0.6254 - mse: 0.6068\n",
      "Epoch 20: val_loss did not improve from 0.62281\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.6257 - mse: 0.6071 - val_loss: 0.6230 - val_mse: 0.6044\n",
      "Epoch 21/25\n",
      "164/169 [============================>.] - ETA: 0s - loss: 0.6255 - mse: 0.6070\n",
      "Epoch 21: val_loss did not improve from 0.62281\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6256 - mse: 0.6070 - val_loss: 0.6229 - val_mse: 0.6043\n",
      "Epoch 22/25\n",
      "163/169 [===========================>..] - ETA: 0s - loss: 0.6258 - mse: 0.6073\n",
      "Epoch 22: val_loss did not improve from 0.62281\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6255 - mse: 0.6070 - val_loss: 0.6229 - val_mse: 0.6044\n",
      "Epoch 23/25\n",
      "161/169 [===========================>..] - ETA: 0s - loss: 0.6252 - mse: 0.6067\n",
      "Epoch 23: val_loss did not improve from 0.62281\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6255 - mse: 0.6070 - val_loss: 0.6228 - val_mse: 0.6043\n",
      "Epoch 24/25\n",
      "161/169 [===========================>..] - ETA: 0s - loss: 0.6256 - mse: 0.6071\n",
      "Epoch 24: val_loss did not improve from 0.62281\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6255 - mse: 0.6070 - val_loss: 0.6229 - val_mse: 0.6044\n",
      "Epoch 25/25\n",
      "165/169 [============================>.] - ETA: 0s - loss: 0.6253 - mse: 0.6068\n",
      "Epoch 25: val_loss improved from 0.62281 to 0.62259, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e025_vl0.623.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6255 - mse: 0.6070 - val_loss: 0.6226 - val_mse: 0.6041\n",
      "Time elapsed to train: 25.33 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.284 2.969 1.579 3.303 2.308 1.664 1.194 0.916 0.563 0.278 0.127 0.027 0.001]\n",
      "<R> = [2.284 2.969 1.579 3.303 2.307 1.664 1.194 0.916 0.563 0.278 0.127 0.027 0.001]\n",
      "s_R = [0.043 0.007 0.000 0.015 0.035 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7260563 2.4151473 6.458945  ... 2.806964  4.011447  4.4332323]\n",
      "mag_pred: [3.7260563 2.4151473 6.458945  ... 2.806964  4.011447  4.4332323]\n",
      "Time elapsed to make plots: 21.11 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [39.57012  32.501446 11.537472 ...  2.807011 36.23736  14.777153]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0115\n",
      "  1% : 0.0947\n",
      "  10% : 0.216\n",
      "  50% : 0.59\n",
      "  90% : 2.98\n",
      "  99% : 65.8\n",
      "  100% : 7.22e+03\n",
      "<chi^2/d.o.f.> = 1.01\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 16254 stars (6.42%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [10.008902  56.764236  15.853113  ...  3.2713673  5.5245814 13.698256 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0147\n",
      "  1% : 0.095\n",
      "  10% : 0.217\n",
      "  50% : 0.596\n",
      "  90% : 2.91\n",
      "  99% : 70.8\n",
      "  100% : 5.18e+03\n",
      "<chi^2/d.o.f.> = 1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 78.98 s\n",
      "learning rate = 7.427357923006639e-05\n",
      "setting learning rate to 6.0810062625217954e-05\n",
      "Iteration 15 of 20.\n",
      "Epoch 1/25\n",
      "157/168 [===========================>..] - ETA: 0s - loss: 0.5895 - mse: 0.5710\n",
      "Epoch 1: val_loss improved from inf to 0.58772, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e001_vl0.588.h5\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.5891 - mse: 0.5706 - val_loss: 0.5877 - val_mse: 0.5692\n",
      "Epoch 2/25\n",
      "164/168 [============================>.] - ETA: 0s - loss: 0.5892 - mse: 0.5707\n",
      "Epoch 2: val_loss improved from 0.58772 to 0.58770, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e002_vl0.588.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5892 - mse: 0.5707 - val_loss: 0.5877 - val_mse: 0.5692\n",
      "Epoch 3/25\n",
      "161/168 [===========================>..] - ETA: 0s - loss: 0.5891 - mse: 0.5706\n",
      "Epoch 3: val_loss did not improve from 0.58770\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5892 - mse: 0.5707 - val_loss: 0.5878 - val_mse: 0.5693\n",
      "Epoch 4/25\n",
      "159/168 [===========================>..] - ETA: 0s - loss: 0.5890 - mse: 0.5706\n",
      "Epoch 4: val_loss improved from 0.58770 to 0.58741, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e004_vl0.587.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5891 - mse: 0.5706 - val_loss: 0.5874 - val_mse: 0.5689\n",
      "Epoch 5/25\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.5888 - mse: 0.5703\n",
      "Epoch 5: val_loss did not improve from 0.58741\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5891 - mse: 0.5706 - val_loss: 0.5878 - val_mse: 0.5694\n",
      "Epoch 6/25\n",
      "163/168 [============================>.] - ETA: 0s - loss: 0.5893 - mse: 0.5709\n",
      "Epoch 6: val_loss did not improve from 0.58741\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5891 - mse: 0.5706 - val_loss: 0.5880 - val_mse: 0.5695\n",
      "Epoch 7/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 0.5893 - mse: 0.5709\n",
      "Epoch 7: val_loss improved from 0.58741 to 0.58726, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e007_vl0.587.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5892 - mse: 0.5707 - val_loss: 0.5873 - val_mse: 0.5688\n",
      "Epoch 8/25\n",
      "163/168 [============================>.] - ETA: 0s - loss: 0.5890 - mse: 0.5705\n",
      "Epoch 8: val_loss did not improve from 0.58726\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5890 - mse: 0.5705 - val_loss: 0.5879 - val_mse: 0.5694\n",
      "Epoch 9/25\n",
      "157/168 [===========================>..] - ETA: 0s - loss: 0.5891 - mse: 0.5707\n",
      "Epoch 9: val_loss did not improve from 0.58726\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5890 - mse: 0.5705 - val_loss: 0.5878 - val_mse: 0.5694\n",
      "Epoch 10/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 0.5888 - mse: 0.5704\n",
      "Epoch 10: val_loss did not improve from 0.58726\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5890 - mse: 0.5705 - val_loss: 0.5916 - val_mse: 0.5731\n",
      "Epoch 11/25\n",
      "157/168 [===========================>..] - ETA: 0s - loss: 0.5896 - mse: 0.5712\n",
      "Epoch 11: val_loss improved from 0.58726 to 0.58720, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e011_vl0.587.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5895 - mse: 0.5710 - val_loss: 0.5872 - val_mse: 0.5688\n",
      "Epoch 12/25\n",
      "163/168 [============================>.] - ETA: 0s - loss: 0.5890 - mse: 0.5705\n",
      "Epoch 12: val_loss did not improve from 0.58720\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5889 - mse: 0.5704 - val_loss: 0.5879 - val_mse: 0.5695\n",
      "Epoch 13/25\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.5889 - mse: 0.5705\n",
      "Epoch 13: val_loss improved from 0.58720 to 0.58713, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e013_vl0.587.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5889 - mse: 0.5705 - val_loss: 0.5871 - val_mse: 0.5687\n",
      "Epoch 14/25\n",
      "160/168 [===========================>..] - ETA: 0s - loss: 0.5890 - mse: 0.5706\n",
      "Epoch 14: val_loss did not improve from 0.58713\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5888 - mse: 0.5704 - val_loss: 0.5880 - val_mse: 0.5696\n",
      "Epoch 15/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 0.5885 - mse: 0.5702\n",
      "Epoch 15: val_loss did not improve from 0.58713\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5889 - mse: 0.5705 - val_loss: 0.5877 - val_mse: 0.5693\n",
      "Epoch 16/25\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.5890 - mse: 0.5706\n",
      "Epoch 16: val_loss did not improve from 0.58713\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5890 - mse: 0.5706 - val_loss: 0.5876 - val_mse: 0.5692\n",
      "Epoch 17/25\n",
      "158/168 [===========================>..] - ETA: 0s - loss: 0.5889 - mse: 0.5705\n",
      "Epoch 17: val_loss did not improve from 0.58713\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5888 - mse: 0.5704 - val_loss: 0.5873 - val_mse: 0.5689\n",
      "Epoch 18/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 0.5889 - mse: 0.5705\n",
      "Epoch 18: val_loss did not improve from 0.58713\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5888 - mse: 0.5704 - val_loss: 0.5877 - val_mse: 0.5694\n",
      "Epoch 19/25\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.5889 - mse: 0.5705\n",
      "Epoch 19: val_loss did not improve from 0.58713\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5889 - mse: 0.5705 - val_loss: 0.5875 - val_mse: 0.5692\n",
      "Epoch 20/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 0.5890 - mse: 0.5707\n",
      "Epoch 20: val_loss did not improve from 0.58713\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5887 - mse: 0.5704 - val_loss: 0.5874 - val_mse: 0.5691\n",
      "Epoch 21/25\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.5887 - mse: 0.5704\n",
      "Epoch 21: val_loss did not improve from 0.58713\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5887 - mse: 0.5704 - val_loss: 0.5873 - val_mse: 0.5689\n",
      "Epoch 22/25\n",
      "160/168 [===========================>..] - ETA: 0s - loss: 0.5882 - mse: 0.5699\n",
      "Epoch 22: val_loss did not improve from 0.58713\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5888 - mse: 0.5704 - val_loss: 0.5882 - val_mse: 0.5699\n",
      "Epoch 23/25\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.5886 - mse: 0.5703\n",
      "Epoch 23: val_loss did not improve from 0.58713\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5888 - mse: 0.5705 - val_loss: 0.5874 - val_mse: 0.5690\n",
      "Epoch 24/25\n",
      "158/168 [===========================>..] - ETA: 0s - loss: 0.5891 - mse: 0.5708\n",
      "Epoch 24: val_loss improved from 0.58713 to 0.58694, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e024_vl0.587.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5887 - mse: 0.5704 - val_loss: 0.5869 - val_mse: 0.5686\n",
      "Epoch 25/25\n",
      "159/168 [===========================>..] - ETA: 0s - loss: 0.5887 - mse: 0.5704\n",
      "Epoch 25: val_loss did not improve from 0.58694\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5887 - mse: 0.5703 - val_loss: 0.5883 - val_mse: 0.5699\n",
      "Time elapsed to train: 25.48 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.280 2.964 1.576 3.296 2.302 1.661 1.192 0.914 0.562 0.278 0.128 0.029 0.001]\n",
      "<R> = [2.280 2.964 1.576 3.296 2.302 1.661 1.192 0.914 0.562 0.278 0.128 0.029 0.001]\n",
      "s_R = [0.046 0.011 0.000 0.010 0.028 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7251916 2.405026  6.4719667 ... 2.8129742 4.0173883 4.4369226]\n",
      "mag_pred: [3.7251916 2.405026  6.4719667 ... 2.8129742 4.0173883 4.4369226]\n",
      "Time elapsed to make plots: 17.75 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [40.173454 32.16649  10.281087 ...  2.909901 36.513535 13.65214 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00992\n",
      "  1% : 0.0945\n",
      "  10% : 0.213\n",
      "  50% : 0.583\n",
      "  90% : 2.98\n",
      "  99% : 66.5\n",
      "  100% : 7.23e+03\n",
      "<chi^2/d.o.f.> = 1\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 16280 stars (6.43%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [10.065582  57.562866  16.161459  ...  3.4240842  5.471926  14.565307 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0153\n",
      "  1% : 0.0945\n",
      "  10% : 0.215\n",
      "  50% : 0.588\n",
      "  90% : 2.91\n",
      "  99% : 71.3\n",
      "  100% : 5.18e+03\n",
      "<chi^2/d.o.f.> = 0.996\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 78.49 s\n",
      "learning rate = 6.0810063587268814e-05\n",
      "setting learning rate to 4.9787068367863945e-05\n",
      "Iteration 16 of 20.\n",
      "Epoch 1/25\n",
      "161/167 [===========================>..] - ETA: 0s - loss: 0.5851 - mse: 0.5667\n",
      "Epoch 1: val_loss improved from inf to 0.58347, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e001_vl0.583.h5\n",
      "167/167 [==============================] - 2s 7ms/step - loss: 0.5849 - mse: 0.5666 - val_loss: 0.5835 - val_mse: 0.5651\n",
      "Epoch 2/25\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.5849 - mse: 0.5666\n",
      "Epoch 2: val_loss improved from 0.58347 to 0.58344, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e002_vl0.583.h5\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.5848 - mse: 0.5665 - val_loss: 0.5834 - val_mse: 0.5651\n",
      "Epoch 3/25\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5848 - mse: 0.5665\n",
      "Epoch 3: val_loss did not improve from 0.58344\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5848 - mse: 0.5665 - val_loss: 0.5837 - val_mse: 0.5654\n",
      "Epoch 4/25\n",
      "161/167 [===========================>..] - ETA: 0s - loss: 0.5846 - mse: 0.5663\n",
      "Epoch 4: val_loss did not improve from 0.58344\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5847 - mse: 0.5664 - val_loss: 0.5837 - val_mse: 0.5654\n",
      "Epoch 5/25\n",
      "159/167 [===========================>..] - ETA: 0s - loss: 0.5843 - mse: 0.5660\n",
      "Epoch 5: val_loss improved from 0.58344 to 0.58339, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e005_vl0.583.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5848 - mse: 0.5665 - val_loss: 0.5834 - val_mse: 0.5651\n",
      "Epoch 6/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.5848 - mse: 0.5665\n",
      "Epoch 6: val_loss did not improve from 0.58339\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5847 - mse: 0.5665 - val_loss: 0.5834 - val_mse: 0.5652\n",
      "Epoch 7/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 0.5845 - mse: 0.5662\n",
      "Epoch 7: val_loss did not improve from 0.58339\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5847 - mse: 0.5664 - val_loss: 0.5835 - val_mse: 0.5653\n",
      "Epoch 8/25\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.5847 - mse: 0.5664\n",
      "Epoch 8: val_loss did not improve from 0.58339\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5847 - mse: 0.5665 - val_loss: 0.5834 - val_mse: 0.5651\n",
      "Epoch 9/25\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5847 - mse: 0.5665\n",
      "Epoch 9: val_loss did not improve from 0.58339\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.5847 - mse: 0.5665 - val_loss: 0.5835 - val_mse: 0.5652\n",
      "Epoch 10/25\n",
      "156/167 [===========================>..] - ETA: 0s - loss: 0.5848 - mse: 0.5666\n",
      "Epoch 10: val_loss did not improve from 0.58339\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5847 - mse: 0.5664 - val_loss: 0.5835 - val_mse: 0.5653\n",
      "Epoch 11/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.5843 - mse: 0.5661\n",
      "Epoch 11: val_loss did not improve from 0.58339\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5847 - mse: 0.5665 - val_loss: 0.5836 - val_mse: 0.5654\n",
      "Epoch 12/25\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.5846 - mse: 0.5664\n",
      "Epoch 12: val_loss did not improve from 0.58339\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5847 - mse: 0.5665 - val_loss: 0.5834 - val_mse: 0.5652\n",
      "Epoch 13/25\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5846 - mse: 0.5664\n",
      "Epoch 13: val_loss improved from 0.58339 to 0.58330, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e013_vl0.583.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5846 - mse: 0.5664 - val_loss: 0.5833 - val_mse: 0.5651\n",
      "Epoch 14/25\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5847 - mse: 0.5664\n",
      "Epoch 14: val_loss did not improve from 0.58330\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5847 - mse: 0.5664 - val_loss: 0.5836 - val_mse: 0.5654\n",
      "Epoch 15/25\n",
      "159/167 [===========================>..] - ETA: 0s - loss: 0.5845 - mse: 0.5663\n",
      "Epoch 15: val_loss improved from 0.58330 to 0.58328, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e015_vl0.583.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5847 - mse: 0.5664 - val_loss: 0.5833 - val_mse: 0.5651\n",
      "Epoch 16/25\n",
      "161/167 [===========================>..] - ETA: 0s - loss: 0.5846 - mse: 0.5664\n",
      "Epoch 16: val_loss did not improve from 0.58328\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5846 - mse: 0.5664 - val_loss: 0.5833 - val_mse: 0.5651\n",
      "Epoch 17/25\n",
      "159/167 [===========================>..] - ETA: 0s - loss: 0.5848 - mse: 0.5665\n",
      "Epoch 17: val_loss improved from 0.58328 to 0.58320, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e017_vl0.583.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5846 - mse: 0.5664 - val_loss: 0.5832 - val_mse: 0.5650\n",
      "Epoch 18/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.5843 - mse: 0.5661\n",
      "Epoch 18: val_loss did not improve from 0.58320\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5846 - mse: 0.5664 - val_loss: 0.5833 - val_mse: 0.5650\n",
      "Epoch 19/25\n",
      "158/167 [===========================>..] - ETA: 0s - loss: 0.5841 - mse: 0.5659\n",
      "Epoch 19: val_loss did not improve from 0.58320\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5846 - mse: 0.5664 - val_loss: 0.5832 - val_mse: 0.5650\n",
      "Epoch 20/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 0.5849 - mse: 0.5667\n",
      "Epoch 20: val_loss improved from 0.58320 to 0.58315, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e020_vl0.583.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5846 - mse: 0.5664 - val_loss: 0.5831 - val_mse: 0.5650\n",
      "Epoch 21/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.5844 - mse: 0.5662\n",
      "Epoch 21: val_loss did not improve from 0.58315\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5845 - mse: 0.5663 - val_loss: 0.5833 - val_mse: 0.5651\n",
      "Epoch 22/25\n",
      "160/167 [===========================>..] - ETA: 0s - loss: 0.5843 - mse: 0.5661\n",
      "Epoch 22: val_loss did not improve from 0.58315\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5845 - mse: 0.5663 - val_loss: 0.5832 - val_mse: 0.5650\n",
      "Epoch 23/25\n",
      "161/167 [===========================>..] - ETA: 0s - loss: 0.5842 - mse: 0.5660\n",
      "Epoch 23: val_loss did not improve from 0.58315\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5845 - mse: 0.5663 - val_loss: 0.5832 - val_mse: 0.5650\n",
      "Epoch 24/25\n",
      "158/167 [===========================>..] - ETA: 0s - loss: 0.5845 - mse: 0.5664\n",
      "Epoch 24: val_loss did not improve from 0.58315\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5845 - mse: 0.5663 - val_loss: 0.5834 - val_mse: 0.5653\n",
      "Epoch 25/25\n",
      "162/167 [============================>.] - ETA: 0s - loss: 0.5842 - mse: 0.5661\n",
      "Epoch 25: val_loss did not improve from 0.58315\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5844 - mse: 0.5663 - val_loss: 0.5832 - val_mse: 0.5651\n",
      "Time elapsed to train: 25.19 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.276 2.958 1.573 3.289 2.299 1.658 1.190 0.912 0.562 0.278 0.129 0.030 0.001]\n",
      "<R> = [2.276 2.958 1.573 3.289 2.298 1.658 1.190 0.912 0.562 0.278 0.129 0.030 0.001]\n",
      "s_R = [0.047 0.013 0.000 0.007 0.027 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7224765 2.397656  6.4795794 ... 2.8162248 4.017486  4.4356356]\n",
      "mag_pred: [3.7224765 2.397656  6.4795794 ... 2.8162248 4.017486  4.4356356]\n",
      "Time elapsed to make plots: 17.66 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [39.468807  32.551075  10.789518  ...  2.7911377 36.273304  13.608221 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0118\n",
      "  1% : 0.0937\n",
      "  10% : 0.212\n",
      "  50% : 0.58\n",
      "  90% : 2.95\n",
      "  99% : 66.5\n",
      "  100% : 7.23e+03\n",
      "<chi^2/d.o.f.> = 0.994\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 16168 stars (6.39%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.957449 58.32086  15.747505 ...  3.338934  5.482416 13.617168]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0111\n",
      "  1% : 0.095\n",
      "  10% : 0.214\n",
      "  50% : 0.586\n",
      "  90% : 2.87\n",
      "  99% : 71.7\n",
      "  100% : 5.18e+03\n",
      "<chi^2/d.o.f.> = 0.989\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 79.40 s\n",
      "learning rate = 4.978706783731468e-05\n",
      "setting learning rate to 4.0762203978366214e-05\n",
      "Iteration 17 of 20.\n",
      "Epoch 1/25\n",
      "159/168 [===========================>..] - ETA: 0s - loss: 0.5841 - mse: 0.5660\n",
      "Epoch 1: val_loss improved from inf to 0.58277, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e001_vl0.583.h5\n",
      "168/168 [==============================] - 2s 7ms/step - loss: 0.5841 - mse: 0.5659 - val_loss: 0.5828 - val_mse: 0.5646\n",
      "Epoch 2/25\n",
      "158/168 [===========================>..] - ETA: 0s - loss: 0.5850 - mse: 0.5668\n",
      "Epoch 2: val_loss did not improve from 0.58277\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5841 - mse: 0.5659 - val_loss: 0.5829 - val_mse: 0.5647\n",
      "Epoch 3/25\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.5841 - mse: 0.5660\n",
      "Epoch 3: val_loss improved from 0.58277 to 0.58267, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e003_vl0.583.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5841 - mse: 0.5660 - val_loss: 0.5827 - val_mse: 0.5645\n",
      "Epoch 4/25\n",
      "161/168 [===========================>..] - ETA: 0s - loss: 0.5845 - mse: 0.5663\n",
      "Epoch 4: val_loss did not improve from 0.58267\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5841 - mse: 0.5659 - val_loss: 0.5827 - val_mse: 0.5645\n",
      "Epoch 5/25\n",
      "163/168 [============================>.] - ETA: 0s - loss: 0.5839 - mse: 0.5658\n",
      "Epoch 5: val_loss did not improve from 0.58267\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5840 - mse: 0.5659 - val_loss: 0.5828 - val_mse: 0.5647\n",
      "Epoch 6/25\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.5841 - mse: 0.5660\n",
      "Epoch 6: val_loss did not improve from 0.58267\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5841 - mse: 0.5660 - val_loss: 0.5832 - val_mse: 0.5651\n",
      "Epoch 7/25\n",
      "161/168 [===========================>..] - ETA: 0s - loss: 0.5837 - mse: 0.5656\n",
      "Epoch 7: val_loss did not improve from 0.58267\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5840 - mse: 0.5659 - val_loss: 0.5827 - val_mse: 0.5646\n",
      "Epoch 8/25\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.5840 - mse: 0.5659\n",
      "Epoch 8: val_loss did not improve from 0.58267\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5840 - mse: 0.5659 - val_loss: 0.5829 - val_mse: 0.5648\n",
      "Epoch 9/25\n",
      "163/168 [============================>.] - ETA: 0s - loss: 0.5842 - mse: 0.5661\n",
      "Epoch 9: val_loss did not improve from 0.58267\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5840 - mse: 0.5659 - val_loss: 0.5828 - val_mse: 0.5647\n",
      "Epoch 10/25\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.5842 - mse: 0.5661\n",
      "Epoch 10: val_loss did not improve from 0.58267\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5840 - mse: 0.5659 - val_loss: 0.5827 - val_mse: 0.5646\n",
      "Epoch 11/25\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.5840 - mse: 0.5659\n",
      "Epoch 11: val_loss did not improve from 0.58267\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5840 - mse: 0.5659 - val_loss: 0.5828 - val_mse: 0.5647\n",
      "Epoch 12/25\n",
      "158/168 [===========================>..] - ETA: 0s - loss: 0.5842 - mse: 0.5661\n",
      "Epoch 12: val_loss did not improve from 0.58267\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5839 - mse: 0.5659 - val_loss: 0.5828 - val_mse: 0.5647\n",
      "Epoch 13/25\n",
      "158/168 [===========================>..] - ETA: 0s - loss: 0.5841 - mse: 0.5660\n",
      "Epoch 13: val_loss did not improve from 0.58267\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5839 - mse: 0.5658 - val_loss: 0.5828 - val_mse: 0.5647\n",
      "Epoch 14/25\n",
      "157/168 [===========================>..] - ETA: 0s - loss: 0.5837 - mse: 0.5656\n",
      "Epoch 14: val_loss improved from 0.58267 to 0.58265, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e014_vl0.583.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5840 - mse: 0.5659 - val_loss: 0.5827 - val_mse: 0.5646\n",
      "Epoch 15/25\n",
      "159/168 [===========================>..] - ETA: 0s - loss: 0.5845 - mse: 0.5664\n",
      "Epoch 15: val_loss did not improve from 0.58265\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5839 - mse: 0.5658 - val_loss: 0.5827 - val_mse: 0.5647\n",
      "Epoch 16/25\n",
      "164/168 [============================>.] - ETA: 0s - loss: 0.5837 - mse: 0.5656\n",
      "Epoch 16: val_loss did not improve from 0.58265\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5839 - mse: 0.5659 - val_loss: 0.5827 - val_mse: 0.5647\n",
      "Epoch 17/25\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.5840 - mse: 0.5659\n",
      "Epoch 17: val_loss did not improve from 0.58265\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5839 - mse: 0.5658 - val_loss: 0.5827 - val_mse: 0.5646\n",
      "Epoch 18/25\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.5837 - mse: 0.5657\n",
      "Epoch 18: val_loss improved from 0.58265 to 0.58263, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e018_vl0.583.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5839 - mse: 0.5658 - val_loss: 0.5826 - val_mse: 0.5646\n",
      "Epoch 19/25\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.5840 - mse: 0.5660\n",
      "Epoch 19: val_loss did not improve from 0.58263\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5839 - mse: 0.5659 - val_loss: 0.5827 - val_mse: 0.5647\n",
      "Epoch 20/25\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.5839 - mse: 0.5658\n",
      "Epoch 20: val_loss did not improve from 0.58263\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5839 - mse: 0.5658 - val_loss: 0.5827 - val_mse: 0.5646\n",
      "Epoch 21/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 0.5843 - mse: 0.5662\n",
      "Epoch 21: val_loss did not improve from 0.58263\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5839 - mse: 0.5659 - val_loss: 0.5828 - val_mse: 0.5647\n",
      "Epoch 22/25\n",
      "161/168 [===========================>..] - ETA: 0s - loss: 0.5842 - mse: 0.5662\n",
      "Epoch 22: val_loss did not improve from 0.58263\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5839 - mse: 0.5658 - val_loss: 0.5827 - val_mse: 0.5647\n",
      "Epoch 23/25\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.5839 - mse: 0.5659\n",
      "Epoch 23: val_loss improved from 0.58263 to 0.58249, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e023_vl0.582.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5839 - mse: 0.5658 - val_loss: 0.5825 - val_mse: 0.5644\n",
      "Epoch 24/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 0.5840 - mse: 0.5660\n",
      "Epoch 24: val_loss improved from 0.58249 to 0.58242, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e024_vl0.582.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5838 - mse: 0.5658 - val_loss: 0.5824 - val_mse: 0.5644\n",
      "Epoch 25/25\n",
      "158/168 [===========================>..] - ETA: 0s - loss: 0.5832 - mse: 0.5652\n",
      "Epoch 25: val_loss did not improve from 0.58242\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5838 - mse: 0.5658 - val_loss: 0.5826 - val_mse: 0.5646\n",
      "Time elapsed to train: 25.40 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.272 2.954 1.571 3.284 2.295 1.655 1.189 0.911 0.561 0.278 0.129 0.031 0.001]\n",
      "<R> = [2.273 2.954 1.571 3.284 2.295 1.655 1.189 0.911 0.561 0.278 0.129 0.031 0.001]\n",
      "s_R = [0.047 0.014 0.000 0.006 0.026 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7208655 2.394631  6.4878144 ... 2.8198035 4.0169487 4.4353776]\n",
      "mag_pred: [3.7208655 2.394631  6.4878144 ... 2.8198035 4.0169487 4.4353776]\n",
      "Time elapsed to make plots: 21.59 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [39.20204   31.749865  10.505202  ...  2.9781296 35.796173  13.248101 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0124\n",
      "  1% : 0.0943\n",
      "  10% : 0.213\n",
      "  50% : 0.58\n",
      "  90% : 2.94\n",
      "  99% : 66.5\n",
      "  100% : 7.22e+03\n",
      "<chi^2/d.o.f.> = 0.992\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 16149 stars (6.38%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [10.117281  58.373055  16.18285   ...  3.2478838  5.411191  14.110527 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0145\n",
      "  1% : 0.0931\n",
      "  10% : 0.215\n",
      "  50% : 0.586\n",
      "  90% : 2.86\n",
      "  99% : 71.9\n",
      "  100% : 5.18e+03\n",
      "<chi^2/d.o.f.> = 0.988\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 81.94 s\n",
      "learning rate = 4.076220284332521e-05\n",
      "setting learning rate to 3.337326996032607e-05\n",
      "Iteration 18 of 20.\n",
      "Epoch 1/25\n",
      "164/168 [============================>.] - ETA: 0s - loss: 0.5834 - mse: 0.5653\n",
      "Epoch 1: val_loss improved from inf to 0.58260, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e001_vl0.583.h5\n",
      "168/168 [==============================] - 2s 7ms/step - loss: 0.5836 - mse: 0.5656 - val_loss: 0.5826 - val_mse: 0.5646\n",
      "Epoch 2/25\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.5834 - mse: 0.5654\n",
      "Epoch 2: val_loss did not improve from 0.58260\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5836 - mse: 0.5656 - val_loss: 0.5826 - val_mse: 0.5646\n",
      "Epoch 3/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 0.5836 - mse: 0.5656\n",
      "Epoch 3: val_loss improved from 0.58260 to 0.58242, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e003_vl0.582.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5836 - mse: 0.5655 - val_loss: 0.5824 - val_mse: 0.5644\n",
      "Epoch 4/25\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.5836 - mse: 0.5656\n",
      "Epoch 4: val_loss did not improve from 0.58242\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5836 - mse: 0.5656 - val_loss: 0.5824 - val_mse: 0.5644\n",
      "Epoch 5/25\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.5837 - mse: 0.5657\n",
      "Epoch 5: val_loss did not improve from 0.58242\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5836 - mse: 0.5656 - val_loss: 0.5825 - val_mse: 0.5645\n",
      "Epoch 6/25\n",
      "161/168 [===========================>..] - ETA: 0s - loss: 0.5831 - mse: 0.5651\n",
      "Epoch 6: val_loss did not improve from 0.58242\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5836 - mse: 0.5656 - val_loss: 0.5824 - val_mse: 0.5645\n",
      "Epoch 7/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 0.5838 - mse: 0.5658\n",
      "Epoch 7: val_loss did not improve from 0.58242\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5836 - mse: 0.5656 - val_loss: 0.5826 - val_mse: 0.5646\n",
      "Epoch 8/25\n",
      "161/168 [===========================>..] - ETA: 0s - loss: 0.5838 - mse: 0.5658\n",
      "Epoch 8: val_loss improved from 0.58242 to 0.58240, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e008_vl0.582.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5835 - mse: 0.5655 - val_loss: 0.5824 - val_mse: 0.5644\n",
      "Epoch 9/25\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.5836 - mse: 0.5656\n",
      "Epoch 9: val_loss did not improve from 0.58240\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5836 - mse: 0.5656 - val_loss: 0.5824 - val_mse: 0.5644\n",
      "Epoch 10/25\n",
      "160/168 [===========================>..] - ETA: 0s - loss: 0.5835 - mse: 0.5656\n",
      "Epoch 10: val_loss did not improve from 0.58240\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5835 - mse: 0.5655 - val_loss: 0.5824 - val_mse: 0.5644\n",
      "Epoch 11/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 0.5838 - mse: 0.5658\n",
      "Epoch 11: val_loss did not improve from 0.58240\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5836 - mse: 0.5656 - val_loss: 0.5827 - val_mse: 0.5647\n",
      "Epoch 12/25\n",
      "159/168 [===========================>..] - ETA: 0s - loss: 0.5837 - mse: 0.5657\n",
      "Epoch 12: val_loss did not improve from 0.58240\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5836 - mse: 0.5656 - val_loss: 0.5825 - val_mse: 0.5646\n",
      "Epoch 13/25\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.5835 - mse: 0.5655\n",
      "Epoch 13: val_loss did not improve from 0.58240\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5835 - mse: 0.5655 - val_loss: 0.5827 - val_mse: 0.5647\n",
      "Epoch 14/25\n",
      "157/168 [===========================>..] - ETA: 0s - loss: 0.5827 - mse: 0.5648\n",
      "Epoch 14: val_loss improved from 0.58240 to 0.58232, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e014_vl0.582.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5835 - mse: 0.5655 - val_loss: 0.5823 - val_mse: 0.5644\n",
      "Epoch 15/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 0.5835 - mse: 0.5655\n",
      "Epoch 15: val_loss did not improve from 0.58232\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5835 - mse: 0.5655 - val_loss: 0.5825 - val_mse: 0.5646\n",
      "Epoch 16/25\n",
      "158/168 [===========================>..] - ETA: 0s - loss: 0.5833 - mse: 0.5653\n",
      "Epoch 16: val_loss improved from 0.58232 to 0.58230, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e016_vl0.582.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5835 - mse: 0.5655 - val_loss: 0.5823 - val_mse: 0.5644\n",
      "Epoch 17/25\n",
      "158/168 [===========================>..] - ETA: 0s - loss: 0.5835 - mse: 0.5656\n",
      "Epoch 17: val_loss did not improve from 0.58230\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5834 - mse: 0.5655 - val_loss: 0.5824 - val_mse: 0.5644\n",
      "Epoch 18/25\n",
      "161/168 [===========================>..] - ETA: 0s - loss: 0.5834 - mse: 0.5655\n",
      "Epoch 18: val_loss did not improve from 0.58230\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5835 - mse: 0.5655 - val_loss: 0.5826 - val_mse: 0.5646\n",
      "Epoch 19/25\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.5832 - mse: 0.5653\n",
      "Epoch 19: val_loss did not improve from 0.58230\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5834 - mse: 0.5655 - val_loss: 0.5824 - val_mse: 0.5645\n",
      "Epoch 20/25\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.5835 - mse: 0.5655\n",
      "Epoch 20: val_loss improved from 0.58230 to 0.58228, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e020_vl0.582.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5834 - mse: 0.5655 - val_loss: 0.5823 - val_mse: 0.5643\n",
      "Epoch 21/25\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.5834 - mse: 0.5655\n",
      "Epoch 21: val_loss did not improve from 0.58228\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5834 - mse: 0.5655 - val_loss: 0.5824 - val_mse: 0.5645\n",
      "Epoch 22/25\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.5833 - mse: 0.5654\n",
      "Epoch 22: val_loss did not improve from 0.58228\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5834 - mse: 0.5655 - val_loss: 0.5823 - val_mse: 0.5644\n",
      "Epoch 23/25\n",
      "159/168 [===========================>..] - ETA: 0s - loss: 0.5839 - mse: 0.5660\n",
      "Epoch 23: val_loss did not improve from 0.58228\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5834 - mse: 0.5654 - val_loss: 0.5823 - val_mse: 0.5644\n",
      "Epoch 24/25\n",
      "159/168 [===========================>..] - ETA: 0s - loss: 0.5835 - mse: 0.5656\n",
      "Epoch 24: val_loss did not improve from 0.58228\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5834 - mse: 0.5655 - val_loss: 0.5825 - val_mse: 0.5646\n",
      "Epoch 25/25\n",
      "161/168 [===========================>..] - ETA: 0s - loss: 0.5835 - mse: 0.5656\n",
      "Epoch 25: val_loss did not improve from 0.58228\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5834 - mse: 0.5655 - val_loss: 0.5823 - val_mse: 0.5644\n",
      "Time elapsed to train: 25.37 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.270 2.951 1.569 3.281 2.293 1.653 1.187 0.910 0.560 0.278 0.130 0.031 0.001]\n",
      "<R> = [2.270 2.951 1.569 3.281 2.293 1.653 1.187 0.910 0.560 0.278 0.130 0.031 0.001]\n",
      "s_R = [0.048 0.014 0.000 0.006 0.025 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.724197  2.3973386 6.4949193 ... 2.8304846 4.019892  4.437603 ]\n",
      "mag_pred: [3.724197  2.3973386 6.4949193 ... 2.8304846 4.019892  4.437603 ]\n",
      "Time elapsed to make plots: 17.93 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [39.298584  31.913902  10.440861  ...  2.8523066 36.03828   13.158293 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0126\n",
      "  1% : 0.0936\n",
      "  10% : 0.212\n",
      "  50% : 0.578\n",
      "  90% : 2.95\n",
      "  99% : 66.6\n",
      "  100% : 7.22e+03\n",
      "<chi^2/d.o.f.> = 0.991\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 16169 stars (6.39%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [10.098967  58.44921   16.197542  ...  3.3091512  5.5138283 13.871075 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0113\n",
      "  1% : 0.0935\n",
      "  10% : 0.213\n",
      "  50% : 0.584\n",
      "  90% : 2.87\n",
      "  99% : 72.6\n",
      "  100% : 5.18e+03\n",
      "<chi^2/d.o.f.> = 0.987\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 79.28 s\n",
      "learning rate = 3.337327143526636e-05\n",
      "setting learning rate to 2.732372244729256e-05\n",
      "Iteration 19 of 20.\n",
      "Epoch 1/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 0.5829 - mse: 0.5650\n",
      "Epoch 1: val_loss improved from inf to 0.58192, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e001_vl0.582.h5\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.5831 - mse: 0.5652 - val_loss: 0.5819 - val_mse: 0.5640\n",
      "Epoch 2/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 0.5835 - mse: 0.5656\n",
      "Epoch 2: val_loss did not improve from 0.58192\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5831 - mse: 0.5652 - val_loss: 0.5822 - val_mse: 0.5642\n",
      "Epoch 3/25\n",
      "161/168 [===========================>..] - ETA: 0s - loss: 0.5834 - mse: 0.5655\n",
      "Epoch 3: val_loss did not improve from 0.58192\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5831 - mse: 0.5652 - val_loss: 0.5819 - val_mse: 0.5641\n",
      "Epoch 4/25\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.5831 - mse: 0.5652\n",
      "Epoch 4: val_loss did not improve from 0.58192\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5831 - mse: 0.5652 - val_loss: 0.5819 - val_mse: 0.5641\n",
      "Epoch 5/25\n",
      "160/168 [===========================>..] - ETA: 0s - loss: 0.5834 - mse: 0.5655\n",
      "Epoch 5: val_loss did not improve from 0.58192\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5831 - mse: 0.5652 - val_loss: 0.5821 - val_mse: 0.5642\n",
      "Epoch 6/25\n",
      "164/168 [============================>.] - ETA: 0s - loss: 0.5832 - mse: 0.5653\n",
      "Epoch 6: val_loss did not improve from 0.58192\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5831 - mse: 0.5652 - val_loss: 0.5820 - val_mse: 0.5641\n",
      "Epoch 7/25\n",
      "160/168 [===========================>..] - ETA: 0s - loss: 0.5826 - mse: 0.5647\n",
      "Epoch 7: val_loss improved from 0.58192 to 0.58189, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e007_vl0.582.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5831 - mse: 0.5652 - val_loss: 0.5819 - val_mse: 0.5640\n",
      "Epoch 8/25\n",
      "159/168 [===========================>..] - ETA: 0s - loss: 0.5825 - mse: 0.5646\n",
      "Epoch 8: val_loss improved from 0.58189 to 0.58187, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e008_vl0.582.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5831 - mse: 0.5652 - val_loss: 0.5819 - val_mse: 0.5640\n",
      "Epoch 9/25\n",
      "163/168 [============================>.] - ETA: 0s - loss: 0.5830 - mse: 0.5651\n",
      "Epoch 9: val_loss did not improve from 0.58187\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5830 - mse: 0.5652 - val_loss: 0.5819 - val_mse: 0.5641\n",
      "Epoch 10/25\n",
      "164/168 [============================>.] - ETA: 0s - loss: 0.5830 - mse: 0.5651\n",
      "Epoch 10: val_loss did not improve from 0.58187\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5830 - mse: 0.5651 - val_loss: 0.5819 - val_mse: 0.5640\n",
      "Epoch 11/25\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.5828 - mse: 0.5650\n",
      "Epoch 11: val_loss did not improve from 0.58187\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5830 - mse: 0.5651 - val_loss: 0.5819 - val_mse: 0.5640\n",
      "Epoch 12/25\n",
      "159/168 [===========================>..] - ETA: 0s - loss: 0.5831 - mse: 0.5652\n",
      "Epoch 12: val_loss did not improve from 0.58187\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5830 - mse: 0.5652 - val_loss: 0.5819 - val_mse: 0.5641\n",
      "Epoch 13/25\n",
      "164/168 [============================>.] - ETA: 0s - loss: 0.5829 - mse: 0.5650\n",
      "Epoch 13: val_loss did not improve from 0.58187\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5830 - mse: 0.5651 - val_loss: 0.5820 - val_mse: 0.5641\n",
      "Epoch 14/25\n",
      "159/168 [===========================>..] - ETA: 0s - loss: 0.5829 - mse: 0.5651\n",
      "Epoch 14: val_loss did not improve from 0.58187\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5830 - mse: 0.5652 - val_loss: 0.5819 - val_mse: 0.5641\n",
      "Epoch 15/25\n",
      "159/168 [===========================>..] - ETA: 0s - loss: 0.5833 - mse: 0.5655\n",
      "Epoch 15: val_loss did not improve from 0.58187\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5830 - mse: 0.5652 - val_loss: 0.5820 - val_mse: 0.5641\n",
      "Epoch 16/25\n",
      "164/168 [============================>.] - ETA: 0s - loss: 0.5829 - mse: 0.5650\n",
      "Epoch 16: val_loss improved from 0.58187 to 0.58181, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e016_vl0.582.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5830 - mse: 0.5651 - val_loss: 0.5818 - val_mse: 0.5639\n",
      "Epoch 17/25\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.5830 - mse: 0.5651\n",
      "Epoch 17: val_loss did not improve from 0.58181\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5830 - mse: 0.5651 - val_loss: 0.5819 - val_mse: 0.5640\n",
      "Epoch 18/25\n",
      "160/168 [===========================>..] - ETA: 0s - loss: 0.5830 - mse: 0.5651\n",
      "Epoch 18: val_loss did not improve from 0.58181\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5830 - mse: 0.5651 - val_loss: 0.5818 - val_mse: 0.5640\n",
      "Epoch 19/25\n",
      "157/168 [===========================>..] - ETA: 0s - loss: 0.5835 - mse: 0.5656\n",
      "Epoch 19: val_loss did not improve from 0.58181\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5829 - mse: 0.5651 - val_loss: 0.5819 - val_mse: 0.5641\n",
      "Epoch 20/25\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.5830 - mse: 0.5651\n",
      "Epoch 20: val_loss did not improve from 0.58181\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5830 - mse: 0.5651 - val_loss: 0.5818 - val_mse: 0.5640\n",
      "Epoch 21/25\n",
      "161/168 [===========================>..] - ETA: 0s - loss: 0.5827 - mse: 0.5649\n",
      "Epoch 21: val_loss improved from 0.58181 to 0.58178, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e021_vl0.582.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5830 - mse: 0.5651 - val_loss: 0.5818 - val_mse: 0.5639\n",
      "Epoch 22/25\n",
      "163/168 [============================>.] - ETA: 0s - loss: 0.5830 - mse: 0.5652\n",
      "Epoch 22: val_loss did not improve from 0.58178\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5830 - mse: 0.5651 - val_loss: 0.5819 - val_mse: 0.5640\n",
      "Epoch 23/25\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.5830 - mse: 0.5652\n",
      "Epoch 23: val_loss did not improve from 0.58178\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5829 - mse: 0.5651 - val_loss: 0.5819 - val_mse: 0.5640\n",
      "Epoch 24/25\n",
      "160/168 [===========================>..] - ETA: 0s - loss: 0.5829 - mse: 0.5650\n",
      "Epoch 24: val_loss did not improve from 0.58178\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5829 - mse: 0.5651 - val_loss: 0.5818 - val_mse: 0.5640\n",
      "Epoch 25/25\n",
      "161/168 [===========================>..] - ETA: 0s - loss: 0.5830 - mse: 0.5651\n",
      "Epoch 25: val_loss did not improve from 0.58178\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5830 - mse: 0.5651 - val_loss: 0.5818 - val_mse: 0.5640\n",
      "Time elapsed to train: 25.14 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.268 2.948 1.568 3.278 2.291 1.652 1.186 0.909 0.560 0.279 0.130 0.032 0.001]\n",
      "<R> = [2.269 2.948 1.568 3.277 2.291 1.652 1.186 0.909 0.560 0.279 0.130 0.032 0.001]\n",
      "s_R = [0.047 0.014 0.000 0.005 0.025 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.72417   2.3964078 6.498871  ... 2.834157  4.0198317 4.4373116]\n",
      "mag_pred: [3.72417   2.3964078 6.498871  ... 2.834157  4.0198317 4.4373116]\n",
      "Time elapsed to make plots: 17.76 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [39.16801   31.738295  10.7500725 ...  2.8766484 35.699097  13.2789545]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0111\n",
      "  1% : 0.0935\n",
      "  10% : 0.212\n",
      "  50% : 0.58\n",
      "  90% : 2.94\n",
      "  99% : 66.6\n",
      "  100% : 7.22e+03\n",
      "<chi^2/d.o.f.> = 0.991\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 16130 stars (6.37%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [10.126911  58.893406  16.099857  ...  3.2455726  5.5487967 13.597305 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0121\n",
      "  1% : 0.0937\n",
      "  10% : 0.214\n",
      "  50% : 0.586\n",
      "  90% : 2.85\n",
      "  99% : 72.7\n",
      "  100% : 5.18e+03\n",
      "<chi^2/d.o.f.> = 0.987\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 78.39 s\n",
      "learning rate = 2.732372195168864e-05\n",
      "setting learning rate to 2.2370771856165592e-05\n",
      "Iteration 20 of 20.\n",
      "Epoch 1/25\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.5837 - mse: 0.5658\n",
      "Epoch 1: val_loss improved from inf to 0.58249, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e001_vl0.582.h5\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.5837 - mse: 0.5658 - val_loss: 0.5825 - val_mse: 0.5647\n",
      "Epoch 2/25\n",
      "157/168 [===========================>..] - ETA: 0s - loss: 0.5830 - mse: 0.5652\n",
      "Epoch 2: val_loss improved from 0.58249 to 0.58246, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e002_vl0.582.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5837 - mse: 0.5659 - val_loss: 0.5825 - val_mse: 0.5646\n",
      "Epoch 3/25\n",
      "159/168 [===========================>..] - ETA: 0s - loss: 0.5840 - mse: 0.5662\n",
      "Epoch 3: val_loss did not improve from 0.58246\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5837 - mse: 0.5658 - val_loss: 0.5826 - val_mse: 0.5648\n",
      "Epoch 4/25\n",
      "163/168 [============================>.] - ETA: 0s - loss: 0.5837 - mse: 0.5659\n",
      "Epoch 4: val_loss did not improve from 0.58246\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5836 - mse: 0.5658 - val_loss: 0.5825 - val_mse: 0.5647\n",
      "Epoch 5/25\n",
      "158/168 [===========================>..] - ETA: 0s - loss: 0.5840 - mse: 0.5662\n",
      "Epoch 5: val_loss improved from 0.58246 to 0.58244, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e005_vl0.582.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5836 - mse: 0.5658 - val_loss: 0.5824 - val_mse: 0.5646\n",
      "Epoch 6/25\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.5837 - mse: 0.5659\n",
      "Epoch 6: val_loss did not improve from 0.58244\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5837 - mse: 0.5658 - val_loss: 0.5825 - val_mse: 0.5646\n",
      "Epoch 7/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 0.5839 - mse: 0.5661\n",
      "Epoch 7: val_loss did not improve from 0.58244\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5836 - mse: 0.5658 - val_loss: 0.5825 - val_mse: 0.5647\n",
      "Epoch 8/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 0.5838 - mse: 0.5660\n",
      "Epoch 8: val_loss did not improve from 0.58244\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5836 - mse: 0.5658 - val_loss: 0.5825 - val_mse: 0.5647\n",
      "Epoch 9/25\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.5837 - mse: 0.5659\n",
      "Epoch 9: val_loss did not improve from 0.58244\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5836 - mse: 0.5658 - val_loss: 0.5825 - val_mse: 0.5647\n",
      "Epoch 10/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 0.5833 - mse: 0.5655\n",
      "Epoch 10: val_loss improved from 0.58244 to 0.58242, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e010_vl0.582.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5836 - mse: 0.5658 - val_loss: 0.5824 - val_mse: 0.5646\n",
      "Epoch 11/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 0.5835 - mse: 0.5657\n",
      "Epoch 11: val_loss did not improve from 0.58242\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5836 - mse: 0.5658 - val_loss: 0.5827 - val_mse: 0.5649\n",
      "Epoch 12/25\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.5834 - mse: 0.5656\n",
      "Epoch 12: val_loss did not improve from 0.58242\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5836 - mse: 0.5658 - val_loss: 0.5825 - val_mse: 0.5647\n",
      "Epoch 13/25\n",
      "161/168 [===========================>..] - ETA: 0s - loss: 0.5836 - mse: 0.5658\n",
      "Epoch 13: val_loss did not improve from 0.58242\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5836 - mse: 0.5658 - val_loss: 0.5826 - val_mse: 0.5648\n",
      "Epoch 14/25\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.5835 - mse: 0.5657\n",
      "Epoch 14: val_loss did not improve from 0.58242\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5836 - mse: 0.5658 - val_loss: 0.5825 - val_mse: 0.5647\n",
      "Epoch 15/25\n",
      "160/168 [===========================>..] - ETA: 0s - loss: 0.5836 - mse: 0.5658\n",
      "Epoch 15: val_loss improved from 0.58242 to 0.58238, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e015_vl0.582.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5836 - mse: 0.5658 - val_loss: 0.5824 - val_mse: 0.5646\n",
      "Epoch 16/25\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.5835 - mse: 0.5658\n",
      "Epoch 16: val_loss did not improve from 0.58238\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5836 - mse: 0.5658 - val_loss: 0.5824 - val_mse: 0.5646\n",
      "Epoch 17/25\n",
      "160/168 [===========================>..] - ETA: 0s - loss: 0.5839 - mse: 0.5661\n",
      "Epoch 17: val_loss did not improve from 0.58238\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5836 - mse: 0.5658 - val_loss: 0.5825 - val_mse: 0.5647\n",
      "Epoch 18/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 0.5837 - mse: 0.5659\n",
      "Epoch 18: val_loss improved from 0.58238 to 0.58236, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e018_vl0.582.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5836 - mse: 0.5658 - val_loss: 0.5824 - val_mse: 0.5646\n",
      "Epoch 19/25\n",
      "157/168 [===========================>..] - ETA: 0s - loss: 0.5838 - mse: 0.5660\n",
      "Epoch 19: val_loss did not improve from 0.58236\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5836 - mse: 0.5658 - val_loss: 0.5824 - val_mse: 0.5646\n",
      "Epoch 20/25\n",
      "161/168 [===========================>..] - ETA: 0s - loss: 0.5834 - mse: 0.5656\n",
      "Epoch 20: val_loss did not improve from 0.58236\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5836 - mse: 0.5658 - val_loss: 0.5825 - val_mse: 0.5648\n",
      "Epoch 21/25\n",
      "158/168 [===========================>..] - ETA: 0s - loss: 0.5836 - mse: 0.5658\n",
      "Epoch 21: val_loss did not improve from 0.58236\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5836 - mse: 0.5658 - val_loss: 0.5825 - val_mse: 0.5647\n",
      "Epoch 22/25\n",
      "163/168 [============================>.] - ETA: 0s - loss: 0.5835 - mse: 0.5657\n",
      "Epoch 22: val_loss did not improve from 0.58236\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5836 - mse: 0.5658 - val_loss: 0.5824 - val_mse: 0.5646\n",
      "Epoch 23/25\n",
      "163/168 [============================>.] - ETA: 0s - loss: 0.5836 - mse: 0.5658\n",
      "Epoch 23: val_loss did not improve from 0.58236\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.5836 - mse: 0.5658 - val_loss: 0.5824 - val_mse: 0.5647\n",
      "Epoch 24/25\n",
      "156/168 [==========================>...] - ETA: 0s - loss: 0.5838 - mse: 0.5661\n",
      "Epoch 24: val_loss improved from 0.58236 to 0.58236, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e024_vl0.582.h5\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5836 - mse: 0.5658 - val_loss: 0.5824 - val_mse: 0.5646\n",
      "Epoch 25/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 0.5831 - mse: 0.5653\n",
      "Epoch 25: val_loss did not improve from 0.58236\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5835 - mse: 0.5658 - val_loss: 0.5824 - val_mse: 0.5647\n",
      "Time elapsed to train: 24.29 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.266 2.946 1.567 3.276 2.290 1.651 1.185 0.909 0.560 0.279 0.130 0.032 0.001]\n",
      "<R> = [2.267 2.946 1.567 3.276 2.289 1.651 1.185 0.909 0.560 0.279 0.130 0.032 0.001]\n",
      "s_R = [0.047 0.014 0.000 0.004 0.025 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.722254  2.3929482 6.500371  ... 2.8342917 4.017664  4.435154 ]\n",
      "mag_pred: [3.722254  2.3929482 6.500371  ... 2.8342917 4.017664  4.435154 ]\n",
      "Time elapsed to make plots: 22.23 s\n"
     ]
    }
   ],
   "source": [
    "for k in range(0, n_iterations):\n",
    "    # Transform data to inputs and outputs\n",
    "    # On subsequent iterations, inflate errors using\n",
    "    # gradients dM/dtheta from trained model, and derive new\n",
    "    # estimates of the reddenings of the stars.\n",
    "    t0 = time()\n",
    "    io_train = get_inputs_outputs(\n",
    "        d_train,\n",
    "        pretrained_model=None if k == 0 else nn_model,\n",
    "        recalc_reddening=True,\n",
    "        rchisq_max=rchisq_max[k]\n",
    "    )                                                                         \n",
    "    io_test = get_inputs_outputs(                                                      #\n",
    "        d_test,                                                                        #\n",
    "        pretrained_model=None if k == 0 else nn_model,                                 #\n",
    "        recalc_reddening=True,                                                         #\n",
    "    )                                                                                  #                                                                        \n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to prepare data: {t1-t0:.2f} s')\n",
    "\n",
    "    # Set learning rate based on the iteration\n",
    "    lr = 0.001 * np.exp(-0.2*k)\n",
    "    print('learning rate = {}'.format(K.get_value(nn_model.optimizer.lr)))\n",
    "    print('setting learning rate to {}'.format(lr))\n",
    "    K.set_value(nn_model.optimizer.lr, lr)\n",
    "\n",
    "    # Train the model\n",
    "    print('Iteration {} of {}.'.format(k+1, n_iterations))\n",
    "    t0 = time()\n",
    "    train_model(\n",
    "        nn_model,\n",
    "        io_train,\n",
    "        epochs=25,\n",
    "        checkpoint_fn='{:s}_{:d}hidden_it{:d}'.format(\n",
    "            nn_name, n_hidden, k\n",
    "        ),\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to train: {t1-t0:.2f} s')\n",
    "    nn_model.save(\n",
    "        'models/{:s}_{:d}hidden_it{:d}.h5'.format(\n",
    "            nn_name, n_hidden, k\n",
    "        )\n",
    "    )\n",
    "    nn_model = keras.models.load_model(                                                #\n",
    "       'models/{:s}_{:d}hidden_it{:d}.h5'.format(nn_name, n_hidden, k)                 #\n",
    "    )                                                                                  #\n",
    "                                                                                       #\n",
    "    # Plot results on test set                                                         #\n",
    "    print('Diagnostic plots ...')                                                      #\n",
    "    t0 = time()                                                                        #\n",
    "    diagnostic_plots(                                                                  #\n",
    "       nn_model,                                                                       #\n",
    "       io_test,                                                                        #\n",
    "       d_test,                                                                         #\n",
    "       #io_train,                                                                      #\n",
    "       #d_train,                                                                       #\n",
    "       suffix='{:s}_{:d}hidden_it{:d}'.format(nn_name, n_hidden, k)                    #\n",
    "    )                                                                                  #\n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to make plots: {t1-t0:.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1d8de09-5d9d-43a1-b6ad-5aa70393a40a",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating covariances and reddening estimates of test dataset ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [10.06535   59.124107  16.06159   ...  3.1848865  5.5428667 13.5630455]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0129\n",
      "  1% : 0.0929\n",
      "  10% : 0.213\n",
      "  50% : 0.585\n",
      "  90% : 2.86\n",
      "  99% : 72.8\n",
      "  100% : 5.18e+03\n",
      "<chi^2/d.o.f.> = 0.986\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to update covariances and reddenings: 8.21 s\n"
     ]
    }
   ],
   "source": [
    "print('Updating covariances and reddening estimates of test dataset ...')\n",
    "t0 = time()\n",
    "io_test = get_inputs_outputs(\n",
    "    d_test,\n",
    "    pretrained_model=nn_model,\n",
    "    recalc_reddening=True\n",
    ")\n",
    "t1 = time()\n",
    "print(f'Time elapsed to update covariances and reddenings: {t1-t0:.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fe20ad0-6076-42e4-b5fa-0a8b44b55833",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: [0.5801098942756653, 0.562350332736969]\n",
      "train loss: [0.583273708820343, 0.5655139088630676]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance on (train, validation and test sets)\n",
    "loss = {}\n",
    "for n,io_eval in (('test',io_test), ('train',io_train)):\n",
    "    loss[n] = evaluate_model(\n",
    "        nn_model,\n",
    "        io_eval,\n",
    "        batch_size=batch_size,\n",
    "        rchisq_max=rchisq_max[-1]\n",
    "    )\n",
    "    print(f'{n} loss: {loss[n]}')\n",
    "fname = 'loss_{:s}_{:d}hidden_it{:d}.json'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "with open(fname, 'w') as f:\n",
    "    json.dump(loss, f, indent=2, sort_keys=True)\n",
    "\n",
    "fname = 'predictions_{:s}_{:d}hidden_it{:d}.h5'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "save_predictions(fname, nn_model, d_test, io_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ef83a49-55d7-41f4-be9e-87606f86734e",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving covariance components for small subset of test dataset ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 1000 bad. Replacing with 14.23750.\n",
      "Band 1: 0 of 1000 bad. Replacing with 14.61455.\n",
      "Band 2: 0 of 1000 bad. Replacing with 13.69537.\n",
      "Band 3: 147 of 1000 bad. Replacing with 14.96300.\n",
      "Band 4: 250 of 1000 bad. Replacing with 14.65440.\n",
      "Band 5: 310 of 1000 bad. Replacing with 14.59245.\n",
      "Band 6: 192 of 1000 bad. Replacing with 14.30900.\n",
      "Band 7: 33 of 1000 bad. Replacing with 14.03010.\n",
      "Band 8: 0 of 1000 bad. Replacing with 13.05500.\n",
      "Band 9: 1 of 1000 bad. Replacing with 12.69000.\n",
      "Band 10: 4 of 1000 bad. Replacing with 12.60650.\n",
      "Band 11: 1 of 1000 bad. Replacing with 15.26814.\n",
      "Band 12: 2 of 1000 bad. Replacing with 15.92215.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 1000 of 1000 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [6.09184313e+00 9.98692608e+00 1.03853407e+01 9.94629860e+00\n",
      " 8.36546803e+00 2.02187653e+01 9.65533638e+00 1.19584976e+02\n",
      " 8.94953918e+01 4.74933052e+00 2.60944462e+01 2.06381941e+00\n",
      " 6.60746098e+00 3.94323730e+01 9.64328766e+00 4.65302992e+00\n",
      " 1.27860367e+00 2.27227283e+00 1.68444767e+01 9.03492737e+00\n",
      " 2.17843933e+01 1.39767170e+00 3.49114037e+01 3.94046688e+00\n",
      " 7.68045950e+00 7.13123417e+00 1.37662935e+00 1.86471996e+01\n",
      " 4.04538059e+00 3.68972540e+00 2.66699290e+00 1.23666172e+01\n",
      " 5.56273689e+01 4.00491867e+01 5.18872929e+00 3.05502319e+00\n",
      " 3.63516426e+00 6.38604689e+00 1.22442341e+01 3.26222420e+00\n",
      " 7.71843109e+01 3.25123825e+01 8.43896580e+00 7.28704977e+00\n",
      " 2.50684643e+00 5.06732082e+00 6.50923061e+00 6.28335333e+00\n",
      " 1.63838172e+00 2.13338113e+00 8.25098419e+00 2.01343036e+00\n",
      " 9.68697846e-01 1.13394232e+01 5.44047928e+00 6.41769361e+00\n",
      " 5.97870541e+00 6.93162060e+00 7.99998808e+00 7.86597300e+00\n",
      " 6.26222754e+00 3.92995167e+00 7.29271269e+00 1.54631176e+01\n",
      " 1.26122463e+00 2.67308187e+00 2.58717823e+00 2.13615155e+00\n",
      " 8.18107128e+00 2.45369930e+01 1.10645180e+01 5.75057411e+00\n",
      " 3.83835244e+00 1.18556118e+01 3.77216983e+00 5.15342665e+00\n",
      " 2.36467266e+01 7.48722458e+00 3.28996582e+01 1.18980827e+01\n",
      " 8.82129002e+00 1.76226521e+01 7.67693758e+00 8.58794212e+00\n",
      " 8.82106018e+00 1.68762608e+01 1.29607229e+01 5.12417793e+00\n",
      " 6.45215225e+00 2.88082075e+00 2.35450745e+01 6.08938932e+00\n",
      " 9.45425606e+00 5.57886887e+00 4.57777405e+00 7.88696814e+00\n",
      " 4.49117041e+00 3.87963223e+00 6.75272083e+00 4.21380186e+00\n",
      " 6.38698196e+00 1.37893076e+01 8.26728439e+01 9.95087528e+00\n",
      " 1.56090631e+01 6.41686726e+00 2.34344425e+01 2.50151777e+00\n",
      " 4.37135620e+01 6.36983490e+00 1.55956678e+01 2.64331555e+00\n",
      " 5.46378899e+00 6.01380062e+00 2.88546777e+00 8.95205212e+00\n",
      " 7.09709072e+00 3.34991932e+00 3.13078690e+00 5.10411549e+00\n",
      " 2.54332876e+00 9.83635616e+00 4.76164818e+00 6.05140591e+00\n",
      " 4.01594019e+00 2.67558074e+00 1.32037926e+01 3.02136326e+00\n",
      " 3.28395844e+01 1.92432070e+00 1.99571979e+00 8.01434803e+00\n",
      " 1.67142344e+00 1.08408582e+00 6.38950253e+00 3.89206839e+00\n",
      " 6.47012472e+00 1.92001190e+01 1.02821484e+01 4.31088924e+00\n",
      " 6.39382172e+00 5.06482840e+00 1.26063700e+01 3.24518347e+00\n",
      " 2.41048775e+01 1.07033180e+02 1.62398696e+00 7.23127136e+01\n",
      " 2.44267960e+01 1.15133035e+00 3.92245674e+00 8.00921631e+00\n",
      " 2.38358383e+01 5.95520515e+01 4.38106251e+00 6.07339621e+00\n",
      " 2.66899824e+00 1.01789675e+01 3.25458908e+00 2.63334179e+01\n",
      " 5.45186138e+00 1.10583580e+00 5.45728922e+00 2.83146820e+01\n",
      " 1.79696808e+01 5.02206898e+00 1.08527298e+02 7.85333014e+00\n",
      " 6.59727812e+00 1.09069176e+01 8.22819352e-01 5.56108141e+00\n",
      " 7.27882957e+00 1.12481775e+01 4.75148916e+00 3.21424651e+00\n",
      " 4.34782219e+00 1.12257034e+02 8.77341938e+00 7.66835499e+00\n",
      " 7.23554802e+00 2.24946404e+01 2.08258820e+00 6.64239883e+00\n",
      " 6.50847673e+00 4.18118048e+00 7.24960279e+00 1.64068069e+02\n",
      " 1.78389335e+00 2.15737705e+01 4.25731754e+00 4.46192408e+00\n",
      " 7.08166885e+00 4.70730829e+00 3.00398517e+00 5.71391010e+00\n",
      " 1.45494553e+02 1.96442642e+01 4.66390753e+00 2.60002637e+00\n",
      " 5.58396769e+00 6.97688007e+00 2.87646389e+00 1.76301708e+01\n",
      " 9.49197197e+00 7.17785835e+00 6.49393463e+00 3.63424325e+00\n",
      " 1.03735232e+00 6.20926952e+00 4.25350428e+00 4.71452904e+00\n",
      " 9.32037163e+00 5.51914740e+00 6.91226768e+00 2.47650099e+00\n",
      " 2.04511595e+00 1.15983982e+01 9.11973178e-01 2.64782190e+00\n",
      " 5.89656448e+00 1.04861994e+01 2.45091133e+01 1.48926563e+01\n",
      " 2.46893620e+00 3.20111108e+00 1.02958651e+01 1.98636360e+01\n",
      " 4.42962497e-01 1.42162237e+01 5.40015364e+00 5.22405457e+02\n",
      " 7.40324974e+00 5.88334751e+00 6.12167358e+00 3.88675213e+00\n",
      " 5.64374638e+00 4.97289753e+00 7.27432728e+00 2.31320839e+01\n",
      " 1.62057900e+00 1.16381512e+01 3.47537756e+00 8.78537231e+02\n",
      " 6.19969368e+00 4.87828827e+00 6.91684723e+00 1.22057953e+01\n",
      " 5.90947390e+00 2.06579304e+00 1.11320782e+01 2.18971658e+00\n",
      " 6.59847736e+00 2.94319534e+00 2.86287098e+01 9.41799641e+00\n",
      " 1.19322281e+01 8.56798935e+00 8.23742867e-01 6.77457199e+01\n",
      " 3.37158875e+02 7.07079315e+00 4.35584259e+00 5.74098396e+00\n",
      " 1.32667141e+01 6.09043407e+00 5.13760757e+00 3.27227354e+00\n",
      " 2.57323570e+01 3.94856071e+00 1.98656654e+00 3.50679207e+00\n",
      " 3.97411585e+00 4.03128004e+00 1.87088242e+01 8.79024696e+00\n",
      " 6.46475935e+00 3.21922159e+00 2.17841988e+01 2.04214644e+00\n",
      " 2.50504780e+01 1.00885868e+01 4.31774569e+00 1.35350428e+01\n",
      " 4.03519096e+01 5.14975548e+00 7.86860752e+00 1.57657397e+00\n",
      " 6.13182640e+00 6.41479349e+00 9.43141937e+00 1.70693111e+01\n",
      " 5.52988291e+00 9.42605209e+00 4.05254021e+01 2.23081374e+00\n",
      " 1.38019180e+01 6.77875853e+00 2.20409603e+01 2.92666173e+00\n",
      " 2.76968694e+00 1.57810080e+00 1.04285679e+01 3.01817489e+00\n",
      " 5.13627338e+00 4.43585587e+00 2.51854181e+00 6.41156435e+00\n",
      " 1.83295465e+00 8.76159573e+00 4.17294846e+01 1.77469845e+01\n",
      " 2.67354012e+01 1.78663025e+01 6.35547543e+00 1.46121573e+00\n",
      " 2.31490755e+00 5.95403910e+00 4.37290144e+00 3.55341887e+00\n",
      " 3.35238504e+00 9.49411106e+00 3.38006186e+00 2.28158875e+01\n",
      " 3.67459536e+00 3.00375438e+00 3.74468064e+00 2.51287746e+00\n",
      " 3.66176414e+00 5.67457056e+00 5.18704128e+00 6.54128647e+00\n",
      " 6.41450596e+00 3.10477448e+00 1.66991746e+00 2.61784887e+00\n",
      " 2.28254414e+00 2.65889435e+01 5.16300201e+00 1.08631187e+02\n",
      " 2.12762856e+00 3.05728960e+00 6.83489990e+01 6.47259903e+00\n",
      " 1.72983885e+00 6.36290407e+00 5.30411625e+00 3.13670006e+01\n",
      " 1.14138269e+00 7.37468433e+00 9.89322662e+00 1.17237413e+00\n",
      " 1.88312206e+01 3.12619543e+00 5.11331879e+02 8.11353683e+00\n",
      " 3.30906029e+01 3.18488646e+00 7.17709160e+00 1.43953552e+01\n",
      " 5.10625792e+00 4.36275482e+00 1.65256081e+01 1.97186327e+00\n",
      " 2.63268661e+01 4.86486197e+00 1.47070618e+01 2.22606778e+00\n",
      " 5.53497672e-01 7.01078844e+00 6.54897690e+00 2.37235031e+01\n",
      " 1.10219040e+01 6.84597826e+00 5.80554152e+00 6.03911400e+00\n",
      " 6.04870653e+00 1.90004559e+01 9.61298370e+00 2.53361130e+00\n",
      " 1.13697655e+02 3.81866193e+00 2.95289764e+01 2.74766088e+00\n",
      " 3.79695368e+00 5.03127956e+00 2.80794311e+00 9.77665961e-01\n",
      " 4.91950607e+00 2.39828730e+00 4.48330116e+00 8.69224739e+00\n",
      " 8.73850346e+00 3.58042860e+00 9.24860573e+00 4.28836853e+02\n",
      " 7.54059362e+00 1.16029148e+01 9.23836422e+00 6.51522684e+00\n",
      " 9.24197388e+00 1.76488171e+01 2.10138893e+01 1.33443308e+00\n",
      " 1.47152758e+00 2.26757669e+00 2.96710205e+00 4.53296852e+00\n",
      " 3.45155430e+00 3.03911924e+00 4.04837799e+00 1.55479550e+00\n",
      " 5.55354023e+00 2.36477563e+03 1.07241416e+00 4.58405495e+00\n",
      " 8.82047729e+01 1.72073498e+01 1.84383655e+00 1.44756195e+02\n",
      " 5.47201252e+00 8.67096043e+00 4.17678976e+00 7.94284744e+01\n",
      " 8.58098297e+01 2.50817513e+00 7.81434441e+00 4.58421230e+00\n",
      " 1.00067263e+01 1.43612442e+01 2.10459948e+00 9.04678726e+00\n",
      " 3.09880428e+01 1.54845638e+01 8.37488747e+00 1.40110397e+01\n",
      " 1.13463230e+01 1.90106392e+01 1.02551603e+01 7.26672745e+00\n",
      " 7.05981922e+00 6.10014725e+00 3.19467664e+00 1.07279987e+01\n",
      " 6.30716562e+00 7.54765177e+00 5.14513445e+00 2.42918897e+00\n",
      " 4.25842438e+01 7.49846268e+01 2.30531001e+00 3.85412455e+00\n",
      " 1.73961830e+01 4.53424549e+00 3.91944146e+00 2.43707085e+00\n",
      " 1.55001068e+00 8.55132580e+00 9.07290578e-01 9.37243938e+00\n",
      " 8.27454185e+00 6.09697914e+00 6.88217545e+00 1.98856592e+00\n",
      " 2.26792850e+01 3.53583121e+00 5.86678362e+00 4.67704296e+00\n",
      " 2.57380257e+01 3.32964563e+00 7.23379946e+00 1.00695336e+00\n",
      " 3.02828956e+00 6.85652399e+00 9.39992368e-01 2.43252134e+00\n",
      " 4.48400841e+01 4.82345295e+00 2.28687382e+01 4.22440186e+01\n",
      " 1.65265083e+01 1.48756065e+01 7.79993773e+00 5.31800537e+03\n",
      " 8.90082550e+00 6.64806843e+00 1.52590096e+00 2.79046416e+00\n",
      " 3.15251398e+00 1.11715050e+01 5.35049057e+00 2.74360466e+00\n",
      " 3.05403376e+00 4.50141573e+00 6.41205120e+00 2.38246846e+00\n",
      " 2.74396801e+00 2.48277950e+00 5.31542969e+00 5.59053612e+00\n",
      " 5.71890974e+00 1.18273869e+01 8.33608627e+00 3.11490250e+00\n",
      " 1.93248425e+01 5.59176540e+00 6.16911411e+00 4.91607761e+00\n",
      " 6.59679413e+00 7.00954723e+00 1.94070034e+01 2.24513865e+00\n",
      " 6.67968369e+00 5.63503408e+00 7.66450071e+00 8.98607063e+00\n",
      " 1.43291330e+01 7.44130707e+00 1.01212444e+01 1.08695097e+01\n",
      " 4.44047880e+00 8.14606571e+00 6.93009233e+00 3.84189558e+00\n",
      " 2.96744609e+00 3.87591934e+00 5.61763763e+01 3.33074951e+00\n",
      " 5.30531311e+00 3.77556801e+01 8.63009453e+00 4.13780689e+00\n",
      " 1.48717957e+01 3.37132239e+00 5.07150173e+00 4.63897896e+00\n",
      " 9.51911032e-01 6.19725704e+00 1.41536961e+01 4.19408321e+00\n",
      " 1.34537306e+01 1.34491529e+01 2.80244136e+00 2.19239407e+01\n",
      " 1.38614101e+01 2.55595684e+00 1.55412750e+01 4.36105537e+00\n",
      " 2.67685938e+00 2.29136753e+00 2.92637205e+00 8.16080284e+00\n",
      " 1.77964745e+01 6.64260712e+01 1.72061455e+00 9.36227036e+00\n",
      " 3.52979355e+01 9.30002689e+00 1.38565159e+01 7.51453400e+00\n",
      " 2.10578465e+00 7.99741864e-01 1.93336906e+01 6.98702669e+00\n",
      " 1.90737307e+00 1.99130285e+00 5.22512436e+00 4.23023272e+00\n",
      " 3.04867363e+00 1.94837487e+00 6.36921930e+00 3.99799204e+00\n",
      " 8.48128891e+00 2.75242340e+02 1.15051050e+01 1.47242661e+01\n",
      " 6.62812042e+00 7.44247131e+01 2.18947258e+01 1.28369737e+00\n",
      " 3.02154303e+00 1.18258495e+01 7.20388889e+00 3.20005965e+00\n",
      " 8.16927719e+00 6.59368801e+00 1.31608164e+00 3.71578002e+00\n",
      " 2.61140575e+01 3.71130013e+00 9.51918030e+00 2.76107645e+00\n",
      " 3.83772802e+00 3.20352435e+00 7.80132246e+00 4.77445269e+00\n",
      " 7.64692974e+00 3.01520705e+00 8.72860718e+01 1.24536438e+01\n",
      " 1.32173157e+01 2.36777935e+01 3.63933635e+00 8.38871193e+00\n",
      " 1.66000862e+01 6.99021339e+00 9.71655655e+00 6.57392597e+00\n",
      " 1.15767231e+01 1.67377838e+02 3.42067122e+00 7.10489702e+00\n",
      " 7.57685165e+01 6.00973282e+01 6.78246880e+00 5.21499586e+00\n",
      " 6.95096922e+00 8.26693821e+00 8.49067116e+00 1.58788335e+00\n",
      " 2.10179567e+00 3.04924660e+01 5.58232975e+00 2.37537527e+00\n",
      " 1.01388493e+01 3.12661314e+00 9.03570271e+00 1.56451445e+01\n",
      " 3.65817308e+00 3.89545937e+01 1.07056961e+01 1.09754143e+01\n",
      " 8.73046112e+00 2.11762409e+01 3.16241121e+00 5.50213718e+00\n",
      " 1.38994017e+01 8.42530537e+00 4.04389668e+00 4.79922628e+00\n",
      " 3.26335793e+01 2.80263257e+00 7.88776541e+00 1.24810886e+01\n",
      " 4.18252487e+01 1.95950546e+01 1.21938000e+01 2.34188557e+00\n",
      " 3.80670619e+00 7.07199907e+00 5.16402912e+00 1.50525417e+01\n",
      " 9.35663223e+00 1.30626249e+01 8.18467140e+00 2.58056068e+01\n",
      " 8.12639046e+00 8.68595839e-01 5.78650146e+03 3.95328069e+00\n",
      " 3.22265816e+00 5.86927605e+00 3.78737092e+00 7.10476112e+00\n",
      " 6.95882654e+00 2.47019935e+00 3.79981542e+00 2.04100647e+01\n",
      " 1.47651901e+01 6.25499105e+00 1.72129107e+00 1.13190975e+01\n",
      " 5.08089142e+01 9.03305244e+00 3.20068283e+01 1.78083265e+00\n",
      " 2.20574570e+00 3.80934954e+00 7.93600235e+01 2.56773624e+01\n",
      " 9.95989323e+00 8.90036011e+00 1.93991604e+01 6.91763639e+00\n",
      " 5.35187006e+00 9.52016449e+00 1.93582687e+01 8.38529778e+00\n",
      " 1.83440399e+00 7.14943409e+00 5.41572762e+00 4.57488632e+00\n",
      " 2.41721863e+02 5.85515070e+00 1.85794067e+01 3.87058115e+00\n",
      " 3.78147602e+00 3.50900793e+00 7.45038176e+00 1.02117872e+01\n",
      " 1.25807724e+01 1.07971344e+01 1.28319025e+00 2.57582498e+00\n",
      " 1.27392807e+01 1.77463379e+02 7.81681824e+00 8.85001278e+00\n",
      " 9.33264434e-01 1.03842297e+01 4.32010555e+00 2.63733208e-01\n",
      " 4.41131248e+01 7.86080658e-01 1.62188950e+01 2.37491455e+01\n",
      " 3.84548569e+00 3.07659292e+00 5.62455463e+00 5.32672501e+00\n",
      " 1.59316909e+00 8.60230446e+00 1.24872370e+01 1.44990072e+01\n",
      " 2.22772384e+00 1.64940643e+01 8.84545326e+00 6.62779808e+00\n",
      " 3.17842445e+01 5.23958778e+01 2.50419426e+00 1.75080662e+01\n",
      " 1.89085522e+01 3.57022667e+00 7.16851997e+00 4.65523624e+00\n",
      " 5.23881912e+00 2.74139442e+01 6.77843857e+00 3.60019873e+03\n",
      " 5.19916964e+00 5.32706976e+00 4.15241623e+00 7.68099403e+00\n",
      " 8.35380077e+00 8.86161613e+00 4.39783430e+00 9.28448296e+00\n",
      " 1.84255266e+00 2.54650974e+00 1.32104959e+01 2.67815852e+00\n",
      " 6.87351036e+00 9.84402084e+00 3.44410095e+02 4.82165670e+00\n",
      " 2.95695662e+00 1.09953461e+01 1.51841993e+01 2.14481497e+00\n",
      " 1.01206398e+01 6.21277332e+00 4.81552410e+00 9.55474377e+00\n",
      " 6.35112476e+00 5.98757553e+00 4.75157595e+00 5.77967453e+00\n",
      " 5.48770142e+00 1.82850895e+01 1.52244530e+01 7.41540909e+00\n",
      " 8.83667183e+00 1.23351030e+01 2.46103287e+01 1.40719962e+00\n",
      " 3.05539036e+00 1.35107479e+01 3.98729634e+00 1.69726810e+01\n",
      " 5.88716602e+00 3.40399933e+00 6.91671219e+01 9.23690128e+00\n",
      " 4.53199434e+00 3.05390429e+00 1.00261536e+01 2.45001078e+00\n",
      " 4.36015224e+00 1.91845207e+01 5.43348694e+00 1.16767282e+01\n",
      " 1.90413952e+01 9.78238106e+00 1.42581577e+01 2.87918434e+01\n",
      " 1.12560520e+01 6.07301617e+00 1.58457108e+01 3.87131596e+00\n",
      " 3.76138077e+01 7.98766184e+00 1.21975889e+01 2.60643077e+00\n",
      " 6.11441135e+00 1.59821403e+00 3.70134950e+00 1.91634858e+00\n",
      " 1.01900053e+01 1.80610924e+01 4.60804605e+00 3.16771579e+00\n",
      " 4.25679636e+00 2.65113235e+00 1.48619251e+01 1.46666451e+01\n",
      " 4.79361629e+00 1.50607700e+01 2.32681322e+00 5.37629223e+00\n",
      " 3.86676292e+01 2.23445606e+00 5.03767456e+02 1.40625315e+01\n",
      " 4.02517825e-01 5.79658651e+00 4.45348787e+00 4.62029743e+00\n",
      " 2.99139214e+01 1.57252092e+01 8.98245525e+00 2.13461572e+03\n",
      " 8.41211987e+00 7.91400528e+00 8.84489536e+00 5.14217281e+00\n",
      " 2.06523561e+00 5.52448702e+00 1.11685829e+01 4.42826176e+00\n",
      " 2.37847576e+01 1.20263996e+01 2.25019073e+00 3.46933899e+01\n",
      " 1.82480907e+01 1.00798244e+01 1.16720543e+01 6.54589462e+00\n",
      " 1.02011261e+01 1.45366531e+02 9.48665524e+00 7.18281221e+00\n",
      " 8.20109081e+00 3.31202245e+00 1.48313723e+01 1.52831078e+01\n",
      " 3.00423946e+01 9.79827404e+00 4.36347198e+00 1.77937663e+00\n",
      " 5.83383894e+00 5.94946957e+00 3.05399551e+01 4.44802189e+00\n",
      " 6.55828476e+00 2.94073939e+00 8.85663223e+00 2.86769271e+00\n",
      " 4.10042763e+00 2.21319160e+01 7.54626465e+00 1.01413708e+01\n",
      " 1.26838303e+00 7.90899849e+00 1.13191553e+03 6.37867785e+00\n",
      " 5.94431229e+01 4.37259941e+01 1.31375456e+00 2.05927525e+01\n",
      " 2.16782513e+01 5.92340708e+00 7.83389950e+00 1.49506512e+01\n",
      " 6.17999573e+01 6.95961571e+00 6.20589256e+01 1.16250286e+01\n",
      " 1.62801743e+00 4.09969044e+00 2.91551447e+00 2.76008949e+01\n",
      " 1.37649183e+01 7.95117722e+01 4.53851366e+00 7.47074805e+03\n",
      " 3.29698300e+00 3.66215467e+00 1.75717723e+00 3.15332069e+01\n",
      " 2.82234025e+00 2.58429956e+00 4.01833076e+01 1.19634924e+01\n",
      " 3.86602783e+00 4.15535393e+01 3.66236448e+00 2.27011890e+03\n",
      " 1.24888241e+00 2.69442749e+00 1.25813179e+01 4.10746861e+00\n",
      " 7.01006174e+00 4.80902958e+00 5.60934877e+00 5.88120794e+00\n",
      " 4.06441307e+00 5.74150467e+00 5.33501434e+00 2.51534653e+01\n",
      " 6.00765896e+00 2.90021396e+00 3.51184893e+00 4.40948219e+01\n",
      " 3.96208072e+00 3.97541499e+00 9.68030262e+00 6.96424389e+00\n",
      " 6.97982252e-01 5.68272209e+00 3.52632809e+00 8.84978867e+00\n",
      " 2.75005684e+01 2.60765610e+01 8.28792691e-01 1.31875014e+00\n",
      " 1.03127098e+01 4.29199028e+00 2.38757873e+00 2.16267729e+00\n",
      " 3.28743887e+00 8.74087906e+00 3.93746018e+00 2.13825760e+01\n",
      " 5.31465244e+00 4.22691345e+00 2.16785216e+00 5.94673967e+00\n",
      " 4.09525452e+02 3.59695053e+00 2.42316577e+03 1.23140182e+01\n",
      " 2.76030922e+00 5.61835670e+00 1.76431122e+02 2.31816196e+01\n",
      " 3.70055771e+00 2.63323498e+00 1.03910103e+01 2.38132501e+00\n",
      " 2.39433975e+02 4.73483673e+02 9.02115822e+00 8.20993710e+00\n",
      " 1.46597929e+01 3.88579845e+00 2.56590533e+00 6.53631592e+02\n",
      " 7.94529676e+00 5.36463118e+00 3.58439231e+00 3.71243706e+01\n",
      " 2.69011521e+00 7.44357300e+00 2.17196894e+00 2.32293177e+00\n",
      " 4.24087477e+00 2.15236759e+00 6.26433945e+00 1.89253545e+00\n",
      " 1.02043571e+01 2.28982239e+01 2.90602922e+00 2.35177469e+00\n",
      " 5.06573200e+00 5.09700203e+00 9.47568893e+00 5.15065575e+00\n",
      " 3.89942980e+00 2.39687309e+01 4.11414185e+01 3.28054094e+00\n",
      " 2.33120861e+01 8.23652267e+00 4.71479034e+00 1.14006157e+01\n",
      " 4.52069187e+00 2.53433847e+00 7.32684422e+00 4.72660160e+00]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0377\n",
      "  1% : 0.0888\n",
      "  10% : 0.208\n",
      "  50% : 0.576\n",
      "  90% : 2.64\n",
      "  99% : 73.4\n",
      "  100% : 747\n",
      "<chi^2/d.o.f.> = 1.01\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n"
     ]
    }
   ],
   "source": [
    "print('Saving covariance components for small subset of test dataset ...')\n",
    "# Fix random seed (same subset every run)\n",
    "np.random.seed(3)\n",
    "idx = np.arange(d_test.size)\n",
    "np.random.shuffle(idx)\n",
    "idx = idx[:1000]\n",
    "d_comp = d_test[idx]\n",
    "io_comp = get_inputs_outputs(\n",
    "    d_comp,\n",
    "    pretrained_model=nn_model,\n",
    "    recalc_reddening=True,\n",
    "    return_cov_components=True\n",
    ")\n",
    "fname = 'predictions_{:s}_{:d}hidden_it{:d}_comp.h5'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "save_predictions(fname, nn_model, d_comp, io_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bf3ec27-6103-4713-9c21-1222e68e39f1",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data and reddening estimates of subset of test dataset ...\n"
     ]
    }
   ],
   "source": [
    "print('Saving data and reddening estimates of subset of test dataset ...')\n",
    "np.random.seed(5)\n",
    "idx = np.arange(d_test.size)\n",
    "np.random.shuffle(idx)\n",
    "idx = idx[:10000]\n",
    "d_small = d_test[idx]\n",
    "r_fit_small = io_test['r'][idx]\n",
    "r_var_small = io_test['r_var'][idx]\n",
    "fname = 'test_data_small_{:s}_{:d}hidden.h5'.format(\n",
    "    nn_name, n_hidden\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82da0ebc-697f-4f8b-ae07-05ba4f0e7217",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving subset to test_data_small_ext_0h_l1n2_2hidden.h5 ...\n"
     ]
    }
   ],
   "source": [
    "print(f'Saving subset to {fname} ...')\n",
    "with h5py.File(fname, 'w') as f:\n",
    "    dset = f.create_dataset(\n",
    "        'data',\n",
    "        data=d_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )\n",
    "    for key in d_attrs:\n",
    "        dset.attrs[key] = d_attrs[key]\n",
    "\n",
    "    # Store updated reddening estimates\n",
    "    dset = f.create_dataset(\n",
    "        'r_fit',\n",
    "        data=r_fit_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )\n",
    "    dset = f.create_dataset(\n",
    "        'r_var',\n",
    "        data=r_var_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 2,
      "defaultCellHeight": 40,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
