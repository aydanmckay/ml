{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b43db49-f88d-44af-8188-9c546a2bb2e1",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "source": [
    "Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12337364-915d-45e0-aa68-ff9ad349e998",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "# # Tell Tensorflow not to allocate all GPU memory right away.\n",
    "# # This is very important in shared environments!\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU') \n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from glob import glob\n",
    "from time import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b0b4d-d609-4535-82f4-76f5979bb893",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### The dataloder used by Green+2020 which will be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f39968a5-1090-448f-a6dc-b53829db1f41",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(fname, return_attrs=False):\n",
    "    print(f'Loading {fname} ...')\n",
    "    attrs = {}\n",
    "    with h5py.File(fname, 'r') as f:\n",
    "        dset = f['io_data']\n",
    "        for key in dset.attrs.keys():\n",
    "            attrs[key] = dset.attrs[key]\n",
    "        d = dset[:]\n",
    "    \n",
    "    if return_attrs:\n",
    "        return d, attrs\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a7c2e5-f232-46ff-b235-d6604c1b5d35",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Obtaining a correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e0eccc-4ffd-4904-a210-7b430692c477",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_corr_matrix(cov):\n",
    "    rho = cov.copy()\n",
    "    sqrt_cov_diag = np.sqrt(cov[np.diag_indices(cov.shape[0])])\n",
    "    rho /= sqrt_cov_diag[:,None]\n",
    "    rho /= sqrt_cov_diag[None,:]\n",
    "    rho[np.diag_indices(cov.shape[0])] = sqrt_cov_diag\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f2ec3-9dba-4970-ab73-494dddd61534",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Cannot be explained in one markdown cell above, need to look through it more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72257ca9-2c06-4d52-9589-9b9086876356",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_inputs_outputs(d, pretrained_model=None,\n",
    "                          recalc_reddening=False,\n",
    "                          rchisq_max=None,\n",
    "                          return_cov_components=False):\n",
    "    n_bands = 13 # Gaia (G, BP, RP), PS1 (grizy), 2MASS (JHK), unWISE (W1,W2)\n",
    "    n_atm_params = 3 # (T_eff, logg, [M/H])\n",
    "    \n",
    "    large_err = 999.\n",
    "\n",
    "    # Stellar spectroscopic parameters\n",
    "    print('Fill in stellar atmospheric parameters ...')\n",
    "    x = np.empty((d.size,3), dtype='f4')\n",
    "    x[:] = d['atm_param'][:]\n",
    "\n",
    "    x_p = np.empty((d.size,3), dtype='f4')\n",
    "    x_p = d['atm_param_p'][:]\n",
    "\n",
    "    # Magnitudes\n",
    "    print('Fill in stellar magnitudes ...')\n",
    "    y = np.empty((d.size,n_bands), dtype='f4')\n",
    "    y[:] = d['mag'][:]\n",
    "\n",
    "    # Covariance of y\n",
    "    print('Empty covariance matrix ...')\n",
    "    cov_y = np.zeros((d.size,n_bands,n_bands), dtype='f4')\n",
    "\n",
    "    # \\delta m\n",
    "    print('Covariance: \\delta m ...')\n",
    "    for i in range(n_bands):\n",
    "        cov_y[:,i,i] = d['mag_err'][:,i]**2\n",
    "\n",
    "    # Replace NaN magnitudes with median (in each band).\n",
    "    # Also set corresponding variances to large number.\n",
    "    print('Replace NaN magnitudes ...')\n",
    "    for b in range(n_bands):\n",
    "        idx = (\n",
    "              ~np.isfinite(y[:,b])\n",
    "            | ~np.isfinite(cov_y[:,b,b])\n",
    "        )\n",
    "        n_bad = np.count_nonzero(idx)\n",
    "        n_tot = idx.size\n",
    "        y0 = np.median(y[~idx,b])\n",
    "        if np.isnan(y0):\n",
    "            y0 = 0.\n",
    "        print(f'Band {b}: {n_bad} of {n_tot} bad. Replacing with {y0:.5f}.')\n",
    "        y[idx,b] = y0\n",
    "        cov_y[idx,b,b] = large_err**2.\n",
    "\n",
    "    # Transform both y and its covariance\n",
    "    B = np.identity(n_bands, dtype='f4')\n",
    "    B[1:,0] = -1.\n",
    "    \n",
    "    print('Transform y -> B y ...')\n",
    "    y = np.einsum('ij,nj->ni', B, y) # y' = B y\n",
    "    print('Transform C -> B C B^T ...')\n",
    "    #cov_y = np.einsum('ik,nkl,jl->nij', B, cov_y, B) # C' = B C B^T\n",
    "    cov_y = np.einsum('nik,jk->nij', cov_y, B)\n",
    "    cov_y = np.einsum('ik,nkj->nij', B, cov_y)\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp = {\n",
    "            'delta_m': cov_y.copy()\n",
    "        }\n",
    "    \n",
    "    # Add in dM/dtheta and dR/dtheta terms\n",
    "    if pretrained_model is not None:\n",
    "        print('Calculate J = dM/dtheta ...')\n",
    "        J_M = calc_dmag_color_dtheta(pretrained_model, x_p)\n",
    "        cov_x = d['atm_param_cov_p']\n",
    "        print('Covariance: J C_theta J^T ...')\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_M)\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['dM/dtheta'] = np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_M)\n",
    "\n",
    "    # If pretrained model provided, could calculate reduced chi^2\n",
    "    # with maximum-likelihood (mu, E) here.\n",
    "\n",
    "    # \\delta \\mu (must be added in after transformation,\n",
    "    #             due to possibly infinite terms).\n",
    "    print('{:d} NaN parallaxes'.format(\n",
    "        np.count_nonzero(np.isnan(d['parallax']))\n",
    "    ))\n",
    "    err_over_plx = d['parallax_err'] / d['parallax']\n",
    "    print('Covariance: DM uncertainty term ...')\n",
    "    cov_y[:,0,0] += (5./np.log(10.) * err_over_plx)**2.\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp['dm'] = np.zeros_like(cov_y)\n",
    "        cov_comp['dm'][:,0,0] = (5./np.log(10.) * err_over_plx)**2.\n",
    "\n",
    "    # Subtract distance modulus from m_G\n",
    "    #dm = -5. * (np.log10(d['parallax']) - 2.)\n",
    "    #dm_corr = 0.5 * err_over_plx**2 + 0.75 * err_over_plx**4\n",
    "    #dm_corr_pct = np.percentile(dm_corr, [1., 5., 10., 50., 90., 95., 99.])\n",
    "    #print(dm_corr_pct)\n",
    "\n",
    "    print('Estimate DM ...')\n",
    "    dm = 10. - 5.*np.log10(d['parallax'])# + 5./np.log(10.)*dm_corr\n",
    "    y[:,0] -= dm\n",
    "\n",
    "    # Don't attempt to predict M_G for poor plx/err or when plx < 0\n",
    "    print('Filter out M_G for poor parallax measurements ...')\n",
    "    idx = (\n",
    "          (err_over_plx > 0.2)\n",
    "        | (d['parallax'] < 1.e-8)\n",
    "        | ~np.isfinite(d['parallax'])\n",
    "        | ~np.isfinite(d['parallax_err'])\n",
    "    )\n",
    "    n_use = idx.size - np.count_nonzero(idx)\n",
    "    print(r'Using {:d} of {:d} ({:.3f}%) of stellar parallaxes.'.format(\n",
    "        n_use, idx.size, n_use/idx.size*100.\n",
    "    ))\n",
    "    cov_y[idx,0,0] = large_err**2\n",
    "    y[idx,0] = np.nanmedian(y[:,0])\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp['dm'][idx,0,0] = large_err**2\n",
    "\n",
    "    # Reddenings\n",
    "    print('Copy reddenings ...')\n",
    "    r = np.empty((d.size,), dtype='f4')\n",
    "    r[:] = d['r'][:]\n",
    "    \n",
    "    if pretrained_model is None:\n",
    "        # If R has not yet been estimated, then\n",
    "        # cut out stars with sigma_r > 0.2 mag.\n",
    "        idx = (d['r_err'] > 0.2)\n",
    "        print(f'Cutting {np.count_nonzero(idx)} stars with large sigma_r.')\n",
    "        for k in range(cov_y.shape[1]):\n",
    "            cov_y[idx,k,k] += large_err**2\n",
    "\n",
    "    if pretrained_model is not None:\n",
    "        # Update reddenings, based on vector R and (y_obs - y_pred).\n",
    "        # Use provided reddenings as a prior.\n",
    "\n",
    "        # First, need to calculate inv_cov_y\n",
    "        print('Invert C_y matrices ...')\n",
    "        inv_cov_y = np.stack([np.linalg.inv(c) for c in cov_y])\n",
    "\n",
    "        # Predict M & R for each star based on atm. params\n",
    "        M_pred = predict_M(pretrained_model, x_p)\n",
    "        R = predict_R(pretrained_model, x_p)\n",
    "        \n",
    "        r_var = d['r_err']**2\n",
    "        \n",
    "        # Calculate posterior on reddening\n",
    "        if recalc_reddening:\n",
    "            print('Calculate posterior on reddening ...')\n",
    "            r_pred, r_var = update_reddenings(\n",
    "                M_pred, R, y,\n",
    "                inv_cov_y,\n",
    "                r, r_var\n",
    "            )\n",
    "            \n",
    "            # Clip mean and variance of reddenings\n",
    "            print('Clip reddenings and reddening variances ...')\n",
    "            r[:] = np.clip(r_pred, 0., 10.) # TODO: Update upper limit?\n",
    "        \n",
    "        # TODO: Different lower bounds on error for different sources?\n",
    "        r_var[:] = np.clip(r_var, 0.02**2 + (0.1*r)**2, 10.**2)\n",
    "        \n",
    "        # Reddening uncertainty term in covariance of y\n",
    "        print('Covariance: reddening uncertainty term ...')\n",
    "        cov_y += r_var[:,None,None] * R[:,:,None]*R[:,None,:]\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['r'] = r_var[:,None,None] * R[:,:,None]*R[:,None,:]\n",
    "        \n",
    "        # Propagate uncertainty in theta to uncertainty in R\n",
    "        print('Calculate J = dA/dtheta ...')\n",
    "        J_A = calc_dext_red_dtheta(pretrained_model, x_p, r)\n",
    "        cov_x = d['atm_param_cov_p']\n",
    "        print('Covariance: J C_theta J^T ...')\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_A)\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_A)\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_M)\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['dA/dtheta'] = np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_A)\n",
    "            cov_comp['dMA/dtheta'] = np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_A)\n",
    "            cov_comp['dAM/dtheta'] = np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_M)\n",
    "        \n",
    "        # Calculate chi^2 for each star\n",
    "        chisq = calc_chisq(M_pred+r[:,None]*R-y, inv_cov_y)\n",
    "        print('chisq =', chisq)\n",
    "\n",
    "        # Calculate d.o.f. of each star\n",
    "        print('Calculate d.o.f. of each star ...')\n",
    "        n_dof = np.zeros(d.size, dtype='i4')\n",
    "        for k in range(n_bands):\n",
    "            n_dof += (cov_y[:,k,k] < (large_err-1.)**2).astype('i4')\n",
    "        #print('n_dof =', n_dof)\n",
    "\n",
    "        # Calculate reduced chi^2 for each star\n",
    "        print('Calculate chi^2/d.o.f. for each star ...')\n",
    "        rchisq = chisq / (n_dof - 1.)\n",
    "        pct = (0., 1., 10., 50., 90., 99., 100.)\n",
    "        rchisq_pct = np.percentile(rchisq[np.isfinite(rchisq)], pct)\n",
    "        print('chi^2/dof percentiles:')\n",
    "        for p,rc in zip(pct,rchisq_pct):\n",
    "            print(rf'  {p:.0f}% : {rc:.3g}')\n",
    "        idx_rchisq = (rchisq < 10.)\n",
    "        print(f'<chi^2/d.o.f.> = {np.mean(rchisq[idx_rchisq]):.3g}')\n",
    "        \n",
    "        # Filter on reduced chi^2\n",
    "        if rchisq_max is not None:\n",
    "            print('Filter on chi^2/d.o.f. ...')\n",
    "            idx = np.isfinite(rchisq) & (rchisq > 0.) & (rchisq < rchisq_max)\n",
    "            n_filt = np.count_nonzero(~idx)\n",
    "            pct_filt = 100. * n_filt / idx.size\n",
    "            print(\n",
    "                rf'Filtering {n_filt:d} stars ({pct_filt:.3g}%) ' +\n",
    "                rf'based on chi^2/dof > {rchisq_max:.1f}'\n",
    "            )\n",
    "            x = x[idx]\n",
    "            x_p = x_p[idx]\n",
    "            r = r[idx]\n",
    "            y = y[idx]\n",
    "            cov_y = cov_y[idx]\n",
    "            r_var = r_var[idx]\n",
    "            rchisq = rchisq[idx]\n",
    "            \n",
    "            if return_cov_components:\n",
    "                for key in cov_comp:\n",
    "                    cov_comp[key] = cov_comp[key][idx]\n",
    "\n",
    "    # Cholesky transform of inverse covariance: L L^T = C^(-1).\n",
    "    print('Cholesky transform of each stellar covariance matrix ...')\n",
    "    LT = np.empty_like(cov_y)\n",
    "    inv_cov_y = np.empty_like(cov_y)\n",
    "    for k,c in enumerate(cov_y):\n",
    "        try:\n",
    "            # Inflate diagonal of cov slightly, to ensure\n",
    "            # positive-definiteness\n",
    "            c_diag = c[np.diag_indices_from(c)]\n",
    "            c[np.diag_indices_from(c)] += 1.e-4 + 1.e-3 * c_diag\n",
    "            \n",
    "            inv_cov_y[k] = np.linalg.inv(c)\n",
    "            LT[k] = np.linalg.cholesky(inv_cov_y[k]).T\n",
    "            #ic = np.linalg.inv(c)\n",
    "            #LT.append(np.linalg.cholesky(ic).T)\n",
    "            #inv_cov_y.append(ic)\n",
    "        except np.linalg.LinAlgError as e:\n",
    "            rho = get_corr_matrix(c)\n",
    "            print('Offending correlation matrix:')\n",
    "            print(np.array2string(\n",
    "                rho[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >7.4f}'.format(z)}\n",
    "            ))\n",
    "            print('Offending covariance matrix:')\n",
    "            print(np.array2string(\n",
    "                c[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >9.6f}'.format(z)}\n",
    "            ))\n",
    "            print('Covariance matrix of (normed) atmospheric parameters:')\n",
    "            print(d['atm_param_cov_p'][k])\n",
    "            if pretrained_model is not None:\n",
    "                print(f'Variance of r: {r_var[k]:.8f}')\n",
    "            \n",
    "            # Inflate errors along the diagonal and try again\n",
    "            c_diag = c[np.diag_indices_from(c)]\n",
    "            c[np.diag_indices_from(c)] += 0.02 + 0.02 * c_diag\n",
    "            rho = get_corr_matrix(c)\n",
    "            print('Inflated correlation matrix:')\n",
    "            print(np.array2string(\n",
    "                rho[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >7.4f}'.format(z)}\n",
    "            ))\n",
    "            \n",
    "            inv_cov_y[k] = np.linalg.inv(c)\n",
    "            LT[k] = np.linalg.cholesky(inv_cov_y[k]).T\n",
    "            #raise e\n",
    "\n",
    "    #print('Stack L^T matrices ...')\n",
    "    #LT = np.stack(LT)\n",
    "    #print('Stack C^(-1) matrices ...')\n",
    "    #inv_cov_y = np.stack(inv_cov_y)\n",
    "\n",
    "    # L^T y\n",
    "    print('Calculate L^T y ...')\n",
    "    LTy = np.einsum('nij,nj->ni', LT, y)\n",
    "\n",
    "    print('Gather inputs and outputs and return ...')\n",
    "    inputs_outputs = {\n",
    "        'x':x, 'x_p':x_p, 'r':r, 'y':y,\n",
    "        'LT':LT, 'LTy':LTy,\n",
    "        'cov_y':cov_y, 'inv_cov_y':inv_cov_y,\n",
    "    }\n",
    "    \n",
    "    if return_cov_components:\n",
    "        inputs_outputs['cov_comp'] = cov_comp\n",
    "    \n",
    "    if pretrained_model is not None:\n",
    "        inputs_outputs['r_var'] = r_var\n",
    "        inputs_outputs['rchisq'] = rchisq\n",
    "\n",
    "    # Check that there are no NaNs or Infs in results\n",
    "    for key in inputs_outputs:\n",
    "        if isinstance(inputs_outputs[key], dict):\n",
    "            continue\n",
    "        if key == 'rchisq': # Infs appear when d.o.f. = 1\n",
    "            continue\n",
    "        if np.any(~np.isfinite(inputs_outputs[key])):\n",
    "            raise ValueError(f'NaNs or Infs detected in {key}.')\n",
    "\n",
    "    return inputs_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caad35d-51ad-4e5f-8e27-57ac56e80468",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Predicts the absolute magnitude in the Gaia G-band and the colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb5329ec-4d17-4a14-9ec3-936b60844ca9",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_M(nn_model, x_p):\n",
    "    \"\"\"\n",
    "    Predicts (absmag0,color1,color2,...) for input\n",
    "    normalized stellar parameters.\n",
    "\n",
    "    Inputs:\n",
    "        nn_model (keras.Model): Neural network model.\n",
    "        x_p (np.ndarray): Normalized stellar parameters.\n",
    "            Shape = (n_stars, 3).\n",
    "    \n",
    "    Outputs:\n",
    "        M (np.ndarray): Shape = (n_stars, n_bands).\n",
    "    \"\"\"\n",
    "    inputs = nn_model.get_layer(name='theta').input\n",
    "    outputs = nn_model.get_layer(name='BM').output\n",
    "    mag_color_model = keras.Model(inputs, outputs)\n",
    "    M = mag_color_model.predict(x_p)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14482c31-4986-4451-b4f7-295c2b3530b0",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Predicting the redenning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b36fc92-d995-4531-a1e4-994b63a9a954",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_R(nn_model, x_p=None):\n",
    "    inputs = nn_model.get_layer(name='theta').input\n",
    "    outputs = nn_model.get_layer(name='R').output\n",
    "    R_model = keras.Model(inputs, outputs)\n",
    "    if x_p is None:\n",
    "        R = R_model.predict(np.array([[0.,0.,0.]]))[0]\n",
    "        R[1:] -= R[0]\n",
    "    else:\n",
    "        R = R_model.predict(x_p)\n",
    "        R[:,1:] -= R[:,0][:,None]\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2cab63-a66c-4c34-a7f1-50cb9568337b",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Saving the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52ee4e30-e866-45c2-a60f-37f5d8996b9f",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_predictions(fname, nn_model, d_test, io_test):\n",
    "    M_pred = predict_M(nn_model, io_test['x_p'])\n",
    "    R_pred = predict_R(nn_model, io_test['x_p'])\n",
    "    R0 = predict_R(nn_model)\n",
    "    \n",
    "    with h5py.File(fname, 'w') as f:\n",
    "        f.create_dataset('/data', data=d_test, chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/y_obs', data=io_test['y'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/cov_y', data=io_test['cov_y'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/r_fit', data=io_test['r'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/M_pred', data=M_pred, chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/R_pred', data=R_pred, chunks=True,\n",
    "                        compression='gzip', compression_opts=3)\n",
    "        f.attrs['R0'] = R0\n",
    "        \n",
    "        if 'cov_comp' in io_test:\n",
    "            for key in io_test['cov_comp']:\n",
    "                f.create_dataset(\n",
    "                    f'/cov_comp/{key.replace(r\"/\",\"_\")}',\n",
    "                    data=io_test['cov_comp'][key],\n",
    "                    chunks=True,\n",
    "                    compression='gzip',\n",
    "                    compression_opts=3\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9dbfb5-0fa8-47b6-b59e-5507d8182916",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Updates the redenning, as in the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12ce532d-8584-46ea-b538-a65837b35597",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_reddenings(M_pred, R, y_obs, inv_cov_y, r0, r_var0):\n",
    "    \"\"\"\n",
    "    Updates the posterior on reddening of each star, given\n",
    "    the predicted absolute magnitudes, reddening vector,\n",
    "    observed magnitudes, inverse covariance matrix, and priors on\n",
    "    reddening.\n",
    "    \n",
    "    The model is given by\n",
    "    \n",
    "        y_obs = M_pred + R r,\n",
    "    \n",
    "    with the uncertainties in y_obs described by inv_cov_y, and\n",
    "    with a prior on r described by (r0, r_var0). We solve for\n",
    "    the Gaussian posterior on r: p(r|y_obs,M_pred,R,r0,r_var0).\n",
    "    \n",
    "    Let n = # of bands, k = # of stars.\n",
    "\n",
    "    Inputs:\n",
    "        M_pred (np.ndarray): Shape-(k,n) array containing predicted\n",
    "            zero-reddening asbolute magnitude & colors for each star.\n",
    "        R (np.ndarray): Shape-(k,n) array containing reddening vector\n",
    "            for each star.\n",
    "        inv_cov_y (np.ndarray): Shape-(k,n,n) array containing\n",
    "            covariance matrix of y_obs-y_pred for each star.\n",
    "        y_obs (np.ndarray): Shape-(k,n) array containing observed\n",
    "            magnitude (minus distance modulus) & colors for each star.\n",
    "        r0 (np.ndarray): Shape-(k,) array containing mean of prior on\n",
    "            reddening for each star.\n",
    "        r_var0 (np.ndarray): Shape-(k,) array containing variance of\n",
    "            prior on reddening for each star.\n",
    "\n",
    "    Outputs:\n",
    "        r_mean (np.ndarray): Shape-(k,) array containing mean posterior\n",
    "            reddening of each star.\n",
    "        r_var (np.ndarray): Shape-(k,) array containing variance of\n",
    "            reddening posterior for each star.\n",
    "    \"\"\"\n",
    "    print('Updating reddenings:')\n",
    "    print('  * R^T C_y^(-1) ...')\n",
    "    RT_Cinv = np.einsum('ni,nij->nj', R, inv_cov_y)\n",
    "    print('  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...')\n",
    "    num = r0/r_var0 + np.einsum('ni,ni->n', RT_Cinv, y_obs - M_pred)\n",
    "    print('  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...')\n",
    "    den = np.einsum('ni,ni->n', RT_Cinv, R) + 1./r_var0\n",
    "    print('  * r_mean, r_var ...')\n",
    "    r_mean = num / den\n",
    "    r_var = 1. / den\n",
    "\n",
    "    return r_mean, r_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d6a72-37ab-4d7a-bfb3-cd329804a9ca",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### calculates the chi^2, as in docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c76cf577-6ee4-41db-a3ea-bada40e97afb",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_chisq(dy, inv_cov_y):\n",
    "    \"\"\"\n",
    "    Returns the chi^2 for each observation, given\n",
    "    an array of residuals and inverse covariance matrices.\n",
    "    \n",
    "        chi^2 = dy^T C^{-1} dy.\n",
    "    \n",
    "    Inputs:\n",
    "        dy (np.ndarray): Residual values. Shape = (n_obs, n_dim),\n",
    "            where n_obs is the number of observations, and n_dim is\n",
    "            the dimensionality of the vector space.\n",
    "        inv_cov_y (np.ndarray): Inverse covariance matrices.\n",
    "            Shape = (n_obs, n_dim, n_dim).\n",
    "    \n",
    "    Returns:\n",
    "        chisq (np.ndarray): Chi^2 for each observation. Shape=(n_obs,).\n",
    "    \"\"\"\n",
    "    C_inv_dy = np.einsum('nij,nj->ni', inv_cov_y, dy)\n",
    "    chisq = np.einsum('ni,ni->n', dy, C_inv_dy)\n",
    "    return chisq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50c262-4e28-419e-83d5-8b75ec32470b",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Creates the architecture of the NN as described in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45204db0-8dfb-448f-879b-11102036d543",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_nn_model(n_hidden_layers=1, hidden_size=32, l1=1.e0, l2=1.e-4, n_bands=13):\n",
    "    # Stellar model: B M(theta)\n",
    "    atm = keras.Input(shape=(3,), name='theta')\n",
    "    x = atm\n",
    "    for i in range(n_hidden_layers):\n",
    "        x = keras.layers.Dense(\n",
    "            hidden_size,\n",
    "            activation='sigmoid',\n",
    "            kernel_regularizer=keras.regularizers.l2(l=l2),\n",
    "            name=f'stellar_model_hidden_{i+1}'\n",
    "        )(x)\n",
    "    mag_color = keras.layers.Dense(n_bands, name='BM')(x)\n",
    "\n",
    "    # Reddening measurement E\n",
    "    red = keras.Input(shape=(1,), name='E')\n",
    "    \n",
    "    # Extinction vector: R(theta)\n",
    "    r = atm\n",
    "    #for i in range(n_hidden_layers):\n",
    "    #    r = keras.layers.Dense(\n",
    "    #        6,\n",
    "    #        use_bias=True,\n",
    "    #        activation='sigmoid',\n",
    "    #        kernel_regularizer=keras.regularizers.l2(l=l2),\n",
    "    #        name=f'extinction_model_hidden_{i+1}'\n",
    "    #    )(r)\n",
    "    ext_vec = keras.layers.Dense(\n",
    "        n_bands,\n",
    "        use_bias=True,\n",
    "        activation='exponential',\n",
    "        #kernel_regularizer=keras.regularizers.l1_l2(l1=1.e0, l2=1.e0),\n",
    "        kernel_regularizer=keras.regularizers.l1(l=l1),\n",
    "        name='R'\n",
    "    )(r)\n",
    "    \n",
    "    # Extinction A = ER\n",
    "    ext = keras.layers.Multiply(name='A')([red, ext_vec])\n",
    "    \n",
    "    # Transform extinction to extinction,reddening using B: BA\n",
    "    B = np.identity(n_bands, dtype='f4')\n",
    "    B[1:,0] = -1.\n",
    "    ext_red = keras.layers.Dense(\n",
    "        n_bands,\n",
    "        use_bias=False,\n",
    "        trainable=False,\n",
    "        weights=[B.T],\n",
    "        name='BA'\n",
    "    )(ext)\n",
    "\n",
    "    # Predicted mag,color, B(M+A)\n",
    "    y = keras.layers.Add(name='B_M_plus_A')([mag_color, ext_red])\n",
    "\n",
    "    # Cholesky decomposition of inverse covariance matrix, L L^T = C^(-1)\n",
    "    LT = keras.Input(shape=(n_bands,n_bands), name='LT')\n",
    "\n",
    "    # Multiply y_pred by L^T, since loss is given by |L^T (y_pred - y_obs)|^2,\n",
    "    # where y_pred = B(M+A), and y_obs = B(m-mu).\n",
    "    LTy = keras.layers.Dot((2,1), name='LT_B_M_plus_A')([LT, y])\n",
    "\n",
    "    # Compile model\n",
    "    model = keras.Model(\n",
    "        inputs=[atm,red,LT],\n",
    "        outputs=LTy,\n",
    "        name='stellar_photometry_model'\n",
    "    )\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer='Adam',\n",
    "        metrics=['mse']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c98052-09ff-4591-830a-446eedd1c701",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### splits the dataset according to a fraction selected by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f096cf60-242d-4eef-8d91-59430a2672dc",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_dataset(frac, *args):\n",
    "    assert len(args) != 0\n",
    "\n",
    "    n_tot = args[0].shape[0]\n",
    "    idx = np.arange(n_tot)\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    n = int(frac * n_tot)\n",
    "    idx_left = idx[:n]\n",
    "    idx_right = idx[n:]\n",
    "\n",
    "    left, right = [], []\n",
    "\n",
    "    for x in args:\n",
    "        left.append(x[idx_left])\n",
    "        right.append(x[idx_right])\n",
    "    \n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a650c5-2ed5-4cfd-bd99-92ff0587e213",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7632b11-b152-4bbf-833b-53c16c38e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "class PlotLearning(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback to plot the learning curves of the model during training.\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.metrics = {}\n",
    "        for metric in logs:\n",
    "            self.metrics[metric] = []\n",
    "            \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Storing metrics\n",
    "        for metric in logs:\n",
    "            if metric in self.metrics:\n",
    "                self.metrics[metric].append(logs.get(metric))\n",
    "            else:\n",
    "                self.metrics[metric] = [logs.get(metric)]\n",
    "        \n",
    "        # Plotting\n",
    "        metrics = [x for x in logs if 'val' not in x]\n",
    "        \n",
    "        f, axs = plt.subplots(1, len(metrics), figsize=(15,5))\n",
    "        # clear_output(wait=True)\n",
    "\n",
    "        for i, metric in enumerate(metrics):\n",
    "            axs[i].plot(range(1, epoch + 2), \n",
    "                        self.metrics[metric], \n",
    "                        label=metric)\n",
    "            if logs['val_' + metric]:\n",
    "                axs[i].plot(range(1, epoch + 2), \n",
    "                            self.metrics['val_' + metric], \n",
    "                            label='val_' + metric)\n",
    "                \n",
    "            axs[i].legend()\n",
    "            axs[i].grid()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d4f6eac-a9dd-4e9d-9d27-f9995997b7a2",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def train_model(nn_model, io_train, k, n_iterations, epochs=100,\n",
    "                checkpoint_fn='checkpoint', batch_size=32,\n",
    "                suff='_'):\n",
    "    checkpoint_fn = (\n",
    "          'checkpoints/'\n",
    "        + checkpoint_fn\n",
    "        + '.e{epoch:03d}_vl{val_loss:.3f}.h5'\n",
    "    )\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_fn,\n",
    "            save_best_only=True,\n",
    "            monitor='val_loss',\n",
    "            verbose=1\n",
    "        )#, PlotLearning()\n",
    "    ]\n",
    "    inputs = [io_train['x_p'], io_train['r'], io_train['LT']]\n",
    "    outputs = io_train['LTy']\n",
    "    nn_model.fit(\n",
    "        inputs, outputs,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.25/0.9,\n",
    "        callbacks=callbacks,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    plt.title('Loss: Iteration {} of {}.'.format(k+1, n_iterations))\n",
    "    plt.plot(range(1,epochs+1),nn_model.history.history['loss'],label='loss')\n",
    "    plt.plot(range(1,epochs+1),nn_model.history.history['val_loss'],label='val_loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig('/arc/home/aydanmckay/networkplots/train_val_loss'+suff+'.svg', dpi=150)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d76b11-59a7-41ca-a531-13411c1a6ce9",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### tests and makes sure the loss is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7eb14a0f-a62d-4d46-ab6d-4b33476566da",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(nn_model, io_eval, batch_size=32, rchisq_max=None):\n",
    "    \"\"\"\n",
    "    Runs the model on the given inputs and outputs, and returns the\n",
    "    MSE and loss.\n",
    "    \n",
    "    Inputs:\n",
    "        nn_model (keras.Model): The neural network model.\n",
    "        io_eval (dict): A dictionary containing, among other things,\n",
    "            x_p, r, LT and LTy. If rchisq_max is provided, then the\n",
    "            dictionary must also contain rchisq.\n",
    "        batch_size (int): Defaults to 32.\n",
    "        rchisq_max (float): Stars with greater than this reduced chi^2\n",
    "            will not be included in the calculation. Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "        A list containing the MSE and loss.\n",
    "    \"\"\"\n",
    "    inputs = [io_eval['x_p'], io_eval['r'], io_eval['LT']]\n",
    "    outputs = io_eval['LTy']\n",
    "    \n",
    "    if rchisq_max is not None:\n",
    "        idx = (io_eval['rchisq'] < rchisq_max)\n",
    "        inputs = [x[idx] for x in inputs]\n",
    "        outputs = outputs[idx]\n",
    "    \n",
    "    loss = nn_model.evaluate(\n",
    "        inputs,\n",
    "        outputs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    loss = [float(x) for x in loss] # Make JSON serializable\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd030e3e-55e6-419d-9a07-ce0a6baeb62c",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### plots? follow up here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d65e396c-7677-41d8-b229-8c3b2377a7b6",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def diagnostic_plots(nn_model, io_test, d_test, suffix=None):\n",
    "    if suffix is None:\n",
    "        suff = ''\n",
    "    else:\n",
    "        suff = '_' + suffix\n",
    "    \n",
    "    inputs = [\n",
    "        nn_model.get_layer(name='theta').input,\n",
    "        nn_model.get_layer(name='E').input\n",
    "    ]\n",
    "    outputs = nn_model.get_layer(name='B_M_plus_A').output\n",
    "    absmag_model = keras.Model(inputs, outputs)\n",
    "\n",
    "    # Predict y for the test dataset\n",
    "    test_pred = {\n",
    "        'y': absmag_model.predict([\n",
    "            io_test['x_p'],\n",
    "            io_test['r']\n",
    "        ]),\n",
    "        'y_dered': absmag_model.predict([\n",
    "            io_test['x_p'],\n",
    "            np.zeros_like(io_test['r'])\n",
    "        ])\n",
    "    }\n",
    "    test_pred['y_resid'] = io_test['y'] - test_pred['y']\n",
    "\n",
    "    # Get the extinction vector\n",
    "    R = predict_R(nn_model)\n",
    "    R[1:] += R[0]\n",
    "    print(\n",
    "          'R(<theta>) = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,R)))\n",
    "        + ']'\n",
    "    )\n",
    "    R_all = predict_R(nn_model, io_test['x_p'])\n",
    "    R_all[:,1:] += R_all[:,0][:,None]\n",
    "    print(\n",
    "          '<R> = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,np.median(R_all,axis=0))))\n",
    "        + ']'\n",
    "    )\n",
    "    print(\n",
    "          's_R = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,np.std(R_all,axis=0))))\n",
    "        + ']'\n",
    "    )\n",
    "\n",
    "    # Read out colors, magnitudes\n",
    "    g = io_test['y'][:,3] + io_test['y'][:,0]\n",
    "    ri = io_test['y'][:,4] - io_test['y'][:,5]\n",
    "    gr = io_test['y'][:,3] - io_test['y'][:,4]\n",
    "    g_pred = test_pred['y'][:,3] + test_pred['y'][:,0]\n",
    "    ri_pred = test_pred['y'][:,4] - test_pred['y'][:,5]\n",
    "    gr_pred = test_pred['y'][:,3] - test_pred['y'][:,4]\n",
    "    g_pred_dered = test_pred['y_dered'][:,3] + test_pred['y_dered'][:,0]\n",
    "    ri_pred_dered = test_pred['y_dered'][:,4] - test_pred['y_dered'][:,5]\n",
    "    gr_pred_dered = test_pred['y_dered'][:,3] - test_pred['y_dered'][:,4]\n",
    "    A_g = 0.25 * R[3]\n",
    "    E_ri = 0.25 * (R[4] - R[5])\n",
    "    E_gr = 0.25 * (R[3] - R[4])\n",
    "\n",
    "    gaia_g = io_test['y'][:,0]\n",
    "    bp_rp = io_test['y'][:,1] - io_test['y'][:,2]\n",
    "    gaia_g_pred = test_pred['y'][:,0]\n",
    "    bp_rp_pred = test_pred['y'][:,1] - test_pred['y'][:,2]\n",
    "    gaia_g_pred_dered = test_pred['y_dered'][:,0]\n",
    "    gaia_bp_rp_pred_dered = test_pred['y_dered'][:,1] - test_pred['y_dered'][:,2]\n",
    "    A_gaia_g = 0.25 * R[0]\n",
    "    E_bp_rp = 0.25 * (R[1] - R[2])\n",
    "\n",
    "    print('g =', g)\n",
    "    print('ri =', ri)\n",
    "    print('gr =', gr)\n",
    "    print('gaia_g =', gaia_g)\n",
    "    print('bp_rp =', bp_rp)\n",
    "\n",
    "    # Plot HRD\n",
    "    params = {\n",
    "        'density': (None, r'$N$', (None, None)),\n",
    "        'teff': (d_test['atm_param'][:,0], r'$T_{\\mathrm{eff}}$', (4000., 8000.)),\n",
    "        'logg': (d_test['atm_param'][:,1], r'$\\log \\left( g \\right)$', (0., 5.)),\n",
    "        'mh': (d_test['atm_param'][:,2], r'$\\left[ \\mathrm{M} / \\mathrm{H} \\right]$', (-2.5, 0.5))\n",
    "    }\n",
    "\n",
    "    plot_spec = [\n",
    "        {\n",
    "            'colors': [(1,2), (4,5)],\n",
    "            'mag': 0\n",
    "        },\n",
    "        {\n",
    "            'colors': [(3,4), (4,5)],\n",
    "            'mag': 0\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    idx_goodobs = np.isfinite(d_test['mag_err'])\n",
    "    idx_goodobs &= (np.abs(io_test['cov_y'][:,0,0]) < 90.)[:,None]\n",
    "    idx_goodobs = idx_goodobs.T\n",
    "\n",
    "    def scatter_or_hexbin(ax, x, y, c, vmin, vmax, extent):\n",
    "        if p == 'density':\n",
    "            im = ax.hexbin(\n",
    "                x, y,\n",
    "                extent=extent,\n",
    "                bins='log',\n",
    "                rasterized=True\n",
    "            )\n",
    "        else:\n",
    "            im = ax.scatter(\n",
    "                x,\n",
    "                y,\n",
    "                c=c,\n",
    "                edgecolors='none',\n",
    "                alpha=0.1,\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "                rasterized=True\n",
    "            )\n",
    "        return im\n",
    "\n",
    "    def get_lim(*args, **kwargs):\n",
    "        expand = kwargs.get('expand', 0.4)\n",
    "        expand_low = kwargs.get('expand_low', expand)\n",
    "        expand_high = kwargs.get('expand_high', expand)\n",
    "        pct = kwargs.get('pct', 1.)\n",
    "        lim = [np.inf, -np.inf]\n",
    "        for a in args:\n",
    "            a0,a1 = np.nanpercentile(a, [pct, 100.-pct])\n",
    "            lim[0] = min(a0, lim[0])\n",
    "            lim[1] = max(a1, lim[1])\n",
    "        w = lim[1] - lim[0]\n",
    "        lim[0] -= expand_low * w\n",
    "        lim[1] += expand_high * w\n",
    "        return lim\n",
    "\n",
    "    labels = ['G', 'BP', 'RP', 'g', 'r', 'i', 'z', 'y']\n",
    "\n",
    "    for ps in plot_spec:\n",
    "        mag_label = r'$M_{{ {} }}$'.format(labels[ps['mag']])\n",
    "        mag_obs = io_test['y'][:,ps['mag']]\n",
    "        mag_pred = test_pred['y'][:,ps['mag']]\n",
    "        mag_pred_dered = test_pred['y_dered'][:,ps['mag']]\n",
    "        A_vec = 0.25 * R[ps['mag']]\n",
    "        print('mag_pred:',mag_pred)\n",
    "\n",
    "        if ps['mag'] != 0:\n",
    "            mag_obs += io_test['y'][:,0]\n",
    "            mag_pred += io_test['y'][:,0]\n",
    "            mag_pred_dered += io_test['y'][:,0]\n",
    "            A_vec += 0.25 * R[0]\n",
    "\n",
    "        color_labels = []\n",
    "        colors_obs = []\n",
    "        colors_pred = []\n",
    "        colors_pred_dered = []\n",
    "        idx_colors_obs = []\n",
    "        E_vec = []\n",
    "        for i1,i2 in ps['colors']:\n",
    "            color_labels.append(r'${} - {}$'.format(labels[i1], labels[i2]))\n",
    "            colors_obs.append(io_test['y'][:,i1] - io_test['y'][:,i2])\n",
    "            colors_pred.append(test_pred['y'][:,i1] - test_pred['y'][:,i2])\n",
    "            colors_pred_dered.append(\n",
    "                test_pred['y_dered'][:,i1] - test_pred['y_dered'][:,i2]\n",
    "            )\n",
    "            idx_colors_obs.append(idx_goodobs[i1] & idx_goodobs[i2])\n",
    "            E_vec.append(0.25 * (R[i1] - R[i2]))\n",
    "\n",
    "        mag_lim = get_lim(\n",
    "            mag_obs[idx_goodobs[ps['mag']]],\n",
    "            pct=2.\n",
    "        )[::-1]\n",
    "        color_lim = [\n",
    "            get_lim(c[idx_colors_obs[k]], expand_low=0.5, expand_high=0.4)\n",
    "            for k,c in enumerate(colors_obs)\n",
    "        ]\n",
    "        \n",
    "        for p in params.keys():\n",
    "            c, label, (vmin,vmax) = params[p]\n",
    "            \n",
    "            fig = plt.figure(figsize=(14,4.5), dpi=150)\n",
    "            fig.patch.set_alpha(0.)\n",
    "            gs = GridSpec(\n",
    "                1,4,\n",
    "                width_ratios=[1,1,1,0.1],\n",
    "                left=0.07, right=0.93,\n",
    "                bottom=0.10, top=0.92\n",
    "            )\n",
    "            ax_obs = fig.add_subplot(gs[0,0], facecolor='gray')\n",
    "            ax_pred = fig.add_subplot(gs[0,1], facecolor='gray')\n",
    "            ax_dered = fig.add_subplot(gs[0,2], facecolor='gray')\n",
    "            cax = fig.add_subplot(gs[0,3], facecolor='w')\n",
    "\n",
    "            extent = color_lim[0] + mag_lim\n",
    "\n",
    "            idx = (\n",
    "                  idx_goodobs[ps['mag']]\n",
    "                & idx_goodobs[ps['colors'][0][0]]\n",
    "                & idx_goodobs[ps['colors'][0][1]]\n",
    "            )\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_obs,\n",
    "                colors_obs[0][idx],\n",
    "                mag_obs[idx],\n",
    "                c if c is None else c[idx],\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "                #(-0.3,1.0,11.5,-2.0)\n",
    "            )\n",
    "\n",
    "            ax_obs.set_xlim(color_lim[0])\n",
    "            ax_obs.set_ylim(mag_lim)\n",
    "            ax_obs.set_xlabel(color_labels[0])\n",
    "            ax_obs.set_ylabel(mag_label)\n",
    "            ax_obs.grid('on', alpha=0.3)\n",
    "            ax_obs.set_title(r'$\\mathrm{Observed}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_pred,\n",
    "                colors_pred[0],\n",
    "                mag_pred,\n",
    "                c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "\n",
    "            ax_pred.set_xlim(color_lim[0])\n",
    "            ax_pred.set_ylim(mag_lim)\n",
    "            ax_pred.set_xlabel(color_labels[0])\n",
    "            ax_pred.grid('on', alpha=0.3)\n",
    "            ax_pred.set_title(r'$\\mathrm{Predicted}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_dered,\n",
    "                colors_pred_dered[0],\n",
    "                mag_pred_dered,\n",
    "                c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "\n",
    "            ax_dered.set_xlim(color_lim[0])\n",
    "            ax_dered.set_ylim(mag_lim)\n",
    "            ax_dered.set_xlabel(color_labels[0])\n",
    "            ax_dered.grid('on', alpha=0.3)\n",
    "            ax_dered.set_title(r'$\\mathrm{Predicted+Dereddened}$')\n",
    "\n",
    "            ax_dered.annotate(\n",
    "                '',\n",
    "                xy=(0.35+E_vec[0], 1.+A_vec),\n",
    "                xytext=(0.35, 1.),\n",
    "                arrowprops=dict(color='r', width=1., headwidth=5., headlength=5.)\n",
    "            )\n",
    "\n",
    "            cb = fig.colorbar(im, cax=cax)\n",
    "            cb.set_label(label)\n",
    "            cb.set_alpha(1.)\n",
    "            cb.draw_all()\n",
    "\n",
    "            cm_desc = '{}_vs_{}{}'.format(\n",
    "                labels[ps['mag']],\n",
    "                labels[ps['colors'][0][0]],\n",
    "                labels[ps['colors'][0][1]]\n",
    "            )\n",
    "            fig.savefig(\n",
    "                '/arc/home/aydanmckay/networkplots/nn_predictions_'+cm_desc+'_'+p+suff+'.svg',\n",
    "                dpi=150,\n",
    "                facecolor=fig.get_facecolor(),\n",
    "                edgecolor='none'\n",
    "            )\n",
    "            plt.close(fig)\n",
    "\n",
    "            # Color-color diagrams\n",
    "            fig = plt.figure(figsize=(14,4.5), dpi=150)\n",
    "            fig.patch.set_alpha(0.)\n",
    "            gs = GridSpec(\n",
    "                1,4,\n",
    "                width_ratios=[1,1,1,0.1],\n",
    "                left=0.07, right=0.93,\n",
    "                bottom=0.10, top=0.92\n",
    "            )\n",
    "            ax_obs = fig.add_subplot(gs[0,0], facecolor='gray')\n",
    "            ax_pred = fig.add_subplot(gs[0,1], facecolor='gray')\n",
    "            ax_dered = fig.add_subplot(gs[0,2], facecolor='gray')\n",
    "            cax = fig.add_subplot(gs[0,3], facecolor='w')\n",
    "\n",
    "            extent = color_lim[0] + color_lim[1]\n",
    "\n",
    "            idx = (\n",
    "                  idx_goodobs[ps['colors'][0][0]]\n",
    "                & idx_goodobs[ps['colors'][0][1]]\n",
    "                & idx_goodobs[ps['colors'][1][0]]\n",
    "                & idx_goodobs[ps['colors'][1][1]]\n",
    "            )\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_obs,\n",
    "                colors_obs[0][idx],\n",
    "                colors_obs[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "                #(-0.2,1.5,-0.15,0.8)\n",
    "            )\n",
    "            ax_obs.set_xlim(color_lim[0])\n",
    "            ax_obs.set_ylim(color_lim[1])\n",
    "            ax_obs.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_obs.set_ylabel(color_labels[1], fontsize=14)\n",
    "            ax_obs.grid('on', alpha=0.3)\n",
    "            ax_obs.set_title(r'$\\mathrm{Observed}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_pred,\n",
    "                colors_pred[0][idx],\n",
    "                colors_pred[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                #c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "            ax_pred.set_xlim(color_lim[0])\n",
    "            ax_pred.set_ylim(color_lim[1])\n",
    "            ax_pred.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_pred.grid('on', alpha=0.3)\n",
    "            ax_pred.set_title(r'$\\mathrm{Predicted}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_dered,\n",
    "                colors_pred_dered[0][idx],\n",
    "                colors_pred_dered[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                #c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "            ax_dered.set_xlim(color_lim[0])\n",
    "            ax_dered.set_ylim(color_lim[1])\n",
    "            ax_dered.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_dered.grid('on', alpha=0.3)\n",
    "            ax_dered.set_title(r'$\\mathrm{Predicted+Dereddened}$')\n",
    "\n",
    "            ax_dered.annotate(\n",
    "                '',\n",
    "                xy=(0.4+E_vec[0], 0.3+E_vec[1]),\n",
    "                xytext=(0.4, 0.3),\n",
    "                arrowprops=dict(color='r', width=1., headwidth=5., headlength=5.)\n",
    "            )\n",
    "\n",
    "            cb = fig.colorbar(im, cax=cax)\n",
    "            cb.set_label(label, fontsize=14)\n",
    "            cb.set_alpha(1.)\n",
    "            cb.draw_all()\n",
    "\n",
    "            cc_desc = '{}{}_vs_{}{}'.format(\n",
    "                labels[ps['colors'][0][0]],\n",
    "                labels[ps['colors'][0][1]],\n",
    "                labels[ps['colors'][1][0]],\n",
    "                labels[ps['colors'][1][1]]\n",
    "            )\n",
    "            fig.savefig(\n",
    "                '/arc/home/aydanmckay/networkplots/test_'+cc_desc+'_'+p+suff+'.svg',\n",
    "                dpi=150,\n",
    "                facecolor=fig.get_facecolor(),\n",
    "                edgecolor='none'\n",
    "            )\n",
    "            plt.close(fig)\n",
    "    \n",
    "    # Plot histograms of residuals\n",
    "    dr = (io_test['r'] - d_test['r'])/np.hypot(np.nanstd(d_test['r']),.01)\n",
    "    # dmag = (io_test['LTy'] - d_test['mag'])\n",
    "    # dm1,dm2,dm3,dm4,dm5,dm6,dm7,dm8,dm9,dm10,dm11,dm12,dm13 = dmag.T\n",
    "    names = ['G','(BP-G)','(RP-G)','(g-G)','(r-G)','(i-G)','(z-G)','(y-G)','(J-G)','(H-G)','(K_s-G)','(W_1-G)','(W_2-G)']\n",
    "    # ds = [dm1,dm2,dm3,dm4,dm5,dm6,dm7,dm8,dm9,dm10,dm11,dm12,dm13]\n",
    "    fig = plt.figure(figsize=(12,18))\n",
    "    ax = fig.add_subplot(5,3,1)\n",
    "    dr_mean = np.nanmean(dr)\n",
    "    dr_std = np.nanstd(dr)\n",
    "    ax.hist(dr, bins=50)\n",
    "    dr_skew = scipy.stats.moment(dr, moment=3, nan_policy='omit')\n",
    "    dr_txt = r'$\\Delta E = {:+.3f} \\pm {:.3f}$'.format(dr_mean, dr_std)\n",
    "    dr_skew /= (dr_std**1.5 + 1.e-5)\n",
    "    dr_txt += '\\n' + r'$\\tilde{{\\mu}}_3 = {:+.3f}$'.format(dr_skew)\n",
    "    ax.text(0.05, 0.95, dr_txt, ha='left', va='top', transform=ax.transAxes)\n",
    "    ax.set_xlabel(r'$\\Delta E \\ \\left( \\mathrm{estimated} - \\mathrm{Bayestar19} \\right)$',fontsize=10)\n",
    "    for it,(io,dm,name) in enumerate(zip(io_test['LTy'].T,d_test['mag'].T,names)):\n",
    "        dd = (io - dm)/np.hypot(np.nanstd(dm),.01)\n",
    "        ax = fig.add_subplot(5,3,it+2)\n",
    "        dd_mean = np.nanmean(dd)\n",
    "        dd_std = np.nanstd(dd)\n",
    "        ax.hist(dd, bins=50)\n",
    "        dd_skew = scipy.stats.moment(dd, moment=3, nan_policy='omit')\n",
    "        dd_txt = r'$\\Delta '+name+r' = {:+.3f} \\pm {:.3f}$'.format(dd_mean, dd_std)\n",
    "        dd_skew /= (dd_std**1.5 + 1.e-5)\n",
    "        dd_txt += '\\n' + r'$\\tilde{{\\mu}}_3 = {:+.3f}$'.format(dd_skew)\n",
    "        ax.text(0.05, 0.95, dd_txt, ha='left', va='top', transform=ax.transAxes)\n",
    "        ax.set_xlabel(r'$\\Delta '+name+r'\\ \\left( \\mathrm{estimated} - \\mathrm{observed} \\right)$',fontsize=10)\n",
    "    fig.savefig('/arc/home/aydanmckay/networkplots/test_z-score_dE'+suff+'.svg', dpi=150)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc50d23-d49f-4732-87e4-a7e1ec8fc816",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "source": [
    "##### Calculates the derivative of the stellar model portion for gradient descent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8c296da-d523-4953-87b3-738be2e038fe",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_dmag_color_dtheta(nn_model, x_p):\n",
    "    m = keras.Model(\n",
    "        inputs=nn_model.get_layer(name='theta').input,\n",
    "        outputs=nn_model.get_layer(name='BM').output\n",
    "    )\n",
    "    with tf.GradientTape() as g:\n",
    "        x_p = tf.constant(x_p)\n",
    "        g.watch(x_p)\n",
    "        mag_color = m(x_p)\n",
    "    J = g.batch_jacobian(mag_color, x_p).numpy()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb05c4c2-5d82-4311-b6f2-b46532797a41",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Calculates the derivative of the extinction model portion for gradient descent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2af63500-d06a-4ba6-bcc1-5fd5c3df6247",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_dext_red_dtheta(nn_model, x_p, r):\n",
    "    A_model = keras.Model(\n",
    "        inputs=[\n",
    "            nn_model.get_layer(name='theta').input,\n",
    "            nn_model.get_layer(name='E').input\n",
    "        ],\n",
    "        outputs=nn_model.get_layer(name='BA').output\n",
    "    )\n",
    "    r = tf.constant(np.reshape(r, (r.size,1)))\n",
    "    #r = tf.reshape(r, (tf.size(r), 1))\n",
    "    with tf.GradientTape() as g:\n",
    "        x_p = tf.constant(x_p)\n",
    "        g.watch(x_p)\n",
    "        A = A_model([x_p, r])\n",
    "    J = g.batch_jacobian(A, x_p).numpy()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fb7f2c-5df5-4b99-aae0-39035aa43797",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Saves the normalizations, which seen in the tutorial is useful for scaling and shifting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86cef280-6cca-48f4-93ce-a8f4b7336300",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_theta_norm(d_attrs, fname):\n",
    "    d = {\n",
    "        'theta_med': d_attrs['atm_param_med'].tolist(),\n",
    "        'theta_std': d_attrs['atm_param_std'].tolist()\n",
    "    }\n",
    "    with open(fname, 'w') as f:\n",
    "        json.dump(d, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab8ecb-d1c9-438d-8794-1ff0b7eceef3",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### start of main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b834ddb7-6836-4e26-b7d7-81ce6cf146fd",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"stellar_photometry_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " theta (InputLayer)             [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " stellar_model_hidden_1 (Dense)  (None, 32)          128         ['theta[0][0]']                  \n",
      "                                                                                                  \n",
      " E (InputLayer)                 [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " R (Dense)                      (None, 13)           52          ['theta[0][0]']                  \n",
      "                                                                                                  \n",
      " stellar_model_hidden_2 (Dense)  (None, 32)          1056        ['stellar_model_hidden_1[0][0]'] \n",
      "                                                                                                  \n",
      " A (Multiply)                   (None, 13)           0           ['E[0][0]',                      \n",
      "                                                                  'R[0][0]']                      \n",
      "                                                                                                  \n",
      " BM (Dense)                     (None, 13)           429         ['stellar_model_hidden_2[0][0]'] \n",
      "                                                                                                  \n",
      " BA (Dense)                     (None, 13)           169         ['A[0][0]']                      \n",
      "                                                                                                  \n",
      " LT (InputLayer)                [(None, 13, 13)]     0           []                               \n",
      "                                                                                                  \n",
      " B_M_plus_A (Add)               (None, 13)           0           ['BM[0][0]',                     \n",
      "                                                                  'BA[0][0]']                     \n",
      "                                                                                                  \n",
      " LT_B_M_plus_A (Dot)            (None, 13)           0           ['LT[0][0]',                     \n",
      "                                                                  'B_M_plus_A[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,834\n",
      "Trainable params: 1,665\n",
      "Non-trainable params: 169\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load/create neural network\n",
    "nn_name = 'ext_3h_l1n2'\n",
    "n_hidden = 2\n",
    "nn_model = get_nn_model(n_hidden_layers=n_hidden, l2=1.e-4, l1=1.e-2)\n",
    "#nn_model = keras.models.load_model(\n",
    "#    'models/{:s}_{:d}hidden_it14.h5'.format(nn_name, n_hidden)\n",
    "#)\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07e4514b-44a8-4a5c-8512-e7feaa15e94e",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Loading /arc/home/aydanmckay/ml/network/datav3.h5 ...\n"
     ]
    }
   ],
   "source": [
    "# Load stellar data\n",
    "print('Loading data ...')\n",
    "fname = '/arc/home/aydanmckay/ml/network/datav3.h5'\n",
    "d, d_attrs = load_data(fname, return_attrs=True)\n",
    "#d = d[::25]\n",
    "save_theta_norm(d_attrs, '3_theta_normalization.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d54baa9f-60d9-4fc0-acb7-e4c49cd83a66",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    184212 training/validation stars.\n",
      "     20468 test stars.\n"
     ]
    }
   ],
   "source": [
    "# (training+validation) / test split\n",
    "# Fix random seed (same split every run)\n",
    "np.random.seed(7)\n",
    "(d_train,), (d_test,) = split_dataset(0.9, d)\n",
    "np.random.shuffle(d_train) # Want d_train to be in random order\n",
    "print(f'{d_train.size: >10d} training/validation stars.')\n",
    "print(f'{d_test.size: >10d} test stars.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa8b04a6-3b93-4b72-9d3f-8855c3111e8c",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi^2/dof = [None, 100.00000000000004, 79.41833348134496, 63.07271692954115, 50.09130066684769, 39.78167620874025, 31.593944275926187, 25.091384024965357, 19.927159040031896, 15.825817619770502, 12.56860061341878, 9.981773149103292, 7.927357886906197, 6.295775522882865, 4.999999999999999, 5.0, 5.0, 5.0, 5.0, 5.0]\n"
     ]
    }
   ],
   "source": [
    "# Iteratively update dM/dtheta contribution to uncertainties,\n",
    "# reddening estimates and reduced chi^2 cut, and retrain.\n",
    "n_iterations = 20\n",
    "\n",
    "# On GPU, use large batch sizes for memory transfer efficiency\n",
    "batch_size = 1024\n",
    "\n",
    "rchisq_max_init = 100.\n",
    "rchisq_max_final = 5.\n",
    "rchisq_max = np.exp(np.linspace(\n",
    "    np.log(rchisq_max_init),\n",
    "    np.log(rchisq_max_final),\n",
    "    n_iterations-6\n",
    "))\n",
    "rchisq_max = [None] + rchisq_max.tolist() + 5*[rchisq_max_final]\n",
    "print('chi^2/dof = {}'.format(rchisq_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b3ee798-6cee-458d-b5e3-e6f014c0c873",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 184212 bad. Replacing with 14.76259.\n",
      "Band 1: 5 of 184212 bad. Replacing with 15.16047.\n",
      "Band 2: 5 of 184212 bad. Replacing with 14.19215.\n",
      "Band 3: 112 of 184212 bad. Replacing with 15.23910.\n",
      "Band 4: 216 of 184212 bad. Replacing with 14.74930.\n",
      "Band 5: 7889 of 184212 bad. Replacing with 14.61470.\n",
      "Band 6: 253 of 184212 bad. Replacing with 14.49600.\n",
      "Band 7: 69 of 184212 bad. Replacing with 14.44160.\n",
      "Band 8: 371 of 184212 bad. Replacing with 13.53800.\n",
      "Band 9: 380 of 184212 bad. Replacing with 13.15900.\n",
      "Band 10: 1544 of 184212 bad. Replacing with 13.07700.\n",
      "Band 11: 201 of 184212 bad. Replacing with 15.74240.\n",
      "Band 12: 223 of 184212 bad. Replacing with 16.41514.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 184209 of 184212 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Cutting 0 stars with large sigma_r.\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20468 bad. Replacing with 14.76698.\n",
      "Band 1: 0 of 20468 bad. Replacing with 15.16434.\n",
      "Band 2: 0 of 20468 bad. Replacing with 14.19739.\n",
      "Band 3: 13 of 20468 bad. Replacing with 15.24670.\n",
      "Band 4: 30 of 20468 bad. Replacing with 14.75285.\n",
      "Band 5: 918 of 20468 bad. Replacing with 14.62265.\n",
      "Band 6: 24 of 20468 bad. Replacing with 14.49655.\n",
      "Band 7: 10 of 20468 bad. Replacing with 14.44405.\n",
      "Band 8: 39 of 20468 bad. Replacing with 13.54000.\n",
      "Band 9: 42 of 20468 bad. Replacing with 13.15900.\n",
      "Band 10: 174 of 20468 bad. Replacing with 13.08100.\n",
      "Band 11: 19 of 20468 bad. Replacing with 15.74144.\n",
      "Band 12: 20 of 20468 bad. Replacing with 16.41437.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20468 of 20468 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Cutting 0 stars with large sigma_r.\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 27.56 s\n",
      "learning rate = 0.0010000000474974513\n",
      "setting learning rate to 0.001\n",
      "Iteration 1 of 20.\n",
      "Epoch 1/25\n",
      "128/130 [============================>.] - ETA: 0s - loss: 1195.8171 - mse: 1195.7164\n",
      "Epoch 1: val_loss improved from inf to 487.04163, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e001_vl487.042.h5\n",
      "130/130 [==============================] - 2s 8ms/step - loss: 1191.2354 - mse: 1191.1348 - val_loss: 487.0416 - val_mse: 486.9438\n",
      "Epoch 2/25\n",
      "125/130 [===========================>..] - ETA: 0s - loss: 315.6925 - mse: 315.5959\n",
      "Epoch 2: val_loss improved from 487.04163 to 237.69569, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e002_vl237.696.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 308.2947 - mse: 308.1981 - val_loss: 237.6957 - val_mse: 237.6001\n",
      "Epoch 3/25\n",
      "125/130 [===========================>..] - ETA: 0s - loss: 191.1635 - mse: 191.0684\n",
      "Epoch 3: val_loss improved from 237.69569 to 171.15288, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e003_vl171.153.h5\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 187.7133 - mse: 187.6183 - val_loss: 171.1529 - val_mse: 171.0585\n",
      "Epoch 4/25\n",
      "122/130 [===========================>..] - ETA: 0s - loss: 146.6090 - mse: 146.5149\n",
      "Epoch 4: val_loss improved from 171.15288 to 130.46178, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e004_vl130.462.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 142.4873 - mse: 142.3933 - val_loss: 130.4618 - val_mse: 130.3678\n",
      "Epoch 5/25\n",
      "120/130 [==========================>...] - ETA: 0s - loss: 112.8287 - mse: 112.7350\n",
      "Epoch 5: val_loss improved from 130.46178 to 100.65996, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e005_vl100.660.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 110.0889 - mse: 109.9952 - val_loss: 100.6600 - val_mse: 100.5673\n",
      "Epoch 6/25\n",
      "121/130 [==========================>...] - ETA: 0s - loss: 89.6679 - mse: 89.5755\n",
      "Epoch 6: val_loss improved from 100.65996 to 81.21442, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e006_vl81.214.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 87.0345 - mse: 86.9422 - val_loss: 81.2144 - val_mse: 81.1225\n",
      "Epoch 7/25\n",
      "129/130 [============================>.] - ETA: 0s - loss: 72.0317 - mse: 71.9402\n",
      "Epoch 7: val_loss improved from 81.21442 to 67.88497, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e007_vl67.885.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 71.7885 - mse: 71.6970 - val_loss: 67.8850 - val_mse: 67.7939\n",
      "Epoch 8/25\n",
      "120/130 [==========================>...] - ETA: 0s - loss: 63.0542 - mse: 62.9634\n",
      "Epoch 8: val_loss improved from 67.88497 to 58.21709, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e008_vl58.217.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 61.2249 - mse: 61.1340 - val_loss: 58.2171 - val_mse: 58.1267\n",
      "Epoch 9/25\n",
      "127/130 [============================>.] - ETA: 0s - loss: 53.9941 - mse: 53.9039\n",
      "Epoch 9: val_loss improved from 58.21709 to 51.33144, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e009_vl51.331.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 53.5020 - mse: 53.4118 - val_loss: 51.3314 - val_mse: 51.2417\n",
      "Epoch 10/25\n",
      "122/130 [===========================>..] - ETA: 0s - loss: 46.0056 - mse: 45.9161\n",
      "Epoch 10: val_loss improved from 51.33144 to 46.48182, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e010_vl46.482.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 47.7912 - mse: 47.7018 - val_loss: 46.4818 - val_mse: 46.3926\n",
      "Epoch 11/25\n",
      "126/130 [============================>.] - ETA: 0s - loss: 43.8384 - mse: 43.7494\n",
      "Epoch 11: val_loss improved from 46.48182 to 42.12077, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e011_vl42.121.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 43.3507 - mse: 43.2617 - val_loss: 42.1208 - val_mse: 42.0320\n",
      "Epoch 12/25\n",
      "126/130 [============================>.] - ETA: 0s - loss: 40.1181 - mse: 40.0297\n",
      "Epoch 12: val_loss improved from 42.12077 to 39.00082, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e012_vl39.001.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 39.7588 - mse: 39.6704 - val_loss: 39.0008 - val_mse: 38.9127\n",
      "Epoch 13/25\n",
      "122/130 [===========================>..] - ETA: 0s - loss: 37.4762 - mse: 37.3884\n",
      "Epoch 13: val_loss improved from 39.00082 to 36.22574, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e013_vl36.226.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 36.9453 - mse: 36.8575 - val_loss: 36.2257 - val_mse: 36.1382\n",
      "Epoch 14/25\n",
      "128/130 [============================>.] - ETA: 0s - loss: 34.5938 - mse: 34.5067\n",
      "Epoch 14: val_loss improved from 36.22574 to 34.02395, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e014_vl34.024.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 34.4900 - mse: 34.4029 - val_loss: 34.0240 - val_mse: 33.9372\n",
      "Epoch 15/25\n",
      "124/130 [===========================>..] - ETA: 0s - loss: 32.7755 - mse: 32.6891\n",
      "Epoch 15: val_loss improved from 34.02395 to 32.10887, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e015_vl32.109.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 32.5559 - mse: 32.4695 - val_loss: 32.1089 - val_mse: 32.0228\n",
      "Epoch 16/25\n",
      "128/130 [============================>.] - ETA: 0s - loss: 30.7187 - mse: 30.6331\n",
      "Epoch 16: val_loss improved from 32.10887 to 30.28960, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e016_vl30.290.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 30.9353 - mse: 30.8497 - val_loss: 30.2896 - val_mse: 30.2044\n",
      "Epoch 17/25\n",
      "120/130 [==========================>...] - ETA: 0s - loss: 29.8615 - mse: 29.7764\n",
      "Epoch 17: val_loss improved from 30.28960 to 28.86178, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e017_vl28.862.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 29.5648 - mse: 29.4797 - val_loss: 28.8618 - val_mse: 28.7770\n",
      "Epoch 18/25\n",
      "121/130 [==========================>...] - ETA: 0s - loss: 28.0833 - mse: 27.9989\n",
      "Epoch 18: val_loss improved from 28.86178 to 27.68492, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e018_vl27.685.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 28.4087 - mse: 28.3244 - val_loss: 27.6849 - val_mse: 27.6009\n",
      "Epoch 19/25\n",
      "125/130 [===========================>..] - ETA: 0s - loss: 27.5832 - mse: 27.4996\n",
      "Epoch 19: val_loss improved from 27.68492 to 26.60718, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e019_vl26.607.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 27.4583 - mse: 27.3747 - val_loss: 26.6072 - val_mse: 26.5238\n",
      "Epoch 20/25\n",
      "125/130 [===========================>..] - ETA: 0s - loss: 26.6367 - mse: 26.5537\n",
      "Epoch 20: val_loss improved from 26.60718 to 25.75462, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e020_vl25.755.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 26.5683 - mse: 26.4854 - val_loss: 25.7546 - val_mse: 25.6721\n",
      "Epoch 21/25\n",
      "124/130 [===========================>..] - ETA: 0s - loss: 25.3961 - mse: 25.3141\n",
      "Epoch 21: val_loss improved from 25.75462 to 24.95433, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e021_vl24.954.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 25.8313 - mse: 25.7493 - val_loss: 24.9543 - val_mse: 24.8727\n",
      "Epoch 22/25\n",
      "126/130 [============================>.] - ETA: 0s - loss: 24.7767 - mse: 24.6955\n",
      "Epoch 22: val_loss improved from 24.95433 to 24.28586, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e022_vl24.286.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 25.1763 - mse: 25.0950 - val_loss: 24.2859 - val_mse: 24.2050\n",
      "Epoch 23/25\n",
      "125/130 [===========================>..] - ETA: 0s - loss: 24.7214 - mse: 24.6410\n",
      "Epoch 23: val_loss improved from 24.28586 to 23.60472, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e023_vl23.605.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 24.5880 - mse: 24.5075 - val_loss: 23.6047 - val_mse: 23.5248\n",
      "Epoch 24/25\n",
      "130/130 [==============================] - ETA: 0s - loss: 24.0689 - mse: 23.9893\n",
      "Epoch 24: val_loss improved from 23.60472 to 23.10409, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e024_vl23.104.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 24.0689 - mse: 23.9893 - val_loss: 23.1041 - val_mse: 23.0250\n",
      "Epoch 25/25\n",
      "130/130 [==============================] - ETA: 0s - loss: 23.6008 - mse: 23.5221\n",
      "Epoch 25: val_loss improved from 23.10409 to 22.61305, saving model to checkpoints/ext_3h_l1n2_2hidden_it0.e025_vl22.613.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 23.6008 - mse: 23.5221 - val_loss: 22.6131 - val_mse: 22.5349\n",
      "Time elapsed to train: 21.39 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [1.642 1.342 0.867 0.867 0.807 0.971 0.713 0.656 0.759 0.835 0.821 0.524 0.676]\n",
      "<R> = [1.644 1.346 0.835 0.880 0.812 0.979 0.688 0.671 0.747 0.831 0.837 0.532 0.670]\n",
      "s_R = [0.700 0.684 0.367 3.263 1.081 0.713 0.341 0.808 0.176 0.500 1.820 1.007 0.405]\n",
      "g = [3.4195356 5.8960295 5.6036396 ... 4.841943  3.8639956 4.457653 ]\n",
      "ri = [ 0.23939991  0.17100048 -1.0026503  ...  0.26299953  0.16529942\n",
      "  0.17879963]\n",
      "gr = [0.6469002  0.50619984 0.59170055 ... 0.6164999  0.39999962 0.4033003 ]\n",
      "gaia_g = [2.816513  5.4193687 5.04416   ... 4.249029  3.470891  4.043084 ]\n",
      "bp_rp = [1.1274042 0.9681673 1.0677004 ... 1.1447258 0.8715458 0.8666172]\n",
      "mag_pred: [4.120767  5.461582  5.637419  ... 4.218605  3.8546386 3.2192168]\n",
      "mag_pred: [4.120767  5.461582  5.637419  ... 4.218605  3.8546386 3.2192168]\n",
      "Time elapsed to make plots: 17.20 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 184212 bad. Replacing with 14.76259.\n",
      "Band 1: 5 of 184212 bad. Replacing with 15.16047.\n",
      "Band 2: 5 of 184212 bad. Replacing with 14.19215.\n",
      "Band 3: 112 of 184212 bad. Replacing with 15.23910.\n",
      "Band 4: 216 of 184212 bad. Replacing with 14.74930.\n",
      "Band 5: 7889 of 184212 bad. Replacing with 14.61470.\n",
      "Band 6: 253 of 184212 bad. Replacing with 14.49600.\n",
      "Band 7: 69 of 184212 bad. Replacing with 14.44160.\n",
      "Band 8: 371 of 184212 bad. Replacing with 13.53800.\n",
      "Band 9: 380 of 184212 bad. Replacing with 13.15900.\n",
      "Band 10: 1544 of 184212 bad. Replacing with 13.07700.\n",
      "Band 11: 201 of 184212 bad. Replacing with 15.74240.\n",
      "Band 12: 223 of 184212 bad. Replacing with 16.41514.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 184209 of 184212 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 16.388891  67.32303  409.12198  ...  21.655409 199.77184   11.952587]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0591\n",
      "  1% : 0.27\n",
      "  10% : 0.531\n",
      "  50% : 1.28\n",
      "  90% : 7.4\n",
      "  99% : 64.3\n",
      "  100% : 7.75e+03\n",
      "<chi^2/d.o.f.> = 1.81\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 1194 stars (0.648%) based on chi^2/dof > 100.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20468 bad. Replacing with 14.76698.\n",
      "Band 1: 0 of 20468 bad. Replacing with 15.16434.\n",
      "Band 2: 0 of 20468 bad. Replacing with 14.19739.\n",
      "Band 3: 13 of 20468 bad. Replacing with 15.24670.\n",
      "Band 4: 30 of 20468 bad. Replacing with 14.75285.\n",
      "Band 5: 918 of 20468 bad. Replacing with 14.62265.\n",
      "Band 6: 24 of 20468 bad. Replacing with 14.49655.\n",
      "Band 7: 10 of 20468 bad. Replacing with 14.44405.\n",
      "Band 8: 39 of 20468 bad. Replacing with 13.54000.\n",
      "Band 9: 42 of 20468 bad. Replacing with 13.15900.\n",
      "Band 10: 174 of 20468 bad. Replacing with 13.08100.\n",
      "Band 11: 19 of 20468 bad. Replacing with 15.74144.\n",
      "Band 12: 20 of 20468 bad. Replacing with 16.41437.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20468 of 20468 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 72.29295     6.0434456  11.244634  ...  46.9644     24.639078\n",
      " 125.0302   ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0884\n",
      "  1% : 0.268\n",
      "  10% : 0.536\n",
      "  50% : 1.3\n",
      "  90% : 7.41\n",
      "  99% : 66.7\n",
      "  100% : 4.96e+03\n",
      "<chi^2/d.o.f.> = 1.84\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 57.90 s\n",
      "learning rate = 0.0010000000474974513\n",
      "setting learning rate to 0.0008187307530779819\n",
      "Iteration 2 of 20.\n",
      "Epoch 1/25\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.5477 - mse: 2.4695\n",
      "Epoch 1: val_loss improved from inf to 2.43209, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e001_vl2.432.h5\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 2.5477 - mse: 2.4695 - val_loss: 2.4321 - val_mse: 2.3539\n",
      "Epoch 2/25\n",
      "122/130 [===========================>..] - ETA: 0s - loss: 2.4635 - mse: 2.3853\n",
      "Epoch 2: val_loss improved from 2.43209 to 2.37960, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e002_vl2.380.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.4655 - mse: 2.3873 - val_loss: 2.3796 - val_mse: 2.3014\n",
      "Epoch 3/25\n",
      "129/130 [============================>.] - ETA: 0s - loss: 2.4215 - mse: 2.3434\n",
      "Epoch 3: val_loss improved from 2.37960 to 2.34251, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e003_vl2.343.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.4212 - mse: 2.3431 - val_loss: 2.3425 - val_mse: 2.2644\n",
      "Epoch 4/25\n",
      "129/130 [============================>.] - ETA: 0s - loss: 2.3871 - mse: 2.3091\n",
      "Epoch 4: val_loss improved from 2.34251 to 2.31248, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e004_vl2.312.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.3874 - mse: 2.3093 - val_loss: 2.3125 - val_mse: 2.2345\n",
      "Epoch 5/25\n",
      "127/130 [============================>.] - ETA: 0s - loss: 2.3588 - mse: 2.2810\n",
      "Epoch 5: val_loss improved from 2.31248 to 2.28661, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e005_vl2.287.h5\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 2.3586 - mse: 2.2807 - val_loss: 2.2866 - val_mse: 2.2088\n",
      "Epoch 6/25\n",
      "128/130 [============================>.] - ETA: 0s - loss: 2.3341 - mse: 2.2565\n",
      "Epoch 6: val_loss improved from 2.28661 to 2.26554, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e006_vl2.266.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.3327 - mse: 2.2550 - val_loss: 2.2655 - val_mse: 2.1880\n",
      "Epoch 7/25\n",
      "124/130 [===========================>..] - ETA: 0s - loss: 2.3119 - mse: 2.2345\n",
      "Epoch 7: val_loss improved from 2.26554 to 2.24239, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e007_vl2.242.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.3096 - mse: 2.2322 - val_loss: 2.2424 - val_mse: 2.1652\n",
      "Epoch 8/25\n",
      "128/130 [============================>.] - ETA: 0s - loss: 2.2881 - mse: 2.2110\n",
      "Epoch 8: val_loss improved from 2.24239 to 2.22090, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e008_vl2.221.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.2881 - mse: 2.2111 - val_loss: 2.2209 - val_mse: 2.1440\n",
      "Epoch 9/25\n",
      "121/130 [==========================>...] - ETA: 0s - loss: 2.2702 - mse: 2.1934\n",
      "Epoch 9: val_loss improved from 2.22090 to 2.20329, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e009_vl2.203.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.2681 - mse: 2.1913 - val_loss: 2.2033 - val_mse: 2.1266\n",
      "Epoch 10/25\n",
      "122/130 [===========================>..] - ETA: 0s - loss: 2.2533 - mse: 2.1768\n",
      "Epoch 10: val_loss improved from 2.20329 to 2.18821, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e010_vl2.188.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.2496 - mse: 2.1731 - val_loss: 2.1882 - val_mse: 2.1119\n",
      "Epoch 11/25\n",
      "122/130 [===========================>..] - ETA: 0s - loss: 2.2353 - mse: 2.1591\n",
      "Epoch 11: val_loss improved from 2.18821 to 2.16985, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e011_vl2.170.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.2328 - mse: 2.1566 - val_loss: 2.1698 - val_mse: 2.0938\n",
      "Epoch 12/25\n",
      "126/130 [============================>.] - ETA: 0s - loss: 2.2187 - mse: 2.1429\n",
      "Epoch 12: val_loss improved from 2.16985 to 2.15372, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e012_vl2.154.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.2164 - mse: 2.1405 - val_loss: 2.1537 - val_mse: 2.0780\n",
      "Epoch 13/25\n",
      "127/130 [============================>.] - ETA: 0s - loss: 2.1973 - mse: 2.1218\n",
      "Epoch 13: val_loss improved from 2.15372 to 2.14042, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e013_vl2.140.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.2009 - mse: 2.1254 - val_loss: 2.1404 - val_mse: 2.0651\n",
      "Epoch 14/25\n",
      "124/130 [===========================>..] - ETA: 0s - loss: 2.1914 - mse: 2.1162\n",
      "Epoch 14: val_loss improved from 2.14042 to 2.12670, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e014_vl2.127.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.1869 - mse: 2.1117 - val_loss: 2.1267 - val_mse: 2.0518\n",
      "Epoch 15/25\n",
      "127/130 [============================>.] - ETA: 0s - loss: 2.1770 - mse: 2.1023\n",
      "Epoch 15: val_loss improved from 2.12670 to 2.11204, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e015_vl2.112.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.1729 - mse: 2.0982 - val_loss: 2.1120 - val_mse: 2.0375\n",
      "Epoch 16/25\n",
      "128/130 [============================>.] - ETA: 0s - loss: 2.1595 - mse: 2.0852\n",
      "Epoch 16: val_loss improved from 2.11204 to 2.09976, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e016_vl2.100.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.1594 - mse: 2.0851 - val_loss: 2.0998 - val_mse: 2.0256\n",
      "Epoch 17/25\n",
      "124/130 [===========================>..] - ETA: 0s - loss: 2.1465 - mse: 2.0725\n",
      "Epoch 17: val_loss improved from 2.09976 to 2.09027, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e017_vl2.090.h5\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 2.1473 - mse: 2.0733 - val_loss: 2.0903 - val_mse: 2.0165\n",
      "Epoch 18/25\n",
      "124/130 [===========================>..] - ETA: 0s - loss: 2.1319 - mse: 2.0583\n",
      "Epoch 18: val_loss improved from 2.09027 to 2.08346, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e018_vl2.083.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.1353 - mse: 2.0617 - val_loss: 2.0835 - val_mse: 2.0101\n",
      "Epoch 19/25\n",
      "127/130 [============================>.] - ETA: 0s - loss: 2.1244 - mse: 2.0512\n",
      "Epoch 19: val_loss improved from 2.08346 to 2.06826, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e019_vl2.068.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.1243 - mse: 2.0511 - val_loss: 2.0683 - val_mse: 1.9952\n",
      "Epoch 20/25\n",
      "125/130 [===========================>..] - ETA: 0s - loss: 2.1129 - mse: 2.0400\n",
      "Epoch 20: val_loss improved from 2.06826 to 2.05894, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e020_vl2.059.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.1131 - mse: 2.0402 - val_loss: 2.0589 - val_mse: 1.9862\n",
      "Epoch 21/25\n",
      "123/130 [===========================>..] - ETA: 0s - loss: 2.1021 - mse: 2.0296\n",
      "Epoch 21: val_loss improved from 2.05894 to 2.04632, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e021_vl2.046.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.1025 - mse: 2.0300 - val_loss: 2.0463 - val_mse: 1.9739\n",
      "Epoch 22/25\n",
      "123/130 [===========================>..] - ETA: 0s - loss: 2.0971 - mse: 2.0249\n",
      "Epoch 22: val_loss improved from 2.04632 to 2.03682, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e022_vl2.037.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.0928 - mse: 2.0206 - val_loss: 2.0368 - val_mse: 1.9648\n",
      "Epoch 23/25\n",
      "127/130 [============================>.] - ETA: 0s - loss: 2.0825 - mse: 2.0106\n",
      "Epoch 23: val_loss improved from 2.03682 to 2.02683, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e023_vl2.027.h5\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 2.0820 - mse: 2.0101 - val_loss: 2.0268 - val_mse: 1.9551\n",
      "Epoch 24/25\n",
      "130/130 [==============================] - ETA: 0s - loss: 2.0727 - mse: 2.0012\n",
      "Epoch 24: val_loss improved from 2.02683 to 2.01817, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e024_vl2.018.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.0727 - mse: 2.0012 - val_loss: 2.0182 - val_mse: 1.9468\n",
      "Epoch 25/25\n",
      "129/130 [============================>.] - ETA: 0s - loss: 2.0639 - mse: 1.9928\n",
      "Epoch 25: val_loss improved from 2.01817 to 2.00900, saving model to checkpoints/ext_3h_l1n2_2hidden_it1.e025_vl2.009.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.0641 - mse: 1.9929 - val_loss: 2.0090 - val_mse: 1.9380\n",
      "Time elapsed to train: 21.01 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [1.232 1.233 0.841 0.869 0.822 0.802 0.646 0.516 0.640 0.826 0.808 0.499 0.587]\n",
      "<R> = [1.236 1.234 0.815 0.882 0.827 0.811 0.640 0.525 0.640 0.823 0.824 0.504 0.584]\n",
      "s_R = [0.579 0.666 0.325 3.275 1.069 0.228 0.218 0.294 0.210 0.439 1.665 0.675 0.435]\n",
      "g = [3.4195356 5.8960295 5.6036396 ... 4.841943  3.8639956 4.457653 ]\n",
      "ri = [ 0.23939991  0.17100048 -1.0026503  ...  0.26299953  0.16529942\n",
      "  0.17879963]\n",
      "gr = [0.6469002  0.50619984 0.59170055 ... 0.6164999  0.39999962 0.4033003 ]\n",
      "gaia_g = [2.816513  5.4193687 5.04416   ... 4.249029  3.470891  4.043084 ]\n",
      "bp_rp = [1.1274042 0.9681673 1.0677004 ... 1.1447258 0.8715458 0.8666172]\n",
      "mag_pred: [3.4043994 5.416468  5.508964  ... 3.8932981 3.6663027 2.8982217]\n",
      "mag_pred: [3.4043994 5.416468  5.508964  ... 3.8932981 3.6663027 2.8982217]\n",
      "Time elapsed to make plots: 16.90 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 184212 bad. Replacing with 14.76259.\n",
      "Band 1: 5 of 184212 bad. Replacing with 15.16047.\n",
      "Band 2: 5 of 184212 bad. Replacing with 14.19215.\n",
      "Band 3: 112 of 184212 bad. Replacing with 15.23910.\n",
      "Band 4: 216 of 184212 bad. Replacing with 14.74930.\n",
      "Band 5: 7889 of 184212 bad. Replacing with 14.61470.\n",
      "Band 6: 253 of 184212 bad. Replacing with 14.49600.\n",
      "Band 7: 69 of 184212 bad. Replacing with 14.44160.\n",
      "Band 8: 371 of 184212 bad. Replacing with 13.53800.\n",
      "Band 9: 380 of 184212 bad. Replacing with 13.15900.\n",
      "Band 10: 1544 of 184212 bad. Replacing with 13.07700.\n",
      "Band 11: 201 of 184212 bad. Replacing with 15.74240.\n",
      "Band 12: 223 of 184212 bad. Replacing with 16.41514.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7fa5c433e9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 184209 of 184212 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7fa5c4334c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  9.766881   8.830996 115.09187  ...  15.901399 248.91466    6.748262]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0329\n",
      "  1% : 0.177\n",
      "  10% : 0.372\n",
      "  50% : 0.921\n",
      "  90% : 4.2\n",
      "  99% : 51.6\n",
      "  100% : 7.57e+03\n",
      "<chi^2/d.o.f.> = 1.36\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 1288 stars (0.699%) based on chi^2/dof > 79.4\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20468 bad. Replacing with 14.76698.\n",
      "Band 1: 0 of 20468 bad. Replacing with 15.16434.\n",
      "Band 2: 0 of 20468 bad. Replacing with 14.19739.\n",
      "Band 3: 13 of 20468 bad. Replacing with 15.24670.\n",
      "Band 4: 30 of 20468 bad. Replacing with 14.75285.\n",
      "Band 5: 918 of 20468 bad. Replacing with 14.62265.\n",
      "Band 6: 24 of 20468 bad. Replacing with 14.49655.\n",
      "Band 7: 10 of 20468 bad. Replacing with 14.44405.\n",
      "Band 8: 39 of 20468 bad. Replacing with 13.54000.\n",
      "Band 9: 42 of 20468 bad. Replacing with 13.15900.\n",
      "Band 10: 174 of 20468 bad. Replacing with 13.08100.\n",
      "Band 11: 19 of 20468 bad. Replacing with 15.74144.\n",
      "Band 12: 20 of 20468 bad. Replacing with 16.41437.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20468 of 20468 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [11.547525   6.2868576  4.688649  ... 27.045727  17.186226  89.84504  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0639\n",
      "  1% : 0.178\n",
      "  10% : 0.379\n",
      "  50% : 0.933\n",
      "  90% : 4.21\n",
      "  99% : 51.3\n",
      "  100% : 4.97e+03\n",
      "<chi^2/d.o.f.> = 1.38\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 57.94 s\n",
      "learning rate = 0.0008187307394109666\n",
      "setting learning rate to 0.0006703200460356394\n",
      "Iteration 3 of 20.\n",
      "Epoch 1/25\n",
      "127/130 [============================>.] - ETA: 0s - loss: 1.7465 - mse: 1.6760\n",
      "Epoch 1: val_loss improved from inf to 1.71423, saving model to checkpoints/ext_3h_l1n2_2hidden_it2.e001_vl1.714.h5\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 1.7478 - mse: 1.6772 - val_loss: 1.7142 - val_mse: 1.6439\n",
      "Epoch 2/25\n",
      "121/130 [==========================>...] - ETA: 0s - loss: 1.7313 - mse: 1.6612\n",
      "Epoch 2: val_loss did not improve from 1.71423\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 1.7338 - mse: 1.6637 - val_loss: 1.7174 - val_mse: 1.6475\n",
      "Epoch 3/25\n",
      "120/130 [==========================>...] - ETA: 0s - loss: 1.7223 - mse: 1.6525\n",
      "Epoch 3: val_loss improved from 1.71423 to 1.70533, saving model to checkpoints/ext_3h_l1n2_2hidden_it2.e003_vl1.705.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 1.7233 - mse: 1.6536 - val_loss: 1.7053 - val_mse: 1.6358\n",
      "Epoch 4/25\n",
      "127/130 [============================>.] - ETA: 0s - loss: 1.7151 - mse: 1.6457\n",
      "Epoch 4: val_loss improved from 1.70533 to 1.68629, saving model to checkpoints/ext_3h_l1n2_2hidden_it2.e004_vl1.686.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 1.7143 - mse: 1.6449 - val_loss: 1.6863 - val_mse: 1.6171\n",
      "Epoch 5/25\n",
      "119/130 [==========================>...] - ETA: 0s - loss: 1.7143 - mse: 1.6452\n",
      "Epoch 5: val_loss improved from 1.68629 to 1.68436, saving model to checkpoints/ext_3h_l1n2_2hidden_it2.e005_vl1.684.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 1.7060 - mse: 1.6370 - val_loss: 1.6844 - val_mse: 1.6155\n",
      "Epoch 6/25\n",
      "121/130 [==========================>...] - ETA: 0s - loss: 1.6975 - mse: 1.6288\n",
      "Epoch 6: val_loss did not improve from 1.68436\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 1.6969 - mse: 1.6283 - val_loss: 1.6848 - val_mse: 1.6163\n",
      "Epoch 7/25\n",
      "119/130 [==========================>...] - ETA: 0s - loss: 1.6892 - mse: 1.6209\n",
      "Epoch 7: val_loss did not improve from 1.68436\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 1.6897 - mse: 1.6214 - val_loss: 1.7347 - val_mse: 1.6666\n",
      "Epoch 8/25\n",
      "119/130 [==========================>...] - ETA: 0s - loss: 1.6897 - mse: 1.6218\n",
      "Epoch 8: val_loss improved from 1.68436 to 1.65581, saving model to checkpoints/ext_3h_l1n2_2hidden_it2.e008_vl1.656.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 1.6865 - mse: 1.6186 - val_loss: 1.6558 - val_mse: 1.5882\n",
      "Epoch 9/25\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.6751 - mse: 1.6076\n",
      "Epoch 9: val_loss did not improve from 1.65581\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 1.6751 - mse: 1.6076 - val_loss: 1.6597 - val_mse: 1.5924\n",
      "Epoch 10/25\n",
      "126/130 [============================>.] - ETA: 0s - loss: 1.6613 - mse: 1.5943\n",
      "Epoch 10: val_loss improved from 1.65581 to 1.64893, saving model to checkpoints/ext_3h_l1n2_2hidden_it2.e010_vl1.649.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 1.6678 - mse: 1.6008 - val_loss: 1.6489 - val_mse: 1.5821\n",
      "Epoch 11/25\n",
      "124/130 [===========================>..] - ETA: 0s - loss: 1.6647 - mse: 1.5981\n",
      "Epoch 11: val_loss improved from 1.64893 to 1.63669, saving model to checkpoints/ext_3h_l1n2_2hidden_it2.e011_vl1.637.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 1.6628 - mse: 1.5962 - val_loss: 1.6367 - val_mse: 1.5704\n",
      "Epoch 12/25\n",
      "124/130 [===========================>..] - ETA: 0s - loss: 1.6553 - mse: 1.5891\n",
      "Epoch 12: val_loss improved from 1.63669 to 1.63617, saving model to checkpoints/ext_3h_l1n2_2hidden_it2.e012_vl1.636.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 1.6557 - mse: 1.5896 - val_loss: 1.6362 - val_mse: 1.5703\n",
      "Epoch 13/25\n",
      "124/130 [===========================>..] - ETA: 0s - loss: 1.6508 - mse: 1.5851\n",
      "Epoch 13: val_loss did not improve from 1.63617\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 1.6490 - mse: 1.5833 - val_loss: 1.6450 - val_mse: 1.5796\n",
      "Epoch 14/25\n",
      "125/130 [===========================>..] - ETA: 0s - loss: 1.6444 - mse: 1.5792\n",
      "Epoch 14: val_loss improved from 1.63617 to 1.62692, saving model to checkpoints/ext_3h_l1n2_2hidden_it2.e014_vl1.627.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 1.6451 - mse: 1.5799 - val_loss: 1.6269 - val_mse: 1.5620\n",
      "Epoch 15/25\n",
      "119/130 [==========================>...] - ETA: 0s - loss: 1.6415 - mse: 1.5768\n",
      "Epoch 15: val_loss improved from 1.62692 to 1.61092, saving model to checkpoints/ext_3h_l1n2_2hidden_it2.e015_vl1.611.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 1.6366 - mse: 1.5719 - val_loss: 1.6109 - val_mse: 1.5464\n",
      "Epoch 16/25\n",
      "123/130 [===========================>..] - ETA: 0s - loss: 1.6315 - mse: 1.5672\n",
      "Epoch 16: val_loss did not improve from 1.61092\n",
      "130/130 [==============================] - 1s 5ms/step - loss: 1.6315 - mse: 1.5672 - val_loss: 1.6741 - val_mse: 1.6100\n",
      "Epoch 17/25\n",
      "123/130 [===========================>..] - ETA: 0s - loss: 1.6333 - mse: 1.5695\n",
      "Epoch 17: val_loss did not improve from 1.61092\n",
      "130/130 [==============================] - 1s 5ms/step - loss: 1.6299 - mse: 1.5661 - val_loss: 1.6129 - val_mse: 1.5493\n",
      "Epoch 18/25\n",
      "125/130 [===========================>..] - ETA: 0s - loss: 1.6228 - mse: 1.5594\n",
      "Epoch 18: val_loss improved from 1.61092 to 1.59851, saving model to checkpoints/ext_3h_l1n2_2hidden_it2.e018_vl1.599.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 1.6210 - mse: 1.5576 - val_loss: 1.5985 - val_mse: 1.5353\n",
      "Epoch 19/25\n",
      "120/130 [==========================>...] - ETA: 0s - loss: 1.6172 - mse: 1.5542\n",
      "Epoch 19: val_loss improved from 1.59851 to 1.59534, saving model to checkpoints/ext_3h_l1n2_2hidden_it2.e019_vl1.595.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 1.6149 - mse: 1.5519 - val_loss: 1.5953 - val_mse: 1.5326\n",
      "Epoch 20/25\n",
      "118/130 [==========================>...] - ETA: 0s - loss: 1.6148 - mse: 1.5522\n",
      "Epoch 20: val_loss did not improve from 1.59534\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 1.6100 - mse: 1.5475 - val_loss: 1.6020 - val_mse: 1.5397\n",
      "Epoch 21/25\n",
      "118/130 [==========================>...] - ETA: 0s - loss: 1.6014 - mse: 1.5394\n",
      "Epoch 21: val_loss improved from 1.59534 to 1.57687, saving model to checkpoints/ext_3h_l1n2_2hidden_it2.e021_vl1.577.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 1.6055 - mse: 1.5434 - val_loss: 1.5769 - val_mse: 1.5150\n",
      "Epoch 22/25\n",
      "125/130 [===========================>..] - ETA: 0s - loss: 1.5991 - mse: 1.5375\n",
      "Epoch 22: val_loss did not improve from 1.57687\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 1.5994 - mse: 1.5378 - val_loss: 1.6896 - val_mse: 1.6282\n",
      "Epoch 23/25\n",
      "127/130 [============================>.] - ETA: 0s - loss: 1.6015 - mse: 1.5404\n",
      "Epoch 23: val_loss did not improve from 1.57687\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 1.6019 - mse: 1.5408 - val_loss: 1.5839 - val_mse: 1.5230\n",
      "Epoch 24/25\n",
      "124/130 [===========================>..] - ETA: 0s - loss: 1.5888 - mse: 1.5281\n",
      "Epoch 24: val_loss did not improve from 1.57687\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 1.5901 - mse: 1.5295 - val_loss: 1.5792 - val_mse: 1.5188\n",
      "Epoch 25/25\n",
      "120/130 [==========================>...] - ETA: 0s - loss: 1.5901 - mse: 1.5300\n",
      "Epoch 25: val_loss improved from 1.57687 to 1.56527, saving model to checkpoints/ext_3h_l1n2_2hidden_it2.e025_vl1.565.h5\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 1.5851 - mse: 1.5251 - val_loss: 1.5653 - val_mse: 1.5055\n",
      "Time elapsed to train: 19.91 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [0.936 1.056 0.753 0.873 0.867 0.762 0.533 0.354 0.528 0.732 0.744 0.416 0.452]\n",
      "<R> = [0.941 1.062 0.750 0.886 0.873 0.766 0.534 0.355 0.529 0.732 0.757 0.416 0.453]\n",
      "s_R = [0.321 0.527 0.232 3.288 1.004 0.089 0.122 0.073 0.142 0.316 1.238 0.189 0.331]\n",
      "g = [3.4195356 5.8960295 5.6036396 ... 4.841943  3.8639956 4.457653 ]\n",
      "ri = [ 0.23939991  0.17100048 -1.0026503  ...  0.26299953  0.16529942\n",
      "  0.17879963]\n",
      "gr = [0.6469002  0.50619984 0.59170055 ... 0.6164999  0.39999962 0.4033003 ]\n",
      "gaia_g = [2.816513  5.4193687 5.04416   ... 4.249029  3.470891  4.043084 ]\n",
      "bp_rp = [1.1274042 0.9681673 1.0677004 ... 1.1447258 0.8715458 0.8666172]\n",
      "mag_pred: [3.074273  5.3781114 5.4936385 ... 3.8865986 3.697144  2.8260858]\n",
      "mag_pred: [3.074273  5.3781114 5.4936385 ... 3.8865986 3.697144  2.8260858]\n",
      "Time elapsed to make plots: 17.38 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 184212 bad. Replacing with 14.76259.\n",
      "Band 1: 5 of 184212 bad. Replacing with 15.16047.\n",
      "Band 2: 5 of 184212 bad. Replacing with 14.19215.\n",
      "Band 3: 112 of 184212 bad. Replacing with 15.23910.\n",
      "Band 4: 216 of 184212 bad. Replacing with 14.74930.\n",
      "Band 5: 7889 of 184212 bad. Replacing with 14.61470.\n",
      "Band 6: 253 of 184212 bad. Replacing with 14.49600.\n",
      "Band 7: 69 of 184212 bad. Replacing with 14.44160.\n",
      "Band 8: 371 of 184212 bad. Replacing with 13.53800.\n",
      "Band 9: 380 of 184212 bad. Replacing with 13.15900.\n",
      "Band 10: 1544 of 184212 bad. Replacing with 13.07700.\n",
      "Band 11: 201 of 184212 bad. Replacing with 15.74240.\n",
      "Band 12: 223 of 184212 bad. Replacing with 16.41514.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 184209 of 184212 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  8.865308    2.73859    33.78205   ...  21.511837  258.90128\n",
      "   7.5874104]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0312\n",
      "  1% : 0.168\n",
      "  10% : 0.347\n",
      "  50% : 0.86\n",
      "  90% : 3.65\n",
      "  99% : 49.1\n",
      "  100% : 7.38e+03\n",
      "<chi^2/d.o.f.> = 1.29\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 1454 stars (0.789%) based on chi^2/dof > 63.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20468 bad. Replacing with 14.76698.\n",
      "Band 1: 0 of 20468 bad. Replacing with 15.16434.\n",
      "Band 2: 0 of 20468 bad. Replacing with 14.19739.\n",
      "Band 3: 13 of 20468 bad. Replacing with 15.24670.\n",
      "Band 4: 30 of 20468 bad. Replacing with 14.75285.\n",
      "Band 5: 918 of 20468 bad. Replacing with 14.62265.\n",
      "Band 6: 24 of 20468 bad. Replacing with 14.49655.\n",
      "Band 7: 10 of 20468 bad. Replacing with 14.44405.\n",
      "Band 8: 39 of 20468 bad. Replacing with 13.54000.\n",
      "Band 9: 42 of 20468 bad. Replacing with 13.15900.\n",
      "Band 10: 174 of 20468 bad. Replacing with 13.08100.\n",
      "Band 11: 19 of 20468 bad. Replacing with 15.74144.\n",
      "Band 12: 20 of 20468 bad. Replacing with 16.41437.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20468 of 20468 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 6.048761   7.6892304  3.9540594 ... 31.492107  13.941518  51.940903 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0323\n",
      "  1% : 0.173\n",
      "  10% : 0.356\n",
      "  50% : 0.873\n",
      "  90% : 3.68\n",
      "  99% : 49.1\n",
      "  100% : 4.96e+03\n",
      "<chi^2/d.o.f.> = 1.3\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 55.11 s\n",
      "learning rate = 0.0006703200633637607\n",
      "setting learning rate to 0.0005488116360940264\n",
      "Iteration 4 of 20.\n",
      "Epoch 1/25\n",
      "122/129 [===========================>..] - ETA: 0s - loss: 1.5269 - mse: 1.4675\n",
      "Epoch 1: val_loss improved from inf to 1.49723, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e001_vl1.497.h5\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5302 - mse: 1.4709 - val_loss: 1.4972 - val_mse: 1.4384\n",
      "Epoch 2/25\n",
      "121/129 [===========================>..] - ETA: 0s - loss: 1.5214 - mse: 1.4629\n",
      "Epoch 2: val_loss improved from 1.49723 to 1.49263, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e002_vl1.493.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5211 - mse: 1.4626 - val_loss: 1.4926 - val_mse: 1.4345\n",
      "Epoch 3/25\n",
      "128/129 [============================>.] - ETA: 0s - loss: 1.5134 - mse: 1.4557\n",
      "Epoch 3: val_loss improved from 1.49263 to 1.48489, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e003_vl1.485.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5141 - mse: 1.4564 - val_loss: 1.4849 - val_mse: 1.4276\n",
      "Epoch 4/25\n",
      "121/129 [===========================>..] - ETA: 0s - loss: 1.5100 - mse: 1.4531\n",
      "Epoch 4: val_loss improved from 1.48489 to 1.47870, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e004_vl1.479.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5079 - mse: 1.4510 - val_loss: 1.4787 - val_mse: 1.4222\n",
      "Epoch 5/25\n",
      "126/129 [============================>.] - ETA: 0s - loss: 1.5026 - mse: 1.4465\n",
      "Epoch 5: val_loss improved from 1.47870 to 1.47164, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e005_vl1.472.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5017 - mse: 1.4456 - val_loss: 1.4716 - val_mse: 1.4160\n",
      "Epoch 6/25\n",
      "123/129 [===========================>..] - ETA: 0s - loss: 1.4964 - mse: 1.4412\n",
      "Epoch 6: val_loss improved from 1.47164 to 1.46639, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e006_vl1.466.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.4960 - mse: 1.4408 - val_loss: 1.4664 - val_mse: 1.4116\n",
      "Epoch 7/25\n",
      "119/129 [==========================>...] - ETA: 0s - loss: 1.4891 - mse: 1.4346\n",
      "Epoch 7: val_loss improved from 1.46639 to 1.46165, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e007_vl1.462.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.4904 - mse: 1.4360 - val_loss: 1.4616 - val_mse: 1.4076\n",
      "Epoch 8/25\n",
      "127/129 [============================>.] - ETA: 0s - loss: 1.4847 - mse: 1.4310\n",
      "Epoch 8: val_loss improved from 1.46165 to 1.45571, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e008_vl1.456.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.4851 - mse: 1.4315 - val_loss: 1.4557 - val_mse: 1.4024\n",
      "Epoch 9/25\n",
      "125/129 [============================>.] - ETA: 0s - loss: 1.4799 - mse: 1.4270\n",
      "Epoch 9: val_loss improved from 1.45571 to 1.45121, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e009_vl1.451.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.4803 - mse: 1.4274 - val_loss: 1.4512 - val_mse: 1.3987\n",
      "Epoch 10/25\n",
      "120/129 [==========================>...] - ETA: 0s - loss: 1.4794 - mse: 1.4273\n",
      "Epoch 10: val_loss improved from 1.45121 to 1.45107, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e010_vl1.451.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.4744 - mse: 1.4224 - val_loss: 1.4511 - val_mse: 1.3994\n",
      "Epoch 11/25\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.4705 - mse: 1.4192\n",
      "Epoch 11: val_loss improved from 1.45107 to 1.44348, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e011_vl1.443.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.4705 - mse: 1.4192 - val_loss: 1.4435 - val_mse: 1.3927\n",
      "Epoch 12/25\n",
      "127/129 [============================>.] - ETA: 0s - loss: 1.4668 - mse: 1.4164\n",
      "Epoch 12: val_loss improved from 1.44348 to 1.43820, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e012_vl1.438.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.4649 - mse: 1.4145 - val_loss: 1.4382 - val_mse: 1.3882\n",
      "Epoch 13/25\n",
      "119/129 [==========================>...] - ETA: 0s - loss: 1.4608 - mse: 1.4112\n",
      "Epoch 13: val_loss improved from 1.43820 to 1.43084, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e013_vl1.431.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.4601 - mse: 1.4104 - val_loss: 1.4308 - val_mse: 1.3816\n",
      "Epoch 14/25\n",
      "126/129 [============================>.] - ETA: 0s - loss: 1.4559 - mse: 1.4071\n",
      "Epoch 14: val_loss improved from 1.43084 to 1.42507, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e014_vl1.425.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.4542 - mse: 1.4053 - val_loss: 1.4251 - val_mse: 1.3765\n",
      "Epoch 15/25\n",
      "126/129 [============================>.] - ETA: 0s - loss: 1.4475 - mse: 1.3992\n",
      "Epoch 15: val_loss improved from 1.42507 to 1.42074, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e015_vl1.421.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.4496 - mse: 1.4014 - val_loss: 1.4207 - val_mse: 1.3727\n",
      "Epoch 16/25\n",
      "128/129 [============================>.] - ETA: 0s - loss: 1.4449 - mse: 1.3971\n",
      "Epoch 16: val_loss improved from 1.42074 to 1.41688, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e016_vl1.417.h5\n",
      "129/129 [==============================] - 1s 5ms/step - loss: 1.4450 - mse: 1.3973 - val_loss: 1.4169 - val_mse: 1.3694\n",
      "Epoch 17/25\n",
      "128/129 [============================>.] - ETA: 0s - loss: 1.4401 - mse: 1.3930\n",
      "Epoch 17: val_loss improved from 1.41688 to 1.41323, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e017_vl1.413.h5\n",
      "129/129 [==============================] - 1s 5ms/step - loss: 1.4402 - mse: 1.3930 - val_loss: 1.4132 - val_mse: 1.3664\n",
      "Epoch 18/25\n",
      "126/129 [============================>.] - ETA: 0s - loss: 1.4377 - mse: 1.3911\n",
      "Epoch 18: val_loss improved from 1.41323 to 1.40700, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e018_vl1.407.h5\n",
      "129/129 [==============================] - 1s 5ms/step - loss: 1.4359 - mse: 1.3893 - val_loss: 1.4070 - val_mse: 1.3607\n",
      "Epoch 19/25\n",
      "126/129 [============================>.] - ETA: 0s - loss: 1.4316 - mse: 1.3857\n",
      "Epoch 19: val_loss improved from 1.40700 to 1.40328, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e019_vl1.403.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.4309 - mse: 1.3849 - val_loss: 1.4033 - val_mse: 1.3576\n",
      "Epoch 20/25\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.4267 - mse: 1.3814\n",
      "Epoch 20: val_loss improved from 1.40328 to 1.39888, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e020_vl1.399.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.4267 - mse: 1.3814 - val_loss: 1.3989 - val_mse: 1.3538\n",
      "Epoch 21/25\n",
      "121/129 [===========================>..] - ETA: 0s - loss: 1.4255 - mse: 1.3807\n",
      "Epoch 21: val_loss improved from 1.39888 to 1.39778, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e021_vl1.398.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.4219 - mse: 1.3771 - val_loss: 1.3978 - val_mse: 1.3534\n",
      "Epoch 22/25\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.4173 - mse: 1.3732\n",
      "Epoch 22: val_loss improved from 1.39778 to 1.38815, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e022_vl1.388.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.4173 - mse: 1.3732 - val_loss: 1.3881 - val_mse: 1.3444\n",
      "Epoch 23/25\n",
      "122/129 [===========================>..] - ETA: 0s - loss: 1.4113 - mse: 1.3678\n",
      "Epoch 23: val_loss did not improve from 1.38815\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.4118 - mse: 1.3683 - val_loss: 1.3895 - val_mse: 1.3463\n",
      "Epoch 24/25\n",
      "126/129 [============================>.] - ETA: 0s - loss: 1.4081 - mse: 1.3652\n",
      "Epoch 24: val_loss improved from 1.38815 to 1.38230, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e024_vl1.382.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.4081 - mse: 1.3653 - val_loss: 1.3823 - val_mse: 1.3397\n",
      "Epoch 25/25\n",
      "123/129 [===========================>..] - ETA: 0s - loss: 1.4059 - mse: 1.3636\n",
      "Epoch 25: val_loss improved from 1.38230 to 1.37880, saving model to checkpoints/ext_3h_l1n2_2hidden_it3.e025_vl1.379.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.4043 - mse: 1.3620 - val_loss: 1.3788 - val_mse: 1.3368\n",
      "Time elapsed to train: 19.68 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [0.865 1.074 0.683 0.886 0.977 0.683 0.422 0.237 0.316 0.519 0.567 0.261 0.267]\n",
      "<R> = [0.870 1.082 0.684 0.899 0.988 0.684 0.422 0.237 0.315 0.520 0.576 0.261 0.267]\n",
      "s_R = [0.103 0.307 0.102 3.294 0.722 0.000 0.003 0.000 0.000 0.153 0.559 0.006 0.110]\n",
      "g = [3.4195356 5.8960295 5.6036396 ... 4.841943  3.8639956 4.457653 ]\n",
      "ri = [ 0.23939991  0.17100048 -1.0026503  ...  0.26299953  0.16529942\n",
      "  0.17879963]\n",
      "gr = [0.6469002  0.50619984 0.59170055 ... 0.6164999  0.39999962 0.4033003 ]\n",
      "gaia_g = [2.816513  5.4193687 5.04416   ... 4.249029  3.470891  4.043084 ]\n",
      "bp_rp = [1.1274042 0.9681673 1.0677004 ... 1.1447258 0.8715458 0.8666172]\n",
      "mag_pred: [3.0215244 5.354251  5.551073  ... 4.000068  3.7669003 2.8981884]\n",
      "mag_pred: [3.0215244 5.354251  5.551073  ... 4.000068  3.7669003 2.8981884]\n",
      "Time elapsed to make plots: 17.09 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 184212 bad. Replacing with 14.76259.\n",
      "Band 1: 5 of 184212 bad. Replacing with 15.16047.\n",
      "Band 2: 5 of 184212 bad. Replacing with 14.19215.\n",
      "Band 3: 112 of 184212 bad. Replacing with 15.23910.\n",
      "Band 4: 216 of 184212 bad. Replacing with 14.74930.\n",
      "Band 5: 7889 of 184212 bad. Replacing with 14.61470.\n",
      "Band 6: 253 of 184212 bad. Replacing with 14.49600.\n",
      "Band 7: 69 of 184212 bad. Replacing with 14.44160.\n",
      "Band 8: 371 of 184212 bad. Replacing with 13.53800.\n",
      "Band 9: 380 of 184212 bad. Replacing with 13.15900.\n",
      "Band 10: 1544 of 184212 bad. Replacing with 13.07700.\n",
      "Band 11: 201 of 184212 bad. Replacing with 15.74240.\n",
      "Band 12: 223 of 184212 bad. Replacing with 16.41514.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 184209 of 184212 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 10.213085    1.9588547  18.10627   ...  31.3503    262.78012\n",
      "   6.4684563]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0295\n",
      "  1% : 0.151\n",
      "  10% : 0.315\n",
      "  50% : 0.81\n",
      "  90% : 3.38\n",
      "  99% : 46.1\n",
      "  100% : 7.24e+03\n",
      "<chi^2/d.o.f.> = 1.24\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 1716 stars (0.932%) based on chi^2/dof > 50.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20468 bad. Replacing with 14.76698.\n",
      "Band 1: 0 of 20468 bad. Replacing with 15.16434.\n",
      "Band 2: 0 of 20468 bad. Replacing with 14.19739.\n",
      "Band 3: 13 of 20468 bad. Replacing with 15.24670.\n",
      "Band 4: 30 of 20468 bad. Replacing with 14.75285.\n",
      "Band 5: 918 of 20468 bad. Replacing with 14.62265.\n",
      "Band 6: 24 of 20468 bad. Replacing with 14.49655.\n",
      "Band 7: 10 of 20468 bad. Replacing with 14.44405.\n",
      "Band 8: 39 of 20468 bad. Replacing with 13.54000.\n",
      "Band 9: 42 of 20468 bad. Replacing with 13.15900.\n",
      "Band 10: 174 of 20468 bad. Replacing with 13.08100.\n",
      "Band 11: 19 of 20468 bad. Replacing with 15.74144.\n",
      "Band 12: 20 of 20468 bad. Replacing with 16.41437.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20468 of 20468 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 5.141053  6.398554 11.57066  ... 30.37827   9.652849 30.087759]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.039\n",
      "  1% : 0.156\n",
      "  10% : 0.323\n",
      "  50% : 0.819\n",
      "  90% : 3.44\n",
      "  99% : 44.2\n",
      "  100% : 4.97e+03\n",
      "<chi^2/d.o.f.> = 1.25\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 57.35 s\n",
      "learning rate = 0.0005488116294145584\n",
      "setting learning rate to 0.0004493289641172216\n",
      "Iteration 5 of 20.\n",
      "Epoch 1/25\n",
      "128/129 [============================>.] - ETA: 0s - loss: 1.3925 - mse: 1.3508\n",
      "Epoch 1: val_loss improved from inf to 1.36288, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e001_vl1.363.h5\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.3935 - mse: 1.3518 - val_loss: 1.3629 - val_mse: 1.3214\n",
      "Epoch 2/25\n",
      "120/129 [==========================>...] - ETA: 0s - loss: 1.3870 - mse: 1.3457\n",
      "Epoch 2: val_loss improved from 1.36288 to 1.35652, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e002_vl1.357.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.3871 - mse: 1.3458 - val_loss: 1.3565 - val_mse: 1.3154\n",
      "Epoch 3/25\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.3826 - mse: 1.3417\n",
      "Epoch 3: val_loss improved from 1.35652 to 1.35144, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e003_vl1.351.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.3826 - mse: 1.3417 - val_loss: 1.3514 - val_mse: 1.3107\n",
      "Epoch 4/25\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.3774 - mse: 1.3369\n",
      "Epoch 4: val_loss improved from 1.35144 to 1.34739, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e004_vl1.347.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.3774 - mse: 1.3369 - val_loss: 1.3474 - val_mse: 1.3070\n",
      "Epoch 5/25\n",
      "124/129 [===========================>..] - ETA: 0s - loss: 1.3757 - mse: 1.3355\n",
      "Epoch 5: val_loss improved from 1.34739 to 1.34259, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e005_vl1.343.h5\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.3734 - mse: 1.3333 - val_loss: 1.3426 - val_mse: 1.3026\n",
      "Epoch 6/25\n",
      "125/129 [============================>.] - ETA: 0s - loss: 1.3674 - mse: 1.3276\n",
      "Epoch 6: val_loss improved from 1.34259 to 1.33820, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e006_vl1.338.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.3693 - mse: 1.3295 - val_loss: 1.3382 - val_mse: 1.2986\n",
      "Epoch 7/25\n",
      "125/129 [============================>.] - ETA: 0s - loss: 1.3644 - mse: 1.3250\n",
      "Epoch 7: val_loss improved from 1.33820 to 1.33447, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e007_vl1.334.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.3659 - mse: 1.3265 - val_loss: 1.3345 - val_mse: 1.2953\n",
      "Epoch 8/25\n",
      "123/129 [===========================>..] - ETA: 0s - loss: 1.3570 - mse: 1.3180\n",
      "Epoch 8: val_loss improved from 1.33447 to 1.33129, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e008_vl1.331.h5\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.3612 - mse: 1.3222 - val_loss: 1.3313 - val_mse: 1.2925\n",
      "Epoch 9/25\n",
      "127/129 [============================>.] - ETA: 0s - loss: 1.3556 - mse: 1.3170\n",
      "Epoch 9: val_loss improved from 1.33129 to 1.32739, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e009_vl1.327.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.3571 - mse: 1.3185 - val_loss: 1.3274 - val_mse: 1.2889\n",
      "Epoch 10/25\n",
      "119/129 [==========================>...] - ETA: 0s - loss: 1.3505 - mse: 1.3122\n",
      "Epoch 10: val_loss improved from 1.32739 to 1.32491, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e010_vl1.325.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.3544 - mse: 1.3161 - val_loss: 1.3249 - val_mse: 1.2868\n",
      "Epoch 11/25\n",
      "121/129 [===========================>..] - ETA: 0s - loss: 1.3465 - mse: 1.3085\n",
      "Epoch 11: val_loss improved from 1.32491 to 1.31917, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e011_vl1.319.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.3495 - mse: 1.3116 - val_loss: 1.3192 - val_mse: 1.2815\n",
      "Epoch 12/25\n",
      "122/129 [===========================>..] - ETA: 0s - loss: 1.3473 - mse: 1.3097\n",
      "Epoch 12: val_loss improved from 1.31917 to 1.31718, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e012_vl1.317.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.3454 - mse: 1.3079 - val_loss: 1.3172 - val_mse: 1.2799\n",
      "Epoch 13/25\n",
      "121/129 [===========================>..] - ETA: 0s - loss: 1.3427 - mse: 1.3057\n",
      "Epoch 13: val_loss improved from 1.31718 to 1.31200, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e013_vl1.312.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.3422 - mse: 1.3051 - val_loss: 1.3120 - val_mse: 1.2751\n",
      "Epoch 14/25\n",
      "122/129 [===========================>..] - ETA: 0s - loss: 1.3423 - mse: 1.3056\n",
      "Epoch 14: val_loss improved from 1.31200 to 1.30983, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e014_vl1.310.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.3391 - mse: 1.3025 - val_loss: 1.3098 - val_mse: 1.2734\n",
      "Epoch 15/25\n",
      "119/129 [==========================>...] - ETA: 0s - loss: 1.3373 - mse: 1.3010\n",
      "Epoch 15: val_loss improved from 1.30983 to 1.30513, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e015_vl1.305.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.3351 - mse: 1.2989 - val_loss: 1.3051 - val_mse: 1.2691\n",
      "Epoch 16/25\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.3323 - mse: 1.2965\n",
      "Epoch 16: val_loss improved from 1.30513 to 1.30495, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e016_vl1.305.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.3323 - mse: 1.2965 - val_loss: 1.3049 - val_mse: 1.2693\n",
      "Epoch 17/25\n",
      "127/129 [============================>.] - ETA: 0s - loss: 1.3307 - mse: 1.2952\n",
      "Epoch 17: val_loss improved from 1.30495 to 1.29852, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e017_vl1.299.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.3290 - mse: 1.2936 - val_loss: 1.2985 - val_mse: 1.2632\n",
      "Epoch 18/25\n",
      "122/129 [===========================>..] - ETA: 0s - loss: 1.3266 - mse: 1.2916\n",
      "Epoch 18: val_loss improved from 1.29852 to 1.29593, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e018_vl1.296.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.3259 - mse: 1.2908 - val_loss: 1.2959 - val_mse: 1.2611\n",
      "Epoch 19/25\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.3226 - mse: 1.2880\n",
      "Epoch 19: val_loss improved from 1.29593 to 1.29287, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e019_vl1.293.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.3226 - mse: 1.2880 - val_loss: 1.2929 - val_mse: 1.2584\n",
      "Epoch 20/25\n",
      "125/129 [============================>.] - ETA: 0s - loss: 1.3186 - mse: 1.2844\n",
      "Epoch 20: val_loss improved from 1.29287 to 1.29196, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e020_vl1.292.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.3194 - mse: 1.2852 - val_loss: 1.2920 - val_mse: 1.2580\n",
      "Epoch 21/25\n",
      "124/129 [===========================>..] - ETA: 0s - loss: 1.3134 - mse: 1.2796\n",
      "Epoch 21: val_loss improved from 1.29196 to 1.28818, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e021_vl1.288.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.3162 - mse: 1.2825 - val_loss: 1.2882 - val_mse: 1.2546\n",
      "Epoch 22/25\n",
      "122/129 [===========================>..] - ETA: 0s - loss: 1.3108 - mse: 1.2775\n",
      "Epoch 22: val_loss improved from 1.28818 to 1.28402, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e022_vl1.284.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.3138 - mse: 1.2805 - val_loss: 1.2840 - val_mse: 1.2510\n",
      "Epoch 23/25\n",
      "126/129 [============================>.] - ETA: 0s - loss: 1.3118 - mse: 1.2789\n",
      "Epoch 23: val_loss improved from 1.28402 to 1.28165, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e023_vl1.282.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.3108 - mse: 1.2780 - val_loss: 1.2816 - val_mse: 1.2490\n",
      "Epoch 24/25\n",
      "127/129 [============================>.] - ETA: 0s - loss: 1.3076 - mse: 1.2752\n",
      "Epoch 24: val_loss improved from 1.28165 to 1.27768, saving model to checkpoints/ext_3h_l1n2_2hidden_it4.e024_vl1.278.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.3088 - mse: 1.2764 - val_loss: 1.2777 - val_mse: 1.2455\n",
      "Epoch 25/25\n",
      "126/129 [============================>.] - ETA: 0s - loss: 1.3067 - mse: 1.2747\n",
      "Epoch 25: val_loss did not improve from 1.27768\n",
      "129/129 [==============================] - 1s 5ms/step - loss: 1.3053 - mse: 1.2733 - val_loss: 1.2792 - val_mse: 1.2473\n",
      "Time elapsed to train: 19.99 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [0.921 1.168 0.662 0.958 1.045 0.694 0.387 0.218 0.191 0.347 0.347 0.155 0.122]\n",
      "<R> = [0.921 1.173 0.662 0.970 1.069 0.693 0.387 0.218 0.191 0.347 0.350 0.155 0.122]\n",
      "s_R = [0.079 0.275 0.009 3.184 0.302 0.048 0.000 0.000 0.000 0.017 0.104 0.000 0.000]\n",
      "g = [3.4195356 5.8960295 5.6036396 ... 4.841943  3.8639956 4.457653 ]\n",
      "ri = [ 0.23939991  0.17100048 -1.0026503  ...  0.26299953  0.16529942\n",
      "  0.17879963]\n",
      "gr = [0.6469002  0.50619984 0.59170055 ... 0.6164999  0.39999962 0.4033003 ]\n",
      "gaia_g = [2.816513  5.4193687 5.04416   ... 4.249029  3.470891  4.043084 ]\n",
      "bp_rp = [1.1274042 0.9681673 1.0677004 ... 1.1447258 0.8715458 0.8666172]\n",
      "mag_pred: [2.9311633 5.384038  5.654504  ... 4.1103277 3.7933774 2.9924283]\n",
      "mag_pred: [2.9311633 5.384038  5.654504  ... 4.1103277 3.7933774 2.9924283]\n",
      "Time elapsed to make plots: 17.14 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 184212 bad. Replacing with 14.76259.\n",
      "Band 1: 5 of 184212 bad. Replacing with 15.16047.\n",
      "Band 2: 5 of 184212 bad. Replacing with 14.19215.\n",
      "Band 3: 112 of 184212 bad. Replacing with 15.23910.\n",
      "Band 4: 216 of 184212 bad. Replacing with 14.74930.\n",
      "Band 5: 7889 of 184212 bad. Replacing with 14.61470.\n",
      "Band 6: 253 of 184212 bad. Replacing with 14.49600.\n",
      "Band 7: 69 of 184212 bad. Replacing with 14.44160.\n",
      "Band 8: 371 of 184212 bad. Replacing with 13.53800.\n",
      "Band 9: 380 of 184212 bad. Replacing with 13.15900.\n",
      "Band 10: 1544 of 184212 bad. Replacing with 13.07700.\n",
      "Band 11: 201 of 184212 bad. Replacing with 15.74240.\n",
      "Band 12: 223 of 184212 bad. Replacing with 16.41514.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 184209 of 184212 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 14.692261    1.886184   11.915047  ...  33.00788   267.7319\n",
      "   7.0401974]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0233\n",
      "  1% : 0.142\n",
      "  10% : 0.297\n",
      "  50% : 0.763\n",
      "  90% : 3.26\n",
      "  99% : 45\n",
      "  100% : 7.23e+03\n",
      "<chi^2/d.o.f.> = 1.19\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 2052 stars (1.11%) based on chi^2/dof > 39.8\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20468 bad. Replacing with 14.76698.\n",
      "Band 1: 0 of 20468 bad. Replacing with 15.16434.\n",
      "Band 2: 0 of 20468 bad. Replacing with 14.19739.\n",
      "Band 3: 13 of 20468 bad. Replacing with 15.24670.\n",
      "Band 4: 30 of 20468 bad. Replacing with 14.75285.\n",
      "Band 5: 918 of 20468 bad. Replacing with 14.62265.\n",
      "Band 6: 24 of 20468 bad. Replacing with 14.49655.\n",
      "Band 7: 10 of 20468 bad. Replacing with 14.44405.\n",
      "Band 8: 39 of 20468 bad. Replacing with 13.54000.\n",
      "Band 9: 42 of 20468 bad. Replacing with 13.15900.\n",
      "Band 10: 174 of 20468 bad. Replacing with 13.08100.\n",
      "Band 11: 19 of 20468 bad. Replacing with 15.74144.\n",
      "Band 12: 20 of 20468 bad. Replacing with 16.41437.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20468 of 20468 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 4.4661894  5.7205954 17.453592  ... 25.573757   8.140155  31.14951  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0334\n",
      "  1% : 0.141\n",
      "  10% : 0.302\n",
      "  50% : 0.771\n",
      "  90% : 3.3\n",
      "  99% : 46.5\n",
      "  100% : 4.94e+03\n",
      "<chi^2/d.o.f.> = 1.2\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 53.59 s\n",
      "learning rate = 0.0004493289743550122\n",
      "setting learning rate to 0.00036787944117144236\n",
      "Iteration 6 of 20.\n",
      "Epoch 1/25\n",
      "119/129 [==========================>...] - ETA: 0s - loss: 1.2907 - mse: 1.2589\n",
      "Epoch 1: val_loss improved from inf to 1.28048, saving model to checkpoints/ext_3h_l1n2_2hidden_it5.e001_vl1.280.h5\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.2924 - mse: 1.2607 - val_loss: 1.2805 - val_mse: 1.2488\n",
      "Epoch 2/25\n",
      "124/129 [===========================>..] - ETA: 0s - loss: 1.2887 - mse: 1.2571\n",
      "Epoch 2: val_loss improved from 1.28048 to 1.27782, saving model to checkpoints/ext_3h_l1n2_2hidden_it5.e002_vl1.278.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2886 - mse: 1.2571 - val_loss: 1.2778 - val_mse: 1.2463\n",
      "Epoch 3/25\n",
      "127/129 [============================>.] - ETA: 0s - loss: 1.2860 - mse: 1.2547\n",
      "Epoch 3: val_loss improved from 1.27782 to 1.27437, saving model to checkpoints/ext_3h_l1n2_2hidden_it5.e003_vl1.274.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2862 - mse: 1.2549 - val_loss: 1.2744 - val_mse: 1.2432\n",
      "Epoch 4/25\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.2830 - mse: 1.2519\n",
      "Epoch 4: val_loss improved from 1.27437 to 1.27154, saving model to checkpoints/ext_3h_l1n2_2hidden_it5.e004_vl1.272.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2830 - mse: 1.2519 - val_loss: 1.2715 - val_mse: 1.2406\n",
      "Epoch 5/25\n",
      "126/129 [============================>.] - ETA: 0s - loss: 1.2813 - mse: 1.2503\n",
      "Epoch 5: val_loss did not improve from 1.27154\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2806 - mse: 1.2497 - val_loss: 1.2724 - val_mse: 1.2415\n",
      "Epoch 6/25\n",
      "127/129 [============================>.] - ETA: 0s - loss: 1.2791 - mse: 1.2482\n",
      "Epoch 6: val_loss improved from 1.27154 to 1.27128, saving model to checkpoints/ext_3h_l1n2_2hidden_it5.e006_vl1.271.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2792 - mse: 1.2483 - val_loss: 1.2713 - val_mse: 1.2404\n",
      "Epoch 7/25\n",
      "128/129 [============================>.] - ETA: 0s - loss: 1.2762 - mse: 1.2453\n",
      "Epoch 7: val_loss improved from 1.27128 to 1.26808, saving model to checkpoints/ext_3h_l1n2_2hidden_it5.e007_vl1.268.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2765 - mse: 1.2456 - val_loss: 1.2681 - val_mse: 1.2373\n",
      "Epoch 8/25\n",
      "125/129 [============================>.] - ETA: 0s - loss: 1.2734 - mse: 1.2427\n",
      "Epoch 8: val_loss improved from 1.26808 to 1.26365, saving model to checkpoints/ext_3h_l1n2_2hidden_it5.e008_vl1.264.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2741 - mse: 1.2434 - val_loss: 1.2636 - val_mse: 1.2329\n",
      "Epoch 9/25\n",
      "122/129 [===========================>..] - ETA: 0s - loss: 1.2734 - mse: 1.2427\n",
      "Epoch 9: val_loss improved from 1.26365 to 1.26098, saving model to checkpoints/ext_3h_l1n2_2hidden_it5.e009_vl1.261.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2723 - mse: 1.2416 - val_loss: 1.2610 - val_mse: 1.2304\n",
      "Epoch 10/25\n",
      "121/129 [===========================>..] - ETA: 0s - loss: 1.2701 - mse: 1.2395\n",
      "Epoch 10: val_loss did not improve from 1.26098\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2696 - mse: 1.2390 - val_loss: 1.2611 - val_mse: 1.2305\n",
      "Epoch 11/25\n",
      "122/129 [===========================>..] - ETA: 0s - loss: 1.2677 - mse: 1.2372\n",
      "Epoch 11: val_loss improved from 1.26098 to 1.26053, saving model to checkpoints/ext_3h_l1n2_2hidden_it5.e011_vl1.261.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2683 - mse: 1.2377 - val_loss: 1.2605 - val_mse: 1.2301\n",
      "Epoch 12/25\n",
      "122/129 [===========================>..] - ETA: 0s - loss: 1.2671 - mse: 1.2367\n",
      "Epoch 12: val_loss improved from 1.26053 to 1.25572, saving model to checkpoints/ext_3h_l1n2_2hidden_it5.e012_vl1.256.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2662 - mse: 1.2358 - val_loss: 1.2557 - val_mse: 1.2253\n",
      "Epoch 13/25\n",
      "126/129 [============================>.] - ETA: 0s - loss: 1.2652 - mse: 1.2348\n",
      "Epoch 13: val_loss improved from 1.25572 to 1.25431, saving model to checkpoints/ext_3h_l1n2_2hidden_it5.e013_vl1.254.h5\n",
      "129/129 [==============================] - 1s 5ms/step - loss: 1.2639 - mse: 1.2335 - val_loss: 1.2543 - val_mse: 1.2240\n",
      "Epoch 14/25\n",
      "128/129 [============================>.] - ETA: 0s - loss: 1.2618 - mse: 1.2316\n",
      "Epoch 14: val_loss improved from 1.25431 to 1.25293, saving model to checkpoints/ext_3h_l1n2_2hidden_it5.e014_vl1.253.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2618 - mse: 1.2316 - val_loss: 1.2529 - val_mse: 1.2228\n",
      "Epoch 15/25\n",
      "120/129 [==========================>...] - ETA: 0s - loss: 1.2591 - mse: 1.2289\n",
      "Epoch 15: val_loss improved from 1.25293 to 1.25033, saving model to checkpoints/ext_3h_l1n2_2hidden_it5.e015_vl1.250.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2602 - mse: 1.2301 - val_loss: 1.2503 - val_mse: 1.2202\n",
      "Epoch 16/25\n",
      "125/129 [============================>.] - ETA: 0s - loss: 1.2600 - mse: 1.2299\n",
      "Epoch 16: val_loss improved from 1.25033 to 1.24886, saving model to checkpoints/ext_3h_l1n2_2hidden_it5.e016_vl1.249.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2587 - mse: 1.2286 - val_loss: 1.2489 - val_mse: 1.2188\n",
      "Epoch 17/25\n",
      "120/129 [==========================>...] - ETA: 0s - loss: 1.2582 - mse: 1.2281\n",
      "Epoch 17: val_loss did not improve from 1.24886\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2563 - mse: 1.2263 - val_loss: 1.2489 - val_mse: 1.2189\n",
      "Epoch 18/25\n",
      "123/129 [===========================>..] - ETA: 0s - loss: 1.2564 - mse: 1.2264\n",
      "Epoch 18: val_loss improved from 1.24886 to 1.24534, saving model to checkpoints/ext_3h_l1n2_2hidden_it5.e018_vl1.245.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2551 - mse: 1.2251 - val_loss: 1.2453 - val_mse: 1.2154\n",
      "Epoch 19/25\n",
      "124/129 [===========================>..] - ETA: 0s - loss: 1.2536 - mse: 1.2237\n",
      "Epoch 19: val_loss improved from 1.24534 to 1.24324, saving model to checkpoints/ext_3h_l1n2_2hidden_it5.e019_vl1.243.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2534 - mse: 1.2235 - val_loss: 1.2432 - val_mse: 1.2133\n",
      "Epoch 20/25\n",
      "122/129 [===========================>..] - ETA: 0s - loss: 1.2534 - mse: 1.2236\n",
      "Epoch 20: val_loss improved from 1.24324 to 1.24212, saving model to checkpoints/ext_3h_l1n2_2hidden_it5.e020_vl1.242.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2513 - mse: 1.2215 - val_loss: 1.2421 - val_mse: 1.2123\n",
      "Epoch 21/25\n",
      "126/129 [============================>.] - ETA: 0s - loss: 1.2500 - mse: 1.2202\n",
      "Epoch 21: val_loss improved from 1.24212 to 1.23989, saving model to checkpoints/ext_3h_l1n2_2hidden_it5.e021_vl1.240.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2492 - mse: 1.2194 - val_loss: 1.2399 - val_mse: 1.2102\n",
      "Epoch 22/25\n",
      "128/129 [============================>.] - ETA: 0s - loss: 1.2484 - mse: 1.2187\n",
      "Epoch 22: val_loss improved from 1.23989 to 1.23774, saving model to checkpoints/ext_3h_l1n2_2hidden_it5.e022_vl1.238.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2476 - mse: 1.2180 - val_loss: 1.2377 - val_mse: 1.2081\n",
      "Epoch 23/25\n",
      "123/129 [===========================>..] - ETA: 0s - loss: 1.2465 - mse: 1.2169\n",
      "Epoch 23: val_loss improved from 1.23774 to 1.23592, saving model to checkpoints/ext_3h_l1n2_2hidden_it5.e023_vl1.236.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2456 - mse: 1.2160 - val_loss: 1.2359 - val_mse: 1.2064\n",
      "Epoch 24/25\n",
      "124/129 [===========================>..] - ETA: 0s - loss: 1.2437 - mse: 1.2142\n",
      "Epoch 24: val_loss improved from 1.23592 to 1.23474, saving model to checkpoints/ext_3h_l1n2_2hidden_it5.e024_vl1.235.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2437 - mse: 1.2142 - val_loss: 1.2347 - val_mse: 1.2052\n",
      "Epoch 25/25\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.2420 - mse: 1.2126\n",
      "Epoch 25: val_loss improved from 1.23474 to 1.23130, saving model to checkpoints/ext_3h_l1n2_2hidden_it5.e025_vl1.231.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.2420 - mse: 1.2126 - val_loss: 1.2313 - val_mse: 1.2018\n",
      "Time elapsed to train: 20.12 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [1.029 1.330 0.700 1.260 1.103 0.749 0.455 0.276 0.160 0.227 0.216 0.085 0.056]\n",
      "<R> = [1.029 1.335 0.700 1.273 1.104 0.749 0.455 0.276 0.160 0.227 0.216 0.085 0.056]\n",
      "s_R = [0.148 0.397 0.089 2.013 0.309 0.116 0.005 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [3.4195356 5.8960295 5.6036396 ... 4.841943  3.8639956 4.457653 ]\n",
      "ri = [ 0.23939991  0.17100048 -1.0026503  ...  0.26299953  0.16529942\n",
      "  0.17879963]\n",
      "gr = [0.6469002  0.50619984 0.59170055 ... 0.6164999  0.39999962 0.4033003 ]\n",
      "gaia_g = [2.816513  5.4193687 5.04416   ... 4.249029  3.470891  4.043084 ]\n",
      "bp_rp = [1.1274042 0.9681673 1.0677004 ... 1.1447258 0.8715458 0.8666172]\n",
      "mag_pred: [2.7855983 5.405076  5.682048  ... 4.172882  3.8139553 3.0589433]\n",
      "mag_pred: [2.7855983 5.405076  5.682048  ... 4.172882  3.8139553 3.0589433]\n",
      "Time elapsed to make plots: 17.27 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 184212 bad. Replacing with 14.76259.\n",
      "Band 1: 5 of 184212 bad. Replacing with 15.16047.\n",
      "Band 2: 5 of 184212 bad. Replacing with 14.19215.\n",
      "Band 3: 112 of 184212 bad. Replacing with 15.23910.\n",
      "Band 4: 216 of 184212 bad. Replacing with 14.74930.\n",
      "Band 5: 7889 of 184212 bad. Replacing with 14.61470.\n",
      "Band 6: 253 of 184212 bad. Replacing with 14.49600.\n",
      "Band 7: 69 of 184212 bad. Replacing with 14.44160.\n",
      "Band 8: 371 of 184212 bad. Replacing with 13.53800.\n",
      "Band 9: 380 of 184212 bad. Replacing with 13.15900.\n",
      "Band 10: 1544 of 184212 bad. Replacing with 13.07700.\n",
      "Band 11: 201 of 184212 bad. Replacing with 15.74240.\n",
      "Band 12: 223 of 184212 bad. Replacing with 16.41514.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 184209 of 184212 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 17.287086    1.9719608  10.400199  ...  33.218105  266.4871\n",
      "   7.5262074]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0244\n",
      "  1% : 0.136\n",
      "  10% : 0.289\n",
      "  50% : 0.742\n",
      "  90% : 3.06\n",
      "  99% : 43.3\n",
      "  100% : 7.34e+03\n",
      "<chi^2/d.o.f.> = 1.15\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 2382 stars (1.29%) based on chi^2/dof > 31.6\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20468 bad. Replacing with 14.76698.\n",
      "Band 1: 0 of 20468 bad. Replacing with 15.16434.\n",
      "Band 2: 0 of 20468 bad. Replacing with 14.19739.\n",
      "Band 3: 13 of 20468 bad. Replacing with 15.24670.\n",
      "Band 4: 30 of 20468 bad. Replacing with 14.75285.\n",
      "Band 5: 918 of 20468 bad. Replacing with 14.62265.\n",
      "Band 6: 24 of 20468 bad. Replacing with 14.49655.\n",
      "Band 7: 10 of 20468 bad. Replacing with 14.44405.\n",
      "Band 8: 39 of 20468 bad. Replacing with 13.54000.\n",
      "Band 9: 42 of 20468 bad. Replacing with 13.15900.\n",
      "Band 10: 174 of 20468 bad. Replacing with 13.08100.\n",
      "Band 11: 19 of 20468 bad. Replacing with 15.74144.\n",
      "Band 12: 20 of 20468 bad. Replacing with 16.41437.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20468 of 20468 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 5.766942  5.515665 15.735678 ... 23.890839  8.129403 34.649826]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0287\n",
      "  1% : 0.138\n",
      "  10% : 0.292\n",
      "  50% : 0.75\n",
      "  90% : 3.1\n",
      "  99% : 45\n",
      "  100% : 4.94e+03\n",
      "<chi^2/d.o.f.> = 1.16\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 57.90 s\n",
      "learning rate = 0.0003678794309962541\n",
      "setting learning rate to 0.00030119421191220205\n",
      "Iteration 7 of 20.\n",
      "Epoch 1/25\n",
      "127/129 [============================>.] - ETA: 0s - loss: 1.1809 - mse: 1.1512\n",
      "Epoch 1: val_loss improved from inf to 1.17213, saving model to checkpoints/ext_3h_l1n2_2hidden_it6.e001_vl1.172.h5\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.1819 - mse: 1.1523 - val_loss: 1.1721 - val_mse: 1.1423\n",
      "Epoch 2/25\n",
      "122/129 [===========================>..] - ETA: 0s - loss: 1.1788 - mse: 1.1488\n",
      "Epoch 2: val_loss improved from 1.17213 to 1.17000, saving model to checkpoints/ext_3h_l1n2_2hidden_it6.e002_vl1.170.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.1804 - mse: 1.1505 - val_loss: 1.1700 - val_mse: 1.1399\n",
      "Epoch 3/25\n",
      "122/129 [===========================>..] - ETA: 0s - loss: 1.1814 - mse: 1.1512\n",
      "Epoch 3: val_loss improved from 1.17000 to 1.16885, saving model to checkpoints/ext_3h_l1n2_2hidden_it6.e003_vl1.169.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.1787 - mse: 1.1485 - val_loss: 1.1689 - val_mse: 1.1385\n",
      "Epoch 4/25\n",
      "125/129 [============================>.] - ETA: 0s - loss: 1.1748 - mse: 1.1443\n",
      "Epoch 4: val_loss did not improve from 1.16885\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.1767 - mse: 1.1462 - val_loss: 1.1692 - val_mse: 1.1387\n",
      "Epoch 5/25\n",
      "127/129 [============================>.] - ETA: 0s - loss: 1.1742 - mse: 1.1436\n",
      "Epoch 5: val_loss improved from 1.16885 to 1.16571, saving model to checkpoints/ext_3h_l1n2_2hidden_it6.e005_vl1.166.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.1748 - mse: 1.1442 - val_loss: 1.1657 - val_mse: 1.1351\n",
      "Epoch 6/25\n",
      "127/129 [============================>.] - ETA: 0s - loss: 1.1731 - mse: 1.1425\n",
      "Epoch 6: val_loss improved from 1.16571 to 1.16295, saving model to checkpoints/ext_3h_l1n2_2hidden_it6.e006_vl1.163.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.1734 - mse: 1.1428 - val_loss: 1.1630 - val_mse: 1.1323\n",
      "Epoch 7/25\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.1716 - mse: 1.1409\n",
      "Epoch 7: val_loss improved from 1.16295 to 1.16123, saving model to checkpoints/ext_3h_l1n2_2hidden_it6.e007_vl1.161.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.1716 - mse: 1.1409 - val_loss: 1.1612 - val_mse: 1.1306\n",
      "Epoch 8/25\n",
      "120/129 [==========================>...] - ETA: 0s - loss: 1.1708 - mse: 1.1401\n",
      "Epoch 8: val_loss improved from 1.16123 to 1.15843, saving model to checkpoints/ext_3h_l1n2_2hidden_it6.e008_vl1.158.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.1695 - mse: 1.1389 - val_loss: 1.1584 - val_mse: 1.1278\n",
      "Epoch 9/25\n",
      "125/129 [============================>.] - ETA: 0s - loss: 1.1680 - mse: 1.1374\n",
      "Epoch 9: val_loss improved from 1.15843 to 1.15679, saving model to checkpoints/ext_3h_l1n2_2hidden_it6.e009_vl1.157.h5\n",
      "129/129 [==============================] - 1s 5ms/step - loss: 1.1676 - mse: 1.1370 - val_loss: 1.1568 - val_mse: 1.1262\n",
      "Epoch 10/25\n",
      "127/129 [============================>.] - ETA: 0s - loss: 1.1654 - mse: 1.1349\n",
      "Epoch 10: val_loss did not improve from 1.15679\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.1655 - mse: 1.1349 - val_loss: 1.1573 - val_mse: 1.1268\n",
      "Epoch 11/25\n",
      "128/129 [============================>.] - ETA: 0s - loss: 1.1640 - mse: 1.1336\n",
      "Epoch 11: val_loss improved from 1.15679 to 1.15358, saving model to checkpoints/ext_3h_l1n2_2hidden_it6.e011_vl1.154.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.1636 - mse: 1.1332 - val_loss: 1.1536 - val_mse: 1.1232\n",
      "Epoch 12/25\n",
      "121/129 [===========================>..] - ETA: 0s - loss: 1.1611 - mse: 1.1308\n",
      "Epoch 12: val_loss improved from 1.15358 to 1.15107, saving model to checkpoints/ext_3h_l1n2_2hidden_it6.e012_vl1.151.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.1620 - mse: 1.1317 - val_loss: 1.1511 - val_mse: 1.1208\n",
      "Epoch 13/25\n",
      "119/129 [==========================>...] - ETA: 0s - loss: 1.1550 - mse: 1.1248\n",
      "Epoch 13: val_loss improved from 1.15107 to 1.14968, saving model to checkpoints/ext_3h_l1n2_2hidden_it6.e013_vl1.150.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.1598 - mse: 1.1297 - val_loss: 1.1497 - val_mse: 1.1196\n",
      "Epoch 14/25\n",
      "121/129 [===========================>..] - ETA: 0s - loss: 1.1592 - mse: 1.1293\n",
      "Epoch 14: val_loss improved from 1.14968 to 1.14699, saving model to checkpoints/ext_3h_l1n2_2hidden_it6.e014_vl1.147.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.1583 - mse: 1.1283 - val_loss: 1.1470 - val_mse: 1.1171\n",
      "Epoch 15/25\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.1568 - mse: 1.1271\n",
      "Epoch 15: val_loss improved from 1.14699 to 1.14425, saving model to checkpoints/ext_3h_l1n2_2hidden_it6.e015_vl1.144.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.1568 - mse: 1.1271 - val_loss: 1.1442 - val_mse: 1.1147\n",
      "Epoch 16/25\n",
      "126/129 [============================>.] - ETA: 0s - loss: 1.1552 - mse: 1.1257\n",
      "Epoch 16: val_loss improved from 1.14425 to 1.14266, saving model to checkpoints/ext_3h_l1n2_2hidden_it6.e016_vl1.143.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.1539 - mse: 1.1244 - val_loss: 1.1427 - val_mse: 1.1133\n",
      "Epoch 17/25\n",
      "128/129 [============================>.] - ETA: 0s - loss: 1.1519 - mse: 1.1227\n",
      "Epoch 17: val_loss improved from 1.14266 to 1.14034, saving model to checkpoints/ext_3h_l1n2_2hidden_it6.e017_vl1.140.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.1520 - mse: 1.1228 - val_loss: 1.1403 - val_mse: 1.1113\n",
      "Epoch 18/25\n",
      "128/129 [============================>.] - ETA: 0s - loss: 1.1501 - mse: 1.1212\n",
      "Epoch 18: val_loss improved from 1.14034 to 1.13904, saving model to checkpoints/ext_3h_l1n2_2hidden_it6.e018_vl1.139.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.1502 - mse: 1.1213 - val_loss: 1.1390 - val_mse: 1.1103\n",
      "Epoch 19/25\n",
      "125/129 [============================>.] - ETA: 0s - loss: 1.1481 - mse: 1.1194\n",
      "Epoch 19: val_loss improved from 1.13904 to 1.13803, saving model to checkpoints/ext_3h_l1n2_2hidden_it6.e019_vl1.138.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.1481 - mse: 1.1195 - val_loss: 1.1380 - val_mse: 1.1096\n",
      "Epoch 20/25\n",
      "122/129 [===========================>..] - ETA: 0s - loss: 1.1466 - mse: 1.1183\n",
      "Epoch 20: val_loss improved from 1.13803 to 1.13653, saving model to checkpoints/ext_3h_l1n2_2hidden_it6.e020_vl1.137.h5\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.1468 - mse: 1.1185 - val_loss: 1.1365 - val_mse: 1.1084\n",
      "Epoch 21/25\n",
      "120/129 [==========================>...] - ETA: 0s - loss: 1.1467 - mse: 1.1188\n",
      "Epoch 21: val_loss improved from 1.13653 to 1.13454, saving model to checkpoints/ext_3h_l1n2_2hidden_it6.e021_vl1.135.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.1447 - mse: 1.1168 - val_loss: 1.1345 - val_mse: 1.1069\n",
      "Epoch 22/25\n",
      "119/129 [==========================>...] - ETA: 0s - loss: 1.1425 - mse: 1.1150\n",
      "Epoch 22: val_loss improved from 1.13454 to 1.13073, saving model to checkpoints/ext_3h_l1n2_2hidden_it6.e022_vl1.131.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.1431 - mse: 1.1156 - val_loss: 1.1307 - val_mse: 1.1035\n",
      "Epoch 23/25\n",
      "127/129 [============================>.] - ETA: 0s - loss: 1.1407 - mse: 1.1136\n",
      "Epoch 23: val_loss did not improve from 1.13073\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.1406 - mse: 1.1136 - val_loss: 1.1325 - val_mse: 1.1057\n",
      "Epoch 24/25\n",
      "126/129 [============================>.] - ETA: 0s - loss: 1.1375 - mse: 1.1110\n",
      "Epoch 24: val_loss improved from 1.13073 to 1.12725, saving model to checkpoints/ext_3h_l1n2_2hidden_it6.e024_vl1.127.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.1387 - mse: 1.1122 - val_loss: 1.1272 - val_mse: 1.1010\n",
      "Epoch 25/25\n",
      "117/129 [==========================>...] - ETA: 0s - loss: 1.1396 - mse: 1.1136\n",
      "Epoch 25: val_loss improved from 1.12725 to 1.12606, saving model to checkpoints/ext_3h_l1n2_2hidden_it6.e025_vl1.126.h5\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.1367 - mse: 1.1107 - val_loss: 1.1261 - val_mse: 1.1004\n",
      "Time elapsed to train: 19.96 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [1.345 1.770 0.897 1.931 1.383 0.956 0.628 0.434 0.210 0.183 0.137 0.050 0.029]\n",
      "<R> = [1.344 1.769 0.897 1.933 1.383 0.956 0.628 0.434 0.210 0.183 0.137 0.050 0.029]\n",
      "s_R = [0.144 0.290 0.108 0.426 0.313 0.126 0.048 0.007 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [3.4195356 5.8960295 5.6036396 ... 4.841943  3.8639956 4.457653 ]\n",
      "ri = [ 0.23939991  0.17100048 -1.0026503  ...  0.26299953  0.16529942\n",
      "  0.17879963]\n",
      "gr = [0.6469002  0.50619984 0.59170055 ... 0.6164999  0.39999962 0.4033003 ]\n",
      "gaia_g = [2.816513  5.4193687 5.04416   ... 4.249029  3.470891  4.043084 ]\n",
      "bp_rp = [1.1274042 0.9681673 1.0677004 ... 1.1447258 0.8715458 0.8666172]\n",
      "mag_pred: [2.7256212 5.4322844 5.6856117 ... 4.2139916 3.8501778 3.1163366]\n",
      "mag_pred: [2.7256212 5.4322844 5.6856117 ... 4.2139916 3.8501778 3.1163366]\n",
      "Time elapsed to make plots: 16.08 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 184212 bad. Replacing with 14.76259.\n",
      "Band 1: 5 of 184212 bad. Replacing with 15.16047.\n",
      "Band 2: 5 of 184212 bad. Replacing with 14.19215.\n",
      "Band 3: 112 of 184212 bad. Replacing with 15.23910.\n",
      "Band 4: 216 of 184212 bad. Replacing with 14.74930.\n",
      "Band 5: 7889 of 184212 bad. Replacing with 14.61470.\n",
      "Band 6: 253 of 184212 bad. Replacing with 14.49600.\n",
      "Band 7: 69 of 184212 bad. Replacing with 14.44160.\n",
      "Band 8: 371 of 184212 bad. Replacing with 13.53800.\n",
      "Band 9: 380 of 184212 bad. Replacing with 13.15900.\n",
      "Band 10: 1544 of 184212 bad. Replacing with 13.07700.\n",
      "Band 11: 201 of 184212 bad. Replacing with 15.74240.\n",
      "Band 12: 223 of 184212 bad. Replacing with 16.41514.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 184209 of 184212 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 16.987686    1.737206    6.55462   ...  38.473557  268.4726\n",
      "   7.4226174]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0189\n",
      "  1% : 0.124\n",
      "  10% : 0.267\n",
      "  50% : 0.695\n",
      "  90% : 2.95\n",
      "  99% : 40.8\n",
      "  100% : 7.41e+03\n",
      "<chi^2/d.o.f.> = 1.1\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 2797 stars (1.52%) based on chi^2/dof > 25.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20468 bad. Replacing with 14.76698.\n",
      "Band 1: 0 of 20468 bad. Replacing with 15.16434.\n",
      "Band 2: 0 of 20468 bad. Replacing with 14.19739.\n",
      "Band 3: 13 of 20468 bad. Replacing with 15.24670.\n",
      "Band 4: 30 of 20468 bad. Replacing with 14.75285.\n",
      "Band 5: 918 of 20468 bad. Replacing with 14.62265.\n",
      "Band 6: 24 of 20468 bad. Replacing with 14.49655.\n",
      "Band 7: 10 of 20468 bad. Replacing with 14.44405.\n",
      "Band 8: 39 of 20468 bad. Replacing with 13.54000.\n",
      "Band 9: 42 of 20468 bad. Replacing with 13.15900.\n",
      "Band 10: 174 of 20468 bad. Replacing with 13.08100.\n",
      "Band 11: 19 of 20468 bad. Replacing with 15.74144.\n",
      "Band 12: 20 of 20468 bad. Replacing with 16.41437.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20468 of 20468 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 4.7308397  4.9123054 14.521288  ... 17.89513    6.618123  37.228077 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0336\n",
      "  1% : 0.128\n",
      "  10% : 0.27\n",
      "  50% : 0.704\n",
      "  90% : 2.99\n",
      "  99% : 42\n",
      "  100% : 4.98e+03\n",
      "<chi^2/d.o.f.> = 1.11\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 56.70 s\n",
      "learning rate = 0.0003011942026205361\n",
      "setting learning rate to 0.00024659696394160646\n",
      "Iteration 8 of 20.\n",
      "Epoch 1/25\n",
      "121/128 [===========================>..] - ETA: 0s - loss: 1.0563 - mse: 1.0308\n",
      "Epoch 1: val_loss improved from inf to 1.05134, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e001_vl1.051.h5\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 1.0568 - mse: 1.0313 - val_loss: 1.0513 - val_mse: 1.0261\n",
      "Epoch 2/25\n",
      "128/128 [==============================] - ETA: 0s - loss: 1.0549 - mse: 1.0300\n",
      "Epoch 2: val_loss improved from 1.05134 to 1.04947, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e002_vl1.049.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0549 - mse: 1.0300 - val_loss: 1.0495 - val_mse: 1.0248\n",
      "Epoch 3/25\n",
      "120/128 [===========================>..] - ETA: 0s - loss: 1.0527 - mse: 1.0282\n",
      "Epoch 3: val_loss improved from 1.04947 to 1.04917, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e003_vl1.049.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0539 - mse: 1.0294 - val_loss: 1.0492 - val_mse: 1.0250\n",
      "Epoch 4/25\n",
      "120/128 [===========================>..] - ETA: 0s - loss: 1.0529 - mse: 1.0290\n",
      "Epoch 4: val_loss improved from 1.04917 to 1.04798, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e004_vl1.048.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0521 - mse: 1.0282 - val_loss: 1.0480 - val_mse: 1.0244\n",
      "Epoch 5/25\n",
      "124/128 [============================>.] - ETA: 0s - loss: 1.0505 - mse: 1.0271\n",
      "Epoch 5: val_loss improved from 1.04798 to 1.04551, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e005_vl1.046.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0506 - mse: 1.0273 - val_loss: 1.0455 - val_mse: 1.0225\n",
      "Epoch 6/25\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 1.0500 - mse: 1.0273\n",
      "Epoch 6: val_loss improved from 1.04551 to 1.04506, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e006_vl1.045.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0493 - mse: 1.0265 - val_loss: 1.0451 - val_mse: 1.0227\n",
      "Epoch 7/25\n",
      "126/128 [============================>.] - ETA: 0s - loss: 1.0469 - mse: 1.0249\n",
      "Epoch 7: val_loss improved from 1.04506 to 1.04285, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e007_vl1.043.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0476 - mse: 1.0255 - val_loss: 1.0428 - val_mse: 1.0211\n",
      "Epoch 8/25\n",
      "127/128 [============================>.] - ETA: 0s - loss: 1.0466 - mse: 1.0252\n",
      "Epoch 8: val_loss improved from 1.04285 to 1.04117, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e008_vl1.041.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0464 - mse: 1.0250 - val_loss: 1.0412 - val_mse: 1.0201\n",
      "Epoch 9/25\n",
      "120/128 [===========================>..] - ETA: 0s - loss: 1.0464 - mse: 1.0256\n",
      "Epoch 9: val_loss improved from 1.04117 to 1.04085, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e009_vl1.041.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0451 - mse: 1.0243 - val_loss: 1.0408 - val_mse: 1.0204\n",
      "Epoch 10/25\n",
      "124/128 [============================>.] - ETA: 0s - loss: 1.0436 - mse: 1.0235\n",
      "Epoch 10: val_loss improved from 1.04085 to 1.03856, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e010_vl1.039.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0432 - mse: 1.0230 - val_loss: 1.0386 - val_mse: 1.0187\n",
      "Epoch 11/25\n",
      "127/128 [============================>.] - ETA: 0s - loss: 1.0415 - mse: 1.0219\n",
      "Epoch 11: val_loss improved from 1.03856 to 1.03703, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e011_vl1.037.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0420 - mse: 1.0225 - val_loss: 1.0370 - val_mse: 1.0177\n",
      "Epoch 12/25\n",
      "127/128 [============================>.] - ETA: 0s - loss: 1.0406 - mse: 1.0216\n",
      "Epoch 12: val_loss improved from 1.03703 to 1.03599, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e012_vl1.036.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0408 - mse: 1.0218 - val_loss: 1.0360 - val_mse: 1.0172\n",
      "Epoch 13/25\n",
      "127/128 [============================>.] - ETA: 0s - loss: 1.0396 - mse: 1.0210\n",
      "Epoch 13: val_loss improved from 1.03599 to 1.03505, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e013_vl1.035.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0397 - mse: 1.0212 - val_loss: 1.0350 - val_mse: 1.0168\n",
      "Epoch 14/25\n",
      "126/128 [============================>.] - ETA: 0s - loss: 1.0382 - mse: 1.0202\n",
      "Epoch 14: val_loss improved from 1.03505 to 1.03430, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e014_vl1.034.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0382 - mse: 1.0202 - val_loss: 1.0343 - val_mse: 1.0165\n",
      "Epoch 15/25\n",
      "126/128 [============================>.] - ETA: 0s - loss: 1.0371 - mse: 1.0195\n",
      "Epoch 15: val_loss improved from 1.03430 to 1.03251, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e015_vl1.033.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0376 - mse: 1.0199 - val_loss: 1.0325 - val_mse: 1.0150\n",
      "Epoch 16/25\n",
      "125/128 [============================>.] - ETA: 0s - loss: 1.0369 - mse: 1.0195\n",
      "Epoch 16: val_loss did not improve from 1.03251\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0363 - mse: 1.0189 - val_loss: 1.0326 - val_mse: 1.0152\n",
      "Epoch 17/25\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 1.0348 - mse: 1.0175\n",
      "Epoch 17: val_loss improved from 1.03251 to 1.03146, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e017_vl1.031.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0354 - mse: 1.0182 - val_loss: 1.0315 - val_mse: 1.0143\n",
      "Epoch 18/25\n",
      "128/128 [==============================] - ETA: 0s - loss: 1.0346 - mse: 1.0175\n",
      "Epoch 18: val_loss improved from 1.03146 to 1.03058, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e018_vl1.031.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0346 - mse: 1.0175 - val_loss: 1.0306 - val_mse: 1.0136\n",
      "Epoch 19/25\n",
      "119/128 [==========================>...] - ETA: 0s - loss: 1.0357 - mse: 1.0188\n",
      "Epoch 19: val_loss improved from 1.03058 to 1.02982, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e019_vl1.030.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0337 - mse: 1.0168 - val_loss: 1.0298 - val_mse: 1.0129\n",
      "Epoch 20/25\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 1.0332 - mse: 1.0163\n",
      "Epoch 20: val_loss improved from 1.02982 to 1.02897, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e020_vl1.029.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0334 - mse: 1.0165 - val_loss: 1.0290 - val_mse: 1.0121\n",
      "Epoch 21/25\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 1.0331 - mse: 1.0162\n",
      "Epoch 21: val_loss improved from 1.02897 to 1.02873, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e021_vl1.029.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0327 - mse: 1.0158 - val_loss: 1.0287 - val_mse: 1.0119\n",
      "Epoch 22/25\n",
      "126/128 [============================>.] - ETA: 0s - loss: 1.0322 - mse: 1.0154\n",
      "Epoch 22: val_loss did not improve from 1.02873\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0323 - mse: 1.0154 - val_loss: 1.0288 - val_mse: 1.0120\n",
      "Epoch 23/25\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 1.0322 - mse: 1.0153\n",
      "Epoch 23: val_loss improved from 1.02873 to 1.02802, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e023_vl1.028.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0314 - mse: 1.0146 - val_loss: 1.0280 - val_mse: 1.0112\n",
      "Epoch 24/25\n",
      "126/128 [============================>.] - ETA: 0s - loss: 1.0312 - mse: 1.0144\n",
      "Epoch 24: val_loss improved from 1.02802 to 1.02663, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e024_vl1.027.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0311 - mse: 1.0143 - val_loss: 1.0266 - val_mse: 1.0098\n",
      "Epoch 25/25\n",
      "124/128 [============================>.] - ETA: 0s - loss: 1.0296 - mse: 1.0128\n",
      "Epoch 25: val_loss improved from 1.02663 to 1.02617, saving model to checkpoints/ext_3h_l1n2_2hidden_it7.e025_vl1.026.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0305 - mse: 1.0136 - val_loss: 1.0262 - val_mse: 1.0094\n",
      "Time elapsed to train: 19.96 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [1.673 2.214 1.133 2.471 1.723 1.204 0.823 0.606 0.319 0.189 0.101 0.034 0.018]\n",
      "<R> = [1.673 2.215 1.133 2.471 1.721 1.204 0.823 0.606 0.319 0.189 0.101 0.034 0.018]\n",
      "s_R = [0.026 0.003 0.000 0.002 0.065 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [3.4195356 5.8960295 5.6036396 ... 4.841943  3.8639956 4.457653 ]\n",
      "ri = [ 0.23939991  0.17100048 -1.0026503  ...  0.26299953  0.16529942\n",
      "  0.17879963]\n",
      "gr = [0.6469002  0.50619984 0.59170055 ... 0.6164999  0.39999962 0.4033003 ]\n",
      "gaia_g = [2.816513  5.4193687 5.04416   ... 4.249029  3.470891  4.043084 ]\n",
      "bp_rp = [1.1274042 0.9681673 1.0677004 ... 1.1447258 0.8715458 0.8666172]\n",
      "mag_pred: [2.6561499 5.4426622 5.6789637 ... 4.2204432 3.8777351 3.1650052]\n",
      "mag_pred: [2.6561499 5.4426622 5.6789637 ... 4.2204432 3.8777351 3.1650052]\n",
      "Time elapsed to make plots: 17.70 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 184212 bad. Replacing with 14.76259.\n",
      "Band 1: 5 of 184212 bad. Replacing with 15.16047.\n",
      "Band 2: 5 of 184212 bad. Replacing with 14.19215.\n",
      "Band 3: 112 of 184212 bad. Replacing with 15.23910.\n",
      "Band 4: 216 of 184212 bad. Replacing with 14.74930.\n",
      "Band 5: 7889 of 184212 bad. Replacing with 14.61470.\n",
      "Band 6: 253 of 184212 bad. Replacing with 14.49600.\n",
      "Band 7: 69 of 184212 bad. Replacing with 14.44160.\n",
      "Band 8: 371 of 184212 bad. Replacing with 13.53800.\n",
      "Band 9: 380 of 184212 bad. Replacing with 13.15900.\n",
      "Band 10: 1544 of 184212 bad. Replacing with 13.07700.\n",
      "Band 11: 201 of 184212 bad. Replacing with 15.74240.\n",
      "Band 12: 223 of 184212 bad. Replacing with 16.41514.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 184209 of 184212 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 15.23412     1.8761773   5.895977  ...  42.776676  270.22433\n",
      "   6.9542284]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0196\n",
      "  1% : 0.121\n",
      "  10% : 0.26\n",
      "  50% : 0.677\n",
      "  90% : 2.85\n",
      "  99% : 40.2\n",
      "  100% : 7.44e+03\n",
      "<chi^2/d.o.f.> = 1.07\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 3329 stars (1.81%) based on chi^2/dof > 19.9\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20468 bad. Replacing with 14.76698.\n",
      "Band 1: 0 of 20468 bad. Replacing with 15.16434.\n",
      "Band 2: 0 of 20468 bad. Replacing with 14.19739.\n",
      "Band 3: 13 of 20468 bad. Replacing with 15.24670.\n",
      "Band 4: 30 of 20468 bad. Replacing with 14.75285.\n",
      "Band 5: 918 of 20468 bad. Replacing with 14.62265.\n",
      "Band 6: 24 of 20468 bad. Replacing with 14.49655.\n",
      "Band 7: 10 of 20468 bad. Replacing with 14.44405.\n",
      "Band 8: 39 of 20468 bad. Replacing with 13.54000.\n",
      "Band 9: 42 of 20468 bad. Replacing with 13.15900.\n",
      "Band 10: 174 of 20468 bad. Replacing with 13.08100.\n",
      "Band 11: 19 of 20468 bad. Replacing with 15.74144.\n",
      "Band 12: 20 of 20468 bad. Replacing with 16.41437.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20468 of 20468 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 4.667715   4.548686  13.067035  ... 15.029936   5.1918354 38.545666 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0385\n",
      "  1% : 0.122\n",
      "  10% : 0.264\n",
      "  50% : 0.685\n",
      "  90% : 2.87\n",
      "  99% : 40.7\n",
      "  100% : 4.99e+03\n",
      "<chi^2/d.o.f.> = 1.08\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 56.76 s\n",
      "learning rate = 0.00024659695918671787\n",
      "setting learning rate to 0.00020189651799465538\n",
      "Iteration 9 of 20.\n",
      "Epoch 1/25\n",
      "121/128 [===========================>..] - ETA: 0s - loss: 0.9713 - mse: 0.9545\n",
      "Epoch 1: val_loss improved from inf to 0.96366, saving model to checkpoints/ext_3h_l1n2_2hidden_it8.e001_vl0.964.h5\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.9718 - mse: 0.9549 - val_loss: 0.9637 - val_mse: 0.9468\n",
      "Epoch 2/25\n",
      "125/128 [============================>.] - ETA: 0s - loss: 0.9717 - mse: 0.9548\n",
      "Epoch 2: val_loss improved from 0.96366 to 0.96330, saving model to checkpoints/ext_3h_l1n2_2hidden_it8.e002_vl0.963.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9714 - mse: 0.9546 - val_loss: 0.9633 - val_mse: 0.9464\n",
      "Epoch 3/25\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 0.9716 - mse: 0.9548\n",
      "Epoch 3: val_loss improved from 0.96330 to 0.96247, saving model to checkpoints/ext_3h_l1n2_2hidden_it8.e003_vl0.962.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9712 - mse: 0.9543 - val_loss: 0.9625 - val_mse: 0.9456\n",
      "Epoch 4/25\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 0.9716 - mse: 0.9547\n",
      "Epoch 4: val_loss did not improve from 0.96247\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9707 - mse: 0.9538 - val_loss: 0.9629 - val_mse: 0.9460\n",
      "Epoch 5/25\n",
      "119/128 [==========================>...] - ETA: 0s - loss: 0.9707 - mse: 0.9538\n",
      "Epoch 5: val_loss did not improve from 0.96247\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9704 - mse: 0.9535 - val_loss: 0.9627 - val_mse: 0.9457\n",
      "Epoch 6/25\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 0.9719 - mse: 0.9550\n",
      "Epoch 6: val_loss improved from 0.96247 to 0.96114, saving model to checkpoints/ext_3h_l1n2_2hidden_it8.e006_vl0.961.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9699 - mse: 0.9530 - val_loss: 0.9611 - val_mse: 0.9442\n",
      "Epoch 7/25\n",
      "127/128 [============================>.] - ETA: 0s - loss: 0.9697 - mse: 0.9527\n",
      "Epoch 7: val_loss did not improve from 0.96114\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9696 - mse: 0.9527 - val_loss: 0.9620 - val_mse: 0.9450\n",
      "Epoch 8/25\n",
      "117/128 [==========================>...] - ETA: 0s - loss: 0.9698 - mse: 0.9529\n",
      "Epoch 8: val_loss did not improve from 0.96114\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9692 - mse: 0.9522 - val_loss: 0.9617 - val_mse: 0.9447\n",
      "Epoch 9/25\n",
      "124/128 [============================>.] - ETA: 0s - loss: 0.9688 - mse: 0.9518\n",
      "Epoch 9: val_loss improved from 0.96114 to 0.96031, saving model to checkpoints/ext_3h_l1n2_2hidden_it8.e009_vl0.960.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9690 - mse: 0.9520 - val_loss: 0.9603 - val_mse: 0.9433\n",
      "Epoch 10/25\n",
      "120/128 [===========================>..] - ETA: 0s - loss: 0.9695 - mse: 0.9525\n",
      "Epoch 10: val_loss did not improve from 0.96031\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.9688 - mse: 0.9518 - val_loss: 0.9607 - val_mse: 0.9437\n",
      "Epoch 11/25\n",
      "124/128 [============================>.] - ETA: 0s - loss: 0.9677 - mse: 0.9507\n",
      "Epoch 11: val_loss did not improve from 0.96031\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.9685 - mse: 0.9515 - val_loss: 0.9605 - val_mse: 0.9436\n",
      "Epoch 12/25\n",
      "128/128 [==============================] - ETA: 0s - loss: 0.9682 - mse: 0.9512\n",
      "Epoch 12: val_loss did not improve from 0.96031\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.9682 - mse: 0.9512 - val_loss: 0.9604 - val_mse: 0.9434\n",
      "Epoch 13/25\n",
      "121/128 [===========================>..] - ETA: 0s - loss: 0.9671 - mse: 0.9501\n",
      "Epoch 13: val_loss improved from 0.96031 to 0.95903, saving model to checkpoints/ext_3h_l1n2_2hidden_it8.e013_vl0.959.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9677 - mse: 0.9507 - val_loss: 0.9590 - val_mse: 0.9420\n",
      "Epoch 14/25\n",
      "118/128 [==========================>...] - ETA: 0s - loss: 0.9675 - mse: 0.9505\n",
      "Epoch 14: val_loss did not improve from 0.95903\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9675 - mse: 0.9505 - val_loss: 0.9590 - val_mse: 0.9420\n",
      "Epoch 15/25\n",
      "125/128 [============================>.] - ETA: 0s - loss: 0.9671 - mse: 0.9501\n",
      "Epoch 15: val_loss improved from 0.95903 to 0.95899, saving model to checkpoints/ext_3h_l1n2_2hidden_it8.e015_vl0.959.h5\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.9672 - mse: 0.9501 - val_loss: 0.9590 - val_mse: 0.9420\n",
      "Epoch 16/25\n",
      "128/128 [==============================] - ETA: 0s - loss: 0.9671 - mse: 0.9501\n",
      "Epoch 16: val_loss improved from 0.95899 to 0.95811, saving model to checkpoints/ext_3h_l1n2_2hidden_it8.e016_vl0.958.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9671 - mse: 0.9501 - val_loss: 0.9581 - val_mse: 0.9411\n",
      "Epoch 17/25\n",
      "123/128 [===========================>..] - ETA: 0s - loss: 0.9667 - mse: 0.9496\n",
      "Epoch 17: val_loss did not improve from 0.95811\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9667 - mse: 0.9497 - val_loss: 0.9582 - val_mse: 0.9412\n",
      "Epoch 18/25\n",
      "125/128 [============================>.] - ETA: 0s - loss: 0.9665 - mse: 0.9494\n",
      "Epoch 18: val_loss did not improve from 0.95811\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9660 - mse: 0.9489 - val_loss: 0.9582 - val_mse: 0.9412\n",
      "Epoch 19/25\n",
      "120/128 [===========================>..] - ETA: 0s - loss: 0.9670 - mse: 0.9500\n",
      "Epoch 19: val_loss improved from 0.95811 to 0.95777, saving model to checkpoints/ext_3h_l1n2_2hidden_it8.e019_vl0.958.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9661 - mse: 0.9491 - val_loss: 0.9578 - val_mse: 0.9408\n",
      "Epoch 20/25\n",
      "126/128 [============================>.] - ETA: 0s - loss: 0.9654 - mse: 0.9483\n",
      "Epoch 20: val_loss improved from 0.95777 to 0.95703, saving model to checkpoints/ext_3h_l1n2_2hidden_it8.e020_vl0.957.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9653 - mse: 0.9482 - val_loss: 0.9570 - val_mse: 0.9400\n",
      "Epoch 21/25\n",
      "119/128 [==========================>...] - ETA: 0s - loss: 0.9634 - mse: 0.9464\n",
      "Epoch 21: val_loss did not improve from 0.95703\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.9652 - mse: 0.9482 - val_loss: 0.9579 - val_mse: 0.9409\n",
      "Epoch 22/25\n",
      "127/128 [============================>.] - ETA: 0s - loss: 0.9654 - mse: 0.9483\n",
      "Epoch 22: val_loss did not improve from 0.95703\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9651 - mse: 0.9480 - val_loss: 0.9572 - val_mse: 0.9402\n",
      "Epoch 23/25\n",
      "126/128 [============================>.] - ETA: 0s - loss: 0.9646 - mse: 0.9476\n",
      "Epoch 23: val_loss did not improve from 0.95703\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9651 - mse: 0.9480 - val_loss: 0.9575 - val_mse: 0.9405\n",
      "Epoch 24/25\n",
      "127/128 [============================>.] - ETA: 0s - loss: 0.9648 - mse: 0.9477\n",
      "Epoch 24: val_loss improved from 0.95703 to 0.95635, saving model to checkpoints/ext_3h_l1n2_2hidden_it8.e024_vl0.956.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9647 - mse: 0.9476 - val_loss: 0.9564 - val_mse: 0.9393\n",
      "Epoch 25/25\n",
      "123/128 [===========================>..] - ETA: 0s - loss: 0.9649 - mse: 0.9478\n",
      "Epoch 25: val_loss improved from 0.95635 to 0.95604, saving model to checkpoints/ext_3h_l1n2_2hidden_it8.e025_vl0.956.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9644 - mse: 0.9474 - val_loss: 0.9560 - val_mse: 0.9390\n",
      "Time elapsed to train: 19.78 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [1.898 2.502 1.298 2.792 1.943 1.376 0.959 0.719 0.403 0.210 0.091 0.027 0.012]\n",
      "<R> = [1.898 2.502 1.298 2.792 1.943 1.376 0.959 0.719 0.403 0.210 0.091 0.027 0.012]\n",
      "s_R = [0.031 0.003 0.000 0.031 0.073 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [3.4195356 5.8960295 5.6036396 ... 4.841943  3.8639956 4.457653 ]\n",
      "ri = [ 0.23939991  0.17100048 -1.0026503  ...  0.26299953  0.16529942\n",
      "  0.17879963]\n",
      "gr = [0.6469002  0.50619984 0.59170055 ... 0.6164999  0.39999962 0.4033003 ]\n",
      "gaia_g = [2.816513  5.4193687 5.04416   ... 4.249029  3.470891  4.043084 ]\n",
      "bp_rp = [1.1274042 0.9681673 1.0677004 ... 1.1447258 0.8715458 0.8666172]\n",
      "mag_pred: [2.627317  5.4517446 5.6780148 ... 4.220312  3.8913748 3.1910553]\n",
      "mag_pred: [2.627317  5.4517446 5.6780148 ... 4.220312  3.8913748 3.1910553]\n",
      "Time elapsed to make plots: 16.19 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 184212 bad. Replacing with 14.76259.\n",
      "Band 1: 5 of 184212 bad. Replacing with 15.16047.\n",
      "Band 2: 5 of 184212 bad. Replacing with 14.19215.\n",
      "Band 3: 112 of 184212 bad. Replacing with 15.23910.\n",
      "Band 4: 216 of 184212 bad. Replacing with 14.74930.\n",
      "Band 5: 7889 of 184212 bad. Replacing with 14.61470.\n",
      "Band 6: 253 of 184212 bad. Replacing with 14.49600.\n",
      "Band 7: 69 of 184212 bad. Replacing with 14.44160.\n",
      "Band 8: 371 of 184212 bad. Replacing with 13.53800.\n",
      "Band 9: 380 of 184212 bad. Replacing with 13.15900.\n",
      "Band 10: 1544 of 184212 bad. Replacing with 13.07700.\n",
      "Band 11: 201 of 184212 bad. Replacing with 15.74240.\n",
      "Band 12: 223 of 184212 bad. Replacing with 16.41514.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 184209 of 184212 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 15.490824    1.9417689   5.6022205 ...  46.71183   273.6083\n",
      "   6.664516 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0158\n",
      "  1% : 0.118\n",
      "  10% : 0.253\n",
      "  50% : 0.666\n",
      "  90% : 2.86\n",
      "  99% : 39.5\n",
      "  100% : 7.5e+03\n",
      "<chi^2/d.o.f.> = 1.06\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 4009 stars (2.18%) based on chi^2/dof > 15.8\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20468 bad. Replacing with 14.76698.\n",
      "Band 1: 0 of 20468 bad. Replacing with 15.16434.\n",
      "Band 2: 0 of 20468 bad. Replacing with 14.19739.\n",
      "Band 3: 13 of 20468 bad. Replacing with 15.24670.\n",
      "Band 4: 30 of 20468 bad. Replacing with 14.75285.\n",
      "Band 5: 918 of 20468 bad. Replacing with 14.62265.\n",
      "Band 6: 24 of 20468 bad. Replacing with 14.49655.\n",
      "Band 7: 10 of 20468 bad. Replacing with 14.44405.\n",
      "Band 8: 39 of 20468 bad. Replacing with 13.54000.\n",
      "Band 9: 42 of 20468 bad. Replacing with 13.15900.\n",
      "Band 10: 174 of 20468 bad. Replacing with 13.08100.\n",
      "Band 11: 19 of 20468 bad. Replacing with 15.74144.\n",
      "Band 12: 20 of 20468 bad. Replacing with 16.41437.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20468 of 20468 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 3.7310176  4.220242  13.238924  ... 13.396565   4.8809614 40.78205  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0381\n",
      "  1% : 0.122\n",
      "  10% : 0.257\n",
      "  50% : 0.675\n",
      "  90% : 2.87\n",
      "  99% : 40.2\n",
      "  100% : 4.99e+03\n",
      "<chi^2/d.o.f.> = 1.07\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 57.30 s\n",
      "learning rate = 0.00020189651695545763\n",
      "setting learning rate to 0.00016529888822158653\n",
      "Iteration 10 of 20.\n",
      "Epoch 1/25\n",
      "118/128 [==========================>...] - ETA: 0s - loss: 0.9072 - mse: 0.8901\n",
      "Epoch 1: val_loss improved from inf to 0.89997, saving model to checkpoints/ext_3h_l1n2_2hidden_it9.e001_vl0.900.h5\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.9039 - mse: 0.8869 - val_loss: 0.9000 - val_mse: 0.8830\n",
      "Epoch 2/25\n",
      "125/128 [============================>.] - ETA: 0s - loss: 0.9036 - mse: 0.8866\n",
      "Epoch 2: val_loss improved from 0.89997 to 0.89821, saving model to checkpoints/ext_3h_l1n2_2hidden_it9.e002_vl0.898.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9038 - mse: 0.8868 - val_loss: 0.8982 - val_mse: 0.8813\n",
      "Epoch 3/25\n",
      "118/128 [==========================>...] - ETA: 0s - loss: 0.9037 - mse: 0.8867\n",
      "Epoch 3: val_loss improved from 0.89821 to 0.89756, saving model to checkpoints/ext_3h_l1n2_2hidden_it9.e003_vl0.898.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9035 - mse: 0.8866 - val_loss: 0.8976 - val_mse: 0.8806\n",
      "Epoch 4/25\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 0.9031 - mse: 0.8861\n",
      "Epoch 4: val_loss improved from 0.89756 to 0.89736, saving model to checkpoints/ext_3h_l1n2_2hidden_it9.e004_vl0.897.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9034 - mse: 0.8865 - val_loss: 0.8974 - val_mse: 0.8804\n",
      "Epoch 5/25\n",
      "118/128 [==========================>...] - ETA: 0s - loss: 0.9043 - mse: 0.8874\n",
      "Epoch 5: val_loss did not improve from 0.89736\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.9033 - mse: 0.8864 - val_loss: 0.8974 - val_mse: 0.8805\n",
      "Epoch 6/25\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 0.9032 - mse: 0.8863\n",
      "Epoch 6: val_loss did not improve from 0.89736\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9031 - mse: 0.8862 - val_loss: 0.8981 - val_mse: 0.8811\n",
      "Epoch 7/25\n",
      "118/128 [==========================>...] - ETA: 0s - loss: 0.9033 - mse: 0.8864\n",
      "Epoch 7: val_loss improved from 0.89736 to 0.89735, saving model to checkpoints/ext_3h_l1n2_2hidden_it9.e007_vl0.897.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9028 - mse: 0.8858 - val_loss: 0.8974 - val_mse: 0.8804\n",
      "Epoch 8/25\n",
      "123/128 [===========================>..] - ETA: 0s - loss: 0.9041 - mse: 0.8871\n",
      "Epoch 8: val_loss did not improve from 0.89735\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.9030 - mse: 0.8860 - val_loss: 0.8984 - val_mse: 0.8814\n",
      "Epoch 9/25\n",
      "120/128 [===========================>..] - ETA: 0s - loss: 0.9038 - mse: 0.8869\n",
      "Epoch 9: val_loss did not improve from 0.89735\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9029 - mse: 0.8859 - val_loss: 0.8983 - val_mse: 0.8813\n",
      "Epoch 10/25\n",
      "125/128 [============================>.] - ETA: 0s - loss: 0.9031 - mse: 0.8862\n",
      "Epoch 10: val_loss improved from 0.89735 to 0.89689, saving model to checkpoints/ext_3h_l1n2_2hidden_it9.e010_vl0.897.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9027 - mse: 0.8858 - val_loss: 0.8969 - val_mse: 0.8799\n",
      "Epoch 11/25\n",
      "124/128 [============================>.] - ETA: 0s - loss: 0.9028 - mse: 0.8859\n",
      "Epoch 11: val_loss improved from 0.89689 to 0.89562, saving model to checkpoints/ext_3h_l1n2_2hidden_it9.e011_vl0.896.h5\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.9024 - mse: 0.8854 - val_loss: 0.8956 - val_mse: 0.8787\n",
      "Epoch 12/25\n",
      "118/128 [==========================>...] - ETA: 0s - loss: 0.9045 - mse: 0.8876\n",
      "Epoch 12: val_loss did not improve from 0.89562\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9020 - mse: 0.8850 - val_loss: 0.8963 - val_mse: 0.8793\n",
      "Epoch 13/25\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 0.9004 - mse: 0.8834\n",
      "Epoch 13: val_loss did not improve from 0.89562\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9020 - mse: 0.8850 - val_loss: 0.8965 - val_mse: 0.8796\n",
      "Epoch 14/25\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 0.9023 - mse: 0.8853\n",
      "Epoch 14: val_loss did not improve from 0.89562\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9018 - mse: 0.8849 - val_loss: 0.8961 - val_mse: 0.8791\n",
      "Epoch 15/25\n",
      "120/128 [===========================>..] - ETA: 0s - loss: 0.9023 - mse: 0.8853\n",
      "Epoch 15: val_loss did not improve from 0.89562\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9015 - mse: 0.8845 - val_loss: 0.8961 - val_mse: 0.8791\n",
      "Epoch 16/25\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 0.9023 - mse: 0.8853\n",
      "Epoch 16: val_loss improved from 0.89562 to 0.89532, saving model to checkpoints/ext_3h_l1n2_2hidden_it9.e016_vl0.895.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9014 - mse: 0.8844 - val_loss: 0.8953 - val_mse: 0.8783\n",
      "Epoch 17/25\n",
      "124/128 [============================>.] - ETA: 0s - loss: 0.9002 - mse: 0.8832\n",
      "Epoch 17: val_loss did not improve from 0.89532\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9012 - mse: 0.8843 - val_loss: 0.8960 - val_mse: 0.8790\n",
      "Epoch 18/25\n",
      "122/128 [===========================>..] - ETA: 0s - loss: 0.9021 - mse: 0.8851\n",
      "Epoch 18: val_loss did not improve from 0.89532\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9011 - mse: 0.8841 - val_loss: 0.8954 - val_mse: 0.8784\n",
      "Epoch 19/25\n",
      "123/128 [===========================>..] - ETA: 0s - loss: 0.8998 - mse: 0.8828\n",
      "Epoch 19: val_loss did not improve from 0.89532\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9011 - mse: 0.8842 - val_loss: 0.8963 - val_mse: 0.8794\n",
      "Epoch 20/25\n",
      "121/128 [===========================>..] - ETA: 0s - loss: 0.9005 - mse: 0.8835\n",
      "Epoch 20: val_loss improved from 0.89532 to 0.89529, saving model to checkpoints/ext_3h_l1n2_2hidden_it9.e020_vl0.895.h5\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.9009 - mse: 0.8840 - val_loss: 0.8953 - val_mse: 0.8783\n",
      "Epoch 21/25\n",
      "125/128 [============================>.] - ETA: 0s - loss: 0.9003 - mse: 0.8834\n",
      "Epoch 21: val_loss improved from 0.89529 to 0.89435, saving model to checkpoints/ext_3h_l1n2_2hidden_it9.e021_vl0.894.h5\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9008 - mse: 0.8838 - val_loss: 0.8944 - val_mse: 0.8774\n",
      "Epoch 22/25\n",
      "117/128 [==========================>...] - ETA: 0s - loss: 0.9008 - mse: 0.8838\n",
      "Epoch 22: val_loss did not improve from 0.89435\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9009 - mse: 0.8839 - val_loss: 0.8951 - val_mse: 0.8781\n",
      "Epoch 23/25\n",
      "115/128 [=========================>....] - ETA: 0s - loss: 0.9018 - mse: 0.8849\n",
      "Epoch 23: val_loss did not improve from 0.89435\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.9008 - mse: 0.8838 - val_loss: 0.8957 - val_mse: 0.8787\n",
      "Epoch 24/25\n",
      "128/128 [==============================] - ETA: 0s - loss: 0.9005 - mse: 0.8835\n",
      "Epoch 24: val_loss improved from 0.89435 to 0.89417, saving model to checkpoints/ext_3h_l1n2_2hidden_it9.e024_vl0.894.h5\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.9005 - mse: 0.8835 - val_loss: 0.8942 - val_mse: 0.8772\n",
      "Epoch 25/25\n",
      "120/128 [===========================>..] - ETA: 0s - loss: 0.8996 - mse: 0.8826\n",
      "Epoch 25: val_loss did not improve from 0.89417\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 0.9002 - mse: 0.8832 - val_loss: 0.8958 - val_mse: 0.8789\n",
      "Time elapsed to train: 19.52 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.038 2.678 1.399 2.984 2.080 1.482 1.045 0.794 0.458 0.229 0.092 0.023 0.009]\n",
      "<R> = [2.038 2.678 1.399 2.984 2.080 1.482 1.045 0.794 0.458 0.229 0.092 0.023 0.009]\n",
      "s_R = [0.034 0.002 0.000 0.031 0.069 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [3.4195356 5.8960295 5.6036396 ... 4.841943  3.8639956 4.457653 ]\n",
      "ri = [ 0.23939991  0.17100048 -1.0026503  ...  0.26299953  0.16529942\n",
      "  0.17879963]\n",
      "gr = [0.6469002  0.50619984 0.59170055 ... 0.6164999  0.39999962 0.4033003 ]\n",
      "gaia_g = [2.816513  5.4193687 5.04416   ... 4.249029  3.470891  4.043084 ]\n",
      "bp_rp = [1.1274042 0.9681673 1.0677004 ... 1.1447258 0.8715458 0.8666172]\n",
      "mag_pred: [2.6161091 5.4540577 5.6760006 ... 4.2147427 3.8973072 3.202518 ]\n",
      "mag_pred: [2.6161091 5.4540577 5.6760006 ... 4.2147427 3.8973072 3.202518 ]\n",
      "Time elapsed to make plots: 18.27 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 184212 bad. Replacing with 14.76259.\n",
      "Band 1: 5 of 184212 bad. Replacing with 15.16047.\n",
      "Band 2: 5 of 184212 bad. Replacing with 14.19215.\n",
      "Band 3: 112 of 184212 bad. Replacing with 15.23910.\n",
      "Band 4: 216 of 184212 bad. Replacing with 14.74930.\n",
      "Band 5: 7889 of 184212 bad. Replacing with 14.61470.\n",
      "Band 6: 253 of 184212 bad. Replacing with 14.49600.\n",
      "Band 7: 69 of 184212 bad. Replacing with 14.44160.\n",
      "Band 8: 371 of 184212 bad. Replacing with 13.53800.\n",
      "Band 9: 380 of 184212 bad. Replacing with 13.15900.\n",
      "Band 10: 1544 of 184212 bad. Replacing with 13.07700.\n",
      "Band 11: 201 of 184212 bad. Replacing with 15.74240.\n",
      "Band 12: 223 of 184212 bad. Replacing with 16.41514.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 184209 of 184212 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 13.386416    1.8669883   5.395058  ...  48.365887  267.42526\n",
      "   6.71458  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.018\n",
      "  1% : 0.119\n",
      "  10% : 0.257\n",
      "  50% : 0.67\n",
      "  90% : 2.82\n",
      "  99% : 39.1\n",
      "  100% : 7.51e+03\n",
      "<chi^2/d.o.f.> = 1.06\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 4891 stars (2.66%) based on chi^2/dof > 12.6\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20468 bad. Replacing with 14.76698.\n",
      "Band 1: 0 of 20468 bad. Replacing with 15.16434.\n",
      "Band 2: 0 of 20468 bad. Replacing with 14.19739.\n",
      "Band 3: 13 of 20468 bad. Replacing with 15.24670.\n",
      "Band 4: 30 of 20468 bad. Replacing with 14.75285.\n",
      "Band 5: 918 of 20468 bad. Replacing with 14.62265.\n",
      "Band 6: 24 of 20468 bad. Replacing with 14.49655.\n",
      "Band 7: 10 of 20468 bad. Replacing with 14.44405.\n",
      "Band 8: 39 of 20468 bad. Replacing with 13.54000.\n",
      "Band 9: 42 of 20468 bad. Replacing with 13.15900.\n",
      "Band 10: 174 of 20468 bad. Replacing with 13.08100.\n",
      "Band 11: 19 of 20468 bad. Replacing with 15.74144.\n",
      "Band 12: 20 of 20468 bad. Replacing with 16.41437.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20468 of 20468 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 4.0054803  4.201413  13.084671  ... 12.704994   4.3956947 42.838287 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0346\n",
      "  1% : 0.121\n",
      "  10% : 0.26\n",
      "  50% : 0.678\n",
      "  90% : 2.84\n",
      "  99% : 39.9\n",
      "  100% : 4.98e+03\n",
      "<chi^2/d.o.f.> = 1.07\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 56.66 s\n",
      "learning rate = 0.00016529888671357185\n",
      "setting learning rate to 0.0001353352832366127\n",
      "Iteration 11 of 20.\n",
      "Epoch 1/25\n",
      "117/127 [==========================>...] - ETA: 0s - loss: 0.8459 - mse: 0.8289\n",
      "Epoch 1: val_loss improved from inf to 0.84041, saving model to checkpoints/ext_3h_l1n2_2hidden_it10.e001_vl0.840.h5\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.8463 - mse: 0.8293 - val_loss: 0.8404 - val_mse: 0.8235\n",
      "Epoch 2/25\n",
      "120/127 [===========================>..] - ETA: 0s - loss: 0.8459 - mse: 0.8290\n",
      "Epoch 2: val_loss improved from 0.84041 to 0.83998, saving model to checkpoints/ext_3h_l1n2_2hidden_it10.e002_vl0.840.h5\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.8460 - mse: 0.8291 - val_loss: 0.8400 - val_mse: 0.8231\n",
      "Epoch 3/25\n",
      "121/127 [===========================>..] - ETA: 0s - loss: 0.8464 - mse: 0.8295\n",
      "Epoch 3: val_loss improved from 0.83998 to 0.83961, saving model to checkpoints/ext_3h_l1n2_2hidden_it10.e003_vl0.840.h5\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.8460 - mse: 0.8291 - val_loss: 0.8396 - val_mse: 0.8227\n",
      "Epoch 4/25\n",
      "121/127 [===========================>..] - ETA: 0s - loss: 0.8461 - mse: 0.8292\n",
      "Epoch 4: val_loss improved from 0.83961 to 0.83938, saving model to checkpoints/ext_3h_l1n2_2hidden_it10.e004_vl0.839.h5\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.8460 - mse: 0.8291 - val_loss: 0.8394 - val_mse: 0.8225\n",
      "Epoch 5/25\n",
      "122/127 [===========================>..] - ETA: 0s - loss: 0.8465 - mse: 0.8296\n",
      "Epoch 5: val_loss did not improve from 0.83938\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.8459 - mse: 0.8290 - val_loss: 0.8394 - val_mse: 0.8225\n",
      "Epoch 6/25\n",
      "119/127 [===========================>..] - ETA: 0s - loss: 0.8458 - mse: 0.8289\n",
      "Epoch 6: val_loss did not improve from 0.83938\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.8458 - mse: 0.8289 - val_loss: 0.8395 - val_mse: 0.8226\n",
      "Epoch 7/25\n",
      "121/127 [===========================>..] - ETA: 0s - loss: 0.8456 - mse: 0.8287\n",
      "Epoch 7: val_loss improved from 0.83938 to 0.83907, saving model to checkpoints/ext_3h_l1n2_2hidden_it10.e007_vl0.839.h5\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.8457 - mse: 0.8288 - val_loss: 0.8391 - val_mse: 0.8222\n",
      "Epoch 8/25\n",
      "120/127 [===========================>..] - ETA: 0s - loss: 0.8455 - mse: 0.8286\n",
      "Epoch 8: val_loss did not improve from 0.83907\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.8456 - mse: 0.8287 - val_loss: 0.8391 - val_mse: 0.8222\n",
      "Epoch 9/25\n",
      "122/127 [===========================>..] - ETA: 0s - loss: 0.8464 - mse: 0.8296\n",
      "Epoch 9: val_loss improved from 0.83907 to 0.83881, saving model to checkpoints/ext_3h_l1n2_2hidden_it10.e009_vl0.839.h5\n",
      "127/127 [==============================] - 1s 7ms/step - loss: 0.8454 - mse: 0.8285 - val_loss: 0.8388 - val_mse: 0.8219\n",
      "Epoch 10/25\n",
      "127/127 [==============================] - ETA: 0s - loss: 0.8454 - mse: 0.8285\n",
      "Epoch 10: val_loss did not improve from 0.83881\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.8454 - mse: 0.8285 - val_loss: 0.8400 - val_mse: 0.8231\n",
      "Epoch 11/25\n",
      "124/127 [============================>.] - ETA: 0s - loss: 0.8456 - mse: 0.8287\n",
      "Epoch 11: val_loss did not improve from 0.83881\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.8452 - mse: 0.8284 - val_loss: 0.8391 - val_mse: 0.8222\n",
      "Epoch 12/25\n",
      "127/127 [==============================] - ETA: 0s - loss: 0.8452 - mse: 0.8283\n",
      "Epoch 12: val_loss improved from 0.83881 to 0.83873, saving model to checkpoints/ext_3h_l1n2_2hidden_it10.e012_vl0.839.h5\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.8452 - mse: 0.8283 - val_loss: 0.8387 - val_mse: 0.8219\n",
      "Epoch 13/25\n",
      "122/127 [===========================>..] - ETA: 0s - loss: 0.8459 - mse: 0.8291\n",
      "Epoch 13: val_loss did not improve from 0.83873\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.8452 - mse: 0.8283 - val_loss: 0.8391 - val_mse: 0.8222\n",
      "Epoch 14/25\n",
      "117/127 [==========================>...] - ETA: 0s - loss: 0.8448 - mse: 0.8279\n",
      "Epoch 14: val_loss improved from 0.83873 to 0.83847, saving model to checkpoints/ext_3h_l1n2_2hidden_it10.e014_vl0.838.h5\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.8451 - mse: 0.8283 - val_loss: 0.8385 - val_mse: 0.8216\n",
      "Epoch 15/25\n",
      "125/127 [============================>.] - ETA: 0s - loss: 0.8449 - mse: 0.8281\n",
      "Epoch 15: val_loss did not improve from 0.83847\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.8450 - mse: 0.8281 - val_loss: 0.8388 - val_mse: 0.8219\n",
      "Epoch 16/25\n",
      "122/127 [===========================>..] - ETA: 0s - loss: 0.8447 - mse: 0.8278\n",
      "Epoch 16: val_loss improved from 0.83847 to 0.83833, saving model to checkpoints/ext_3h_l1n2_2hidden_it10.e016_vl0.838.h5\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.8451 - mse: 0.8283 - val_loss: 0.8383 - val_mse: 0.8215\n",
      "Epoch 17/25\n",
      "119/127 [===========================>..] - ETA: 0s - loss: 0.8445 - mse: 0.8276\n",
      "Epoch 17: val_loss did not improve from 0.83833\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.8447 - mse: 0.8279 - val_loss: 0.8386 - val_mse: 0.8217\n",
      "Epoch 18/25\n",
      "118/127 [==========================>...] - ETA: 0s - loss: 0.8445 - mse: 0.8277\n",
      "Epoch 18: val_loss did not improve from 0.83833\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.8445 - mse: 0.8277 - val_loss: 0.8385 - val_mse: 0.8216\n",
      "Epoch 19/25\n",
      "124/127 [============================>.] - ETA: 0s - loss: 0.8449 - mse: 0.8280\n",
      "Epoch 19: val_loss did not improve from 0.83833\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.8449 - mse: 0.8281 - val_loss: 0.8385 - val_mse: 0.8217\n",
      "Epoch 20/25\n",
      "118/127 [==========================>...] - ETA: 0s - loss: 0.8437 - mse: 0.8268\n",
      "Epoch 20: val_loss improved from 0.83833 to 0.83815, saving model to checkpoints/ext_3h_l1n2_2hidden_it10.e020_vl0.838.h5\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.8444 - mse: 0.8276 - val_loss: 0.8382 - val_mse: 0.8213\n",
      "Epoch 21/25\n",
      "123/127 [============================>.] - ETA: 0s - loss: 0.8454 - mse: 0.8286\n",
      "Epoch 21: val_loss did not improve from 0.83815\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.8444 - mse: 0.8275 - val_loss: 0.8388 - val_mse: 0.8220\n",
      "Epoch 22/25\n",
      "122/127 [===========================>..] - ETA: 0s - loss: 0.8449 - mse: 0.8280\n",
      "Epoch 22: val_loss improved from 0.83815 to 0.83773, saving model to checkpoints/ext_3h_l1n2_2hidden_it10.e022_vl0.838.h5\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.8444 - mse: 0.8276 - val_loss: 0.8377 - val_mse: 0.8209\n",
      "Epoch 23/25\n",
      "121/127 [===========================>..] - ETA: 0s - loss: 0.8447 - mse: 0.8279\n",
      "Epoch 23: val_loss improved from 0.83773 to 0.83756, saving model to checkpoints/ext_3h_l1n2_2hidden_it10.e023_vl0.838.h5\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.8443 - mse: 0.8275 - val_loss: 0.8376 - val_mse: 0.8207\n",
      "Epoch 24/25\n",
      "122/127 [===========================>..] - ETA: 0s - loss: 0.8436 - mse: 0.8268\n",
      "Epoch 24: val_loss did not improve from 0.83756\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.8441 - mse: 0.8273 - val_loss: 0.8384 - val_mse: 0.8216\n",
      "Epoch 25/25\n",
      "117/127 [==========================>...] - ETA: 0s - loss: 0.8448 - mse: 0.8280\n",
      "Epoch 25: val_loss did not improve from 0.83756\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.8442 - mse: 0.8273 - val_loss: 0.8377 - val_mse: 0.8209\n",
      "Time elapsed to train: 19.85 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.132 2.796 1.468 3.114 2.171 1.553 1.102 0.842 0.492 0.244 0.096 0.022 0.007]\n",
      "<R> = [2.133 2.796 1.468 3.114 2.170 1.553 1.102 0.842 0.492 0.244 0.096 0.022 0.007]\n",
      "s_R = [0.036 0.004 0.000 0.035 0.067 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [3.4195356 5.8960295 5.6036396 ... 4.841943  3.8639956 4.457653 ]\n",
      "ri = [ 0.23939991  0.17100048 -1.0026503  ...  0.26299953  0.16529942\n",
      "  0.17879963]\n",
      "gr = [0.6469002  0.50619984 0.59170055 ... 0.6164999  0.39999962 0.4033003 ]\n",
      "gaia_g = [2.816513  5.4193687 5.04416   ... 4.249029  3.470891  4.043084 ]\n",
      "bp_rp = [1.1274042 0.9681673 1.0677004 ... 1.1447258 0.8715458 0.8666172]\n",
      "mag_pred: [2.5980437 5.4587984 5.6778316 ... 4.2052264 3.900145  3.20451  ]\n",
      "mag_pred: [2.5980437 5.4587984 5.6778316 ... 4.2052264 3.900145  3.20451  ]\n",
      "Time elapsed to make plots: 16.17 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 184212 bad. Replacing with 14.76259.\n",
      "Band 1: 5 of 184212 bad. Replacing with 15.16047.\n",
      "Band 2: 5 of 184212 bad. Replacing with 14.19215.\n",
      "Band 3: 112 of 184212 bad. Replacing with 15.23910.\n",
      "Band 4: 216 of 184212 bad. Replacing with 14.74930.\n",
      "Band 5: 7889 of 184212 bad. Replacing with 14.61470.\n",
      "Band 6: 253 of 184212 bad. Replacing with 14.49600.\n",
      "Band 7: 69 of 184212 bad. Replacing with 14.44160.\n",
      "Band 8: 371 of 184212 bad. Replacing with 13.53800.\n",
      "Band 9: 380 of 184212 bad. Replacing with 13.15900.\n",
      "Band 10: 1544 of 184212 bad. Replacing with 13.07700.\n",
      "Band 11: 201 of 184212 bad. Replacing with 15.74240.\n",
      "Band 12: 223 of 184212 bad. Replacing with 16.41514.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 184209 of 184212 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 13.5977      1.9275641   5.4778214 ...  50.417984  267.9213\n",
      "   6.4021606]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0177\n",
      "  1% : 0.117\n",
      "  10% : 0.252\n",
      "  50% : 0.662\n",
      "  90% : 2.82\n",
      "  99% : 39.1\n",
      "  100% : 7.49e+03\n",
      "<chi^2/d.o.f.> = 1.06\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 5964 stars (3.24%) based on chi^2/dof > 10.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20468 bad. Replacing with 14.76698.\n",
      "Band 1: 0 of 20468 bad. Replacing with 15.16434.\n",
      "Band 2: 0 of 20468 bad. Replacing with 14.19739.\n",
      "Band 3: 13 of 20468 bad. Replacing with 15.24670.\n",
      "Band 4: 30 of 20468 bad. Replacing with 14.75285.\n",
      "Band 5: 918 of 20468 bad. Replacing with 14.62265.\n",
      "Band 6: 24 of 20468 bad. Replacing with 14.49655.\n",
      "Band 7: 10 of 20468 bad. Replacing with 14.44405.\n",
      "Band 8: 39 of 20468 bad. Replacing with 13.54000.\n",
      "Band 9: 42 of 20468 bad. Replacing with 13.15900.\n",
      "Band 10: 174 of 20468 bad. Replacing with 13.08100.\n",
      "Band 11: 19 of 20468 bad. Replacing with 15.74144.\n",
      "Band 12: 20 of 20468 bad. Replacing with 16.41437.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20468 of 20468 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 3.4534125  4.2091627 12.818247  ... 12.02069    4.2969894 43.992634 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0396\n",
      "  1% : 0.118\n",
      "  10% : 0.256\n",
      "  50% : 0.67\n",
      "  90% : 2.82\n",
      "  99% : 39.6\n",
      "  100% : 4.98e+03\n",
      "<chi^2/d.o.f.> = 1.06\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 56.63 s\n",
      "learning rate = 0.00013533528544940054\n",
      "setting learning rate to 0.00011080315836233387\n",
      "Iteration 12 of 20.\n",
      "Epoch 1/25\n",
      "123/126 [============================>.] - ETA: 0s - loss: 0.7946 - mse: 0.7778\n",
      "Epoch 1: val_loss improved from inf to 0.78742, saving model to checkpoints/ext_3h_l1n2_2hidden_it11.e001_vl0.787.h5\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7950 - mse: 0.7782 - val_loss: 0.7874 - val_mse: 0.7706\n",
      "Epoch 2/25\n",
      "121/126 [===========================>..] - ETA: 0s - loss: 0.7944 - mse: 0.7776\n",
      "Epoch 2: val_loss did not improve from 0.78742\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7948 - mse: 0.7780 - val_loss: 0.7878 - val_mse: 0.7710\n",
      "Epoch 3/25\n",
      "118/126 [===========================>..] - ETA: 0s - loss: 0.7954 - mse: 0.7786\n",
      "Epoch 3: val_loss did not improve from 0.78742\n",
      "126/126 [==============================] - 1s 5ms/step - loss: 0.7948 - mse: 0.7780 - val_loss: 0.7875 - val_mse: 0.7707\n",
      "Epoch 4/25\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.7946 - mse: 0.7779\n",
      "Epoch 4: val_loss did not improve from 0.78742\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7946 - mse: 0.7779 - val_loss: 0.7879 - val_mse: 0.7712\n",
      "Epoch 5/25\n",
      "119/126 [===========================>..] - ETA: 0s - loss: 0.7948 - mse: 0.7780\n",
      "Epoch 5: val_loss improved from 0.78742 to 0.78723, saving model to checkpoints/ext_3h_l1n2_2hidden_it11.e005_vl0.787.h5\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7946 - mse: 0.7779 - val_loss: 0.7872 - val_mse: 0.7705\n",
      "Epoch 6/25\n",
      "121/126 [===========================>..] - ETA: 0s - loss: 0.7947 - mse: 0.7780\n",
      "Epoch 6: val_loss did not improve from 0.78723\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7945 - mse: 0.7777 - val_loss: 0.7875 - val_mse: 0.7708\n",
      "Epoch 7/25\n",
      "124/126 [============================>.] - ETA: 0s - loss: 0.7945 - mse: 0.7778\n",
      "Epoch 7: val_loss did not improve from 0.78723\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7946 - mse: 0.7779 - val_loss: 0.7887 - val_mse: 0.7720\n",
      "Epoch 8/25\n",
      "123/126 [============================>.] - ETA: 0s - loss: 0.7946 - mse: 0.7779\n",
      "Epoch 8: val_loss improved from 0.78723 to 0.78707, saving model to checkpoints/ext_3h_l1n2_2hidden_it11.e008_vl0.787.h5\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7945 - mse: 0.7777 - val_loss: 0.7871 - val_mse: 0.7703\n",
      "Epoch 9/25\n",
      "120/126 [===========================>..] - ETA: 0s - loss: 0.7953 - mse: 0.7785\n",
      "Epoch 9: val_loss improved from 0.78707 to 0.78704, saving model to checkpoints/ext_3h_l1n2_2hidden_it11.e009_vl0.787.h5\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7945 - mse: 0.7778 - val_loss: 0.7870 - val_mse: 0.7703\n",
      "Epoch 10/25\n",
      "122/126 [============================>.] - ETA: 0s - loss: 0.7937 - mse: 0.7770\n",
      "Epoch 10: val_loss improved from 0.78704 to 0.78682, saving model to checkpoints/ext_3h_l1n2_2hidden_it11.e010_vl0.787.h5\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7942 - mse: 0.7775 - val_loss: 0.7868 - val_mse: 0.7701\n",
      "Epoch 11/25\n",
      "125/126 [============================>.] - ETA: 0s - loss: 0.7943 - mse: 0.7775\n",
      "Epoch 11: val_loss did not improve from 0.78682\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7943 - mse: 0.7776 - val_loss: 0.7869 - val_mse: 0.7702\n",
      "Epoch 12/25\n",
      "125/126 [============================>.] - ETA: 0s - loss: 0.7946 - mse: 0.7779\n",
      "Epoch 12: val_loss did not improve from 0.78682\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7943 - mse: 0.7776 - val_loss: 0.7871 - val_mse: 0.7704\n",
      "Epoch 13/25\n",
      "115/126 [==========================>...] - ETA: 0s - loss: 0.7938 - mse: 0.7771\n",
      "Epoch 13: val_loss did not improve from 0.78682\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7941 - mse: 0.7774 - val_loss: 0.7876 - val_mse: 0.7709\n",
      "Epoch 14/25\n",
      "118/126 [===========================>..] - ETA: 0s - loss: 0.7942 - mse: 0.7775\n",
      "Epoch 14: val_loss improved from 0.78682 to 0.78674, saving model to checkpoints/ext_3h_l1n2_2hidden_it11.e014_vl0.787.h5\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7943 - mse: 0.7776 - val_loss: 0.7867 - val_mse: 0.7700\n",
      "Epoch 15/25\n",
      "121/126 [===========================>..] - ETA: 0s - loss: 0.7935 - mse: 0.7768\n",
      "Epoch 15: val_loss did not improve from 0.78674\n",
      "126/126 [==============================] - 1s 5ms/step - loss: 0.7944 - mse: 0.7777 - val_loss: 0.7871 - val_mse: 0.7704\n",
      "Epoch 16/25\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.7940 - mse: 0.7773\n",
      "Epoch 16: val_loss did not improve from 0.78674\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7940 - mse: 0.7773 - val_loss: 0.7871 - val_mse: 0.7704\n",
      "Epoch 17/25\n",
      "124/126 [============================>.] - ETA: 0s - loss: 0.7938 - mse: 0.7771\n",
      "Epoch 17: val_loss improved from 0.78674 to 0.78672, saving model to checkpoints/ext_3h_l1n2_2hidden_it11.e017_vl0.787.h5\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7939 - mse: 0.7773 - val_loss: 0.7867 - val_mse: 0.7700\n",
      "Epoch 18/25\n",
      "117/126 [==========================>...] - ETA: 0s - loss: 0.7938 - mse: 0.7771\n",
      "Epoch 18: val_loss improved from 0.78672 to 0.78648, saving model to checkpoints/ext_3h_l1n2_2hidden_it11.e018_vl0.786.h5\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7939 - mse: 0.7772 - val_loss: 0.7865 - val_mse: 0.7698\n",
      "Epoch 19/25\n",
      "125/126 [============================>.] - ETA: 0s - loss: 0.7942 - mse: 0.7775\n",
      "Epoch 19: val_loss did not improve from 0.78648\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7937 - mse: 0.7771 - val_loss: 0.7867 - val_mse: 0.7700\n",
      "Epoch 20/25\n",
      "124/126 [============================>.] - ETA: 0s - loss: 0.7941 - mse: 0.7775\n",
      "Epoch 20: val_loss improved from 0.78648 to 0.78640, saving model to checkpoints/ext_3h_l1n2_2hidden_it11.e020_vl0.786.h5\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7938 - mse: 0.7771 - val_loss: 0.7864 - val_mse: 0.7697\n",
      "Epoch 21/25\n",
      "118/126 [===========================>..] - ETA: 0s - loss: 0.7934 - mse: 0.7767\n",
      "Epoch 21: val_loss did not improve from 0.78640\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7938 - mse: 0.7771 - val_loss: 0.7870 - val_mse: 0.7703\n",
      "Epoch 22/25\n",
      "123/126 [============================>.] - ETA: 0s - loss: 0.7939 - mse: 0.7772\n",
      "Epoch 22: val_loss did not improve from 0.78640\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7938 - mse: 0.7771 - val_loss: 0.7866 - val_mse: 0.7699\n",
      "Epoch 23/25\n",
      "116/126 [==========================>...] - ETA: 0s - loss: 0.7942 - mse: 0.7776\n",
      "Epoch 23: val_loss did not improve from 0.78640\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7938 - mse: 0.7772 - val_loss: 0.7866 - val_mse: 0.7699\n",
      "Epoch 24/25\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.7936 - mse: 0.7769\n",
      "Epoch 24: val_loss did not improve from 0.78640\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7936 - mse: 0.7769 - val_loss: 0.7867 - val_mse: 0.7700\n",
      "Epoch 25/25\n",
      "118/126 [===========================>..] - ETA: 0s - loss: 0.7937 - mse: 0.7770\n",
      "Epoch 25: val_loss did not improve from 0.78640\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7936 - mse: 0.7769 - val_loss: 0.7870 - val_mse: 0.7703\n",
      "Time elapsed to train: 19.50 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.192 2.870 1.512 3.198 2.228 1.598 1.140 0.874 0.515 0.253 0.100 0.022 0.005]\n",
      "<R> = [2.192 2.870 1.512 3.198 2.228 1.598 1.140 0.874 0.515 0.253 0.100 0.022 0.005]\n",
      "s_R = [0.040 0.001 0.000 0.034 0.061 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [3.4195356 5.8960295 5.6036396 ... 4.841943  3.8639956 4.457653 ]\n",
      "ri = [ 0.23939991  0.17100048 -1.0026503  ...  0.26299953  0.16529942\n",
      "  0.17879963]\n",
      "gr = [0.6469002  0.50619984 0.59170055 ... 0.6164999  0.39999962 0.4033003 ]\n",
      "gaia_g = [2.816513  5.4193687 5.04416   ... 4.249029  3.470891  4.043084 ]\n",
      "bp_rp = [1.1274042 0.9681673 1.0677004 ... 1.1447258 0.8715458 0.8666172]\n",
      "mag_pred: [2.5808334 5.457925  5.6740303 ... 4.194429  3.8999565 3.2035608]\n",
      "mag_pred: [2.5808334 5.457925  5.6740303 ... 4.194429  3.8999565 3.2035608]\n",
      "Time elapsed to make plots: 16.48 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 184212 bad. Replacing with 14.76259.\n",
      "Band 1: 5 of 184212 bad. Replacing with 15.16047.\n",
      "Band 2: 5 of 184212 bad. Replacing with 14.19215.\n",
      "Band 3: 112 of 184212 bad. Replacing with 15.23910.\n",
      "Band 4: 216 of 184212 bad. Replacing with 14.74930.\n",
      "Band 5: 7889 of 184212 bad. Replacing with 14.61470.\n",
      "Band 6: 253 of 184212 bad. Replacing with 14.49600.\n",
      "Band 7: 69 of 184212 bad. Replacing with 14.44160.\n",
      "Band 8: 371 of 184212 bad. Replacing with 13.53800.\n",
      "Band 9: 380 of 184212 bad. Replacing with 13.15900.\n",
      "Band 10: 1544 of 184212 bad. Replacing with 13.07700.\n",
      "Band 11: 201 of 184212 bad. Replacing with 15.74240.\n",
      "Band 12: 223 of 184212 bad. Replacing with 16.41514.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 184209 of 184212 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 14.0803175   1.9833491   5.8063555 ...  52.164135  270.1209\n",
      "   6.123535 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0219\n",
      "  1% : 0.113\n",
      "  10% : 0.244\n",
      "  50% : 0.648\n",
      "  90% : 2.84\n",
      "  99% : 39.3\n",
      "  100% : 7.48e+03\n",
      "<chi^2/d.o.f.> = 1.05\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 7306 stars (3.97%) based on chi^2/dof > 7.9\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20468 bad. Replacing with 14.76698.\n",
      "Band 1: 0 of 20468 bad. Replacing with 15.16434.\n",
      "Band 2: 0 of 20468 bad. Replacing with 14.19739.\n",
      "Band 3: 13 of 20468 bad. Replacing with 15.24670.\n",
      "Band 4: 30 of 20468 bad. Replacing with 14.75285.\n",
      "Band 5: 918 of 20468 bad. Replacing with 14.62265.\n",
      "Band 6: 24 of 20468 bad. Replacing with 14.49655.\n",
      "Band 7: 10 of 20468 bad. Replacing with 14.44405.\n",
      "Band 8: 39 of 20468 bad. Replacing with 13.54000.\n",
      "Band 9: 42 of 20468 bad. Replacing with 13.15900.\n",
      "Band 10: 174 of 20468 bad. Replacing with 13.08100.\n",
      "Band 11: 19 of 20468 bad. Replacing with 15.74144.\n",
      "Band 12: 20 of 20468 bad. Replacing with 16.41437.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20468 of 20468 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 2.949758  3.820569 12.638012 ... 11.445426  4.328597 45.489475]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0391\n",
      "  1% : 0.116\n",
      "  10% : 0.247\n",
      "  50% : 0.656\n",
      "  90% : 2.83\n",
      "  99% : 39.8\n",
      "  100% : 4.98e+03\n",
      "<chi^2/d.o.f.> = 1.06\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 56.23 s\n",
      "learning rate = 0.00011080315744038671\n",
      "setting learning rate to 9.071795328941248e-05\n",
      "Iteration 13 of 20.\n",
      "Epoch 1/25\n",
      "120/125 [===========================>..] - ETA: 0s - loss: 0.7462 - mse: 0.7296\n",
      "Epoch 1: val_loss improved from inf to 0.73997, saving model to checkpoints/ext_3h_l1n2_2hidden_it12.e001_vl0.740.h5\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.7463 - mse: 0.7296 - val_loss: 0.7400 - val_mse: 0.7233\n",
      "Epoch 2/25\n",
      "123/125 [============================>.] - ETA: 0s - loss: 0.7458 - mse: 0.7292\n",
      "Epoch 2: val_loss did not improve from 0.73997\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7462 - mse: 0.7295 - val_loss: 0.7401 - val_mse: 0.7235\n",
      "Epoch 3/25\n",
      "118/125 [===========================>..] - ETA: 0s - loss: 0.7463 - mse: 0.7297\n",
      "Epoch 3: val_loss improved from 0.73997 to 0.73990, saving model to checkpoints/ext_3h_l1n2_2hidden_it12.e003_vl0.740.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7460 - mse: 0.7294 - val_loss: 0.7399 - val_mse: 0.7233\n",
      "Epoch 4/25\n",
      "123/125 [============================>.] - ETA: 0s - loss: 0.7460 - mse: 0.7294\n",
      "Epoch 4: val_loss did not improve from 0.73990\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7461 - mse: 0.7295 - val_loss: 0.7401 - val_mse: 0.7235\n",
      "Epoch 5/25\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.7460 - mse: 0.7294\n",
      "Epoch 5: val_loss did not improve from 0.73990\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7460 - mse: 0.7294 - val_loss: 0.7399 - val_mse: 0.7233\n",
      "Epoch 6/25\n",
      "120/125 [===========================>..] - ETA: 0s - loss: 0.7463 - mse: 0.7298\n",
      "Epoch 6: val_loss did not improve from 0.73990\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7460 - mse: 0.7294 - val_loss: 0.7405 - val_mse: 0.7239\n",
      "Epoch 7/25\n",
      "124/125 [============================>.] - ETA: 0s - loss: 0.7460 - mse: 0.7294\n",
      "Epoch 7: val_loss did not improve from 0.73990\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7460 - mse: 0.7294 - val_loss: 0.7403 - val_mse: 0.7237\n",
      "Epoch 8/25\n",
      "121/125 [============================>.] - ETA: 0s - loss: 0.7455 - mse: 0.7289\n",
      "Epoch 8: val_loss improved from 0.73990 to 0.73958, saving model to checkpoints/ext_3h_l1n2_2hidden_it12.e008_vl0.740.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7459 - mse: 0.7294 - val_loss: 0.7396 - val_mse: 0.7230\n",
      "Epoch 9/25\n",
      "118/125 [===========================>..] - ETA: 0s - loss: 0.7453 - mse: 0.7288\n",
      "Epoch 9: val_loss did not improve from 0.73958\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7458 - mse: 0.7292 - val_loss: 0.7397 - val_mse: 0.7232\n",
      "Epoch 10/25\n",
      "117/125 [===========================>..] - ETA: 0s - loss: 0.7467 - mse: 0.7301\n",
      "Epoch 10: val_loss did not improve from 0.73958\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7459 - mse: 0.7293 - val_loss: 0.7396 - val_mse: 0.7231\n",
      "Epoch 11/25\n",
      "123/125 [============================>.] - ETA: 0s - loss: 0.7457 - mse: 0.7291\n",
      "Epoch 11: val_loss improved from 0.73958 to 0.73947, saving model to checkpoints/ext_3h_l1n2_2hidden_it12.e011_vl0.739.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7457 - mse: 0.7292 - val_loss: 0.7395 - val_mse: 0.7229\n",
      "Epoch 12/25\n",
      "123/125 [============================>.] - ETA: 0s - loss: 0.7459 - mse: 0.7293\n",
      "Epoch 12: val_loss did not improve from 0.73947\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7457 - mse: 0.7292 - val_loss: 0.7399 - val_mse: 0.7234\n",
      "Epoch 13/25\n",
      "119/125 [===========================>..] - ETA: 0s - loss: 0.7456 - mse: 0.7291\n",
      "Epoch 13: val_loss did not improve from 0.73947\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7457 - mse: 0.7292 - val_loss: 0.7400 - val_mse: 0.7234\n",
      "Epoch 14/25\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.7456 - mse: 0.7291\n",
      "Epoch 14: val_loss did not improve from 0.73947\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7456 - mse: 0.7291 - val_loss: 0.7398 - val_mse: 0.7233\n",
      "Epoch 15/25\n",
      "117/125 [===========================>..] - ETA: 0s - loss: 0.7452 - mse: 0.7286\n",
      "Epoch 15: val_loss improved from 0.73947 to 0.73942, saving model to checkpoints/ext_3h_l1n2_2hidden_it12.e015_vl0.739.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7457 - mse: 0.7291 - val_loss: 0.7394 - val_mse: 0.7229\n",
      "Epoch 16/25\n",
      "123/125 [============================>.] - ETA: 0s - loss: 0.7454 - mse: 0.7289\n",
      "Epoch 16: val_loss did not improve from 0.73942\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7457 - mse: 0.7291 - val_loss: 0.7396 - val_mse: 0.7231\n",
      "Epoch 17/25\n",
      "123/125 [============================>.] - ETA: 0s - loss: 0.7458 - mse: 0.7293\n",
      "Epoch 17: val_loss did not improve from 0.73942\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7456 - mse: 0.7291 - val_loss: 0.7397 - val_mse: 0.7232\n",
      "Epoch 18/25\n",
      "122/125 [============================>.] - ETA: 0s - loss: 0.7456 - mse: 0.7291\n",
      "Epoch 18: val_loss improved from 0.73942 to 0.73916, saving model to checkpoints/ext_3h_l1n2_2hidden_it12.e018_vl0.739.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7456 - mse: 0.7290 - val_loss: 0.7392 - val_mse: 0.7226\n",
      "Epoch 19/25\n",
      "124/125 [============================>.] - ETA: 0s - loss: 0.7452 - mse: 0.7287\n",
      "Epoch 19: val_loss improved from 0.73916 to 0.73911, saving model to checkpoints/ext_3h_l1n2_2hidden_it12.e019_vl0.739.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7455 - mse: 0.7290 - val_loss: 0.7391 - val_mse: 0.7226\n",
      "Epoch 20/25\n",
      "121/125 [============================>.] - ETA: 0s - loss: 0.7453 - mse: 0.7288\n",
      "Epoch 20: val_loss did not improve from 0.73911\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7455 - mse: 0.7290 - val_loss: 0.7395 - val_mse: 0.7230\n",
      "Epoch 21/25\n",
      "118/125 [===========================>..] - ETA: 0s - loss: 0.7456 - mse: 0.7291\n",
      "Epoch 21: val_loss did not improve from 0.73911\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7454 - mse: 0.7289 - val_loss: 0.7399 - val_mse: 0.7234\n",
      "Epoch 22/25\n",
      "115/125 [==========================>...] - ETA: 0s - loss: 0.7457 - mse: 0.7292\n",
      "Epoch 22: val_loss improved from 0.73911 to 0.73898, saving model to checkpoints/ext_3h_l1n2_2hidden_it12.e022_vl0.739.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7453 - mse: 0.7288 - val_loss: 0.7390 - val_mse: 0.7225\n",
      "Epoch 23/25\n",
      "116/125 [==========================>...] - ETA: 0s - loss: 0.7464 - mse: 0.7299\n",
      "Epoch 23: val_loss did not improve from 0.73898\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7453 - mse: 0.7288 - val_loss: 0.7393 - val_mse: 0.7228\n",
      "Epoch 24/25\n",
      "119/125 [===========================>..] - ETA: 0s - loss: 0.7462 - mse: 0.7297\n",
      "Epoch 24: val_loss did not improve from 0.73898\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7453 - mse: 0.7288 - val_loss: 0.7393 - val_mse: 0.7228\n",
      "Epoch 25/25\n",
      "123/125 [============================>.] - ETA: 0s - loss: 0.7452 - mse: 0.7287\n",
      "Epoch 25: val_loss did not improve from 0.73898\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7452 - mse: 0.7287 - val_loss: 0.7393 - val_mse: 0.7229\n",
      "Time elapsed to train: 19.23 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.230 2.915 1.540 3.247 2.265 1.626 1.163 0.893 0.530 0.260 0.104 0.023 0.005]\n",
      "<R> = [2.230 2.915 1.540 3.247 2.264 1.626 1.163 0.893 0.530 0.260 0.104 0.023 0.005]\n",
      "s_R = [0.041 0.001 0.000 0.035 0.056 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [3.4195356 5.8960295 5.6036396 ... 4.841943  3.8639956 4.457653 ]\n",
      "ri = [ 0.23939991  0.17100048 -1.0026503  ...  0.26299953  0.16529942\n",
      "  0.17879963]\n",
      "gr = [0.6469002  0.50619984 0.59170055 ... 0.6164999  0.39999962 0.4033003 ]\n",
      "gaia_g = [2.816513  5.4193687 5.04416   ... 4.249029  3.470891  4.043084 ]\n",
      "bp_rp = [1.1274042 0.9681673 1.0677004 ... 1.1447258 0.8715458 0.8666172]\n",
      "mag_pred: [2.5639887 5.456559  5.6699257 ... 4.1811566 3.8949525 3.1992805]\n",
      "mag_pred: [2.5639887 5.456559  5.6699257 ... 4.1811566 3.8949525 3.1992805]\n",
      "Time elapsed to make plots: 16.10 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 184212 bad. Replacing with 14.76259.\n",
      "Band 1: 5 of 184212 bad. Replacing with 15.16047.\n",
      "Band 2: 5 of 184212 bad. Replacing with 14.19215.\n",
      "Band 3: 112 of 184212 bad. Replacing with 15.23910.\n",
      "Band 4: 216 of 184212 bad. Replacing with 14.74930.\n",
      "Band 5: 7889 of 184212 bad. Replacing with 14.61470.\n",
      "Band 6: 253 of 184212 bad. Replacing with 14.49600.\n",
      "Band 7: 69 of 184212 bad. Replacing with 14.44160.\n",
      "Band 8: 371 of 184212 bad. Replacing with 13.53800.\n",
      "Band 9: 380 of 184212 bad. Replacing with 13.15900.\n",
      "Band 10: 1544 of 184212 bad. Replacing with 13.07700.\n",
      "Band 11: 201 of 184212 bad. Replacing with 15.74240.\n",
      "Band 12: 223 of 184212 bad. Replacing with 16.41514.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 184209 of 184212 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 13.948347    1.8482039   5.747533  ...  51.99527   269.26697\n",
      "   6.0140786]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0215\n",
      "  1% : 0.113\n",
      "  10% : 0.242\n",
      "  50% : 0.642\n",
      "  90% : 2.82\n",
      "  99% : 39.3\n",
      "  100% : 7.45e+03\n",
      "<chi^2/d.o.f.> = 1.04\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 8875 stars (4.82%) based on chi^2/dof > 6.3\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20468 bad. Replacing with 14.76698.\n",
      "Band 1: 0 of 20468 bad. Replacing with 15.16434.\n",
      "Band 2: 0 of 20468 bad. Replacing with 14.19739.\n",
      "Band 3: 13 of 20468 bad. Replacing with 15.24670.\n",
      "Band 4: 30 of 20468 bad. Replacing with 14.75285.\n",
      "Band 5: 918 of 20468 bad. Replacing with 14.62265.\n",
      "Band 6: 24 of 20468 bad. Replacing with 14.49655.\n",
      "Band 7: 10 of 20468 bad. Replacing with 14.44405.\n",
      "Band 8: 39 of 20468 bad. Replacing with 13.54000.\n",
      "Band 9: 42 of 20468 bad. Replacing with 13.15900.\n",
      "Band 10: 174 of 20468 bad. Replacing with 13.08100.\n",
      "Band 11: 19 of 20468 bad. Replacing with 15.74144.\n",
      "Band 12: 20 of 20468 bad. Replacing with 16.41437.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20468 of 20468 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 3.0278082  3.792844  12.2315    ... 11.517178   4.073283  47.991177 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0431\n",
      "  1% : 0.115\n",
      "  10% : 0.246\n",
      "  50% : 0.651\n",
      "  90% : 2.81\n",
      "  99% : 39.9\n",
      "  100% : 4.97e+03\n",
      "<chi^2/d.o.f.> = 1.05\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 55.73 s\n",
      "learning rate = 9.071795648196712e-05\n",
      "setting learning rate to 7.427357821433387e-05\n",
      "Iteration 14 of 20.\n",
      "Epoch 1/25\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.7030 - mse: 0.6865\n",
      "Epoch 1: val_loss improved from inf to 0.69875, saving model to checkpoints/ext_3h_l1n2_2hidden_it13.e001_vl0.699.h5\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.7025 - mse: 0.6861 - val_loss: 0.6987 - val_mse: 0.6823\n",
      "Epoch 2/25\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.7026 - mse: 0.6861\n",
      "Epoch 2: val_loss improved from 0.69875 to 0.69870, saving model to checkpoints/ext_3h_l1n2_2hidden_it13.e002_vl0.699.h5\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7025 - mse: 0.6860 - val_loss: 0.6987 - val_mse: 0.6822\n",
      "Epoch 3/25\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.7020 - mse: 0.6856\n",
      "Epoch 3: val_loss did not improve from 0.69870\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7024 - mse: 0.6859 - val_loss: 0.6988 - val_mse: 0.6823\n",
      "Epoch 4/25\n",
      "118/124 [===========================>..] - ETA: 0s - loss: 0.7022 - mse: 0.6858\n",
      "Epoch 4: val_loss did not improve from 0.69870\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7024 - mse: 0.6860 - val_loss: 0.6989 - val_mse: 0.6825\n",
      "Epoch 5/25\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.7025 - mse: 0.6861\n",
      "Epoch 5: val_loss did not improve from 0.69870\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7024 - mse: 0.6860 - val_loss: 0.6994 - val_mse: 0.6830\n",
      "Epoch 6/25\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.7019 - mse: 0.6854\n",
      "Epoch 6: val_loss did not improve from 0.69870\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7022 - mse: 0.6858 - val_loss: 0.6987 - val_mse: 0.6823\n",
      "Epoch 7/25\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.7023 - mse: 0.6859\n",
      "Epoch 7: val_loss improved from 0.69870 to 0.69856, saving model to checkpoints/ext_3h_l1n2_2hidden_it13.e007_vl0.699.h5\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7022 - mse: 0.6858 - val_loss: 0.6986 - val_mse: 0.6822\n",
      "Epoch 8/25\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.7019 - mse: 0.6855\n",
      "Epoch 8: val_loss improved from 0.69856 to 0.69856, saving model to checkpoints/ext_3h_l1n2_2hidden_it13.e008_vl0.699.h5\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7022 - mse: 0.6858 - val_loss: 0.6986 - val_mse: 0.6822\n",
      "Epoch 9/25\n",
      "114/124 [==========================>...] - ETA: 0s - loss: 0.7026 - mse: 0.6862\n",
      "Epoch 9: val_loss did not improve from 0.69856\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7024 - mse: 0.6860 - val_loss: 0.6991 - val_mse: 0.6827\n",
      "Epoch 10/25\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.7021 - mse: 0.6857\n",
      "Epoch 10: val_loss did not improve from 0.69856\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7022 - mse: 0.6858 - val_loss: 0.6987 - val_mse: 0.6823\n",
      "Epoch 11/25\n",
      "112/124 [==========================>...] - ETA: 0s - loss: 0.7015 - mse: 0.6851\n",
      "Epoch 11: val_loss did not improve from 0.69856\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7022 - mse: 0.6858 - val_loss: 0.6992 - val_mse: 0.6829\n",
      "Epoch 12/25\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.7025 - mse: 0.6862\n",
      "Epoch 12: val_loss did not improve from 0.69856\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7022 - mse: 0.6858 - val_loss: 0.6988 - val_mse: 0.6825\n",
      "Epoch 13/25\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.7022 - mse: 0.6858\n",
      "Epoch 13: val_loss did not improve from 0.69856\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.7022 - mse: 0.6858 - val_loss: 0.6986 - val_mse: 0.6823\n",
      "Epoch 14/25\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.7019 - mse: 0.6855\n",
      "Epoch 14: val_loss did not improve from 0.69856\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7021 - mse: 0.6857 - val_loss: 0.6988 - val_mse: 0.6824\n",
      "Epoch 15/25\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.7020 - mse: 0.6856\n",
      "Epoch 15: val_loss did not improve from 0.69856\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7020 - mse: 0.6857 - val_loss: 0.6988 - val_mse: 0.6824\n",
      "Epoch 16/25\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.7024 - mse: 0.6860\n",
      "Epoch 16: val_loss improved from 0.69856 to 0.69849, saving model to checkpoints/ext_3h_l1n2_2hidden_it13.e016_vl0.698.h5\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7021 - mse: 0.6857 - val_loss: 0.6985 - val_mse: 0.6821\n",
      "Epoch 17/25\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.7019 - mse: 0.6856\n",
      "Epoch 17: val_loss improved from 0.69849 to 0.69833, saving model to checkpoints/ext_3h_l1n2_2hidden_it13.e017_vl0.698.h5\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.7020 - mse: 0.6856 - val_loss: 0.6983 - val_mse: 0.6820\n",
      "Epoch 18/25\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.7021 - mse: 0.6858\n",
      "Epoch 18: val_loss improved from 0.69833 to 0.69826, saving model to checkpoints/ext_3h_l1n2_2hidden_it13.e018_vl0.698.h5\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7019 - mse: 0.6856 - val_loss: 0.6983 - val_mse: 0.6819\n",
      "Epoch 19/25\n",
      "120/124 [============================>.] - ETA: 0s - loss: 0.7022 - mse: 0.6858\n",
      "Epoch 19: val_loss improved from 0.69826 to 0.69823, saving model to checkpoints/ext_3h_l1n2_2hidden_it13.e019_vl0.698.h5\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7019 - mse: 0.6856 - val_loss: 0.6982 - val_mse: 0.6819\n",
      "Epoch 20/25\n",
      "121/124 [============================>.] - ETA: 0s - loss: 0.7022 - mse: 0.6858\n",
      "Epoch 20: val_loss improved from 0.69823 to 0.69823, saving model to checkpoints/ext_3h_l1n2_2hidden_it13.e020_vl0.698.h5\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7019 - mse: 0.6856 - val_loss: 0.6982 - val_mse: 0.6819\n",
      "Epoch 21/25\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.7019 - mse: 0.6856\n",
      "Epoch 21: val_loss improved from 0.69823 to 0.69821, saving model to checkpoints/ext_3h_l1n2_2hidden_it13.e021_vl0.698.h5\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7019 - mse: 0.6856 - val_loss: 0.6982 - val_mse: 0.6819\n",
      "Epoch 22/25\n",
      "122/124 [============================>.] - ETA: 0s - loss: 0.7020 - mse: 0.6856\n",
      "Epoch 22: val_loss did not improve from 0.69821\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7019 - mse: 0.6855 - val_loss: 0.6984 - val_mse: 0.6821\n",
      "Epoch 23/25\n",
      "119/124 [===========================>..] - ETA: 0s - loss: 0.7020 - mse: 0.6857\n",
      "Epoch 23: val_loss did not improve from 0.69821\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7019 - mse: 0.6855 - val_loss: 0.6982 - val_mse: 0.6819\n",
      "Epoch 24/25\n",
      "115/124 [==========================>...] - ETA: 0s - loss: 0.7023 - mse: 0.6860\n",
      "Epoch 24: val_loss improved from 0.69821 to 0.69812, saving model to checkpoints/ext_3h_l1n2_2hidden_it13.e024_vl0.698.h5\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7018 - mse: 0.6855 - val_loss: 0.6981 - val_mse: 0.6818\n",
      "Epoch 25/25\n",
      "116/124 [===========================>..] - ETA: 0s - loss: 0.7022 - mse: 0.6859\n",
      "Epoch 25: val_loss did not improve from 0.69812\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7018 - mse: 0.6855 - val_loss: 0.6983 - val_mse: 0.6820\n",
      "Time elapsed to train: 19.58 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.252 2.942 1.556 3.276 2.286 1.643 1.176 0.903 0.538 0.264 0.108 0.024 0.004]\n",
      "<R> = [2.253 2.942 1.556 3.276 2.285 1.643 1.176 0.903 0.538 0.264 0.108 0.024 0.004]\n",
      "s_R = [0.043 0.001 0.000 0.033 0.051 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [3.4195356 5.8960295 5.6036396 ... 4.841943  3.8639956 4.457653 ]\n",
      "ri = [ 0.23939991  0.17100048 -1.0026503  ...  0.26299953  0.16529942\n",
      "  0.17879963]\n",
      "gr = [0.6469002  0.50619984 0.59170055 ... 0.6164999  0.39999962 0.4033003 ]\n",
      "gaia_g = [2.816513  5.4193687 5.04416   ... 4.249029  3.470891  4.043084 ]\n",
      "bp_rp = [1.1274042 0.9681673 1.0677004 ... 1.1447258 0.8715458 0.8666172]\n",
      "mag_pred: [2.5384061 5.4590225 5.6700544 ... 4.170985  3.8932014 3.1958642]\n",
      "mag_pred: [2.5384061 5.4590225 5.6700544 ... 4.170985  3.8932014 3.1958642]\n",
      "Time elapsed to make plots: 19.49 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 184212 bad. Replacing with 14.76259.\n",
      "Band 1: 5 of 184212 bad. Replacing with 15.16047.\n",
      "Band 2: 5 of 184212 bad. Replacing with 14.19215.\n",
      "Band 3: 112 of 184212 bad. Replacing with 15.23910.\n",
      "Band 4: 216 of 184212 bad. Replacing with 14.74930.\n",
      "Band 5: 7889 of 184212 bad. Replacing with 14.61470.\n",
      "Band 6: 253 of 184212 bad. Replacing with 14.49600.\n",
      "Band 7: 69 of 184212 bad. Replacing with 14.44160.\n",
      "Band 8: 371 of 184212 bad. Replacing with 13.53800.\n",
      "Band 9: 380 of 184212 bad. Replacing with 13.15900.\n",
      "Band 10: 1544 of 184212 bad. Replacing with 13.07700.\n",
      "Band 11: 201 of 184212 bad. Replacing with 15.74240.\n",
      "Band 12: 223 of 184212 bad. Replacing with 16.41514.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 184209 of 184212 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 14.315941    1.9151564   5.781351  ...  52.273586  269.48312\n",
      "   5.7190795]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0228\n",
      "  1% : 0.111\n",
      "  10% : 0.238\n",
      "  50% : 0.633\n",
      "  90% : 2.81\n",
      "  99% : 39.5\n",
      "  100% : 7.43e+03\n",
      "<chi^2/d.o.f.> = 1.03\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 10895 stars (5.91%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20468 bad. Replacing with 14.76698.\n",
      "Band 1: 0 of 20468 bad. Replacing with 15.16434.\n",
      "Band 2: 0 of 20468 bad. Replacing with 14.19739.\n",
      "Band 3: 13 of 20468 bad. Replacing with 15.24670.\n",
      "Band 4: 30 of 20468 bad. Replacing with 14.75285.\n",
      "Band 5: 918 of 20468 bad. Replacing with 14.62265.\n",
      "Band 6: 24 of 20468 bad. Replacing with 14.49655.\n",
      "Band 7: 10 of 20468 bad. Replacing with 14.44405.\n",
      "Band 8: 39 of 20468 bad. Replacing with 13.54000.\n",
      "Band 9: 42 of 20468 bad. Replacing with 13.15900.\n",
      "Band 10: 174 of 20468 bad. Replacing with 13.08100.\n",
      "Band 11: 19 of 20468 bad. Replacing with 15.74144.\n",
      "Band 12: 20 of 20468 bad. Replacing with 16.41437.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20468 of 20468 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 2.943458   3.4957504 11.908109  ... 11.433179   4.1218543 49.393887 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0423\n",
      "  1% : 0.113\n",
      "  10% : 0.242\n",
      "  50% : 0.642\n",
      "  90% : 2.82\n",
      "  99% : 39.9\n",
      "  100% : 4.97e+03\n",
      "<chi^2/d.o.f.> = 1.04\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 55.92 s\n",
      "learning rate = 7.427357923006639e-05\n",
      "setting learning rate to 6.0810062625217954e-05\n",
      "Iteration 15 of 20.\n",
      "Epoch 1/25\n",
      "115/123 [===========================>..] - ETA: 0s - loss: 0.6596 - mse: 0.6433\n",
      "Epoch 1: val_loss improved from inf to 0.65775, saving model to checkpoints/ext_3h_l1n2_2hidden_it14.e001_vl0.658.h5\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6597 - mse: 0.6434 - val_loss: 0.6578 - val_mse: 0.6415\n",
      "Epoch 2/25\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6596 - mse: 0.6433\n",
      "Epoch 2: val_loss improved from 0.65775 to 0.65774, saving model to checkpoints/ext_3h_l1n2_2hidden_it14.e002_vl0.658.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6596 - mse: 0.6433 - val_loss: 0.6577 - val_mse: 0.6415\n",
      "Epoch 3/25\n",
      "120/123 [============================>.] - ETA: 0s - loss: 0.6594 - mse: 0.6431\n",
      "Epoch 3: val_loss did not improve from 0.65774\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6596 - mse: 0.6433 - val_loss: 0.6577 - val_mse: 0.6415\n",
      "Epoch 4/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 0.6599 - mse: 0.6437\n",
      "Epoch 4: val_loss improved from 0.65774 to 0.65742, saving model to checkpoints/ext_3h_l1n2_2hidden_it14.e004_vl0.657.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6595 - mse: 0.6432 - val_loss: 0.6574 - val_mse: 0.6412\n",
      "Epoch 5/25\n",
      "115/123 [===========================>..] - ETA: 0s - loss: 0.6594 - mse: 0.6431\n",
      "Epoch 5: val_loss did not improve from 0.65742\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6596 - mse: 0.6434 - val_loss: 0.6578 - val_mse: 0.6416\n",
      "Epoch 6/25\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6596 - mse: 0.6434\n",
      "Epoch 6: val_loss improved from 0.65742 to 0.65738, saving model to checkpoints/ext_3h_l1n2_2hidden_it14.e006_vl0.657.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6596 - mse: 0.6433 - val_loss: 0.6574 - val_mse: 0.6411\n",
      "Epoch 7/25\n",
      "114/123 [==========================>...] - ETA: 0s - loss: 0.6593 - mse: 0.6430\n",
      "Epoch 7: val_loss improved from 0.65738 to 0.65731, saving model to checkpoints/ext_3h_l1n2_2hidden_it14.e007_vl0.657.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6595 - mse: 0.6432 - val_loss: 0.6573 - val_mse: 0.6411\n",
      "Epoch 8/25\n",
      "115/123 [===========================>..] - ETA: 0s - loss: 0.6596 - mse: 0.6434\n",
      "Epoch 8: val_loss improved from 0.65731 to 0.65728, saving model to checkpoints/ext_3h_l1n2_2hidden_it14.e008_vl0.657.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6595 - mse: 0.6433 - val_loss: 0.6573 - val_mse: 0.6410\n",
      "Epoch 9/25\n",
      "121/123 [============================>.] - ETA: 0s - loss: 0.6595 - mse: 0.6433\n",
      "Epoch 9: val_loss improved from 0.65728 to 0.65722, saving model to checkpoints/ext_3h_l1n2_2hidden_it14.e009_vl0.657.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6594 - mse: 0.6432 - val_loss: 0.6572 - val_mse: 0.6410\n",
      "Epoch 10/25\n",
      "120/123 [============================>.] - ETA: 0s - loss: 0.6592 - mse: 0.6429\n",
      "Epoch 10: val_loss did not improve from 0.65722\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6594 - mse: 0.6432 - val_loss: 0.6572 - val_mse: 0.6410\n",
      "Epoch 11/25\n",
      "113/123 [==========================>...] - ETA: 0s - loss: 0.6598 - mse: 0.6436\n",
      "Epoch 11: val_loss did not improve from 0.65722\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6594 - mse: 0.6432 - val_loss: 0.6576 - val_mse: 0.6414\n",
      "Epoch 12/25\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6594 - mse: 0.6432\n",
      "Epoch 12: val_loss did not improve from 0.65722\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6594 - mse: 0.6431 - val_loss: 0.6574 - val_mse: 0.6412\n",
      "Epoch 13/25\n",
      "121/123 [============================>.] - ETA: 0s - loss: 0.6592 - mse: 0.6430\n",
      "Epoch 13: val_loss did not improve from 0.65722\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6594 - mse: 0.6432 - val_loss: 0.6573 - val_mse: 0.6411\n",
      "Epoch 14/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 0.6591 - mse: 0.6429\n",
      "Epoch 14: val_loss did not improve from 0.65722\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6593 - mse: 0.6431 - val_loss: 0.6574 - val_mse: 0.6412\n",
      "Epoch 15/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 0.6588 - mse: 0.6426\n",
      "Epoch 15: val_loss did not improve from 0.65722\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6593 - mse: 0.6431 - val_loss: 0.6573 - val_mse: 0.6411\n",
      "Epoch 16/25\n",
      "113/123 [==========================>...] - ETA: 0s - loss: 0.6594 - mse: 0.6432\n",
      "Epoch 16: val_loss did not improve from 0.65722\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.6593 - mse: 0.6431 - val_loss: 0.6573 - val_mse: 0.6411\n",
      "Epoch 17/25\n",
      "120/123 [============================>.] - ETA: 0s - loss: 0.6592 - mse: 0.6430\n",
      "Epoch 17: val_loss improved from 0.65722 to 0.65708, saving model to checkpoints/ext_3h_l1n2_2hidden_it14.e017_vl0.657.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6592 - mse: 0.6431 - val_loss: 0.6571 - val_mse: 0.6409\n",
      "Epoch 18/25\n",
      "113/123 [==========================>...] - ETA: 0s - loss: 0.6595 - mse: 0.6433\n",
      "Epoch 18: val_loss improved from 0.65708 to 0.65701, saving model to checkpoints/ext_3h_l1n2_2hidden_it14.e018_vl0.657.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6593 - mse: 0.6431 - val_loss: 0.6570 - val_mse: 0.6408\n",
      "Epoch 19/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 0.6590 - mse: 0.6429\n",
      "Epoch 19: val_loss did not improve from 0.65701\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6592 - mse: 0.6430 - val_loss: 0.6574 - val_mse: 0.6412\n",
      "Epoch 20/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 0.6596 - mse: 0.6434\n",
      "Epoch 20: val_loss did not improve from 0.65701\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6592 - mse: 0.6431 - val_loss: 0.6574 - val_mse: 0.6412\n",
      "Epoch 21/25\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6592 - mse: 0.6431\n",
      "Epoch 21: val_loss did not improve from 0.65701\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6593 - mse: 0.6431 - val_loss: 0.6572 - val_mse: 0.6410\n",
      "Epoch 22/25\n",
      "121/123 [============================>.] - ETA: 0s - loss: 0.6595 - mse: 0.6433\n",
      "Epoch 22: val_loss did not improve from 0.65701\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6592 - mse: 0.6430 - val_loss: 0.6570 - val_mse: 0.6409\n",
      "Epoch 23/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 0.6589 - mse: 0.6427\n",
      "Epoch 23: val_loss did not improve from 0.65701\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6591 - mse: 0.6430 - val_loss: 0.6574 - val_mse: 0.6413\n",
      "Epoch 24/25\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.6591 - mse: 0.6429\n",
      "Epoch 24: val_loss improved from 0.65701 to 0.65690, saving model to checkpoints/ext_3h_l1n2_2hidden_it14.e024_vl0.657.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6591 - mse: 0.6429 - val_loss: 0.6569 - val_mse: 0.6408\n",
      "Epoch 25/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 0.6581 - mse: 0.6420\n",
      "Epoch 25: val_loss did not improve from 0.65690\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6591 - mse: 0.6430 - val_loss: 0.6580 - val_mse: 0.6419\n",
      "Time elapsed to train: 19.12 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.266 2.956 1.566 3.292 2.297 1.654 1.184 0.910 0.543 0.267 0.110 0.025 0.004]\n",
      "<R> = [2.266 2.956 1.566 3.292 2.297 1.654 1.184 0.910 0.543 0.267 0.110 0.025 0.004]\n",
      "s_R = [0.044 0.001 0.000 0.030 0.046 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [3.4195356 5.8960295 5.6036396 ... 4.841943  3.8639956 4.457653 ]\n",
      "ri = [ 0.23939991  0.17100048 -1.0026503  ...  0.26299953  0.16529942\n",
      "  0.17879963]\n",
      "gr = [0.6469002  0.50619984 0.59170055 ... 0.6164999  0.39999962 0.4033003 ]\n",
      "gaia_g = [2.816513  5.4193687 5.04416   ... 4.249029  3.470891  4.043084 ]\n",
      "bp_rp = [1.1274042 0.9681673 1.0677004 ... 1.1447258 0.8715458 0.8666172]\n",
      "mag_pred: [2.5189245 5.461398  5.669313  ... 4.162835  3.8954048 3.1983857]\n",
      "mag_pred: [2.5189245 5.461398  5.669313  ... 4.162835  3.8954048 3.1983857]\n",
      "Time elapsed to make plots: 16.32 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 184212 bad. Replacing with 14.76259.\n",
      "Band 1: 5 of 184212 bad. Replacing with 15.16047.\n",
      "Band 2: 5 of 184212 bad. Replacing with 14.19215.\n",
      "Band 3: 112 of 184212 bad. Replacing with 15.23910.\n",
      "Band 4: 216 of 184212 bad. Replacing with 14.74930.\n",
      "Band 5: 7889 of 184212 bad. Replacing with 14.61470.\n",
      "Band 6: 253 of 184212 bad. Replacing with 14.49600.\n",
      "Band 7: 69 of 184212 bad. Replacing with 14.44160.\n",
      "Band 8: 371 of 184212 bad. Replacing with 13.53800.\n",
      "Band 9: 380 of 184212 bad. Replacing with 13.15900.\n",
      "Band 10: 1544 of 184212 bad. Replacing with 13.07700.\n",
      "Band 11: 201 of 184212 bad. Replacing with 15.74240.\n",
      "Band 12: 223 of 184212 bad. Replacing with 16.41514.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 184209 of 184212 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 13.256655    1.8614584   5.793771  ...  50.757233  268.69418\n",
      "   5.7405686]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0198\n",
      "  1% : 0.113\n",
      "  10% : 0.241\n",
      "  50% : 0.633\n",
      "  90% : 2.77\n",
      "  99% : 40.1\n",
      "  100% : 7.42e+03\n",
      "<chi^2/d.o.f.> = 1.03\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 10822 stars (5.87%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20468 bad. Replacing with 14.76698.\n",
      "Band 1: 0 of 20468 bad. Replacing with 15.16434.\n",
      "Band 2: 0 of 20468 bad. Replacing with 14.19739.\n",
      "Band 3: 13 of 20468 bad. Replacing with 15.24670.\n",
      "Band 4: 30 of 20468 bad. Replacing with 14.75285.\n",
      "Band 5: 918 of 20468 bad. Replacing with 14.62265.\n",
      "Band 6: 24 of 20468 bad. Replacing with 14.49655.\n",
      "Band 7: 10 of 20468 bad. Replacing with 14.44405.\n",
      "Band 8: 39 of 20468 bad. Replacing with 13.54000.\n",
      "Band 9: 42 of 20468 bad. Replacing with 13.15900.\n",
      "Band 10: 174 of 20468 bad. Replacing with 13.08100.\n",
      "Band 11: 19 of 20468 bad. Replacing with 15.74144.\n",
      "Band 12: 20 of 20468 bad. Replacing with 16.41437.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20468 of 20468 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 3.2877493  3.472187  11.407401  ... 11.864185   3.9753332 51.017372 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0384\n",
      "  1% : 0.112\n",
      "  10% : 0.244\n",
      "  50% : 0.642\n",
      "  90% : 2.77\n",
      "  99% : 40.2\n",
      "  100% : 4.97e+03\n",
      "<chi^2/d.o.f.> = 1.04\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 56.07 s\n",
      "learning rate = 6.0810063587268814e-05\n",
      "setting learning rate to 4.9787068367863945e-05\n",
      "Iteration 16 of 20.\n",
      "Epoch 1/25\n",
      "114/123 [==========================>...] - ETA: 0s - loss: 0.6567 - mse: 0.6405\n",
      "Epoch 1: val_loss improved from inf to 0.65563, saving model to checkpoints/ext_3h_l1n2_2hidden_it15.e001_vl0.656.h5\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6571 - mse: 0.6409 - val_loss: 0.6556 - val_mse: 0.6395\n",
      "Epoch 2/25\n",
      "113/123 [==========================>...] - ETA: 0s - loss: 0.6576 - mse: 0.6415\n",
      "Epoch 2: val_loss improved from 0.65563 to 0.65527, saving model to checkpoints/ext_3h_l1n2_2hidden_it15.e002_vl0.655.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6571 - mse: 0.6409 - val_loss: 0.6553 - val_mse: 0.6391\n",
      "Epoch 3/25\n",
      "117/123 [===========================>..] - ETA: 0s - loss: 0.6575 - mse: 0.6413\n",
      "Epoch 3: val_loss improved from 0.65527 to 0.65500, saving model to checkpoints/ext_3h_l1n2_2hidden_it15.e003_vl0.655.h5\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6571 - mse: 0.6409 - val_loss: 0.6550 - val_mse: 0.6389\n",
      "Epoch 4/25\n",
      "120/123 [============================>.] - ETA: 0s - loss: 0.6577 - mse: 0.6416\n",
      "Epoch 4: val_loss did not improve from 0.65500\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6570 - mse: 0.6409 - val_loss: 0.6550 - val_mse: 0.6389\n",
      "Epoch 5/25\n",
      "119/123 [============================>.] - ETA: 0s - loss: 0.6569 - mse: 0.6407\n",
      "Epoch 5: val_loss did not improve from 0.65500\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6570 - mse: 0.6409 - val_loss: 0.6550 - val_mse: 0.6389\n",
      "Epoch 6/25\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6569 - mse: 0.6408\n",
      "Epoch 6: val_loss did not improve from 0.65500\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6570 - mse: 0.6408 - val_loss: 0.6551 - val_mse: 0.6390\n",
      "Epoch 7/25\n",
      "113/123 [==========================>...] - ETA: 0s - loss: 0.6574 - mse: 0.6413\n",
      "Epoch 7: val_loss did not improve from 0.65500\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6570 - mse: 0.6408 - val_loss: 0.6554 - val_mse: 0.6393\n",
      "Epoch 8/25\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6570 - mse: 0.6409\n",
      "Epoch 8: val_loss improved from 0.65500 to 0.65491, saving model to checkpoints/ext_3h_l1n2_2hidden_it15.e008_vl0.655.h5\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6570 - mse: 0.6409 - val_loss: 0.6549 - val_mse: 0.6388\n",
      "Epoch 9/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 0.6574 - mse: 0.6413\n",
      "Epoch 9: val_loss did not improve from 0.65491\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6570 - mse: 0.6409 - val_loss: 0.6550 - val_mse: 0.6389\n",
      "Epoch 10/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 0.6570 - mse: 0.6409\n",
      "Epoch 10: val_loss did not improve from 0.65491\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6570 - mse: 0.6409 - val_loss: 0.6549 - val_mse: 0.6388\n",
      "Epoch 11/25\n",
      "120/123 [============================>.] - ETA: 0s - loss: 0.6568 - mse: 0.6407\n",
      "Epoch 11: val_loss did not improve from 0.65491\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6569 - mse: 0.6408 - val_loss: 0.6551 - val_mse: 0.6390\n",
      "Epoch 12/25\n",
      "114/123 [==========================>...] - ETA: 0s - loss: 0.6569 - mse: 0.6408\n",
      "Epoch 12: val_loss improved from 0.65491 to 0.65485, saving model to checkpoints/ext_3h_l1n2_2hidden_it15.e012_vl0.655.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6570 - mse: 0.6409 - val_loss: 0.6548 - val_mse: 0.6388\n",
      "Epoch 13/25\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6567 - mse: 0.6406\n",
      "Epoch 13: val_loss did not improve from 0.65485\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.6568 - mse: 0.6408 - val_loss: 0.6549 - val_mse: 0.6388\n",
      "Epoch 14/25\n",
      "112/123 [==========================>...] - ETA: 0s - loss: 0.6566 - mse: 0.6405\n",
      "Epoch 14: val_loss did not improve from 0.65485\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.6569 - mse: 0.6408 - val_loss: 0.6549 - val_mse: 0.6388\n",
      "Epoch 15/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 0.6570 - mse: 0.6409\n",
      "Epoch 15: val_loss did not improve from 0.65485\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6569 - mse: 0.6408 - val_loss: 0.6549 - val_mse: 0.6388\n",
      "Epoch 16/25\n",
      "113/123 [==========================>...] - ETA: 0s - loss: 0.6558 - mse: 0.6398\n",
      "Epoch 16: val_loss did not improve from 0.65485\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.6568 - mse: 0.6407 - val_loss: 0.6550 - val_mse: 0.6389\n",
      "Epoch 17/25\n",
      "114/123 [==========================>...] - ETA: 0s - loss: 0.6564 - mse: 0.6404\n",
      "Epoch 17: val_loss improved from 0.65485 to 0.65472, saving model to checkpoints/ext_3h_l1n2_2hidden_it15.e017_vl0.655.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6568 - mse: 0.6407 - val_loss: 0.6547 - val_mse: 0.6386\n",
      "Epoch 18/25\n",
      "111/123 [==========================>...] - ETA: 0s - loss: 0.6572 - mse: 0.6411\n",
      "Epoch 18: val_loss did not improve from 0.65472\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.6568 - mse: 0.6407 - val_loss: 0.6550 - val_mse: 0.6390\n",
      "Epoch 19/25\n",
      "112/123 [==========================>...] - ETA: 0s - loss: 0.6572 - mse: 0.6412\n",
      "Epoch 19: val_loss did not improve from 0.65472\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.6567 - mse: 0.6407 - val_loss: 0.6548 - val_mse: 0.6387\n",
      "Epoch 20/25\n",
      "117/123 [===========================>..] - ETA: 0s - loss: 0.6569 - mse: 0.6409\n",
      "Epoch 20: val_loss improved from 0.65472 to 0.65467, saving model to checkpoints/ext_3h_l1n2_2hidden_it15.e020_vl0.655.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6569 - mse: 0.6408 - val_loss: 0.6547 - val_mse: 0.6386\n",
      "Epoch 21/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 0.6573 - mse: 0.6413\n",
      "Epoch 21: val_loss did not improve from 0.65467\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6568 - mse: 0.6407 - val_loss: 0.6552 - val_mse: 0.6391\n",
      "Epoch 22/25\n",
      "120/123 [============================>.] - ETA: 0s - loss: 0.6565 - mse: 0.6404\n",
      "Epoch 22: val_loss did not improve from 0.65467\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6567 - mse: 0.6407 - val_loss: 0.6547 - val_mse: 0.6387\n",
      "Epoch 23/25\n",
      "119/123 [============================>.] - ETA: 0s - loss: 0.6566 - mse: 0.6406\n",
      "Epoch 23: val_loss did not improve from 0.65467\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6567 - mse: 0.6407 - val_loss: 0.6547 - val_mse: 0.6387\n",
      "Epoch 24/25\n",
      "116/123 [===========================>..] - ETA: 0s - loss: 0.6568 - mse: 0.6407\n",
      "Epoch 24: val_loss improved from 0.65467 to 0.65466, saving model to checkpoints/ext_3h_l1n2_2hidden_it15.e024_vl0.655.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6567 - mse: 0.6407 - val_loss: 0.6547 - val_mse: 0.6386\n",
      "Epoch 25/25\n",
      "120/123 [============================>.] - ETA: 0s - loss: 0.6563 - mse: 0.6403\n",
      "Epoch 25: val_loss did not improve from 0.65466\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6567 - mse: 0.6407 - val_loss: 0.6547 - val_mse: 0.6387\n",
      "Time elapsed to train: 18.80 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.275 2.968 1.573 3.304 2.306 1.661 1.190 0.915 0.547 0.269 0.112 0.026 0.003]\n",
      "<R> = [2.276 2.968 1.573 3.303 2.306 1.662 1.190 0.915 0.547 0.269 0.112 0.026 0.003]\n",
      "s_R = [0.043 0.001 0.000 0.029 0.047 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [3.4195356 5.8960295 5.6036396 ... 4.841943  3.8639956 4.457653 ]\n",
      "ri = [ 0.23939991  0.17100048 -1.0026503  ...  0.26299953  0.16529942\n",
      "  0.17879963]\n",
      "gr = [0.6469002  0.50619984 0.59170055 ... 0.6164999  0.39999962 0.4033003 ]\n",
      "gaia_g = [2.816513  5.4193687 5.04416   ... 4.249029  3.470891  4.043084 ]\n",
      "bp_rp = [1.1274042 0.9681673 1.0677004 ... 1.1447258 0.8715458 0.8666172]\n",
      "mag_pred: [2.5231774 5.4637117 5.671915  ... 4.1625047 3.89872   3.20226  ]\n",
      "mag_pred: [2.5231774 5.4637117 5.671915  ... 4.1625047 3.89872   3.20226  ]\n",
      "Time elapsed to make plots: 16.01 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 184212 bad. Replacing with 14.76259.\n",
      "Band 1: 5 of 184212 bad. Replacing with 15.16047.\n",
      "Band 2: 5 of 184212 bad. Replacing with 14.19215.\n",
      "Band 3: 112 of 184212 bad. Replacing with 15.23910.\n",
      "Band 4: 216 of 184212 bad. Replacing with 14.74930.\n",
      "Band 5: 7889 of 184212 bad. Replacing with 14.61470.\n",
      "Band 6: 253 of 184212 bad. Replacing with 14.49600.\n",
      "Band 7: 69 of 184212 bad. Replacing with 14.44160.\n",
      "Band 8: 371 of 184212 bad. Replacing with 13.53800.\n",
      "Band 9: 380 of 184212 bad. Replacing with 13.15900.\n",
      "Band 10: 1544 of 184212 bad. Replacing with 13.07700.\n",
      "Band 11: 201 of 184212 bad. Replacing with 15.74240.\n",
      "Band 12: 223 of 184212 bad. Replacing with 16.41514.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 184209 of 184212 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 13.943734    1.8880444   5.875369  ...  51.97251   269.4021\n",
      "   5.552941 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0232\n",
      "  1% : 0.111\n",
      "  10% : 0.237\n",
      "  50% : 0.626\n",
      "  90% : 2.79\n",
      "  99% : 40.3\n",
      "  100% : 7.4e+03\n",
      "<chi^2/d.o.f.> = 1.02\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 10873 stars (5.9%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20468 bad. Replacing with 14.76698.\n",
      "Band 1: 0 of 20468 bad. Replacing with 15.16434.\n",
      "Band 2: 0 of 20468 bad. Replacing with 14.19739.\n",
      "Band 3: 13 of 20468 bad. Replacing with 15.24670.\n",
      "Band 4: 30 of 20468 bad. Replacing with 14.75285.\n",
      "Band 5: 918 of 20468 bad. Replacing with 14.62265.\n",
      "Band 6: 24 of 20468 bad. Replacing with 14.49655.\n",
      "Band 7: 10 of 20468 bad. Replacing with 14.44405.\n",
      "Band 8: 39 of 20468 bad. Replacing with 13.54000.\n",
      "Band 9: 42 of 20468 bad. Replacing with 13.15900.\n",
      "Band 10: 174 of 20468 bad. Replacing with 13.08100.\n",
      "Band 11: 19 of 20468 bad. Replacing with 15.74144.\n",
      "Band 12: 20 of 20468 bad. Replacing with 16.41437.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20468 of 20468 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 3.0985723  3.3001852 11.576511  ... 11.607538   4.052289  51.346287 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0401\n",
      "  1% : 0.113\n",
      "  10% : 0.241\n",
      "  50% : 0.635\n",
      "  90% : 2.8\n",
      "  99% : 40.3\n",
      "  100% : 4.96e+03\n",
      "<chi^2/d.o.f.> = 1.03\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 57.24 s\n",
      "learning rate = 4.978706783731468e-05\n",
      "setting learning rate to 4.0762203978366214e-05\n",
      "Iteration 17 of 20.\n",
      "Epoch 1/25\n",
      "114/123 [==========================>...] - ETA: 0s - loss: 0.6556 - mse: 0.6396\n",
      "Epoch 1: val_loss improved from inf to 0.65305, saving model to checkpoints/ext_3h_l1n2_2hidden_it16.e001_vl0.653.h5\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6554 - mse: 0.6393 - val_loss: 0.6531 - val_mse: 0.6370\n",
      "Epoch 2/25\n",
      "119/123 [============================>.] - ETA: 0s - loss: 0.6553 - mse: 0.6393\n",
      "Epoch 2: val_loss improved from 0.65305 to 0.65305, saving model to checkpoints/ext_3h_l1n2_2hidden_it16.e002_vl0.653.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6553 - mse: 0.6393 - val_loss: 0.6531 - val_mse: 0.6370\n",
      "Epoch 3/25\n",
      "120/123 [============================>.] - ETA: 0s - loss: 0.6554 - mse: 0.6394\n",
      "Epoch 3: val_loss did not improve from 0.65305\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.6552 - mse: 0.6392 - val_loss: 0.6531 - val_mse: 0.6370\n",
      "Epoch 4/25\n",
      "119/123 [============================>.] - ETA: 0s - loss: 0.6548 - mse: 0.6387\n",
      "Epoch 4: val_loss did not improve from 0.65305\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6552 - mse: 0.6392 - val_loss: 0.6531 - val_mse: 0.6371\n",
      "Epoch 5/25\n",
      "120/123 [============================>.] - ETA: 0s - loss: 0.6550 - mse: 0.6390\n",
      "Epoch 5: val_loss improved from 0.65305 to 0.65304, saving model to checkpoints/ext_3h_l1n2_2hidden_it16.e005_vl0.653.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6553 - mse: 0.6392 - val_loss: 0.6530 - val_mse: 0.6370\n",
      "Epoch 6/25\n",
      "113/123 [==========================>...] - ETA: 0s - loss: 0.6552 - mse: 0.6392\n",
      "Epoch 6: val_loss did not improve from 0.65304\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6552 - mse: 0.6392 - val_loss: 0.6532 - val_mse: 0.6372\n",
      "Epoch 7/25\n",
      "114/123 [==========================>...] - ETA: 0s - loss: 0.6551 - mse: 0.6391\n",
      "Epoch 7: val_loss improved from 0.65304 to 0.65293, saving model to checkpoints/ext_3h_l1n2_2hidden_it16.e007_vl0.653.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6553 - mse: 0.6393 - val_loss: 0.6529 - val_mse: 0.6369\n",
      "Epoch 8/25\n",
      "114/123 [==========================>...] - ETA: 0s - loss: 0.6560 - mse: 0.6400\n",
      "Epoch 8: val_loss did not improve from 0.65293\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6552 - mse: 0.6392 - val_loss: 0.6533 - val_mse: 0.6373\n",
      "Epoch 9/25\n",
      "120/123 [============================>.] - ETA: 0s - loss: 0.6554 - mse: 0.6394\n",
      "Epoch 9: val_loss did not improve from 0.65293\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6552 - mse: 0.6392 - val_loss: 0.6530 - val_mse: 0.6370\n",
      "Epoch 10/25\n",
      "116/123 [===========================>..] - ETA: 0s - loss: 0.6555 - mse: 0.6395\n",
      "Epoch 10: val_loss did not improve from 0.65293\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6551 - mse: 0.6392 - val_loss: 0.6533 - val_mse: 0.6373\n",
      "Epoch 11/25\n",
      "115/123 [===========================>..] - ETA: 0s - loss: 0.6554 - mse: 0.6394\n",
      "Epoch 11: val_loss did not improve from 0.65293\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6552 - mse: 0.6392 - val_loss: 0.6530 - val_mse: 0.6370\n",
      "Epoch 12/25\n",
      "116/123 [===========================>..] - ETA: 0s - loss: 0.6555 - mse: 0.6395\n",
      "Epoch 12: val_loss did not improve from 0.65293\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6552 - mse: 0.6392 - val_loss: 0.6530 - val_mse: 0.6371\n",
      "Epoch 13/25\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6552 - mse: 0.6393\n",
      "Epoch 13: val_loss did not improve from 0.65293\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6552 - mse: 0.6392 - val_loss: 0.6532 - val_mse: 0.6373\n",
      "Epoch 14/25\n",
      "119/123 [============================>.] - ETA: 0s - loss: 0.6556 - mse: 0.6396\n",
      "Epoch 14: val_loss did not improve from 0.65293\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6551 - mse: 0.6391 - val_loss: 0.6538 - val_mse: 0.6378\n",
      "Epoch 15/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 0.6558 - mse: 0.6398\n",
      "Epoch 15: val_loss did not improve from 0.65293\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6551 - mse: 0.6392 - val_loss: 0.6531 - val_mse: 0.6371\n",
      "Epoch 16/25\n",
      "116/123 [===========================>..] - ETA: 0s - loss: 0.6554 - mse: 0.6394\n",
      "Epoch 16: val_loss did not improve from 0.65293\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6551 - mse: 0.6391 - val_loss: 0.6532 - val_mse: 0.6372\n",
      "Epoch 17/25\n",
      "114/123 [==========================>...] - ETA: 0s - loss: 0.6555 - mse: 0.6395\n",
      "Epoch 17: val_loss improved from 0.65293 to 0.65282, saving model to checkpoints/ext_3h_l1n2_2hidden_it16.e017_vl0.653.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6552 - mse: 0.6392 - val_loss: 0.6528 - val_mse: 0.6369\n",
      "Epoch 18/25\n",
      "113/123 [==========================>...] - ETA: 0s - loss: 0.6548 - mse: 0.6388\n",
      "Epoch 18: val_loss did not improve from 0.65282\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6551 - mse: 0.6391 - val_loss: 0.6530 - val_mse: 0.6370\n",
      "Epoch 19/25\n",
      "119/123 [============================>.] - ETA: 0s - loss: 0.6548 - mse: 0.6388\n",
      "Epoch 19: val_loss did not improve from 0.65282\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6551 - mse: 0.6391 - val_loss: 0.6529 - val_mse: 0.6369\n",
      "Epoch 20/25\n",
      "114/123 [==========================>...] - ETA: 0s - loss: 0.6552 - mse: 0.6393\n",
      "Epoch 20: val_loss improved from 0.65282 to 0.65272, saving model to checkpoints/ext_3h_l1n2_2hidden_it16.e020_vl0.653.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6551 - mse: 0.6391 - val_loss: 0.6527 - val_mse: 0.6368\n",
      "Epoch 21/25\n",
      "119/123 [============================>.] - ETA: 0s - loss: 0.6553 - mse: 0.6393\n",
      "Epoch 21: val_loss did not improve from 0.65272\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6550 - mse: 0.6391 - val_loss: 0.6529 - val_mse: 0.6369\n",
      "Epoch 22/25\n",
      "115/123 [===========================>..] - ETA: 0s - loss: 0.6556 - mse: 0.6396\n",
      "Epoch 22: val_loss did not improve from 0.65272\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6550 - mse: 0.6391 - val_loss: 0.6529 - val_mse: 0.6370\n",
      "Epoch 23/25\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.6550 - mse: 0.6391\n",
      "Epoch 23: val_loss did not improve from 0.65272\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6550 - mse: 0.6391 - val_loss: 0.6530 - val_mse: 0.6371\n",
      "Epoch 24/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 0.6555 - mse: 0.6395\n",
      "Epoch 24: val_loss did not improve from 0.65272\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6550 - mse: 0.6391 - val_loss: 0.6528 - val_mse: 0.6368\n",
      "Epoch 25/25\n",
      "117/123 [===========================>..] - ETA: 0s - loss: 0.6545 - mse: 0.6386\n",
      "Epoch 25: val_loss did not improve from 0.65272\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6549 - mse: 0.6390 - val_loss: 0.6532 - val_mse: 0.6373\n",
      "Time elapsed to train: 18.92 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.282 2.976 1.578 3.313 2.312 1.667 1.195 0.919 0.550 0.270 0.114 0.027 0.003]\n",
      "<R> = [2.282 2.976 1.578 3.313 2.312 1.667 1.195 0.919 0.550 0.270 0.114 0.027 0.003]\n",
      "s_R = [0.043 0.001 0.000 0.029 0.046 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [3.4195356 5.8960295 5.6036396 ... 4.841943  3.8639956 4.457653 ]\n",
      "ri = [ 0.23939991  0.17100048 -1.0026503  ...  0.26299953  0.16529942\n",
      "  0.17879963]\n",
      "gr = [0.6469002  0.50619984 0.59170055 ... 0.6164999  0.39999962 0.4033003 ]\n",
      "gaia_g = [2.816513  5.4193687 5.04416   ... 4.249029  3.470891  4.043084 ]\n",
      "bp_rp = [1.1274042 0.9681673 1.0677004 ... 1.1447258 0.8715458 0.8666172]\n",
      "mag_pred: [2.5226958 5.461459  5.669006  ... 4.158017  3.897492  3.201466 ]\n",
      "mag_pred: [2.5226958 5.461459  5.669006  ... 4.158017  3.897492  3.201466 ]\n",
      "Time elapsed to make plots: 20.09 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 184212 bad. Replacing with 14.76259.\n",
      "Band 1: 5 of 184212 bad. Replacing with 15.16047.\n",
      "Band 2: 5 of 184212 bad. Replacing with 14.19215.\n",
      "Band 3: 112 of 184212 bad. Replacing with 15.23910.\n",
      "Band 4: 216 of 184212 bad. Replacing with 14.74930.\n",
      "Band 5: 7889 of 184212 bad. Replacing with 14.61470.\n",
      "Band 6: 253 of 184212 bad. Replacing with 14.49600.\n",
      "Band 7: 69 of 184212 bad. Replacing with 14.44160.\n",
      "Band 8: 371 of 184212 bad. Replacing with 13.53800.\n",
      "Band 9: 380 of 184212 bad. Replacing with 13.15900.\n",
      "Band 10: 1544 of 184212 bad. Replacing with 13.07700.\n",
      "Band 11: 201 of 184212 bad. Replacing with 15.74240.\n",
      "Band 12: 223 of 184212 bad. Replacing with 16.41514.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 184209 of 184212 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 13.443699    1.8328862   5.880786  ...  51.503357  268.9313\n",
      "   5.502835 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0197\n",
      "  1% : 0.112\n",
      "  10% : 0.24\n",
      "  50% : 0.629\n",
      "  90% : 2.77\n",
      "  99% : 40.3\n",
      "  100% : 7.38e+03\n",
      "<chi^2/d.o.f.> = 1.02\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 10826 stars (5.88%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20468 bad. Replacing with 14.76698.\n",
      "Band 1: 0 of 20468 bad. Replacing with 15.16434.\n",
      "Band 2: 0 of 20468 bad. Replacing with 14.19739.\n",
      "Band 3: 13 of 20468 bad. Replacing with 15.24670.\n",
      "Band 4: 30 of 20468 bad. Replacing with 14.75285.\n",
      "Band 5: 918 of 20468 bad. Replacing with 14.62265.\n",
      "Band 6: 24 of 20468 bad. Replacing with 14.49655.\n",
      "Band 7: 10 of 20468 bad. Replacing with 14.44405.\n",
      "Band 8: 39 of 20468 bad. Replacing with 13.54000.\n",
      "Band 9: 42 of 20468 bad. Replacing with 13.15900.\n",
      "Band 10: 174 of 20468 bad. Replacing with 13.08100.\n",
      "Band 11: 19 of 20468 bad. Replacing with 15.74144.\n",
      "Band 12: 20 of 20468 bad. Replacing with 16.41437.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20468 of 20468 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 3.2529314  3.5041459 11.241931  ... 11.832661   3.9584966 52.223747 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0417\n",
      "  1% : 0.111\n",
      "  10% : 0.243\n",
      "  50% : 0.637\n",
      "  90% : 2.76\n",
      "  99% : 40.3\n",
      "  100% : 4.96e+03\n",
      "<chi^2/d.o.f.> = 1.03\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 54.88 s\n",
      "learning rate = 4.076220284332521e-05\n",
      "setting learning rate to 3.337326996032607e-05\n",
      "Iteration 18 of 20.\n",
      "Epoch 1/25\n",
      "116/123 [===========================>..] - ETA: 0s - loss: 0.6557 - mse: 0.6398\n",
      "Epoch 1: val_loss improved from inf to 0.65325, saving model to checkpoints/ext_3h_l1n2_2hidden_it17.e001_vl0.653.h5\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6554 - mse: 0.6395 - val_loss: 0.6533 - val_mse: 0.6373\n",
      "Epoch 2/25\n",
      "119/123 [============================>.] - ETA: 0s - loss: 0.6555 - mse: 0.6395\n",
      "Epoch 2: val_loss did not improve from 0.65325\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6554 - mse: 0.6394 - val_loss: 0.6534 - val_mse: 0.6375\n",
      "Epoch 3/25\n",
      "114/123 [==========================>...] - ETA: 0s - loss: 0.6556 - mse: 0.6397\n",
      "Epoch 3: val_loss did not improve from 0.65325\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6555 - mse: 0.6396 - val_loss: 0.6535 - val_mse: 0.6376\n",
      "Epoch 4/25\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.6554 - mse: 0.6395\n",
      "Epoch 4: val_loss did not improve from 0.65325\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6554 - mse: 0.6395 - val_loss: 0.6535 - val_mse: 0.6375\n",
      "Epoch 5/25\n",
      "121/123 [============================>.] - ETA: 0s - loss: 0.6553 - mse: 0.6394\n",
      "Epoch 5: val_loss did not improve from 0.65325\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6554 - mse: 0.6395 - val_loss: 0.6533 - val_mse: 0.6374\n",
      "Epoch 6/25\n",
      "115/123 [===========================>..] - ETA: 0s - loss: 0.6557 - mse: 0.6398\n",
      "Epoch 6: val_loss did not improve from 0.65325\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6554 - mse: 0.6395 - val_loss: 0.6533 - val_mse: 0.6374\n",
      "Epoch 7/25\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6554 - mse: 0.6395\n",
      "Epoch 7: val_loss did not improve from 0.65325\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6554 - mse: 0.6395 - val_loss: 0.6533 - val_mse: 0.6374\n",
      "Epoch 8/25\n",
      "119/123 [============================>.] - ETA: 0s - loss: 0.6554 - mse: 0.6395\n",
      "Epoch 8: val_loss did not improve from 0.65325\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6554 - mse: 0.6394 - val_loss: 0.6533 - val_mse: 0.6374\n",
      "Epoch 9/25\n",
      "115/123 [===========================>..] - ETA: 0s - loss: 0.6550 - mse: 0.6391\n",
      "Epoch 9: val_loss did not improve from 0.65325\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6554 - mse: 0.6395 - val_loss: 0.6535 - val_mse: 0.6376\n",
      "Epoch 10/25\n",
      "117/123 [===========================>..] - ETA: 0s - loss: 0.6550 - mse: 0.6391\n",
      "Epoch 10: val_loss did not improve from 0.65325\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6554 - mse: 0.6394 - val_loss: 0.6533 - val_mse: 0.6374\n",
      "Epoch 11/25\n",
      "117/123 [===========================>..] - ETA: 0s - loss: 0.6556 - mse: 0.6396\n",
      "Epoch 11: val_loss did not improve from 0.65325\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6553 - mse: 0.6394 - val_loss: 0.6534 - val_mse: 0.6375\n",
      "Epoch 12/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 0.6548 - mse: 0.6389\n",
      "Epoch 12: val_loss did not improve from 0.65325\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6554 - mse: 0.6395 - val_loss: 0.6533 - val_mse: 0.6374\n",
      "Epoch 13/25\n",
      "115/123 [===========================>..] - ETA: 0s - loss: 0.6545 - mse: 0.6386\n",
      "Epoch 13: val_loss did not improve from 0.65325\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6553 - mse: 0.6394 - val_loss: 0.6533 - val_mse: 0.6374\n",
      "Epoch 14/25\n",
      "115/123 [===========================>..] - ETA: 0s - loss: 0.6546 - mse: 0.6387\n",
      "Epoch 14: val_loss improved from 0.65325 to 0.65323, saving model to checkpoints/ext_3h_l1n2_2hidden_it17.e014_vl0.653.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6553 - mse: 0.6394 - val_loss: 0.6532 - val_mse: 0.6373\n",
      "Epoch 15/25\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6554 - mse: 0.6395\n",
      "Epoch 15: val_loss improved from 0.65323 to 0.65312, saving model to checkpoints/ext_3h_l1n2_2hidden_it17.e015_vl0.653.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6553 - mse: 0.6394 - val_loss: 0.6531 - val_mse: 0.6372\n",
      "Epoch 16/25\n",
      "117/123 [===========================>..] - ETA: 0s - loss: 0.6555 - mse: 0.6396\n",
      "Epoch 16: val_loss did not improve from 0.65312\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6553 - mse: 0.6394 - val_loss: 0.6533 - val_mse: 0.6374\n",
      "Epoch 17/25\n",
      "112/123 [==========================>...] - ETA: 0s - loss: 0.6562 - mse: 0.6403\n",
      "Epoch 17: val_loss did not improve from 0.65312\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6553 - mse: 0.6394 - val_loss: 0.6531 - val_mse: 0.6372\n",
      "Epoch 18/25\n",
      "121/123 [============================>.] - ETA: 0s - loss: 0.6551 - mse: 0.6392\n",
      "Epoch 18: val_loss did not improve from 0.65312\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6553 - mse: 0.6394 - val_loss: 0.6532 - val_mse: 0.6374\n",
      "Epoch 19/25\n",
      "117/123 [===========================>..] - ETA: 0s - loss: 0.6557 - mse: 0.6398\n",
      "Epoch 19: val_loss did not improve from 0.65312\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6552 - mse: 0.6393 - val_loss: 0.6532 - val_mse: 0.6373\n",
      "Epoch 20/25\n",
      "113/123 [==========================>...] - ETA: 0s - loss: 0.6553 - mse: 0.6394\n",
      "Epoch 20: val_loss did not improve from 0.65312\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6553 - mse: 0.6394 - val_loss: 0.6532 - val_mse: 0.6373\n",
      "Epoch 21/25\n",
      "115/123 [===========================>..] - ETA: 0s - loss: 0.6549 - mse: 0.6390\n",
      "Epoch 21: val_loss did not improve from 0.65312\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6552 - mse: 0.6394 - val_loss: 0.6532 - val_mse: 0.6374\n",
      "Epoch 22/25\n",
      "116/123 [===========================>..] - ETA: 0s - loss: 0.6548 - mse: 0.6389\n",
      "Epoch 22: val_loss did not improve from 0.65312\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6552 - mse: 0.6394 - val_loss: 0.6533 - val_mse: 0.6374\n",
      "Epoch 23/25\n",
      "120/123 [============================>.] - ETA: 0s - loss: 0.6551 - mse: 0.6392\n",
      "Epoch 23: val_loss did not improve from 0.65312\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6553 - mse: 0.6394 - val_loss: 0.6531 - val_mse: 0.6373\n",
      "Epoch 24/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 0.6556 - mse: 0.6398\n",
      "Epoch 24: val_loss did not improve from 0.65312\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6552 - mse: 0.6393 - val_loss: 0.6533 - val_mse: 0.6374\n",
      "Epoch 25/25\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6553 - mse: 0.6394\n",
      "Epoch 25: val_loss did not improve from 0.65312\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6553 - mse: 0.6394 - val_loss: 0.6533 - val_mse: 0.6374\n",
      "Time elapsed to train: 19.09 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.287 2.982 1.582 3.320 2.318 1.671 1.198 0.922 0.552 0.272 0.115 0.027 0.003]\n",
      "<R> = [2.287 2.982 1.582 3.320 2.317 1.671 1.198 0.922 0.552 0.272 0.115 0.027 0.003]\n",
      "s_R = [0.043 0.001 0.000 0.029 0.046 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [3.4195356 5.8960295 5.6036396 ... 4.841943  3.8639956 4.457653 ]\n",
      "ri = [ 0.23939991  0.17100048 -1.0026503  ...  0.26299953  0.16529942\n",
      "  0.17879963]\n",
      "gr = [0.6469002  0.50619984 0.59170055 ... 0.6164999  0.39999962 0.4033003 ]\n",
      "gaia_g = [2.816513  5.4193687 5.04416   ... 4.249029  3.470891  4.043084 ]\n",
      "bp_rp = [1.1274042 0.9681673 1.0677004 ... 1.1447258 0.8715458 0.8666172]\n",
      "mag_pred: [2.522673  5.461061  5.669003  ... 4.1558332 3.8969767 3.200585 ]\n",
      "mag_pred: [2.522673  5.461061  5.669003  ... 4.1558332 3.8969767 3.200585 ]\n",
      "Time elapsed to make plots: 16.35 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 184212 bad. Replacing with 14.76259.\n",
      "Band 1: 5 of 184212 bad. Replacing with 15.16047.\n",
      "Band 2: 5 of 184212 bad. Replacing with 14.19215.\n",
      "Band 3: 112 of 184212 bad. Replacing with 15.23910.\n",
      "Band 4: 216 of 184212 bad. Replacing with 14.74930.\n",
      "Band 5: 7889 of 184212 bad. Replacing with 14.61470.\n",
      "Band 6: 253 of 184212 bad. Replacing with 14.49600.\n",
      "Band 7: 69 of 184212 bad. Replacing with 14.44160.\n",
      "Band 8: 371 of 184212 bad. Replacing with 13.53800.\n",
      "Band 9: 380 of 184212 bad. Replacing with 13.15900.\n",
      "Band 10: 1544 of 184212 bad. Replacing with 13.07700.\n",
      "Band 11: 201 of 184212 bad. Replacing with 15.74240.\n",
      "Band 12: 223 of 184212 bad. Replacing with 16.41514.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 184209 of 184212 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 14.097868    1.8771257   5.7447925 ...  52.1669    269.76474\n",
      "   5.4875402]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0214\n",
      "  1% : 0.11\n",
      "  10% : 0.235\n",
      "  50% : 0.624\n",
      "  90% : 2.79\n",
      "  99% : 40.4\n",
      "  100% : 7.38e+03\n",
      "<chi^2/d.o.f.> = 1.02\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 10886 stars (5.91%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20468 bad. Replacing with 14.76698.\n",
      "Band 1: 0 of 20468 bad. Replacing with 15.16434.\n",
      "Band 2: 0 of 20468 bad. Replacing with 14.19739.\n",
      "Band 3: 13 of 20468 bad. Replacing with 15.24670.\n",
      "Band 4: 30 of 20468 bad. Replacing with 14.75285.\n",
      "Band 5: 918 of 20468 bad. Replacing with 14.62265.\n",
      "Band 6: 24 of 20468 bad. Replacing with 14.49655.\n",
      "Band 7: 10 of 20468 bad. Replacing with 14.44405.\n",
      "Band 8: 39 of 20468 bad. Replacing with 13.54000.\n",
      "Band 9: 42 of 20468 bad. Replacing with 13.15900.\n",
      "Band 10: 174 of 20468 bad. Replacing with 13.08100.\n",
      "Band 11: 19 of 20468 bad. Replacing with 15.74144.\n",
      "Band 12: 20 of 20468 bad. Replacing with 16.41437.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20468 of 20468 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 2.8967822  3.3302708 11.393055  ... 11.221941   4.029788  52.680138 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0394\n",
      "  1% : 0.111\n",
      "  10% : 0.239\n",
      "  50% : 0.632\n",
      "  90% : 2.8\n",
      "  99% : 40.4\n",
      "  100% : 4.96e+03\n",
      "<chi^2/d.o.f.> = 1.03\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 56.02 s\n",
      "learning rate = 3.337327143526636e-05\n",
      "setting learning rate to 2.732372244729256e-05\n",
      "Iteration 19 of 20.\n",
      "Epoch 1/25\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.6539 - mse: 0.6380\n",
      "Epoch 1: val_loss improved from inf to 0.65157, saving model to checkpoints/ext_3h_l1n2_2hidden_it18.e001_vl0.652.h5\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6539 - mse: 0.6380 - val_loss: 0.6516 - val_mse: 0.6357\n",
      "Epoch 2/25\n",
      "115/123 [===========================>..] - ETA: 0s - loss: 0.6537 - mse: 0.6379\n",
      "Epoch 2: val_loss did not improve from 0.65157\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6539 - mse: 0.6380 - val_loss: 0.6517 - val_mse: 0.6358\n",
      "Epoch 3/25\n",
      "115/123 [===========================>..] - ETA: 0s - loss: 0.6542 - mse: 0.6383\n",
      "Epoch 3: val_loss improved from 0.65157 to 0.65155, saving model to checkpoints/ext_3h_l1n2_2hidden_it18.e003_vl0.652.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6539 - mse: 0.6380 - val_loss: 0.6515 - val_mse: 0.6357\n",
      "Epoch 4/25\n",
      "114/123 [==========================>...] - ETA: 0s - loss: 0.6538 - mse: 0.6379\n",
      "Epoch 4: val_loss improved from 0.65155 to 0.65149, saving model to checkpoints/ext_3h_l1n2_2hidden_it18.e004_vl0.651.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6538 - mse: 0.6380 - val_loss: 0.6515 - val_mse: 0.6356\n",
      "Epoch 5/25\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.6539 - mse: 0.6380\n",
      "Epoch 5: val_loss did not improve from 0.65149\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6539 - mse: 0.6380 - val_loss: 0.6516 - val_mse: 0.6357\n",
      "Epoch 6/25\n",
      "112/123 [==========================>...] - ETA: 0s - loss: 0.6530 - mse: 0.6371\n",
      "Epoch 6: val_loss did not improve from 0.65149\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6539 - mse: 0.6380 - val_loss: 0.6517 - val_mse: 0.6358\n",
      "Epoch 7/25\n",
      "121/123 [============================>.] - ETA: 0s - loss: 0.6537 - mse: 0.6378\n",
      "Epoch 7: val_loss did not improve from 0.65149\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6538 - mse: 0.6379 - val_loss: 0.6517 - val_mse: 0.6358\n",
      "Epoch 8/25\n",
      "115/123 [===========================>..] - ETA: 0s - loss: 0.6544 - mse: 0.6385\n",
      "Epoch 8: val_loss did not improve from 0.65149\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6539 - mse: 0.6380 - val_loss: 0.6515 - val_mse: 0.6357\n",
      "Epoch 9/25\n",
      "113/123 [==========================>...] - ETA: 0s - loss: 0.6536 - mse: 0.6378\n",
      "Epoch 9: val_loss did not improve from 0.65149\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6538 - mse: 0.6380 - val_loss: 0.6516 - val_mse: 0.6357\n",
      "Epoch 10/25\n",
      "116/123 [===========================>..] - ETA: 0s - loss: 0.6539 - mse: 0.6380\n",
      "Epoch 10: val_loss did not improve from 0.65149\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6538 - mse: 0.6379 - val_loss: 0.6516 - val_mse: 0.6357\n",
      "Epoch 11/25\n",
      "120/123 [============================>.] - ETA: 0s - loss: 0.6538 - mse: 0.6379\n",
      "Epoch 11: val_loss did not improve from 0.65149\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6538 - mse: 0.6379 - val_loss: 0.6515 - val_mse: 0.6357\n",
      "Epoch 12/25\n",
      "119/123 [============================>.] - ETA: 0s - loss: 0.6537 - mse: 0.6378\n",
      "Epoch 12: val_loss did not improve from 0.65149\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6538 - mse: 0.6379 - val_loss: 0.6516 - val_mse: 0.6358\n",
      "Epoch 13/25\n",
      "112/123 [==========================>...] - ETA: 0s - loss: 0.6533 - mse: 0.6375\n",
      "Epoch 13: val_loss did not improve from 0.65149\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.6538 - mse: 0.6380 - val_loss: 0.6515 - val_mse: 0.6357\n",
      "Epoch 14/25\n",
      "120/123 [============================>.] - ETA: 0s - loss: 0.6538 - mse: 0.6379\n",
      "Epoch 14: val_loss did not improve from 0.65149\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6538 - mse: 0.6379 - val_loss: 0.6515 - val_mse: 0.6357\n",
      "Epoch 15/25\n",
      "120/123 [============================>.] - ETA: 0s - loss: 0.6537 - mse: 0.6379\n",
      "Epoch 15: val_loss did not improve from 0.65149\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.6538 - mse: 0.6379 - val_loss: 0.6516 - val_mse: 0.6357\n",
      "Epoch 16/25\n",
      "112/123 [==========================>...] - ETA: 0s - loss: 0.6537 - mse: 0.6378\n",
      "Epoch 16: val_loss did not improve from 0.65149\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6538 - mse: 0.6380 - val_loss: 0.6516 - val_mse: 0.6358\n",
      "Epoch 17/25\n",
      "115/123 [===========================>..] - ETA: 0s - loss: 0.6533 - mse: 0.6374\n",
      "Epoch 17: val_loss improved from 0.65149 to 0.65146, saving model to checkpoints/ext_3h_l1n2_2hidden_it18.e017_vl0.651.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6537 - mse: 0.6379 - val_loss: 0.6515 - val_mse: 0.6356\n",
      "Epoch 18/25\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6538 - mse: 0.6379\n",
      "Epoch 18: val_loss improved from 0.65146 to 0.65141, saving model to checkpoints/ext_3h_l1n2_2hidden_it18.e018_vl0.651.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6538 - mse: 0.6379 - val_loss: 0.6514 - val_mse: 0.6356\n",
      "Epoch 19/25\n",
      "115/123 [===========================>..] - ETA: 0s - loss: 0.6535 - mse: 0.6376\n",
      "Epoch 19: val_loss did not improve from 0.65141\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6537 - mse: 0.6379 - val_loss: 0.6515 - val_mse: 0.6357\n",
      "Epoch 20/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 0.6531 - mse: 0.6373\n",
      "Epoch 20: val_loss did not improve from 0.65141\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.6537 - mse: 0.6379 - val_loss: 0.6516 - val_mse: 0.6357\n",
      "Epoch 21/25\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6537 - mse: 0.6378\n",
      "Epoch 21: val_loss did not improve from 0.65141\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6538 - mse: 0.6380 - val_loss: 0.6514 - val_mse: 0.6356\n",
      "Epoch 22/25\n",
      "119/123 [============================>.] - ETA: 0s - loss: 0.6536 - mse: 0.6378\n",
      "Epoch 22: val_loss did not improve from 0.65141\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6538 - mse: 0.6379 - val_loss: 0.6514 - val_mse: 0.6356\n",
      "Epoch 23/25\n",
      "116/123 [===========================>..] - ETA: 0s - loss: 0.6539 - mse: 0.6381\n",
      "Epoch 23: val_loss did not improve from 0.65141\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6537 - mse: 0.6379 - val_loss: 0.6517 - val_mse: 0.6359\n",
      "Epoch 24/25\n",
      "119/123 [============================>.] - ETA: 0s - loss: 0.6532 - mse: 0.6374\n",
      "Epoch 24: val_loss did not improve from 0.65141\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.6537 - mse: 0.6379 - val_loss: 0.6516 - val_mse: 0.6357\n",
      "Epoch 25/25\n",
      "111/123 [==========================>...] - ETA: 0s - loss: 0.6544 - mse: 0.6386\n",
      "Epoch 25: val_loss did not improve from 0.65141\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.6537 - mse: 0.6379 - val_loss: 0.6515 - val_mse: 0.6357\n",
      "Time elapsed to train: 18.61 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.291 2.987 1.585 3.325 2.321 1.674 1.200 0.924 0.553 0.273 0.116 0.028 0.003]\n",
      "<R> = [2.291 2.987 1.585 3.325 2.321 1.674 1.200 0.924 0.553 0.273 0.116 0.028 0.003]\n",
      "s_R = [0.043 0.000 0.000 0.029 0.046 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [3.4195356 5.8960295 5.6036396 ... 4.841943  3.8639956 4.457653 ]\n",
      "ri = [ 0.23939991  0.17100048 -1.0026503  ...  0.26299953  0.16529942\n",
      "  0.17879963]\n",
      "gr = [0.6469002  0.50619984 0.59170055 ... 0.6164999  0.39999962 0.4033003 ]\n",
      "gaia_g = [2.816513  5.4193687 5.04416   ... 4.249029  3.470891  4.043084 ]\n",
      "bp_rp = [1.1274042 0.9681673 1.0677004 ... 1.1447258 0.8715458 0.8666172]\n",
      "mag_pred: [2.5195324 5.458122  5.665716  ... 4.1515455 3.8948696 3.1987371]\n",
      "mag_pred: [2.5195324 5.458122  5.665716  ... 4.1515455 3.8948696 3.1987371]\n",
      "Time elapsed to make plots: 16.19 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 184212 bad. Replacing with 14.76259.\n",
      "Band 1: 5 of 184212 bad. Replacing with 15.16047.\n",
      "Band 2: 5 of 184212 bad. Replacing with 14.19215.\n",
      "Band 3: 112 of 184212 bad. Replacing with 15.23910.\n",
      "Band 4: 216 of 184212 bad. Replacing with 14.74930.\n",
      "Band 5: 7889 of 184212 bad. Replacing with 14.61470.\n",
      "Band 6: 253 of 184212 bad. Replacing with 14.49600.\n",
      "Band 7: 69 of 184212 bad. Replacing with 14.44160.\n",
      "Band 8: 371 of 184212 bad. Replacing with 13.53800.\n",
      "Band 9: 380 of 184212 bad. Replacing with 13.15900.\n",
      "Band 10: 1544 of 184212 bad. Replacing with 13.07700.\n",
      "Band 11: 201 of 184212 bad. Replacing with 15.74240.\n",
      "Band 12: 223 of 184212 bad. Replacing with 16.41514.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 184209 of 184212 (99.998%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 13.655767    1.8526952   5.827839  ...  51.628323  269.2602\n",
      "   5.474978 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0229\n",
      "  1% : 0.112\n",
      "  10% : 0.238\n",
      "  50% : 0.627\n",
      "  90% : 2.78\n",
      "  99% : 40.4\n",
      "  100% : 7.37e+03\n",
      "<chi^2/d.o.f.> = 1.02\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 10825 stars (5.88%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20468 bad. Replacing with 14.76698.\n",
      "Band 1: 0 of 20468 bad. Replacing with 15.16434.\n",
      "Band 2: 0 of 20468 bad. Replacing with 14.19739.\n",
      "Band 3: 13 of 20468 bad. Replacing with 15.24670.\n",
      "Band 4: 30 of 20468 bad. Replacing with 14.75285.\n",
      "Band 5: 918 of 20468 bad. Replacing with 14.62265.\n",
      "Band 6: 24 of 20468 bad. Replacing with 14.49655.\n",
      "Band 7: 10 of 20468 bad. Replacing with 14.44405.\n",
      "Band 8: 39 of 20468 bad. Replacing with 13.54000.\n",
      "Band 9: 42 of 20468 bad. Replacing with 13.15900.\n",
      "Band 10: 174 of 20468 bad. Replacing with 13.08100.\n",
      "Band 11: 19 of 20468 bad. Replacing with 15.74144.\n",
      "Band 12: 20 of 20468 bad. Replacing with 16.41437.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20468 of 20468 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 3.122243   3.4655888 11.196863  ... 11.66062    3.9256575 53.44149  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0422\n",
      "  1% : 0.112\n",
      "  10% : 0.242\n",
      "  50% : 0.635\n",
      "  90% : 2.77\n",
      "  99% : 40.2\n",
      "  100% : 4.96e+03\n",
      "<chi^2/d.o.f.> = 1.03\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 54.88 s\n",
      "learning rate = 2.732372195168864e-05\n",
      "setting learning rate to 2.2370771856165592e-05\n",
      "Iteration 20 of 20.\n",
      "Epoch 1/25\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.6545 - mse: 0.6387\n",
      "Epoch 1: val_loss improved from inf to 0.65253, saving model to checkpoints/ext_3h_l1n2_2hidden_it19.e001_vl0.653.h5\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6545 - mse: 0.6387 - val_loss: 0.6525 - val_mse: 0.6367\n",
      "Epoch 2/25\n",
      "114/123 [==========================>...] - ETA: 0s - loss: 0.6539 - mse: 0.6381\n",
      "Epoch 2: val_loss did not improve from 0.65253\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6545 - mse: 0.6387 - val_loss: 0.6525 - val_mse: 0.6367\n",
      "Epoch 3/25\n",
      "121/123 [============================>.] - ETA: 0s - loss: 0.6547 - mse: 0.6389\n",
      "Epoch 3: val_loss improved from 0.65253 to 0.65250, saving model to checkpoints/ext_3h_l1n2_2hidden_it19.e003_vl0.652.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6545 - mse: 0.6387 - val_loss: 0.6525 - val_mse: 0.6367\n",
      "Epoch 4/25\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6545 - mse: 0.6387\n",
      "Epoch 4: val_loss did not improve from 0.65250\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6545 - mse: 0.6387 - val_loss: 0.6525 - val_mse: 0.6367\n",
      "Epoch 5/25\n",
      "121/123 [============================>.] - ETA: 0s - loss: 0.6548 - mse: 0.6389\n",
      "Epoch 5: val_loss did not improve from 0.65250\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6545 - mse: 0.6387 - val_loss: 0.6526 - val_mse: 0.6367\n",
      "Epoch 6/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 0.6548 - mse: 0.6390\n",
      "Epoch 6: val_loss did not improve from 0.65250\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6545 - mse: 0.6387 - val_loss: 0.6526 - val_mse: 0.6368\n",
      "Epoch 7/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 0.6542 - mse: 0.6384\n",
      "Epoch 7: val_loss did not improve from 0.65250\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6545 - mse: 0.6387 - val_loss: 0.6525 - val_mse: 0.6367\n",
      "Epoch 8/25\n",
      "119/123 [============================>.] - ETA: 0s - loss: 0.6545 - mse: 0.6387\n",
      "Epoch 8: val_loss did not improve from 0.65250\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6545 - mse: 0.6387 - val_loss: 0.6525 - val_mse: 0.6367\n",
      "Epoch 9/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 0.6548 - mse: 0.6390\n",
      "Epoch 9: val_loss did not improve from 0.65250\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6545 - mse: 0.6386 - val_loss: 0.6525 - val_mse: 0.6367\n",
      "Epoch 10/25\n",
      "111/123 [==========================>...] - ETA: 0s - loss: 0.6546 - mse: 0.6388\n",
      "Epoch 10: val_loss did not improve from 0.65250\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6545 - mse: 0.6387 - val_loss: 0.6526 - val_mse: 0.6368\n",
      "Epoch 11/25\n",
      "116/123 [===========================>..] - ETA: 0s - loss: 0.6548 - mse: 0.6390\n",
      "Epoch 11: val_loss improved from 0.65250 to 0.65248, saving model to checkpoints/ext_3h_l1n2_2hidden_it19.e011_vl0.652.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6544 - mse: 0.6386 - val_loss: 0.6525 - val_mse: 0.6367\n",
      "Epoch 12/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 0.6544 - mse: 0.6386\n",
      "Epoch 12: val_loss did not improve from 0.65248\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6544 - mse: 0.6386 - val_loss: 0.6525 - val_mse: 0.6367\n",
      "Epoch 13/25\n",
      "120/123 [============================>.] - ETA: 0s - loss: 0.6544 - mse: 0.6386\n",
      "Epoch 13: val_loss improved from 0.65248 to 0.65247, saving model to checkpoints/ext_3h_l1n2_2hidden_it19.e013_vl0.652.h5\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6545 - mse: 0.6387 - val_loss: 0.6525 - val_mse: 0.6367\n",
      "Epoch 14/25\n",
      "120/123 [============================>.] - ETA: 0s - loss: 0.6543 - mse: 0.6385\n",
      "Epoch 14: val_loss did not improve from 0.65247\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6544 - mse: 0.6386 - val_loss: 0.6526 - val_mse: 0.6368\n",
      "Epoch 15/25\n",
      "114/123 [==========================>...] - ETA: 0s - loss: 0.6542 - mse: 0.6384\n",
      "Epoch 15: val_loss did not improve from 0.65247\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6544 - mse: 0.6386 - val_loss: 0.6525 - val_mse: 0.6367\n",
      "Epoch 16/25\n",
      "115/123 [===========================>..] - ETA: 0s - loss: 0.6547 - mse: 0.6389\n",
      "Epoch 16: val_loss improved from 0.65247 to 0.65246, saving model to checkpoints/ext_3h_l1n2_2hidden_it19.e016_vl0.652.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6545 - mse: 0.6387 - val_loss: 0.6525 - val_mse: 0.6367\n",
      "Epoch 17/25\n",
      "115/123 [===========================>..] - ETA: 0s - loss: 0.6543 - mse: 0.6385\n",
      "Epoch 17: val_loss improved from 0.65246 to 0.65242, saving model to checkpoints/ext_3h_l1n2_2hidden_it19.e017_vl0.652.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6544 - mse: 0.6386 - val_loss: 0.6524 - val_mse: 0.6366\n",
      "Epoch 18/25\n",
      "120/123 [============================>.] - ETA: 0s - loss: 0.6550 - mse: 0.6392\n",
      "Epoch 18: val_loss did not improve from 0.65242\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6545 - mse: 0.6387 - val_loss: 0.6525 - val_mse: 0.6367\n",
      "Epoch 19/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 0.6541 - mse: 0.6383\n",
      "Epoch 19: val_loss did not improve from 0.65242\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6544 - mse: 0.6386 - val_loss: 0.6525 - val_mse: 0.6367\n",
      "Epoch 20/25\n",
      "111/123 [==========================>...] - ETA: 0s - loss: 0.6543 - mse: 0.6385\n",
      "Epoch 20: val_loss did not improve from 0.65242\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6544 - mse: 0.6386 - val_loss: 0.6526 - val_mse: 0.6369\n",
      "Epoch 21/25\n",
      "120/123 [============================>.] - ETA: 0s - loss: 0.6543 - mse: 0.6385\n",
      "Epoch 21: val_loss did not improve from 0.65242\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.6544 - mse: 0.6386 - val_loss: 0.6524 - val_mse: 0.6366\n",
      "Epoch 22/25\n",
      "116/123 [===========================>..] - ETA: 0s - loss: 0.6539 - mse: 0.6381\n",
      "Epoch 22: val_loss did not improve from 0.65242\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6544 - mse: 0.6386 - val_loss: 0.6526 - val_mse: 0.6368\n",
      "Epoch 23/25\n",
      "119/123 [============================>.] - ETA: 0s - loss: 0.6546 - mse: 0.6388\n",
      "Epoch 23: val_loss did not improve from 0.65242\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6544 - mse: 0.6386 - val_loss: 0.6525 - val_mse: 0.6367\n",
      "Epoch 24/25\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.6544 - mse: 0.6386\n",
      "Epoch 24: val_loss did not improve from 0.65242\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6544 - mse: 0.6386 - val_loss: 0.6526 - val_mse: 0.6368\n",
      "Epoch 25/25\n",
      "120/123 [============================>.] - ETA: 0s - loss: 0.6544 - mse: 0.6386\n",
      "Epoch 25: val_loss improved from 0.65242 to 0.65239, saving model to checkpoints/ext_3h_l1n2_2hidden_it19.e025_vl0.652.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6544 - mse: 0.6386 - val_loss: 0.6524 - val_mse: 0.6366\n",
      "Time elapsed to train: 19.16 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.295 2.991 1.587 3.329 2.324 1.676 1.203 0.926 0.555 0.274 0.117 0.029 0.003]\n",
      "<R> = [2.295 2.991 1.587 3.329 2.324 1.676 1.203 0.926 0.555 0.274 0.117 0.029 0.003]\n",
      "s_R = [0.044 0.001 0.000 0.029 0.046 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [3.4195356 5.8960295 5.6036396 ... 4.841943  3.8639956 4.457653 ]\n",
      "ri = [ 0.23939991  0.17100048 -1.0026503  ...  0.26299953  0.16529942\n",
      "  0.17879963]\n",
      "gr = [0.6469002  0.50619984 0.59170055 ... 0.6164999  0.39999962 0.4033003 ]\n",
      "gaia_g = [2.816513  5.4193687 5.04416   ... 4.249029  3.470891  4.043084 ]\n",
      "bp_rp = [1.1274042 0.9681673 1.0677004 ... 1.1447258 0.8715458 0.8666172]\n",
      "mag_pred: [2.5223625 5.458616  5.6665983 ... 4.1514745 3.8952749 3.1986003]\n",
      "mag_pred: [2.5223625 5.458616  5.6665983 ... 4.1514745 3.8952749 3.1986003]\n",
      "Time elapsed to make plots: 20.19 s\n"
     ]
    }
   ],
   "source": [
    "for k in range(0, n_iterations):\n",
    "    # Transform data to inputs and outputs\n",
    "    # On subsequent iterations, inflate errors using\n",
    "    # gradients dM/dtheta from trained model, and derive new\n",
    "    # estimates of the reddenings of the stars.\n",
    "    t0 = time()\n",
    "    io_train = get_inputs_outputs(\n",
    "        d_train,\n",
    "        pretrained_model=None if k == 0 else nn_model,\n",
    "        recalc_reddening=True,\n",
    "        rchisq_max=rchisq_max[k]\n",
    "    )                                                                         \n",
    "    io_test = get_inputs_outputs(\n",
    "        d_test,\n",
    "        pretrained_model=None if k == 0 else nn_model,\n",
    "        recalc_reddening=True,\n",
    "    )                                                                        \n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to prepare data: {t1-t0:.2f} s')\n",
    "    # Set learning rate based on the iteration\n",
    "    lr = 0.001 * np.exp(-0.2*k)\n",
    "    print('learning rate = {}'.format(K.get_value(nn_model.optimizer.lr)))\n",
    "    print('setting learning rate to {}'.format(lr))\n",
    "    K.set_value(nn_model.optimizer.lr, lr)\n",
    "\n",
    "    # Train the model\n",
    "    print('Iteration {} of {}.'.format(k+1, n_iterations))\n",
    "    t0 = time()\n",
    "    train_model(\n",
    "        nn_model,\n",
    "        io_train,\n",
    "        k,\n",
    "        n_iterations,\n",
    "        epochs=25,\n",
    "        checkpoint_fn='{:s}_{:d}hidden_it{:d}'.format(\n",
    "            nn_name, n_hidden, k\n",
    "        ),\n",
    "        batch_size=batch_size,\n",
    "        suff='{:s}_{:d}hidden_it{:d}'.format(nn_name, n_hidden, k)\n",
    "    )\n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to train: {t1-t0:.2f} s')\n",
    "    nn_model.save(\n",
    "        'models/{:s}_{:d}hidden_it{:d}.h5'.format(\n",
    "            nn_name, n_hidden, k\n",
    "        )\n",
    "    )\n",
    "    nn_model = keras.models.load_model(\n",
    "       'models/{:s}_{:d}hidden_it{:d}.h5'.format(nn_name, n_hidden, k)\n",
    "    )\n",
    "\n",
    "    # Plot results on test set\n",
    "    print('Diagnostic plots ...')\n",
    "    t0 = time()\n",
    "    diagnostic_plots(\n",
    "       nn_model,\n",
    "       io_test,\n",
    "       d_test,\n",
    "       #io_train,\n",
    "       #d_train,\n",
    "       suffix='{:s}_{:d}hidden_it{:d}'.format(nn_name, n_hidden, k)\n",
    "    )\n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to make plots: {t1-t0:.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1d8de09-5d9d-43a1-b6ad-5aa70393a40a",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating covariances and reddening estimates of test dataset ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 20468 bad. Replacing with 14.76698.\n",
      "Band 1: 0 of 20468 bad. Replacing with 15.16434.\n",
      "Band 2: 0 of 20468 bad. Replacing with 14.19739.\n",
      "Band 3: 13 of 20468 bad. Replacing with 15.24670.\n",
      "Band 4: 30 of 20468 bad. Replacing with 14.75285.\n",
      "Band 5: 918 of 20468 bad. Replacing with 14.62265.\n",
      "Band 6: 24 of 20468 bad. Replacing with 14.49655.\n",
      "Band 7: 10 of 20468 bad. Replacing with 14.44405.\n",
      "Band 8: 39 of 20468 bad. Replacing with 13.54000.\n",
      "Band 9: 42 of 20468 bad. Replacing with 13.15900.\n",
      "Band 10: 174 of 20468 bad. Replacing with 13.08100.\n",
      "Band 11: 19 of 20468 bad. Replacing with 15.74144.\n",
      "Band 12: 20 of 20468 bad. Replacing with 16.41437.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 20468 of 20468 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 3.009112   3.4456906 11.334532  ... 11.452497   3.940875  53.640507 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0406\n",
      "  1% : 0.112\n",
      "  10% : 0.241\n",
      "  50% : 0.635\n",
      "  90% : 2.78\n",
      "  99% : 40.4\n",
      "  100% : 4.96e+03\n",
      "<chi^2/d.o.f.> = 1.03\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to update covariances and reddenings: 5.90 s\n"
     ]
    }
   ],
   "source": [
    "print('Updating covariances and reddening estimates of test dataset ...')\n",
    "t0 = time()\n",
    "io_test = get_inputs_outputs(\n",
    "    d_test,\n",
    "    pretrained_model=nn_model,\n",
    "    recalc_reddening=True\n",
    ")\n",
    "t1 = time()\n",
    "print(f'Time elapsed to update covariances and reddenings: {t1-t0:.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fe20ad0-6076-42e4-b5fa-0a8b44b55833",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: [0.6612114310264587, 0.6454277634620667]\n",
      "train loss: [0.6537625193595886, 0.6379788517951965]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance on (train, validation and test sets)\n",
    "loss = {}\n",
    "for n,io_eval in (('test',io_test), ('train',io_train)):\n",
    "    loss[n] = evaluate_model(\n",
    "        nn_model,\n",
    "        io_eval,\n",
    "        batch_size=batch_size,\n",
    "        rchisq_max=rchisq_max[-1]\n",
    "    )\n",
    "    print(f'{n} loss: {loss[n]}')\n",
    "fname = 'loss_{:s}_{:d}hidden_it{:d}.json'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "with open(fname, 'w') as f:\n",
    "    json.dump(loss, f, indent=2, sort_keys=True)\n",
    "\n",
    "fname = 'predictions_{:s}_{:d}hidden_it{:d}.h5'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "save_predictions(fname, nn_model, d_test, io_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ef83a49-55d7-41f4-be9e-87606f86734e",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving covariance components for small subset of test dataset ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 1000 bad. Replacing with 14.74157.\n",
      "Band 1: 0 of 1000 bad. Replacing with 15.13587.\n",
      "Band 2: 0 of 1000 bad. Replacing with 14.16693.\n",
      "Band 3: 0 of 1000 bad. Replacing with 15.22345.\n",
      "Band 4: 2 of 1000 bad. Replacing with 14.72325.\n",
      "Band 5: 30 of 1000 bad. Replacing with 14.58165.\n",
      "Band 6: 2 of 1000 bad. Replacing with 14.46810.\n",
      "Band 7: 1 of 1000 bad. Replacing with 14.41670.\n",
      "Band 8: 2 of 1000 bad. Replacing with 13.51600.\n",
      "Band 9: 4 of 1000 bad. Replacing with 13.14000.\n",
      "Band 10: 3 of 1000 bad. Replacing with 13.07200.\n",
      "Band 11: 0 of 1000 bad. Replacing with 15.72640.\n",
      "Band 12: 0 of 1000 bad. Replacing with 16.39494.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 1000 of 1000 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [4.03790665e+00 1.44697781e+01 1.62151604e+01 6.94540596e+00\n",
      " 6.67488384e+00 1.36608267e+01 7.17259312e+00 4.16536999e+00\n",
      " 2.88524127e+00 1.66998444e+01 5.06595802e+00 1.08538237e+01\n",
      " 8.57480907e+00 8.90691948e+00 1.79380188e+01 1.05038815e+01\n",
      " 6.35312510e+00 1.09167471e+01 6.38044405e+00 1.72978115e+01\n",
      " 7.32645845e+00 9.09698200e+00 8.64734173e+00 5.35315990e+00\n",
      " 5.86803722e+00 1.00881500e+01 8.05662537e+00 1.41904840e+01\n",
      " 7.62130737e+00 2.63029242e+00 6.97476387e+00 6.91644192e+00\n",
      " 9.20716190e+00 1.07803467e+02 7.87511635e+00 1.35762014e+01\n",
      " 8.42736626e+00 3.88643026e+00 5.25308037e+00 5.56582260e+00\n",
      " 8.45447540e+00 5.39689102e+01 7.17698383e+00 4.14116096e+00\n",
      " 2.84123718e+02 2.25205350e+00 2.79214325e+01 2.02708888e+00\n",
      " 8.35044861e+00 1.05932426e+01 9.31414795e+00 2.67427559e+01\n",
      " 8.86998463e+00 1.88615112e+01 1.09366951e+01 4.73229742e+00\n",
      " 1.61052017e+01 2.11673679e+01 1.84073380e+02 7.35087919e+00\n",
      " 1.35206490e+01 5.66187000e+00 7.91339159e+00 5.08480787e+00\n",
      " 3.45807362e+00 6.54258251e+00 2.74681330e+00 5.93164349e+00\n",
      " 1.70295181e+01 1.28228226e+01 3.32788730e+00 1.19868917e+01\n",
      " 4.81406069e+00 3.46733689e+00 2.64841247e+00 5.73571968e+00\n",
      " 7.10516930e+00 4.51386032e+01 5.22869186e+01 2.16687450e+01\n",
      " 1.33557739e+01 6.72925091e+00 1.55185051e+01 1.63473663e+01\n",
      " 1.75906219e+01 6.41791058e+00 8.45614090e+01 3.93079853e+00\n",
      " 5.76419735e+00 4.11887321e+01 2.83649135e+00 4.46757603e+00\n",
      " 5.81254148e+00 5.70284367e+00 1.01864090e+02 7.22782135e+00\n",
      " 9.16268555e+03 1.04766407e+01 1.25768547e+01 2.45035381e+01\n",
      " 3.98543048e+00 9.97759056e+00 1.18624649e+01 2.06616974e+00\n",
      " 1.73236771e+02 8.98898983e+00 5.40776968e+00 2.24529529e+00\n",
      " 8.32403946e+00 5.61520576e+00 1.13065672e+01 4.24170151e+01\n",
      " 4.04059696e+00 4.18482542e+00 1.78578148e+01 1.20745096e+01\n",
      " 4.16527224e+00 1.17154865e+01 6.77811098e+00 3.20607686e+00\n",
      " 4.20413971e+00 5.01257038e+00 2.14533114e+00 2.10386143e+01\n",
      " 3.02746081e+00 2.68331604e+01 7.06930923e+00 3.65135527e+00\n",
      " 2.24320149e+00 9.56166458e+00 1.26826630e+01 1.30315685e+01\n",
      " 1.21177835e+01 4.24393463e+00 6.66614914e+01 2.93434334e+00\n",
      " 4.93477203e+02 8.19840527e+00 5.67809181e+01 1.25285113e+00\n",
      " 1.60518990e+01 4.04705715e+00 2.84654503e+01 6.48205471e+00\n",
      " 2.19621582e+01 4.83806658e+00 7.43580103e+00 5.44811821e+00\n",
      " 1.07158442e+01 2.14627123e+00 1.28486023e+01 7.99838734e+00\n",
      " 1.07429686e+01 1.77905331e+01 9.16777611e+00 4.53594446e+00\n",
      " 4.46154118e+00 3.55346794e+01 1.72998371e+01 2.81540823e+00\n",
      " 4.55869150e+00 1.00078754e+01 1.88111954e+01 5.08216715e+00\n",
      " 2.23165822e+00 6.36951447e+00 4.56295681e+00 1.56217408e+00\n",
      " 7.94033813e+00 7.74052811e+01 4.75837421e+00 4.39578819e+00\n",
      " 1.02366276e+01 7.15869522e+00 9.90796753e+02 2.56802106e+00\n",
      " 1.31289320e+01 8.03822041e+00 7.88076019e+00 1.12886257e+01\n",
      " 2.79878354e+00 2.60198164e+00 1.00879574e+01 2.37912178e+01\n",
      " 9.38595963e+00 1.84279385e+01 4.37751436e+00 7.78450632e+00\n",
      " 1.41256785e+00 8.69894505e+00 3.01947975e+00 1.48108053e+01\n",
      " 5.82793198e+01 2.49566460e+00 4.03225327e+00 7.10102224e+00\n",
      " 5.72670746e+00 1.10442982e+01 8.54360294e+00 4.01566601e+00\n",
      " 1.34890957e+01 1.53298731e+01 5.32977295e+00 7.97024727e+00\n",
      " 9.02729607e+00 1.06502953e+01 6.80489922e+00 4.37493896e+00\n",
      " 9.81440544e+00 8.81533241e+00 8.93197060e+00 7.98934555e+00\n",
      " 7.76814032e+00 2.42406750e+00 8.29693794e+00 1.17566605e+01\n",
      " 3.86395264e+00 1.98703117e+01 2.31560946e+00 8.16942692e+00\n",
      " 1.08723288e+01 1.45168400e+00 4.22057199e+00 4.41866922e+00\n",
      " 1.04831543e+01 2.76933861e+00 4.92029572e+00 7.78437424e+00\n",
      " 1.77298031e+01 5.63007736e+00 6.14874077e+00 4.18079185e+00\n",
      " 2.12983298e+00 2.62448215e+00 6.20301247e+00 5.45209885e+00\n",
      " 1.47586174e+01 1.15511913e+01 5.49841404e+00 7.64729929e+00\n",
      " 8.48629475e+00 1.54058146e+00 1.21455093e+02 7.83917665e+00\n",
      " 7.53092670e+00 8.90683823e+01 4.75151730e+00 1.74009933e+01\n",
      " 2.89592123e+00 9.15153623e-01 6.48648405e+00 5.31124830e+00\n",
      " 2.04887733e+01 7.71570587e+00 8.49254227e+00 5.16020012e+00\n",
      " 1.37721071e+01 3.82598448e+00 2.67489648e+00 2.13127995e+00\n",
      " 3.26193428e+01 3.49465752e+00 7.48787928e+00 1.40317659e+01\n",
      " 1.37946844e+01 1.29812078e+01 1.36256504e+01 9.61313248e+00\n",
      " 1.69934654e+00 2.94148707e+00 2.59464073e+00 4.28482819e+00\n",
      " 2.25660181e+00 2.15797329e+00 1.40216837e+01 8.62027645e+00\n",
      " 5.46207352e+01 2.47396717e+01 7.17609501e+00 3.17046261e+00\n",
      " 3.10501719e+00 5.17333794e+00 7.94843340e+00 1.27210674e+01\n",
      " 1.20346606e+03 4.39331532e+00 1.73744476e+02 6.96205292e+01\n",
      " 1.55201607e+01 6.62497091e+00 5.06354618e+00 2.08614159e+01\n",
      " 1.32903948e+01 9.36220741e+00 1.15876780e+01 6.11459198e+01\n",
      " 9.55856991e+00 2.70655131e+00 5.60299873e+00 4.29145718e+00\n",
      " 6.98718567e+01 2.55713749e+01 1.29097147e+01 2.94960451e+00\n",
      " 1.35462265e+01 7.51763773e+00 5.37008572e+00 9.53218079e+00\n",
      " 1.53878498e+00 1.06667137e+02 1.12250824e+01 6.41338825e+00\n",
      " 8.70983963e+01 3.66687727e+00 6.93719864e+00 2.65743580e+01\n",
      " 7.37428188e+00 2.95191689e+01 8.12405586e+00 1.10680332e+01\n",
      " 6.55189705e+00 7.94493008e+00 4.40913757e+02 3.85026321e+01\n",
      " 8.26808929e+00 1.28017559e+01 7.25518188e+01 7.09379053e+00\n",
      " 4.73384666e+00 2.44452782e+01 8.27930546e+00 1.15877361e+01\n",
      " 4.41026115e+00 3.18887756e+02 6.09010839e+00 4.83163261e+01\n",
      " 2.77486348e+00 2.07962728e+00 2.77384329e+00 8.92864799e+00\n",
      " 6.65092373e+00 4.26420069e+00 1.30748234e+01 3.62016439e+00\n",
      " 1.00440264e+01 2.21167011e+01 3.30825377e+00 2.25145674e+00\n",
      " 6.75912571e+00 5.87063503e+00 1.44038115e+01 1.10071573e+01\n",
      " 1.13742104e+01 1.08777771e+01 1.09705324e+01 7.27331829e+00\n",
      " 9.03756142e+00 7.85117817e+00 5.49236755e+02 1.23387051e+01\n",
      " 2.79188180e+00 4.79885244e+00 4.79612637e+00 7.26992226e+00\n",
      " 6.91169310e+00 1.97601204e+01 9.10981655e+00 1.43103075e+01\n",
      " 8.41877270e+00 8.81670856e+00 5.03233624e+00 3.54362183e+02\n",
      " 1.30504589e+01 1.65235126e+00 6.00693321e+00 2.97181892e+00\n",
      " 1.32704048e+01 1.05974236e+01 1.40276775e+01 6.49317360e+00\n",
      " 1.71492285e+03 6.02461243e+00 1.77658498e+00 7.30716801e+00\n",
      " 2.37695026e+00 7.86199379e+00 6.47322178e+00 3.11034727e+00\n",
      " 9.22853565e+00 4.10758400e+00 4.53785181e+00 7.92302656e+00\n",
      " 3.19817495e+00 3.57870579e+00 2.62519703e+01 2.22091341e+00\n",
      " 1.70469284e+01 1.12074642e+01 4.32722378e+00 3.66239572e+00\n",
      " 2.80881023e+00 1.01514854e+01 1.31300144e+01 8.35241795e+00\n",
      " 2.07594562e+00 4.22889614e+00 3.19168739e+01 1.06160259e+01\n",
      " 4.17690086e+00 5.41796827e+00 3.15713906e+00 8.90782833e+00\n",
      " 1.72136211e+01 6.38804398e+01 2.87018585e+00 6.72290134e+00\n",
      " 6.00217724e+00 2.89229083e+00 9.32669353e+00 5.58931780e+00\n",
      " 2.60776234e+00 2.32757912e+01 3.98743939e+00 9.29887772e+00\n",
      " 9.23028870e+01 7.68797874e+00 5.01099300e+00 2.70887160e+00\n",
      " 1.25253363e+01 2.16856003e+01 2.31280518e+00 6.97167969e+00\n",
      " 4.01819725e+01 5.85340929e+00 5.31463394e+01 6.04255867e+00\n",
      " 5.76071596e+00 3.15073185e+01 5.79614878e+00 2.07693558e+01\n",
      " 1.58542004e+01 2.20466426e+04 5.86986160e+00 3.69078374e+00\n",
      " 4.08728886e+00 1.66585236e+01 2.72299933e+00 1.89731026e+01\n",
      " 3.69937539e+00 1.00613308e+01 4.64180088e+00 3.63552551e+01\n",
      " 2.68005390e+01 3.76372719e+01 1.03513222e+01 3.99534035e+00\n",
      " 3.42121696e+00 5.87151480e+00 4.24860191e+00 1.18550583e+02\n",
      " 1.13315954e+01 9.37679672e+00 1.50416870e+01 1.31314125e+01\n",
      " 1.35365629e+01 3.02794552e+01 2.43843292e+02 2.33546009e+01\n",
      " 1.07744379e+01 1.11388531e+01 6.70585060e+00 3.33788872e+00\n",
      " 5.54852438e+00 2.19158697e+00 8.90112400e+00 2.90812445e+00\n",
      " 8.23109913e+00 4.89185238e+00 1.47764912e+01 3.99913559e+01\n",
      " 3.51093384e+02 2.18509254e+01 1.30592337e+01 2.32273793e+00\n",
      " 1.36189404e+01 4.43652821e+00 4.76093817e+00 3.07714081e+01\n",
      " 3.99721985e+02 6.78909445e+00 1.21147842e+01 1.53073158e+01\n",
      " 5.08384705e+00 7.85894012e+01 1.72563350e+00 1.90240440e+01\n",
      " 7.41483784e+00 3.25179791e+00 9.16210842e+00 6.66086769e+00\n",
      " 6.07245445e+00 5.57732868e+00 1.45271263e+01 5.85624790e+00\n",
      " 1.09068108e+01 1.20593176e+01 2.07560806e+01 2.32752228e+01\n",
      " 1.23340378e+01 1.20364799e+01 1.12256870e+01 1.68355713e+02\n",
      " 7.43871307e+00 3.16193027e+01 2.90918040e+00 3.58714199e+00\n",
      " 9.70427322e+00 1.83083093e+00 2.60967875e+00 1.14955378e+01\n",
      " 1.37357239e+02 2.89054222e+01 1.23926392e+01 3.71196270e+00\n",
      " 2.09057446e+01 1.92948647e+01 5.19243240e+00 3.00451779e+00\n",
      " 9.16725731e+00 3.56289911e+00 6.56594238e+01 3.68811059e+00\n",
      " 6.79348564e+00 6.38564873e+00 4.52805233e+00 2.81622124e+01\n",
      " 8.57288456e+00 5.43116188e+00 4.99707413e+00 6.75836563e+00\n",
      " 6.63900089e+00 2.11184006e+01 4.89076710e+00 5.40101624e+00\n",
      " 5.08506393e+00 7.76362801e+00 6.32329798e+00 3.05129425e+02\n",
      " 2.62002869e+01 3.96032667e+00 5.32515907e+00 2.11496353e+00\n",
      " 2.47920151e+01 8.87989235e+00 6.78303146e+00 7.29578018e+00\n",
      " 2.11284733e+01 3.49573660e+00 4.53949404e+00 1.89861908e+01\n",
      " 6.89386702e+00 7.75083733e+00 4.93541384e+00 2.17296944e+01\n",
      " 4.55693960e+00 2.55845928e+00 5.79807854e+00 2.55266533e+01\n",
      " 1.51513147e+01 1.33982382e+01 3.09898901e+00 1.90024531e+00\n",
      " 1.00127964e+01 4.31325073e+01 2.02153778e+01 5.70558643e+00\n",
      " 9.42504311e+00 7.76583147e+00 1.27869499e+02 1.29833965e+01\n",
      " 4.63186932e+00 1.58410091e+01 7.13227320e+00 8.46342373e+00\n",
      " 2.78060169e+01 5.47291183e+00 1.25730543e+01 1.04925804e+01\n",
      " 2.17283974e+01 6.90457678e+00 2.18334937e+00 4.42653513e+00\n",
      " 2.46689105e+00 9.35841084e+00 4.53068256e+00 7.03596020e+00\n",
      " 1.42732840e+01 2.99195528e+00 1.49451477e+02 3.41534781e+00\n",
      " 3.95521641e+00 1.46433029e+01 4.61820698e+00 4.42896557e+00\n",
      " 2.70593762e+00 2.02669315e+01 5.56568384e+00 6.23104239e+00\n",
      " 1.59941721e+01 2.01223240e+01 1.99057364e+00 2.76305885e+01\n",
      " 8.26083374e+00 5.61383533e+00 8.07334328e+00 3.13838840e+00\n",
      " 1.90804329e+01 8.83344746e+00 3.91808510e+00 3.63832045e+00\n",
      " 6.22817421e+00 2.85228062e+00 1.53068399e+00 1.71911602e+01\n",
      " 3.56186700e+00 4.02603054e+00 3.66917467e+00 1.28797283e+01\n",
      " 4.46445084e+00 1.02314901e+01 5.42904282e+00 2.08596973e+01\n",
      " 6.02851391e+00 8.25429058e+00 3.93766832e+00 1.00401764e+02\n",
      " 3.79368305e+00 5.89752293e+00 7.30022478e+00 1.06847954e+01\n",
      " 1.25960655e+01 1.03991480e+01 1.77681808e+01 1.91634369e+01\n",
      " 4.42102242e+00 7.04828310e+00 3.28839922e+00 5.27230787e+00\n",
      " 1.43242651e+03 5.49520063e+00 2.01415467e+00 2.07630054e+03\n",
      " 1.20993385e+01 1.03053169e+01 1.63400993e+01 1.05530624e+01\n",
      " 7.84597778e+01 9.91858959e+00 4.53019571e+00 1.33488073e+01\n",
      " 2.56974077e+00 2.41813135e+00 4.69860306e+01 4.97029114e+00\n",
      " 4.16601706e+00 9.17273903e+00 1.14132557e+01 1.63386841e+02\n",
      " 5.04367018e+00 1.26924810e+01 1.52526035e+01 9.60702705e+00\n",
      " 5.42037535e+00 2.65448570e+00 2.70879793e+00 3.30624619e+01\n",
      " 7.65180779e+00 2.48502541e+01 4.30823898e+00 1.09578371e+01\n",
      " 6.53979015e+00 1.58640274e+02 9.41514664e+01 2.29546661e+01\n",
      " 2.87823367e+00 4.89499807e+00 1.10320511e+01 8.15310478e+00\n",
      " 1.48374653e+01 3.12110500e+01 3.36016846e+00 9.74027252e+00\n",
      " 5.28073025e+00 5.87630892e+00 2.39619589e+00 5.59499893e+01\n",
      " 4.79811907e+00 2.95181465e+00 2.43195007e+02 5.14234066e+00\n",
      " 8.12050247e+00 3.97796202e+00 9.47866917e+00 5.03672552e+00\n",
      " 2.23337307e+01 1.16345463e+01 7.10757875e+00 1.36811991e+01\n",
      " 6.87013292e+00 6.26658154e+00 6.20172386e+01 2.77117682e+00\n",
      " 3.07880664e+00 7.94018173e+00 3.77470398e+00 4.51730585e+00\n",
      " 1.17574520e+01 4.95791149e+00 3.94993687e+00 4.98605871e+00\n",
      " 1.38245239e+01 7.79631329e+00 1.11955624e+01 6.35316610e+00\n",
      " 5.55538864e+01 4.30206919e+00 7.08740616e+00 2.50453734e+00\n",
      " 5.36189032e+00 4.61437750e+00 1.20115156e+01 4.13644218e+00\n",
      " 9.70144272e+00 8.44004631e+00 1.68353462e+01 1.41135907e+00\n",
      " 4.77841616e+00 9.42449951e+00 2.15300202e+00 2.50506802e+01\n",
      " 3.28037186e+01 7.86980915e+00 1.36687336e+01 1.04363518e+01\n",
      " 1.72068119e+00 1.78684502e+01 2.32339172e+02 3.20951128e+00\n",
      " 2.06072578e+01 4.72727585e+00 3.87379360e+00 5.76699448e+00\n",
      " 1.22332535e+02 4.97413063e+00 4.85639000e+00 4.02408361e+00\n",
      " 6.93880653e+00 7.02975941e+00 1.34652924e+02 5.18696165e+00\n",
      " 6.22300959e+00 7.21567631e+00 2.90479112e+00 5.49932575e+00\n",
      " 3.54894495e+00 9.33528709e+00 9.33382702e+00 1.51081467e+01\n",
      " 1.10470877e+01 9.16162300e+00 3.09940186e+01 9.17507839e+00\n",
      " 4.62904692e+00 2.47409177e+00 8.98384953e+00 5.60539865e+00\n",
      " 5.60745735e+01 1.47719264e+00 4.63907528e+00 3.20481801e+00\n",
      " 4.61436224e+00 6.90010910e+01 6.87525177e+00 4.77199268e+00\n",
      " 8.83541012e+00 1.11362858e+01 1.04156296e+02 4.88057852e+00\n",
      " 9.05116940e+00 4.26839828e+00 2.04889221e+01 1.84464359e+01\n",
      " 2.49145603e+00 8.00778961e+00 7.77872562e+00 4.51792908e+00\n",
      " 7.54632711e+00 2.73292770e+01 1.32453327e+01 1.22162104e+01\n",
      " 3.45167084e+01 3.02192044e+00 5.85700655e+00 4.36501312e+00\n",
      " 4.19556618e+00 4.52358150e+00 3.59260988e+00 7.77262211e+00\n",
      " 7.74162388e+00 9.47511196e+00 4.51552696e+01 1.13486996e+01\n",
      " 6.11417341e+00 1.43174839e+01 1.65051117e+01 1.70602341e+01\n",
      " 1.10967045e+01 4.74814415e+00 2.91900015e+00 2.77049327e+00\n",
      " 3.48436499e+00 8.48874092e+00 2.85178894e+02 1.37004814e+01\n",
      " 2.36022034e+01 7.26221514e+00 1.57631197e+01 1.13255262e+01\n",
      " 3.72659988e+01 9.92518711e+00 9.23311424e+00 4.04110336e+00\n",
      " 1.36019115e+01 5.76904488e+00 2.02843595e+00 2.15887508e+01\n",
      " 1.02746449e+01 3.05534577e+00 6.41274118e+00 1.64735687e+02\n",
      " 4.73791473e+02 4.79456749e+01 8.77506924e+00 1.17559147e+01\n",
      " 8.52608967e+00 2.41264706e+01 2.59720993e+00 1.15476112e+01\n",
      " 1.32123070e+01 8.98280907e+00 8.90618057e+01 7.67174816e+00\n",
      " 6.90104818e+00 1.09701061e+01 7.66665983e+00 1.27531128e+01\n",
      " 5.93504286e+00 5.43272495e+00 1.21026695e+00 2.96046505e+01\n",
      " 3.97985458e+01 5.23139763e+00 4.02428055e+00 3.01565685e+01\n",
      " 8.49289799e+00 1.13567209e+01 2.89303422e+00 9.20943069e+00\n",
      " 4.32696419e+01 5.46878433e+00 1.54584513e+01 3.25868011e+00\n",
      " 3.48593664e+00 2.89456215e+01 4.66312504e+00 1.35288131e+00\n",
      " 1.60543633e+01 7.85412025e+00 5.58907843e+00 6.24327850e+01\n",
      " 3.45898461e+00 3.97572803e+00 1.14727600e+03 4.39409304e+00\n",
      " 7.67641640e+00 6.26734161e+00 6.39818096e+00 3.82075119e+00\n",
      " 8.37916946e+00 1.27294283e+01 2.83493829e+00 1.39128132e+01\n",
      " 8.72349930e+00 9.19183350e+00 1.40565119e+01 1.66126895e+00\n",
      " 9.65610218e+00 2.60205860e+01 1.12893057e+01 3.85974407e+00\n",
      " 1.13255653e+01 1.11670570e+01 2.22109604e+00 7.81073475e+00\n",
      " 9.03577900e+00 4.13738060e+01 4.80644188e+01 1.11363792e+01\n",
      " 1.63205986e+01 2.18743992e+00 8.67866898e+00 2.31118226e+00\n",
      " 1.86377563e+02 1.46670189e+01 1.29097824e+01 1.87675552e+01\n",
      " 1.50424995e+01 4.24473953e+00 4.91925764e+00 1.03885069e+01\n",
      " 8.36848545e+00 1.14679918e+01 5.27912998e+00 1.66746998e+00\n",
      " 8.65034485e+00 7.00934124e+00 7.13531542e+00 2.56803250e+00\n",
      " 3.73545074e+01 7.93854856e+00 6.44436340e+01 1.01652651e+01\n",
      " 7.91681337e+00 9.19428539e+00 2.49530745e+00 2.41453819e+01\n",
      " 5.73845482e+00 2.67203350e+01 6.89455748e+00 8.48135090e+00\n",
      " 1.05603771e+01 4.18880701e+00 4.35008812e+00 2.07184839e+00\n",
      " 7.08633362e+02 1.79392660e+00 7.04239941e+00 6.24700546e+00\n",
      " 1.91992683e+01 1.47786922e+01 1.32075367e+01 5.39496517e+00\n",
      " 6.61039162e+00 4.10528259e+01 1.62628174e+01 9.68977832e+03\n",
      " 2.64280834e+01 9.12288208e+01 1.82538891e+01 2.59966207e+00\n",
      " 1.68897915e+01 2.93644371e+01 1.60994415e+01 1.62005310e+01\n",
      " 3.43966913e+00 6.57456875e+00 2.53812981e+00 4.46068802e+01\n",
      " 2.75812893e+01 2.97627306e+00 6.22602844e+00 1.14795313e+01\n",
      " 7.76985121e+00 9.88227844e+00 4.15417633e+01 1.17981663e+01\n",
      " 7.03016472e+00 1.14516659e+01 2.19797821e+01 4.24436951e+00\n",
      " 6.96448994e+00 1.06454182e+01 1.47141161e+01 2.19030037e+01\n",
      " 4.86516714e+00 1.49271698e+01 6.94565439e+00 4.59802151e+00\n",
      " 1.72193203e+01 3.24162750e+01 3.66844463e+00 3.49933410e+00\n",
      " 3.50786662e+00 1.37681627e+01 3.67392325e+00 5.06064272e+00\n",
      " 1.06561489e+01 2.68123150e+01 2.03450394e+00 3.15126181e+00]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0763\n",
      "  1% : 0.128\n",
      "  10% : 0.242\n",
      "  50% : 0.662\n",
      "  90% : 2.74\n",
      "  99% : 50\n",
      "  100% : 2e+03\n",
      "<chi^2/d.o.f.> = 1.04\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n"
     ]
    }
   ],
   "source": [
    "print('Saving covariance components for small subset of test dataset ...')\n",
    "# Fix random seed (same subset every run)\n",
    "np.random.seed(3)\n",
    "idx = np.arange(d_test.size)\n",
    "np.random.shuffle(idx)\n",
    "idx = idx[:1000]\n",
    "d_comp = d_test[idx]\n",
    "io_comp = get_inputs_outputs(\n",
    "    d_comp,\n",
    "    pretrained_model=nn_model,\n",
    "    recalc_reddening=True,\n",
    "    return_cov_components=True\n",
    ")\n",
    "fname = 'predictions_{:s}_{:d}hidden_it{:d}_comp.h5'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "save_predictions(fname, nn_model, d_comp, io_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bf3ec27-6103-4713-9c21-1222e68e39f1",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data and reddening estimates of subset of test dataset ...\n"
     ]
    }
   ],
   "source": [
    "print('Saving data and reddening estimates of subset of test dataset ...')\n",
    "np.random.seed(5)\n",
    "idx = np.arange(d_test.size)\n",
    "np.random.shuffle(idx)\n",
    "idx = idx[:10000]\n",
    "d_small = d_test[idx]\n",
    "r_fit_small = io_test['r'][idx]\n",
    "r_var_small = io_test['r_var'][idx]\n",
    "fname = 'test_data_small_{:s}_{:d}hidden.h5'.format(\n",
    "    nn_name, n_hidden\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82da0ebc-697f-4f8b-ae07-05ba4f0e7217",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving subset to test_data_small_ext_3h_l1n2_2hidden.h5 ...\n"
     ]
    }
   ],
   "source": [
    "print(f'Saving subset to {fname} ...')\n",
    "with h5py.File(fname, 'w') as f:\n",
    "    dset = f.create_dataset(\n",
    "        'data',\n",
    "        data=d_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )\n",
    "    for key in d_attrs:\n",
    "        dset.attrs[key] = d_attrs[key]\n",
    "\n",
    "    # Store updated reddening estimates\n",
    "    dset = f.create_dataset(\n",
    "        'r_fit',\n",
    "        data=r_fit_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )\n",
    "    dset = f.create_dataset(\n",
    "        'r_var',\n",
    "        data=r_var_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 2,
      "defaultCellHeight": 40,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
