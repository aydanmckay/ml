{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b43db49-f88d-44af-8188-9c546a2bb2e1",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "source": [
    "Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12337364-915d-45e0-aa68-ff9ad349e998",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "# # Tell Tensorflow not to allocate all GPU memory right away.\n",
    "# # This is very important in shared environments!\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU') \n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from glob import glob\n",
    "from time import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b0b4d-d609-4535-82f4-76f5979bb893",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### The dataloder used by Green+2020 which will be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f39968a5-1090-448f-a6dc-b53829db1f41",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(fname, return_attrs=False):\n",
    "    print(f'Loading {fname} ...')\n",
    "    attrs = {}\n",
    "    with h5py.File(fname, 'r') as f:\n",
    "        dset = f['io_data']\n",
    "        for key in dset.attrs.keys():\n",
    "            attrs[key] = dset.attrs[key]\n",
    "        d = dset[:]\n",
    "    \n",
    "    if return_attrs:\n",
    "        return d, attrs\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a7c2e5-f232-46ff-b235-d6604c1b5d35",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Obtaining a correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e0eccc-4ffd-4904-a210-7b430692c477",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_corr_matrix(cov):\n",
    "    rho = cov.copy()\n",
    "    sqrt_cov_diag = np.sqrt(cov[np.diag_indices(cov.shape[0])])\n",
    "    rho /= sqrt_cov_diag[:,None]\n",
    "    rho /= sqrt_cov_diag[None,:]\n",
    "    rho[np.diag_indices(cov.shape[0])] = sqrt_cov_diag\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f2ec3-9dba-4970-ab73-494dddd61534",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Cannot be explained in one markdown cell above, need to look through it more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72257ca9-2c06-4d52-9589-9b9086876356",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_inputs_outputs(d, pretrained_model=None,\n",
    "                          recalc_reddening=False,\n",
    "                          rchisq_max=None,\n",
    "                          return_cov_components=False):\n",
    "    n_bands = 13 # Gaia (G, BP, RP), PS1 (grizy), 2MASS (JHK), unWISE (W1,W2)\n",
    "    n_atm_params = 3 # (T_eff, logg, [M/H])\n",
    "    \n",
    "    large_err = 999.\n",
    "\n",
    "    # Stellar spectroscopic parameters\n",
    "    print('Fill in stellar atmospheric parameters ...')\n",
    "    x = np.empty((d.size,3), dtype='f4')\n",
    "    x[:] = d['atm_param'][:]\n",
    "\n",
    "    x_p = np.empty((d.size,3), dtype='f4')\n",
    "    x_p = d['atm_param_p'][:]\n",
    "\n",
    "    # Magnitudes\n",
    "    print('Fill in stellar magnitudes ...')\n",
    "    y = np.empty((d.size,n_bands), dtype='f4')\n",
    "    y[:] = d['mag'][:]\n",
    "\n",
    "    # Covariance of y\n",
    "    print('Empty covariance matrix ...')\n",
    "    cov_y = np.zeros((d.size,n_bands,n_bands), dtype='f4')\n",
    "\n",
    "    # \\delta m\n",
    "    print('Covariance: \\delta m ...')\n",
    "    for i in range(n_bands):\n",
    "        cov_y[:,i,i] = d['mag_err'][:,i]**2\n",
    "\n",
    "    # Replace NaN magnitudes with median (in each band).\n",
    "    # Also set corresponding variances to large number.\n",
    "    print('Replace NaN magnitudes ...')\n",
    "    for b in range(n_bands):\n",
    "        idx = (\n",
    "              ~np.isfinite(y[:,b])\n",
    "            | ~np.isfinite(cov_y[:,b,b])\n",
    "        )\n",
    "        n_bad = np.count_nonzero(idx)\n",
    "        n_tot = idx.size\n",
    "        y0 = np.median(y[~idx,b])\n",
    "        if np.isnan(y0):\n",
    "            y0 = 0.\n",
    "        print(f'Band {b}: {n_bad} of {n_tot} bad. Replacing with {y0:.5f}.')\n",
    "        y[idx,b] = y0\n",
    "        cov_y[idx,b,b] = large_err**2.\n",
    "\n",
    "    # Transform both y and its covariance\n",
    "    B = np.identity(n_bands, dtype='f4')\n",
    "    B[1:,0] = -1.\n",
    "    \n",
    "    print('Transform y -> B y ...')\n",
    "    y = np.einsum('ij,nj->ni', B, y) # y' = B y\n",
    "    print('Transform C -> B C B^T ...')\n",
    "    #cov_y = np.einsum('ik,nkl,jl->nij', B, cov_y, B) # C' = B C B^T\n",
    "    cov_y = np.einsum('nik,jk->nij', cov_y, B)\n",
    "    cov_y = np.einsum('ik,nkj->nij', B, cov_y)\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp = {\n",
    "            'delta_m': cov_y.copy()\n",
    "        }\n",
    "    \n",
    "    # Add in dM/dtheta and dR/dtheta terms\n",
    "    if pretrained_model is not None:\n",
    "        print('Calculate J = dM/dtheta ...')\n",
    "        J_M = calc_dmag_color_dtheta(pretrained_model, x_p)\n",
    "        cov_x = d['atm_param_cov_p']\n",
    "        print('Covariance: J C_theta J^T ...')\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_M)\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['dM/dtheta'] = np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_M)\n",
    "\n",
    "    # If pretrained model provided, could calculate reduced chi^2\n",
    "    # with maximum-likelihood (mu, E) here.\n",
    "\n",
    "    # \\delta \\mu (must be added in after transformation,\n",
    "    #             due to possibly infinite terms).\n",
    "    print('{:d} NaN parallaxes'.format(\n",
    "        np.count_nonzero(np.isnan(d['parallax']))\n",
    "    ))\n",
    "    err_over_plx = d['parallax_err'] / d['parallax']\n",
    "    print('Covariance: DM uncertainty term ...')\n",
    "    cov_y[:,0,0] += (5./np.log(10.) * err_over_plx)**2.\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp['dm'] = np.zeros_like(cov_y)\n",
    "        cov_comp['dm'][:,0,0] = (5./np.log(10.) * err_over_plx)**2.\n",
    "\n",
    "    # Subtract distance modulus from m_G\n",
    "    #dm = -5. * (np.log10(d['parallax']) - 2.)\n",
    "    #dm_corr = 0.5 * err_over_plx**2 + 0.75 * err_over_plx**4\n",
    "    #dm_corr_pct = np.percentile(dm_corr, [1., 5., 10., 50., 90., 95., 99.])\n",
    "    #print(dm_corr_pct)\n",
    "\n",
    "    print('Estimate DM ...')\n",
    "    dm = 10. - 5.*np.log10(d['parallax'])# + 5./np.log(10.)*dm_corr\n",
    "    y[:,0] -= dm\n",
    "\n",
    "    # Don't attempt to predict M_G for poor plx/err or when plx < 0\n",
    "    print('Filter out M_G for poor parallax measurements ...')\n",
    "    idx = (\n",
    "          (err_over_plx > 0.2)\n",
    "        | (d['parallax'] < 1.e-8)\n",
    "        | ~np.isfinite(d['parallax'])\n",
    "        | ~np.isfinite(d['parallax_err'])\n",
    "    )\n",
    "    n_use = idx.size - np.count_nonzero(idx)\n",
    "    print(r'Using {:d} of {:d} ({:.3f}%) of stellar parallaxes.'.format(\n",
    "        n_use, idx.size, n_use/idx.size*100.\n",
    "    ))\n",
    "    cov_y[idx,0,0] = large_err**2\n",
    "    y[idx,0] = np.nanmedian(y[:,0])\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp['dm'][idx,0,0] = large_err**2\n",
    "\n",
    "    # Reddenings\n",
    "    print('Copy reddenings ...')\n",
    "    r = np.empty((d.size,), dtype='f4')\n",
    "    r[:] = d['r'][:]\n",
    "    \n",
    "    if pretrained_model is None:\n",
    "        # If R has not yet been estimated, then\n",
    "        # cut out stars with sigma_r > 0.2 mag.\n",
    "        idx = (d['r_err'] > 0.2)\n",
    "        print(f'Cutting {np.count_nonzero(idx)} stars with large sigma_r.')\n",
    "        for k in range(cov_y.shape[1]):\n",
    "            cov_y[idx,k,k] += large_err**2\n",
    "\n",
    "    if pretrained_model is not None:\n",
    "        # Update reddenings, based on vector R and (y_obs - y_pred).\n",
    "        # Use provided reddenings as a prior.\n",
    "\n",
    "        # First, need to calculate inv_cov_y\n",
    "        print('Invert C_y matrices ...')\n",
    "        inv_cov_y = np.stack([np.linalg.inv(c) for c in cov_y])\n",
    "\n",
    "        # Predict M & R for each star based on atm. params\n",
    "        M_pred = predict_M(pretrained_model, x_p)\n",
    "        R = predict_R(pretrained_model, x_p)\n",
    "        \n",
    "        r_var = d['r_err']**2\n",
    "        \n",
    "        # Calculate posterior on reddening\n",
    "        if recalc_reddening:\n",
    "            print('Calculate posterior on reddening ...')\n",
    "            r_pred, r_var = update_reddenings(\n",
    "                M_pred, R, y,\n",
    "                inv_cov_y,\n",
    "                r, r_var\n",
    "            )\n",
    "            \n",
    "            # Clip mean and variance of reddenings\n",
    "            print('Clip reddenings and reddening variances ...')\n",
    "            r[:] = np.clip(r_pred, 0., 10.) # TODO: Update upper limit?\n",
    "        \n",
    "        # TODO: Different lower bounds on error for different sources?\n",
    "        r_var[:] = np.clip(r_var, 0.02**2 + (0.1*r)**2, 10.**2)\n",
    "        \n",
    "        # Reddening uncertainty term in covariance of y\n",
    "        print('Covariance: reddening uncertainty term ...')\n",
    "        cov_y += r_var[:,None,None] * R[:,:,None]*R[:,None,:]\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['r'] = r_var[:,None,None] * R[:,:,None]*R[:,None,:]\n",
    "        \n",
    "        # Propagate uncertainty in theta to uncertainty in R\n",
    "        print('Calculate J = dA/dtheta ...')\n",
    "        J_A = calc_dext_red_dtheta(pretrained_model, x_p, r)\n",
    "        cov_x = d['atm_param_cov_p']\n",
    "        print('Covariance: J C_theta J^T ...')\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_A)\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_A)\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_M)\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['dA/dtheta'] = np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_A)\n",
    "            cov_comp['dMA/dtheta'] = np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_A)\n",
    "            cov_comp['dAM/dtheta'] = np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_M)\n",
    "        \n",
    "        # Calculate chi^2 for each star\n",
    "        chisq = calc_chisq(M_pred+r[:,None]*R-y, inv_cov_y)\n",
    "        print('chisq =', chisq)\n",
    "\n",
    "        # Calculate d.o.f. of each star\n",
    "        print('Calculate d.o.f. of each star ...')\n",
    "        n_dof = np.zeros(d.size, dtype='i4')\n",
    "        for k in range(n_bands):\n",
    "            n_dof += (cov_y[:,k,k] < (large_err-1.)**2).astype('i4')\n",
    "        #print('n_dof =', n_dof)\n",
    "\n",
    "        # Calculate reduced chi^2 for each star\n",
    "        print('Calculate chi^2/d.o.f. for each star ...')\n",
    "        rchisq = chisq / (n_dof - 1.)\n",
    "        pct = (0., 1., 10., 50., 90., 99., 100.)\n",
    "        rchisq_pct = np.percentile(rchisq[np.isfinite(rchisq)], pct)\n",
    "        print('chi^2/dof percentiles:')\n",
    "        for p,rc in zip(pct,rchisq_pct):\n",
    "            print(rf'  {p:.0f}% : {rc:.3g}')\n",
    "        idx_rchisq = (rchisq < 10.)\n",
    "        print(f'<chi^2/d.o.f.> = {np.mean(rchisq[idx_rchisq]):.3g}')\n",
    "        \n",
    "        # Filter on reduced chi^2\n",
    "        if rchisq_max is not None:\n",
    "            print('Filter on chi^2/d.o.f. ...')\n",
    "            idx = np.isfinite(rchisq) & (rchisq > 0.) & (rchisq < rchisq_max)\n",
    "            n_filt = np.count_nonzero(~idx)\n",
    "            pct_filt = 100. * n_filt / idx.size\n",
    "            print(\n",
    "                rf'Filtering {n_filt:d} stars ({pct_filt:.3g}%) ' +\n",
    "                rf'based on chi^2/dof > {rchisq_max:.1f}'\n",
    "            )\n",
    "            x = x[idx]\n",
    "            x_p = x_p[idx]\n",
    "            r = r[idx]\n",
    "            y = y[idx]\n",
    "            cov_y = cov_y[idx]\n",
    "            r_var = r_var[idx]\n",
    "            rchisq = rchisq[idx]\n",
    "            \n",
    "            if return_cov_components:\n",
    "                for key in cov_comp:\n",
    "                    cov_comp[key] = cov_comp[key][idx]\n",
    "\n",
    "    # Cholesky transform of inverse covariance: L L^T = C^(-1).\n",
    "    print('Cholesky transform of each stellar covariance matrix ...')\n",
    "    LT = np.empty_like(cov_y)\n",
    "    inv_cov_y = np.empty_like(cov_y)\n",
    "    for k,c in enumerate(cov_y):\n",
    "        try:\n",
    "            # Inflate diagonal of cov slightly, to ensure\n",
    "            # positive-definiteness\n",
    "            c_diag = c[np.diag_indices_from(c)]\n",
    "            c[np.diag_indices_from(c)] += 1.e-4 + 1.e-3 * c_diag\n",
    "            \n",
    "            inv_cov_y[k] = np.linalg.inv(c)\n",
    "            LT[k] = np.linalg.cholesky(inv_cov_y[k]).T\n",
    "            #ic = np.linalg.inv(c)\n",
    "            #LT.append(np.linalg.cholesky(ic).T)\n",
    "            #inv_cov_y.append(ic)\n",
    "        except np.linalg.LinAlgError as e:\n",
    "            rho = get_corr_matrix(c)\n",
    "            print('Offending correlation matrix:')\n",
    "            print(np.array2string(\n",
    "                rho[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >7.4f}'.format(z)}\n",
    "            ))\n",
    "            print('Offending covariance matrix:')\n",
    "            print(np.array2string(\n",
    "                c[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >9.6f}'.format(z)}\n",
    "            ))\n",
    "            print('Covariance matrix of (normed) atmospheric parameters:')\n",
    "            print(d['atm_param_cov_p'][k])\n",
    "            if pretrained_model is not None:\n",
    "                print(f'Variance of r: {r_var[k]:.8f}')\n",
    "            \n",
    "            # Inflate errors along the diagonal and try again\n",
    "            c_diag = c[np.diag_indices_from(c)]\n",
    "            c[np.diag_indices_from(c)] += 0.02 + 0.02 * c_diag\n",
    "            rho = get_corr_matrix(c)\n",
    "            print('Inflated correlation matrix:')\n",
    "            print(np.array2string(\n",
    "                rho[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >7.4f}'.format(z)}\n",
    "            ))\n",
    "            \n",
    "            inv_cov_y[k] = np.linalg.inv(c)\n",
    "            LT[k] = np.linalg.cholesky(inv_cov_y[k]).T\n",
    "            #raise e\n",
    "\n",
    "    #print('Stack L^T matrices ...')\n",
    "    #LT = np.stack(LT)\n",
    "    #print('Stack C^(-1) matrices ...')\n",
    "    #inv_cov_y = np.stack(inv_cov_y)\n",
    "\n",
    "    # L^T y\n",
    "    print('Calculate L^T y ...')\n",
    "    LTy = np.einsum('nij,nj->ni', LT, y)\n",
    "\n",
    "    print('Gather inputs and outputs and return ...')\n",
    "    inputs_outputs = {\n",
    "        'x':x, 'x_p':x_p, 'r':r, 'y':y,\n",
    "        'LT':LT, 'LTy':LTy,\n",
    "        'cov_y':cov_y, 'inv_cov_y':inv_cov_y,\n",
    "    }\n",
    "    \n",
    "    if return_cov_components:\n",
    "        inputs_outputs['cov_comp'] = cov_comp\n",
    "    \n",
    "    if pretrained_model is not None:\n",
    "        inputs_outputs['r_var'] = r_var\n",
    "        inputs_outputs['rchisq'] = rchisq\n",
    "\n",
    "    # Check that there are no NaNs or Infs in results\n",
    "    for key in inputs_outputs:\n",
    "        if isinstance(inputs_outputs[key], dict):\n",
    "            continue\n",
    "        if key == 'rchisq': # Infs appear when d.o.f. = 1\n",
    "            continue\n",
    "        if np.any(~np.isfinite(inputs_outputs[key])):\n",
    "            raise ValueError(f'NaNs or Infs detected in {key}.')\n",
    "\n",
    "    return inputs_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caad35d-51ad-4e5f-8e27-57ac56e80468",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Predicts the absolute magnitude in the Gaia G-band and the colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb5329ec-4d17-4a14-9ec3-936b60844ca9",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_M(nn_model, x_p):\n",
    "    \"\"\"\n",
    "    Predicts (absmag0,color1,color2,...) for input\n",
    "    normalized stellar parameters.\n",
    "\n",
    "    Inputs:\n",
    "        nn_model (keras.Model): Neural network model.\n",
    "        x_p (np.ndarray): Normalized stellar parameters.\n",
    "            Shape = (n_stars, 3).\n",
    "    \n",
    "    Outputs:\n",
    "        M (np.ndarray): Shape = (n_stars, n_bands).\n",
    "    \"\"\"\n",
    "    inputs = nn_model.get_layer(name='theta').input\n",
    "    outputs = nn_model.get_layer(name='BM').output\n",
    "    mag_color_model = keras.Model(inputs, outputs)\n",
    "    M = mag_color_model.predict(x_p)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14482c31-4986-4451-b4f7-295c2b3530b0",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Predicting the redenning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b36fc92-d995-4531-a1e4-994b63a9a954",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_R(nn_model, x_p=None):\n",
    "    inputs = nn_model.get_layer(name='theta').input\n",
    "    outputs = nn_model.get_layer(name='R').output\n",
    "    R_model = keras.Model(inputs, outputs)\n",
    "    if x_p is None:\n",
    "        R = R_model.predict(np.array([[0.,0.,0.]]))[0]\n",
    "        R[1:] -= R[0]\n",
    "    else:\n",
    "        R = R_model.predict(x_p)\n",
    "        R[:,1:] -= R[:,0][:,None]\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2cab63-a66c-4c34-a7f1-50cb9568337b",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Saving the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52ee4e30-e866-45c2-a60f-37f5d8996b9f",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_predictions(fname, nn_model, d_test, io_test):\n",
    "    M_pred = predict_M(nn_model, io_test['x_p'])\n",
    "    R_pred = predict_R(nn_model, io_test['x_p'])\n",
    "    R0 = predict_R(nn_model)\n",
    "    \n",
    "    with h5py.File(fname, 'w') as f:\n",
    "        f.create_dataset('/data', data=d_test, chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/y_obs', data=io_test['y'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/cov_y', data=io_test['cov_y'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/r_fit', data=io_test['r'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/M_pred', data=M_pred, chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/R_pred', data=R_pred, chunks=True,\n",
    "                        compression='gzip', compression_opts=3)\n",
    "        f.attrs['R0'] = R0\n",
    "        \n",
    "        if 'cov_comp' in io_test:\n",
    "            for key in io_test['cov_comp']:\n",
    "                f.create_dataset(\n",
    "                    f'/cov_comp/{key.replace(r\"/\",\"_\")}',\n",
    "                    data=io_test['cov_comp'][key],\n",
    "                    chunks=True,\n",
    "                    compression='gzip',\n",
    "                    compression_opts=3\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9dbfb5-0fa8-47b6-b59e-5507d8182916",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Updates the redenning, as in the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12ce532d-8584-46ea-b538-a65837b35597",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_reddenings(M_pred, R, y_obs, inv_cov_y, r0, r_var0):\n",
    "    \"\"\"\n",
    "    Updates the posterior on reddening of each star, given\n",
    "    the predicted absolute magnitudes, reddening vector,\n",
    "    observed magnitudes, inverse covariance matrix, and priors on\n",
    "    reddening.\n",
    "    \n",
    "    The model is given by\n",
    "    \n",
    "        y_obs = M_pred + R r,\n",
    "    \n",
    "    with the uncertainties in y_obs described by inv_cov_y, and\n",
    "    with a prior on r described by (r0, r_var0). We solve for\n",
    "    the Gaussian posterior on r: p(r|y_obs,M_pred,R,r0,r_var0).\n",
    "    \n",
    "    Let n = # of bands, k = # of stars.\n",
    "\n",
    "    Inputs:\n",
    "        M_pred (np.ndarray): Shape-(k,n) array containing predicted\n",
    "            zero-reddening asbolute magnitude & colors for each star.\n",
    "        R (np.ndarray): Shape-(k,n) array containing reddening vector\n",
    "            for each star.\n",
    "        inv_cov_y (np.ndarray): Shape-(k,n,n) array containing\n",
    "            covariance matrix of y_obs-y_pred for each star.\n",
    "        y_obs (np.ndarray): Shape-(k,n) array containing observed\n",
    "            magnitude (minus distance modulus) & colors for each star.\n",
    "        r0 (np.ndarray): Shape-(k,) array containing mean of prior on\n",
    "            reddening for each star.\n",
    "        r_var0 (np.ndarray): Shape-(k,) array containing variance of\n",
    "            prior on reddening for each star.\n",
    "\n",
    "    Outputs:\n",
    "        r_mean (np.ndarray): Shape-(k,) array containing mean posterior\n",
    "            reddening of each star.\n",
    "        r_var (np.ndarray): Shape-(k,) array containing variance of\n",
    "            reddening posterior for each star.\n",
    "    \"\"\"\n",
    "    print('Updating reddenings:')\n",
    "    print('  * R^T C_y^(-1) ...')\n",
    "    RT_Cinv = np.einsum('ni,nij->nj', R, inv_cov_y)\n",
    "    print('  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...')\n",
    "    num = r0/r_var0 + np.einsum('ni,ni->n', RT_Cinv, y_obs - M_pred)\n",
    "    print('  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...')\n",
    "    den = np.einsum('ni,ni->n', RT_Cinv, R) + 1./r_var0\n",
    "    print('  * r_mean, r_var ...')\n",
    "    r_mean = num / den\n",
    "    r_var = 1. / den\n",
    "\n",
    "    return r_mean, r_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d6a72-37ab-4d7a-bfb3-cd329804a9ca",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### calculates the chi^2, as in docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c76cf577-6ee4-41db-a3ea-bada40e97afb",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_chisq(dy, inv_cov_y):\n",
    "    \"\"\"\n",
    "    Returns the chi^2 for each observation, given\n",
    "    an array of residuals and inverse covariance matrices.\n",
    "    \n",
    "        chi^2 = dy^T C^{-1} dy.\n",
    "    \n",
    "    Inputs:\n",
    "        dy (np.ndarray): Residual values. Shape = (n_obs, n_dim),\n",
    "            where n_obs is the number of observations, and n_dim is\n",
    "            the dimensionality of the vector space.\n",
    "        inv_cov_y (np.ndarray): Inverse covariance matrices.\n",
    "            Shape = (n_obs, n_dim, n_dim).\n",
    "    \n",
    "    Returns:\n",
    "        chisq (np.ndarray): Chi^2 for each observation. Shape=(n_obs,).\n",
    "    \"\"\"\n",
    "    C_inv_dy = np.einsum('nij,nj->ni', inv_cov_y, dy)\n",
    "    chisq = np.einsum('ni,ni->n', dy, C_inv_dy)\n",
    "    return chisq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50c262-4e28-419e-83d5-8b75ec32470b",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Creates the architecture of the NN as described in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45204db0-8dfb-448f-879b-11102036d543",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_nn_model(n_hidden_layers=1, hidden_size=32, l1=1.e0, l2=1.e-4, n_bands=13):\n",
    "    # Stellar model: B M(theta)\n",
    "    atm = keras.Input(shape=(3,), name='theta')\n",
    "    x = atm\n",
    "    for i in range(n_hidden_layers):\n",
    "        x = keras.layers.Dense(\n",
    "            hidden_size,\n",
    "            activation='sigmoid',\n",
    "            kernel_regularizer=keras.regularizers.l2(l=l2),\n",
    "            name=f'stellar_model_hidden_{i+1}'\n",
    "        )(x)\n",
    "    mag_color = keras.layers.Dense(n_bands, name='BM')(x)\n",
    "\n",
    "    # Reddening measurement E\n",
    "    red = keras.Input(shape=(1,), name='E')\n",
    "    \n",
    "    # Extinction vector: R(theta)\n",
    "    r = atm\n",
    "    #for i in range(n_hidden_layers):\n",
    "    #    r = keras.layers.Dense(\n",
    "    #        6,\n",
    "    #        use_bias=True,\n",
    "    #        activation='sigmoid',\n",
    "    #        kernel_regularizer=keras.regularizers.l2(l=l2),\n",
    "    #        name=f'extinction_model_hidden_{i+1}'\n",
    "    #    )(r)\n",
    "    ext_vec = keras.layers.Dense(\n",
    "        n_bands,\n",
    "        use_bias=True,\n",
    "        activation='exponential',\n",
    "        #kernel_regularizer=keras.regularizers.l1_l2(l1=1.e0, l2=1.e0),\n",
    "        kernel_regularizer=keras.regularizers.l1(l=l1),\n",
    "        name='R'\n",
    "    )(r)\n",
    "    \n",
    "    # Extinction A = ER\n",
    "    ext = keras.layers.Multiply(name='A')([red, ext_vec])\n",
    "    \n",
    "    # Transform extinction to extinction,reddening using B: BA\n",
    "    B = np.identity(n_bands, dtype='f4')\n",
    "    B[1:,0] = -1.\n",
    "    ext_red = keras.layers.Dense(\n",
    "        n_bands,\n",
    "        use_bias=False,\n",
    "        trainable=False,\n",
    "        weights=[B.T],\n",
    "        name='BA'\n",
    "    )(ext)\n",
    "\n",
    "    # Predicted mag,color, B(M+A)\n",
    "    y = keras.layers.Add(name='B_M_plus_A')([mag_color, ext_red])\n",
    "\n",
    "    # Cholesky decomposition of inverse covariance matrix, L L^T = C^(-1)\n",
    "    LT = keras.Input(shape=(n_bands,n_bands), name='LT')\n",
    "\n",
    "    # Multiply y_pred by L^T, since loss is given by |L^T (y_pred - y_obs)|^2,\n",
    "    # where y_pred = B(M+A), and y_obs = B(m-mu).\n",
    "    LTy = keras.layers.Dot((2,1), name='LT_B_M_plus_A')([LT, y])\n",
    "\n",
    "    # Compile model\n",
    "    model = keras.Model(\n",
    "        inputs=[atm,red,LT],\n",
    "        outputs=LTy,\n",
    "        name='stellar_photometry_model'\n",
    "    )\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer='Adam',\n",
    "        metrics=['mse']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c98052-09ff-4591-830a-446eedd1c701",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### splits the dataset according to a fraction selected by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f096cf60-242d-4eef-8d91-59430a2672dc",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_dataset(frac, *args):\n",
    "    assert len(args) != 0\n",
    "\n",
    "    n_tot = args[0].shape[0]\n",
    "    idx = np.arange(n_tot)\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    n = int(frac * n_tot)\n",
    "    idx_left = idx[:n]\n",
    "    idx_right = idx[n:]\n",
    "\n",
    "    left, right = [], []\n",
    "\n",
    "    for x in args:\n",
    "        left.append(x[idx_left])\n",
    "        right.append(x[idx_right])\n",
    "    \n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a650c5-2ed5-4cfd-bd99-92ff0587e213",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7632b11-b152-4bbf-833b-53c16c38e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "class PlotLearning(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback to plot the learning curves of the model during training.\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.metrics = {}\n",
    "        for metric in logs:\n",
    "            self.metrics[metric] = []\n",
    "            \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Storing metrics\n",
    "        for metric in logs:\n",
    "            if metric in self.metrics:\n",
    "                self.metrics[metric].append(logs.get(metric))\n",
    "            else:\n",
    "                self.metrics[metric] = [logs.get(metric)]\n",
    "        \n",
    "        # Plotting\n",
    "        metrics = [x for x in logs if 'val' not in x]\n",
    "        \n",
    "        f, axs = plt.subplots(1, len(metrics), figsize=(15,5))\n",
    "        # clear_output(wait=True)\n",
    "\n",
    "        for i, metric in enumerate(metrics):\n",
    "            axs[i].plot(range(1, epoch + 2), \n",
    "                        self.metrics[metric], \n",
    "                        label=metric)\n",
    "            if logs['val_' + metric]:\n",
    "                axs[i].plot(range(1, epoch + 2), \n",
    "                            self.metrics['val_' + metric], \n",
    "                            label='val_' + metric)\n",
    "                \n",
    "            axs[i].legend()\n",
    "            axs[i].grid()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d4f6eac-a9dd-4e9d-9d27-f9995997b7a2",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def train_model(nn_model, io_train, k, n_iterations, epochs=100,\n",
    "                checkpoint_fn='checkpoint', batch_size=32,\n",
    "                suff='_'):\n",
    "    checkpoint_fn = (\n",
    "          'checkpoints/'\n",
    "        + checkpoint_fn\n",
    "        + '.e{epoch:03d}_vl{val_loss:.3f}.h5'\n",
    "    )\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_fn,\n",
    "            save_best_only=True,\n",
    "            monitor='val_loss',\n",
    "            verbose=1\n",
    "        )#, PlotLearning()\n",
    "    ]\n",
    "    inputs = [io_train['x_p'], io_train['r'], io_train['LT']]\n",
    "    outputs = io_train['LTy']\n",
    "    nn_model.fit(\n",
    "        inputs, outputs,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.25/0.9,\n",
    "        callbacks=callbacks,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    plt.title('Loss: Iteration {} of {}.'.format(k+1, n_iterations))\n",
    "    plt.plot(range(1,epochs+1),nn_model.history.history['loss'],label='loss')\n",
    "    plt.plot(range(1,epochs+1),nn_model.history.history['val_loss'],label='val_loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig('/arc/home/aydanmckay/networkplots/train_val_loss'+suff+'.svg', dpi=150)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d76b11-59a7-41ca-a531-13411c1a6ce9",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### tests and makes sure the loss is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7eb14a0f-a62d-4d46-ab6d-4b33476566da",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(nn_model, io_eval, batch_size=32, rchisq_max=None):\n",
    "    \"\"\"\n",
    "    Runs the model on the given inputs and outputs, and returns the\n",
    "    MSE and loss.\n",
    "    \n",
    "    Inputs:\n",
    "        nn_model (keras.Model): The neural network model.\n",
    "        io_eval (dict): A dictionary containing, among other things,\n",
    "            x_p, r, LT and LTy. If rchisq_max is provided, then the\n",
    "            dictionary must also contain rchisq.\n",
    "        batch_size (int): Defaults to 32.\n",
    "        rchisq_max (float): Stars with greater than this reduced chi^2\n",
    "            will not be included in the calculation. Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "        A list containing the MSE and loss.\n",
    "    \"\"\"\n",
    "    inputs = [io_eval['x_p'], io_eval['r'], io_eval['LT']]\n",
    "    outputs = io_eval['LTy']\n",
    "    \n",
    "    if rchisq_max is not None:\n",
    "        idx = (io_eval['rchisq'] < rchisq_max)\n",
    "        inputs = [x[idx] for x in inputs]\n",
    "        outputs = outputs[idx]\n",
    "    \n",
    "    loss = nn_model.evaluate(\n",
    "        inputs,\n",
    "        outputs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    loss = [float(x) for x in loss] # Make JSON serializable\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd030e3e-55e6-419d-9a07-ce0a6baeb62c",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### plots? follow up here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d65e396c-7677-41d8-b229-8c3b2377a7b6",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def diagnostic_plots(nn_model, io_test, d_test, suffix=None):\n",
    "    if suffix is None:\n",
    "        suff = ''\n",
    "    else:\n",
    "        suff = '_' + suffix\n",
    "    \n",
    "    inputs = [\n",
    "        nn_model.get_layer(name='theta').input,\n",
    "        nn_model.get_layer(name='E').input\n",
    "    ]\n",
    "    outputs = nn_model.get_layer(name='B_M_plus_A').output\n",
    "    absmag_model = keras.Model(inputs, outputs)\n",
    "\n",
    "    # Predict y for the test dataset\n",
    "    test_pred = {\n",
    "        'y': absmag_model.predict([\n",
    "            io_test['x_p'],\n",
    "            io_test['r']\n",
    "        ]),\n",
    "        'y_dered': absmag_model.predict([\n",
    "            io_test['x_p'],\n",
    "            np.zeros_like(io_test['r'])\n",
    "        ])\n",
    "    }\n",
    "    test_pred['y_resid'] = io_test['y'] - test_pred['y']\n",
    "\n",
    "    # Get the extinction vector\n",
    "    R = predict_R(nn_model)\n",
    "    R[1:] += R[0]\n",
    "    print(\n",
    "          'R(<theta>) = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,R)))\n",
    "        + ']'\n",
    "    )\n",
    "    R_all = predict_R(nn_model, io_test['x_p'])\n",
    "    R_all[:,1:] += R_all[:,0][:,None]\n",
    "    print(\n",
    "          '<R> = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,np.median(R_all,axis=0))))\n",
    "        + ']'\n",
    "    )\n",
    "    print(\n",
    "          's_R = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,np.std(R_all,axis=0))))\n",
    "        + ']'\n",
    "    )\n",
    "\n",
    "    # Read out colors, magnitudes\n",
    "    g = io_test['y'][:,3] + io_test['y'][:,0]\n",
    "    ri = io_test['y'][:,4] - io_test['y'][:,5]\n",
    "    gr = io_test['y'][:,3] - io_test['y'][:,4]\n",
    "    g_pred = test_pred['y'][:,3] + test_pred['y'][:,0]\n",
    "    ri_pred = test_pred['y'][:,4] - test_pred['y'][:,5]\n",
    "    gr_pred = test_pred['y'][:,3] - test_pred['y'][:,4]\n",
    "    g_pred_dered = test_pred['y_dered'][:,3] + test_pred['y_dered'][:,0]\n",
    "    ri_pred_dered = test_pred['y_dered'][:,4] - test_pred['y_dered'][:,5]\n",
    "    gr_pred_dered = test_pred['y_dered'][:,3] - test_pred['y_dered'][:,4]\n",
    "    A_g = 0.25 * R[3]\n",
    "    E_ri = 0.25 * (R[4] - R[5])\n",
    "    E_gr = 0.25 * (R[3] - R[4])\n",
    "\n",
    "    gaia_g = io_test['y'][:,0]\n",
    "    bp_rp = io_test['y'][:,1] - io_test['y'][:,2]\n",
    "    gaia_g_pred = test_pred['y'][:,0]\n",
    "    bp_rp_pred = test_pred['y'][:,1] - test_pred['y'][:,2]\n",
    "    gaia_g_pred_dered = test_pred['y_dered'][:,0]\n",
    "    gaia_bp_rp_pred_dered = test_pred['y_dered'][:,1] - test_pred['y_dered'][:,2]\n",
    "    A_gaia_g = 0.25 * R[0]\n",
    "    E_bp_rp = 0.25 * (R[1] - R[2])\n",
    "\n",
    "    print('g =', g)\n",
    "    print('ri =', ri)\n",
    "    print('gr =', gr)\n",
    "    print('gaia_g =', gaia_g)\n",
    "    print('bp_rp =', bp_rp)\n",
    "\n",
    "    # Plot HRD\n",
    "    params = {\n",
    "        'density': (None, r'$N$', (None, None)),\n",
    "        'teff': (d_test['atm_param'][:,0], r'$T_{\\mathrm{eff}}$', (4000., 8000.)),\n",
    "        'logg': (d_test['atm_param'][:,1], r'$\\log \\left( g \\right)$', (0., 5.)),\n",
    "        'mh': (d_test['atm_param'][:,2], r'$\\left[ \\mathrm{M} / \\mathrm{H} \\right]$', (-2.5, 0.5))\n",
    "    }\n",
    "\n",
    "    plot_spec = [\n",
    "        {\n",
    "            'colors': [(1,2), (4,5)],\n",
    "            'mag': 0\n",
    "        },\n",
    "        {\n",
    "            'colors': [(3,4), (4,5)],\n",
    "            'mag': 0\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    idx_goodobs = np.isfinite(d_test['mag_err'])\n",
    "    idx_goodobs &= (np.abs(io_test['cov_y'][:,0,0]) < 90.)[:,None]\n",
    "    idx_goodobs = idx_goodobs.T\n",
    "\n",
    "    def scatter_or_hexbin(ax, x, y, c, vmin, vmax, extent):\n",
    "        if p == 'density':\n",
    "            im = ax.hexbin(\n",
    "                x, y,\n",
    "                extent=extent,\n",
    "                bins='log',\n",
    "                rasterized=True\n",
    "            )\n",
    "        else:\n",
    "            im = ax.scatter(\n",
    "                x,\n",
    "                y,\n",
    "                c=c,\n",
    "                edgecolors='none',\n",
    "                alpha=0.1,\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "                rasterized=True\n",
    "            )\n",
    "        return im\n",
    "\n",
    "    def get_lim(*args, **kwargs):\n",
    "        expand = kwargs.get('expand', 0.4)\n",
    "        expand_low = kwargs.get('expand_low', expand)\n",
    "        expand_high = kwargs.get('expand_high', expand)\n",
    "        pct = kwargs.get('pct', 1.)\n",
    "        lim = [np.inf, -np.inf]\n",
    "        for a in args:\n",
    "            a0,a1 = np.nanpercentile(a, [pct, 100.-pct])\n",
    "            lim[0] = min(a0, lim[0])\n",
    "            lim[1] = max(a1, lim[1])\n",
    "        w = lim[1] - lim[0]\n",
    "        lim[0] -= expand_low * w\n",
    "        lim[1] += expand_high * w\n",
    "        return lim\n",
    "\n",
    "    labels = ['G', 'BP', 'RP', 'g', 'r', 'i', 'z', 'y']\n",
    "\n",
    "    for ps in plot_spec:\n",
    "        mag_label = r'$M_{{ {} }}$'.format(labels[ps['mag']])\n",
    "        mag_obs = io_test['y'][:,ps['mag']]\n",
    "        mag_pred = test_pred['y'][:,ps['mag']]\n",
    "        mag_pred_dered = test_pred['y_dered'][:,ps['mag']]\n",
    "        A_vec = 0.25 * R[ps['mag']]\n",
    "        print('mag_pred:',mag_pred)\n",
    "\n",
    "        if ps['mag'] != 0:\n",
    "            mag_obs += io_test['y'][:,0]\n",
    "            mag_pred += io_test['y'][:,0]\n",
    "            mag_pred_dered += io_test['y'][:,0]\n",
    "            A_vec += 0.25 * R[0]\n",
    "\n",
    "        color_labels = []\n",
    "        colors_obs = []\n",
    "        colors_pred = []\n",
    "        colors_pred_dered = []\n",
    "        idx_colors_obs = []\n",
    "        E_vec = []\n",
    "        for i1,i2 in ps['colors']:\n",
    "            color_labels.append(r'${} - {}$'.format(labels[i1], labels[i2]))\n",
    "            colors_obs.append(io_test['y'][:,i1] - io_test['y'][:,i2])\n",
    "            colors_pred.append(test_pred['y'][:,i1] - test_pred['y'][:,i2])\n",
    "            colors_pred_dered.append(\n",
    "                test_pred['y_dered'][:,i1] - test_pred['y_dered'][:,i2]\n",
    "            )\n",
    "            idx_colors_obs.append(idx_goodobs[i1] & idx_goodobs[i2])\n",
    "            E_vec.append(0.25 * (R[i1] - R[i2]))\n",
    "\n",
    "        mag_lim = get_lim(\n",
    "            mag_obs[idx_goodobs[ps['mag']]],\n",
    "            pct=2.\n",
    "        )[::-1]\n",
    "        color_lim = [\n",
    "            get_lim(c[idx_colors_obs[k]], expand_low=0.5, expand_high=0.4)\n",
    "            for k,c in enumerate(colors_obs)\n",
    "        ]\n",
    "        \n",
    "        for p in params.keys():\n",
    "            c, label, (vmin,vmax) = params[p]\n",
    "            \n",
    "            fig = plt.figure(figsize=(14,4.5), dpi=150)\n",
    "            fig.patch.set_alpha(0.)\n",
    "            gs = GridSpec(\n",
    "                1,4,\n",
    "                width_ratios=[1,1,1,0.1],\n",
    "                left=0.07, right=0.93,\n",
    "                bottom=0.10, top=0.92\n",
    "            )\n",
    "            ax_obs = fig.add_subplot(gs[0,0], facecolor='gray')\n",
    "            ax_pred = fig.add_subplot(gs[0,1], facecolor='gray')\n",
    "            ax_dered = fig.add_subplot(gs[0,2], facecolor='gray')\n",
    "            cax = fig.add_subplot(gs[0,3], facecolor='w')\n",
    "\n",
    "            extent = color_lim[0] + mag_lim\n",
    "\n",
    "            idx = (\n",
    "                  idx_goodobs[ps['mag']]\n",
    "                & idx_goodobs[ps['colors'][0][0]]\n",
    "                & idx_goodobs[ps['colors'][0][1]]\n",
    "            )\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_obs,\n",
    "                colors_obs[0][idx],\n",
    "                mag_obs[idx],\n",
    "                c if c is None else c[idx],\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "                #(-0.3,1.0,11.5,-2.0)\n",
    "            )\n",
    "\n",
    "            ax_obs.set_xlim(color_lim[0])\n",
    "            ax_obs.set_ylim(mag_lim)\n",
    "            ax_obs.set_xlabel(color_labels[0])\n",
    "            ax_obs.set_ylabel(mag_label)\n",
    "            ax_obs.grid('on', alpha=0.3)\n",
    "            ax_obs.set_title(r'$\\mathrm{Observed}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_pred,\n",
    "                colors_pred[0],\n",
    "                mag_pred,\n",
    "                c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "\n",
    "            ax_pred.set_xlim(color_lim[0])\n",
    "            ax_pred.set_ylim(mag_lim)\n",
    "            ax_pred.set_xlabel(color_labels[0])\n",
    "            ax_pred.grid('on', alpha=0.3)\n",
    "            ax_pred.set_title(r'$\\mathrm{Predicted}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_dered,\n",
    "                colors_pred_dered[0],\n",
    "                mag_pred_dered,\n",
    "                c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "\n",
    "            ax_dered.set_xlim(color_lim[0])\n",
    "            ax_dered.set_ylim(mag_lim)\n",
    "            ax_dered.set_xlabel(color_labels[0])\n",
    "            ax_dered.grid('on', alpha=0.3)\n",
    "            ax_dered.set_title(r'$\\mathrm{Predicted+Dereddened}$')\n",
    "\n",
    "            ax_dered.annotate(\n",
    "                '',\n",
    "                xy=(0.35+E_vec[0], 1.+A_vec),\n",
    "                xytext=(0.35, 1.),\n",
    "                arrowprops=dict(color='r', width=1., headwidth=5., headlength=5.)\n",
    "            )\n",
    "\n",
    "            cb = fig.colorbar(im, cax=cax)\n",
    "            cb.set_label(label)\n",
    "            cb.set_alpha(1.)\n",
    "            cb.draw_all()\n",
    "\n",
    "            cm_desc = '{}_vs_{}{}'.format(\n",
    "                labels[ps['mag']],\n",
    "                labels[ps['colors'][0][0]],\n",
    "                labels[ps['colors'][0][1]]\n",
    "            )\n",
    "            fig.savefig(\n",
    "                '/arc/home/aydanmckay/networkplots/nn_predictions_'+cm_desc+'_'+p+suff+'.svg',\n",
    "                dpi=150,\n",
    "                facecolor=fig.get_facecolor(),\n",
    "                edgecolor='none'\n",
    "            )\n",
    "            plt.close(fig)\n",
    "\n",
    "            # Color-color diagrams\n",
    "            fig = plt.figure(figsize=(14,4.5), dpi=150)\n",
    "            fig.patch.set_alpha(0.)\n",
    "            gs = GridSpec(\n",
    "                1,4,\n",
    "                width_ratios=[1,1,1,0.1],\n",
    "                left=0.07, right=0.93,\n",
    "                bottom=0.10, top=0.92\n",
    "            )\n",
    "            ax_obs = fig.add_subplot(gs[0,0], facecolor='gray')\n",
    "            ax_pred = fig.add_subplot(gs[0,1], facecolor='gray')\n",
    "            ax_dered = fig.add_subplot(gs[0,2], facecolor='gray')\n",
    "            cax = fig.add_subplot(gs[0,3], facecolor='w')\n",
    "\n",
    "            extent = color_lim[0] + color_lim[1]\n",
    "\n",
    "            idx = (\n",
    "                  idx_goodobs[ps['colors'][0][0]]\n",
    "                & idx_goodobs[ps['colors'][0][1]]\n",
    "                & idx_goodobs[ps['colors'][1][0]]\n",
    "                & idx_goodobs[ps['colors'][1][1]]\n",
    "            )\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_obs,\n",
    "                colors_obs[0][idx],\n",
    "                colors_obs[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "                #(-0.2,1.5,-0.15,0.8)\n",
    "            )\n",
    "            ax_obs.set_xlim(color_lim[0])\n",
    "            ax_obs.set_ylim(color_lim[1])\n",
    "            ax_obs.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_obs.set_ylabel(color_labels[1], fontsize=14)\n",
    "            ax_obs.grid('on', alpha=0.3)\n",
    "            ax_obs.set_title(r'$\\mathrm{Observed}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_pred,\n",
    "                colors_pred[0][idx],\n",
    "                colors_pred[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                #c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "            ax_pred.set_xlim(color_lim[0])\n",
    "            ax_pred.set_ylim(color_lim[1])\n",
    "            ax_pred.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_pred.grid('on', alpha=0.3)\n",
    "            ax_pred.set_title(r'$\\mathrm{Predicted}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_dered,\n",
    "                colors_pred_dered[0][idx],\n",
    "                colors_pred_dered[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                #c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "            ax_dered.set_xlim(color_lim[0])\n",
    "            ax_dered.set_ylim(color_lim[1])\n",
    "            ax_dered.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_dered.grid('on', alpha=0.3)\n",
    "            ax_dered.set_title(r'$\\mathrm{Predicted+Dereddened}$')\n",
    "\n",
    "            ax_dered.annotate(\n",
    "                '',\n",
    "                xy=(0.4+E_vec[0], 0.3+E_vec[1]),\n",
    "                xytext=(0.4, 0.3),\n",
    "                arrowprops=dict(color='r', width=1., headwidth=5., headlength=5.)\n",
    "            )\n",
    "\n",
    "            cb = fig.colorbar(im, cax=cax)\n",
    "            cb.set_label(label, fontsize=14)\n",
    "            cb.set_alpha(1.)\n",
    "            cb.draw_all()\n",
    "\n",
    "            cc_desc = '{}{}_vs_{}{}'.format(\n",
    "                labels[ps['colors'][0][0]],\n",
    "                labels[ps['colors'][0][1]],\n",
    "                labels[ps['colors'][1][0]],\n",
    "                labels[ps['colors'][1][1]]\n",
    "            )\n",
    "            fig.savefig(\n",
    "                '/arc/home/aydanmckay/networkplots/test_'+cc_desc+'_'+p+suff+'.svg',\n",
    "                dpi=150,\n",
    "                facecolor=fig.get_facecolor(),\n",
    "                edgecolor='none'\n",
    "            )\n",
    "            plt.close(fig)\n",
    "    \n",
    "    # Plot histograms of residuals\n",
    "    dr = (io_test['r'] - d_test['r'])/np.hypot(np.nanstd(d_test['r']),.01)\n",
    "    # dmag = (io_test['LTy'] - d_test['mag'])\n",
    "    # dm1,dm2,dm3,dm4,dm5,dm6,dm7,dm8,dm9,dm10,dm11,dm12,dm13 = dmag.T\n",
    "    names = ['G','(BP-G)','(RP-G)','(g-G)','(r-G)','(i-G)','(z-G)','(y-G)','(J-G)','(H-G)','(K_s-G)','(W_1-G)','(W_2-G)']\n",
    "    # ds = [dm1,dm2,dm3,dm4,dm5,dm6,dm7,dm8,dm9,dm10,dm11,dm12,dm13]\n",
    "    fig = plt.figure(figsize=(12,18))\n",
    "    ax = fig.add_subplot(5,3,1)\n",
    "    dr_mean = np.nanmean(dr)\n",
    "    dr_std = np.nanstd(dr)\n",
    "    ax.hist(dr, bins=50)\n",
    "    dr_skew = scipy.stats.moment(dr, moment=3, nan_policy='omit')\n",
    "    dr_txt = r'$\\Delta E = {:+.3f} \\pm {:.3f}$'.format(dr_mean, dr_std)\n",
    "    dr_skew /= (dr_std**1.5 + 1.e-5)\n",
    "    dr_txt += '\\n' + r'$\\tilde{{\\mu}}_3 = {:+.3f}$'.format(dr_skew)\n",
    "    ax.text(0.05, 0.95, dr_txt, ha='left', va='top', transform=ax.transAxes)\n",
    "    ax.set_xlabel(r'$\\Delta E \\ \\left( \\mathrm{estimated} - \\mathrm{Bayestar19} \\right)$',fontsize=10)\n",
    "    for it,(io,dm,name) in enumerate(zip(io_test['LTy'].T,d_test['mag'].T,names)):\n",
    "        dd = (io - dm)/np.hypot(np.nanstd(dm),.01)\n",
    "        ax = fig.add_subplot(5,3,it+2)\n",
    "        dd_mean = np.nanmean(dd)\n",
    "        dd_std = np.nanstd(dd)\n",
    "        ax.hist(dd, bins=50)\n",
    "        dd_skew = scipy.stats.moment(dd, moment=3, nan_policy='omit')\n",
    "        dd_txt = r'$\\Delta '+name+r' = {:+.3f} \\pm {:.3f}$'.format(dd_mean, dd_std)\n",
    "        dd_skew /= (dd_std**1.5 + 1.e-5)\n",
    "        dd_txt += '\\n' + r'$\\tilde{{\\mu}}_3 = {:+.3f}$'.format(dd_skew)\n",
    "        ax.text(0.05, 0.95, dd_txt, ha='left', va='top', transform=ax.transAxes)\n",
    "        ax.set_xlabel(r'$\\Delta '+name+r'\\ \\left( \\mathrm{estimated} - \\mathrm{observed} \\right)$',fontsize=10)\n",
    "    fig.savefig('/arc/home/aydanmckay/networkplots/test_z-score_dE'+suff+'.svg', dpi=150)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc50d23-d49f-4732-87e4-a7e1ec8fc816",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "source": [
    "##### Calculates the derivative of the stellar model portion for gradient descent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8c296da-d523-4953-87b3-738be2e038fe",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_dmag_color_dtheta(nn_model, x_p):\n",
    "    m = keras.Model(\n",
    "        inputs=nn_model.get_layer(name='theta').input,\n",
    "        outputs=nn_model.get_layer(name='BM').output\n",
    "    )\n",
    "    with tf.GradientTape() as g:\n",
    "        x_p = tf.constant(x_p)\n",
    "        g.watch(x_p)\n",
    "        mag_color = m(x_p)\n",
    "    J = g.batch_jacobian(mag_color, x_p).numpy()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb05c4c2-5d82-4311-b6f2-b46532797a41",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Calculates the derivative of the extinction model portion for gradient descent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2af63500-d06a-4ba6-bcc1-5fd5c3df6247",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_dext_red_dtheta(nn_model, x_p, r):\n",
    "    A_model = keras.Model(\n",
    "        inputs=[\n",
    "            nn_model.get_layer(name='theta').input,\n",
    "            nn_model.get_layer(name='E').input\n",
    "        ],\n",
    "        outputs=nn_model.get_layer(name='BA').output\n",
    "    )\n",
    "    r = tf.constant(np.reshape(r, (r.size,1)))\n",
    "    #r = tf.reshape(r, (tf.size(r), 1))\n",
    "    with tf.GradientTape() as g:\n",
    "        x_p = tf.constant(x_p)\n",
    "        g.watch(x_p)\n",
    "        A = A_model([x_p, r])\n",
    "    J = g.batch_jacobian(A, x_p).numpy()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fb7f2c-5df5-4b99-aae0-39035aa43797",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Saves the normalizations, which seen in the tutorial is useful for scaling and shifting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86cef280-6cca-48f4-93ce-a8f4b7336300",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_theta_norm(d_attrs, fname):\n",
    "    d = {\n",
    "        'theta_med': d_attrs['atm_param_med'].tolist(),\n",
    "        'theta_std': d_attrs['atm_param_std'].tolist()\n",
    "    }\n",
    "    with open(fname, 'w') as f:\n",
    "        json.dump(d, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab8ecb-d1c9-438d-8794-1ff0b7eceef3",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### start of main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b834ddb7-6836-4e26-b7d7-81ce6cf146fd",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"stellar_photometry_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " theta (InputLayer)             [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " stellar_model_hidden_1 (Dense)  (None, 32)          128         ['theta[0][0]']                  \n",
      "                                                                                                  \n",
      " E (InputLayer)                 [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " R (Dense)                      (None, 13)           52          ['theta[0][0]']                  \n",
      "                                                                                                  \n",
      " stellar_model_hidden_2 (Dense)  (None, 32)          1056        ['stellar_model_hidden_1[0][0]'] \n",
      "                                                                                                  \n",
      " A (Multiply)                   (None, 13)           0           ['E[0][0]',                      \n",
      "                                                                  'R[0][0]']                      \n",
      "                                                                                                  \n",
      " BM (Dense)                     (None, 13)           429         ['stellar_model_hidden_2[0][0]'] \n",
      "                                                                                                  \n",
      " BA (Dense)                     (None, 13)           169         ['A[0][0]']                      \n",
      "                                                                                                  \n",
      " LT (InputLayer)                [(None, 13, 13)]     0           []                               \n",
      "                                                                                                  \n",
      " B_M_plus_A (Add)               (None, 13)           0           ['BM[0][0]',                     \n",
      "                                                                  'BA[0][0]']                     \n",
      "                                                                                                  \n",
      " LT_B_M_plus_A (Dot)            (None, 13)           0           ['LT[0][0]',                     \n",
      "                                                                  'B_M_plus_A[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,834\n",
      "Trainable params: 1,665\n",
      "Non-trainable params: 169\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load/create neural network\n",
    "nn_name = 'ext_0h_l1n2'\n",
    "n_hidden = 2\n",
    "nn_model = get_nn_model(n_hidden_layers=n_hidden, l2=1.e-4, l1=1.e-2)\n",
    "#nn_model = keras.models.load_model(\n",
    "#    'models/{:s}_{:d}hidden_it14.h5'.format(nn_name, n_hidden)\n",
    "#)\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07e4514b-44a8-4a5c-8512-e7feaa15e94e",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Loading /arc/home/aydanmckay/ml/network/datav2.h5 ...\n"
     ]
    }
   ],
   "source": [
    "# Load stellar data\n",
    "print('Loading data ...')\n",
    "fname = '/arc/home/aydanmckay/ml/network/datav2.h5'\n",
    "d, d_attrs = load_data(fname, return_attrs=True)\n",
    "#d = d[::25]\n",
    "save_theta_norm(d_attrs, 'theta_normalization.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d54baa9f-60d9-4fc0-acb7-e4c49cd83a66",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    253053 training/validation stars.\n",
      "     28118 test stars.\n"
     ]
    }
   ],
   "source": [
    "# (training+validation) / test split\n",
    "# Fix random seed (same split every run)\n",
    "np.random.seed(7)\n",
    "(d_train,), (d_test,) = split_dataset(0.9, d)\n",
    "np.random.shuffle(d_train) # Want d_train to be in random order\n",
    "print(f'{d_train.size: >10d} training/validation stars.')\n",
    "print(f'{d_test.size: >10d} test stars.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa8b04a6-3b93-4b72-9d3f-8855c3111e8c",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi^2/dof = [None, 100.00000000000004, 79.41833348134496, 63.07271692954115, 50.09130066684769, 39.78167620874025, 31.593944275926187, 25.091384024965357, 19.927159040031896, 15.825817619770502, 12.56860061341878, 9.981773149103292, 7.927357886906197, 6.295775522882865, 4.999999999999999, 5.0, 5.0, 5.0, 5.0, 5.0]\n"
     ]
    }
   ],
   "source": [
    "# Iteratively update dM/dtheta contribution to uncertainties,\n",
    "# reddening estimates and reduced chi^2 cut, and retrain.\n",
    "n_iterations = 20\n",
    "\n",
    "# On GPU, use large batch sizes for memory transfer efficiency\n",
    "batch_size = 1024\n",
    "\n",
    "rchisq_max_init = 100.\n",
    "rchisq_max_final = 5.\n",
    "rchisq_max = np.exp(np.linspace(\n",
    "    np.log(rchisq_max_init),\n",
    "    np.log(rchisq_max_final),\n",
    "    n_iterations-6\n",
    "))\n",
    "rchisq_max = [None] + rchisq_max.tolist() + 5*[rchisq_max_final]\n",
    "print('chi^2/dof = {}'.format(rchisq_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b3ee798-6cee-458d-b5e3-e6f014c0c873",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Cutting 0 stars with large sigma_r.\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Cutting 0 stars with large sigma_r.\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 34.34 s\n",
      "learning rate = 0.0010000000474974513\n",
      "setting learning rate to 0.001\n",
      "Iteration 1 of 20.\n",
      "Epoch 1/25\n",
      "178/179 [============================>.] - ETA: 0s - loss: 1807.2444 - mse: 1807.1378\n",
      "Epoch 1: val_loss improved from inf to 1307.15710, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e001_vl1307.157.h5\n",
      "179/179 [==============================] - 2s 8ms/step - loss: 1802.8855 - mse: 1802.7789 - val_loss: 1307.1571 - val_mse: 1307.0500\n",
      "Epoch 2/25\n",
      "170/179 [===========================>..] - ETA: 0s - loss: 596.5941 - mse: 596.4854\n",
      "Epoch 2: val_loss improved from 1307.15710 to 758.86639, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e002_vl758.866.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 583.5784 - mse: 583.4698 - val_loss: 758.8664 - val_mse: 758.7585\n",
      "Epoch 3/25\n",
      "172/179 [===========================>..] - ETA: 0s - loss: 390.8979 - mse: 390.7915\n",
      "Epoch 3: val_loss improved from 758.86639 to 493.67557, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e003_vl493.676.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 380.2663 - mse: 380.1599 - val_loss: 493.6756 - val_mse: 493.5713\n",
      "Epoch 4/25\n",
      "167/179 [==========================>...] - ETA: 0s - loss: 251.9805 - mse: 251.8785\n",
      "Epoch 4: val_loss improved from 493.67557 to 383.77191, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e004_vl383.772.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 260.5499 - mse: 260.4481 - val_loss: 383.7719 - val_mse: 383.6722\n",
      "Epoch 5/25\n",
      "175/179 [============================>.] - ETA: 0s - loss: 195.8658 - mse: 195.7670\n",
      "Epoch 5: val_loss improved from 383.77191 to 222.61499, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e005_vl222.615.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 193.4890 - mse: 193.3901 - val_loss: 222.6150 - val_mse: 222.5172\n",
      "Epoch 6/25\n",
      "172/179 [===========================>..] - ETA: 0s - loss: 149.9198 - mse: 149.8223\n",
      "Epoch 6: val_loss improved from 222.61499 to 176.91162, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e006_vl176.912.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 146.7620 - mse: 146.6646 - val_loss: 176.9116 - val_mse: 176.8145\n",
      "Epoch 7/25\n",
      "174/179 [============================>.] - ETA: 0s - loss: 119.5874 - mse: 119.4906\n",
      "Epoch 7: val_loss improved from 176.91162 to 145.09351, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e007_vl145.094.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 117.8408 - mse: 117.7440 - val_loss: 145.0935 - val_mse: 144.9970\n",
      "Epoch 8/25\n",
      "172/179 [===========================>..] - ETA: 0s - loss: 100.1817 - mse: 100.0854\n",
      "Epoch 8: val_loss improved from 145.09351 to 121.53634, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e008_vl121.536.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 97.9039 - mse: 97.8076 - val_loss: 121.5363 - val_mse: 121.4402\n",
      "Epoch 9/25\n",
      "178/179 [============================>.] - ETA: 0s - loss: 83.4331 - mse: 83.3371\n",
      "Epoch 9: val_loss improved from 121.53634 to 103.23618, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e009_vl103.236.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 83.3092 - mse: 83.2132 - val_loss: 103.2362 - val_mse: 103.1411\n",
      "Epoch 10/25\n",
      "177/179 [============================>.] - ETA: 0s - loss: 73.1200 - mse: 73.0253\n",
      "Epoch 10: val_loss improved from 103.23618 to 91.41745, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e010_vl91.417.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 72.8026 - mse: 72.7079 - val_loss: 91.4174 - val_mse: 91.3225\n",
      "Epoch 11/25\n",
      "172/179 [===========================>..] - ETA: 0s - loss: 66.1135 - mse: 66.0187\n",
      "Epoch 11: val_loss improved from 91.41745 to 80.06974, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e011_vl80.070.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 65.0190 - mse: 64.9243 - val_loss: 80.0697 - val_mse: 79.9759\n",
      "Epoch 12/25\n",
      "176/179 [============================>.] - ETA: 0s - loss: 53.0504 - mse: 52.9569\n",
      "Epoch 12: val_loss improved from 80.06974 to 72.21975, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e012_vl72.220.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 58.5542 - mse: 58.4607 - val_loss: 72.2197 - val_mse: 72.1266\n",
      "Epoch 13/25\n",
      "174/179 [============================>.] - ETA: 0s - loss: 53.8310 - mse: 53.7383\n",
      "Epoch 13: val_loss improved from 72.21975 to 65.03194, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e013_vl65.032.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 53.4973 - mse: 53.4046 - val_loss: 65.0319 - val_mse: 64.9396\n",
      "Epoch 14/25\n",
      "172/179 [===========================>..] - ETA: 0s - loss: 49.9902 - mse: 49.8983\n",
      "Epoch 14: val_loss improved from 65.03194 to 59.23659, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e014_vl59.237.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 49.3109 - mse: 49.2190 - val_loss: 59.2366 - val_mse: 59.1449\n",
      "Epoch 15/25\n",
      "171/179 [===========================>..] - ETA: 0s - loss: 46.4471 - mse: 46.3558\n",
      "Epoch 15: val_loss improved from 59.23659 to 54.59527, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e015_vl54.595.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 45.7316 - mse: 45.6402 - val_loss: 54.5953 - val_mse: 54.5043\n",
      "Epoch 16/25\n",
      "178/179 [============================>.] - ETA: 0s - loss: 42.8465 - mse: 42.7557\n",
      "Epoch 16: val_loss improved from 54.59527 to 50.23814, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e016_vl50.238.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 42.7922 - mse: 42.7013 - val_loss: 50.2381 - val_mse: 50.1474\n",
      "Epoch 17/25\n",
      "170/179 [===========================>..] - ETA: 0s - loss: 40.2601 - mse: 40.1696\n",
      "Epoch 17: val_loss improved from 50.23814 to 46.75609, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e017_vl46.756.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 40.2132 - mse: 40.1227 - val_loss: 46.7561 - val_mse: 46.6661\n",
      "Epoch 18/25\n",
      "172/179 [===========================>..] - ETA: 0s - loss: 38.5225 - mse: 38.4328\n",
      "Epoch 18: val_loss improved from 46.75609 to 43.71014, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e018_vl43.710.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 38.0565 - mse: 37.9668 - val_loss: 43.7101 - val_mse: 43.6203\n",
      "Epoch 19/25\n",
      "171/179 [===========================>..] - ETA: 0s - loss: 33.6446 - mse: 33.5555\n",
      "Epoch 19: val_loss improved from 43.71014 to 41.29758, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e019_vl41.298.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 36.2041 - mse: 36.1150 - val_loss: 41.2976 - val_mse: 41.2084\n",
      "Epoch 20/25\n",
      "173/179 [===========================>..] - ETA: 0s - loss: 34.1349 - mse: 34.0459\n",
      "Epoch 20: val_loss improved from 41.29758 to 38.97543, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e020_vl38.975.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 34.5571 - mse: 34.4681 - val_loss: 38.9754 - val_mse: 38.8867\n",
      "Epoch 21/25\n",
      "179/179 [==============================] - ETA: 0s - loss: 33.1282 - mse: 33.0399\n",
      "Epoch 21: val_loss improved from 38.97543 to 37.15152, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e021_vl37.152.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 33.1282 - mse: 33.0399 - val_loss: 37.1515 - val_mse: 37.0636\n",
      "Epoch 22/25\n",
      "170/179 [===========================>..] - ETA: 0s - loss: 32.0174 - mse: 31.9299\n",
      "Epoch 22: val_loss improved from 37.15152 to 35.48019, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e022_vl35.480.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 31.9082 - mse: 31.8208 - val_loss: 35.4802 - val_mse: 35.3931\n",
      "Epoch 23/25\n",
      "172/179 [===========================>..] - ETA: 0s - loss: 31.0235 - mse: 30.9365\n",
      "Epoch 23: val_loss improved from 35.48019 to 34.12484, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e023_vl34.125.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 30.8362 - mse: 30.7492 - val_loss: 34.1248 - val_mse: 34.0386\n",
      "Epoch 24/25\n",
      "172/179 [===========================>..] - ETA: 0s - loss: 30.1573 - mse: 30.0712\n",
      "Epoch 24: val_loss improved from 34.12484 to 32.83948, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e024_vl32.839.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 29.9033 - mse: 29.8172 - val_loss: 32.8395 - val_mse: 32.7539\n",
      "Epoch 25/25\n",
      "167/179 [==========================>...] - ETA: 0s - loss: 29.2485 - mse: 29.1631\n",
      "Epoch 25: val_loss improved from 32.83948 to 31.74260, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e025_vl31.743.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 29.0440 - mse: 28.9587 - val_loss: 31.7426 - val_mse: 31.6575\n",
      "Time elapsed to train: 28.26 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [1.680 2.311 0.840 2.474 1.683 0.869 0.827 0.688 0.513 0.438 0.856 0.452 0.447]\n",
      "<R> = [1.721 2.354 0.860 2.522 1.723 0.904 0.816 0.682 0.517 0.443 0.889 0.466 0.448]\n",
      "s_R = [0.838 0.826 0.973 0.810 0.828 1.749 0.346 0.227 0.307 0.426 5.461 0.841 0.211]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6253455 3.0689528 6.5362415 ... 3.1915445 4.161138  4.453006 ]\n",
      "mag_pred: [3.6253455 3.0689528 6.5362415 ... 3.1915445 4.161138  4.453006 ]\n",
      "Time elapsed to make plots: 18.60 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [56.83412  36.199905 16.314262 ...  3.805219 37.427345 16.5739  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0468\n",
      "  1% : 0.214\n",
      "  10% : 0.436\n",
      "  50% : 1.06\n",
      "  90% : 4.99\n",
      "  99% : 111\n",
      "  100% : 6.48e+03\n",
      "<chi^2/d.o.f.> = 1.52\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 2730 stars (1.08%) based on chi^2/dof > 100.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [14.505053  49.551617  14.590063  ... 29.512978   7.1743064 15.318682 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0828\n",
      "  1% : 0.21\n",
      "  10% : 0.436\n",
      "  50% : 1.06\n",
      "  90% : 4.93\n",
      "  99% : 117\n",
      "  100% : 4.58e+03\n",
      "<chi^2/d.o.f.> = 1.53\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 79.68 s\n",
      "learning rate = 0.0010000000474974513\n",
      "setting learning rate to 0.0008187307530779819\n",
      "Iteration 2 of 20.\n",
      "Epoch 1/25\n",
      "168/177 [===========================>..] - ETA: 0s - loss: 1.8541 - mse: 1.7692\n",
      "Epoch 1: val_loss improved from inf to 1.80928, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e001_vl1.809.h5\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.8554 - mse: 1.7706 - val_loss: 1.8093 - val_mse: 1.7246\n",
      "Epoch 2/25\n",
      "173/177 [============================>.] - ETA: 0s - loss: 1.7957 - mse: 1.7111\n",
      "Epoch 2: val_loss improved from 1.80928 to 1.77408, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e002_vl1.774.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.7943 - mse: 1.7097 - val_loss: 1.7741 - val_mse: 1.6897\n",
      "Epoch 3/25\n",
      "175/177 [============================>.] - ETA: 0s - loss: 1.7675 - mse: 1.6834\n",
      "Epoch 3: val_loss improved from 1.77408 to 1.75227, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e003_vl1.752.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.7661 - mse: 1.6819 - val_loss: 1.7523 - val_mse: 1.6683\n",
      "Epoch 4/25\n",
      "173/177 [============================>.] - ETA: 0s - loss: 1.7459 - mse: 1.6621\n",
      "Epoch 4: val_loss improved from 1.75227 to 1.73460, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e004_vl1.735.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.7455 - mse: 1.6618 - val_loss: 1.7346 - val_mse: 1.6511\n",
      "Epoch 5/25\n",
      "173/177 [============================>.] - ETA: 0s - loss: 1.7309 - mse: 1.6476\n",
      "Epoch 5: val_loss improved from 1.73460 to 1.72016, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e005_vl1.720.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.7286 - mse: 1.6454 - val_loss: 1.7202 - val_mse: 1.6371\n",
      "Epoch 6/25\n",
      "175/177 [============================>.] - ETA: 0s - loss: 1.7164 - mse: 1.6337\n",
      "Epoch 6: val_loss improved from 1.72016 to 1.70844, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e006_vl1.708.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.7149 - mse: 1.6322 - val_loss: 1.7084 - val_mse: 1.6260\n",
      "Epoch 7/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.7023 - mse: 1.6201\n",
      "Epoch 7: val_loss improved from 1.70844 to 1.69667, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e007_vl1.697.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.7020 - mse: 1.6198 - val_loss: 1.6967 - val_mse: 1.6148\n",
      "Epoch 8/25\n",
      "174/177 [============================>.] - ETA: 0s - loss: 1.6899 - mse: 1.6084\n",
      "Epoch 8: val_loss improved from 1.69667 to 1.68328, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e008_vl1.683.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.6902 - mse: 1.6087 - val_loss: 1.6833 - val_mse: 1.6021\n",
      "Epoch 9/25\n",
      "171/177 [===========================>..] - ETA: 0s - loss: 1.6799 - mse: 1.5990\n",
      "Epoch 9: val_loss improved from 1.68328 to 1.67451, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e009_vl1.675.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.6795 - mse: 1.5986 - val_loss: 1.6745 - val_mse: 1.5940\n",
      "Epoch 10/25\n",
      "170/177 [===========================>..] - ETA: 0s - loss: 1.6678 - mse: 1.5876\n",
      "Epoch 10: val_loss improved from 1.67451 to 1.66379, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e010_vl1.664.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.6691 - mse: 1.5889 - val_loss: 1.6638 - val_mse: 1.5840\n",
      "Epoch 11/25\n",
      "176/177 [============================>.] - ETA: 0s - loss: 1.6588 - mse: 1.5793\n",
      "Epoch 11: val_loss improved from 1.66379 to 1.65512, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e011_vl1.655.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.6593 - mse: 1.5798 - val_loss: 1.6551 - val_mse: 1.5760\n",
      "Epoch 12/25\n",
      "175/177 [============================>.] - ETA: 0s - loss: 1.6500 - mse: 1.5713\n",
      "Epoch 12: val_loss improved from 1.65512 to 1.64628, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e012_vl1.646.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.6502 - mse: 1.5715 - val_loss: 1.6463 - val_mse: 1.5679\n",
      "Epoch 13/25\n",
      "170/177 [===========================>..] - ETA: 0s - loss: 1.6395 - mse: 1.5615\n",
      "Epoch 13: val_loss improved from 1.64628 to 1.63602, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e013_vl1.636.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.6407 - mse: 1.5627 - val_loss: 1.6360 - val_mse: 1.5584\n",
      "Epoch 14/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.6320 - mse: 1.5548\n",
      "Epoch 14: val_loss improved from 1.63602 to 1.62828, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e014_vl1.628.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.6325 - mse: 1.5553 - val_loss: 1.6283 - val_mse: 1.5514\n",
      "Epoch 15/25\n",
      "170/177 [===========================>..] - ETA: 0s - loss: 1.6233 - mse: 1.5468\n",
      "Epoch 15: val_loss improved from 1.62828 to 1.62155, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e015_vl1.622.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.6238 - mse: 1.5472 - val_loss: 1.6216 - val_mse: 1.5453\n",
      "Epoch 16/25\n",
      "168/177 [===========================>..] - ETA: 0s - loss: 1.6139 - mse: 1.5379\n",
      "Epoch 16: val_loss improved from 1.62155 to 1.61428, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e016_vl1.614.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.6164 - mse: 1.5405 - val_loss: 1.6143 - val_mse: 1.5387\n",
      "Epoch 17/25\n",
      "170/177 [===========================>..] - ETA: 0s - loss: 1.6111 - mse: 1.5358\n",
      "Epoch 17: val_loss improved from 1.61428 to 1.60693, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e017_vl1.607.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.6094 - mse: 1.5341 - val_loss: 1.6069 - val_mse: 1.5320\n",
      "Epoch 18/25\n",
      "175/177 [============================>.] - ETA: 0s - loss: 1.6002 - mse: 1.5256\n",
      "Epoch 18: val_loss improved from 1.60693 to 1.59737, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e018_vl1.597.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.6016 - mse: 1.5270 - val_loss: 1.5974 - val_mse: 1.5231\n",
      "Epoch 19/25\n",
      "174/177 [============================>.] - ETA: 0s - loss: 1.5932 - mse: 1.5193\n",
      "Epoch 19: val_loss improved from 1.59737 to 1.59546, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e019_vl1.595.h5\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 1.5944 - mse: 1.5204 - val_loss: 1.5955 - val_mse: 1.5217\n",
      "Epoch 20/25\n",
      "167/177 [===========================>..] - ETA: 0s - loss: 1.5890 - mse: 1.5153\n",
      "Epoch 20: val_loss improved from 1.59546 to 1.58911, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e020_vl1.589.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.5879 - mse: 1.5143 - val_loss: 1.5891 - val_mse: 1.5156\n",
      "Epoch 21/25\n",
      "173/177 [============================>.] - ETA: 0s - loss: 1.5806 - mse: 1.5072\n",
      "Epoch 21: val_loss improved from 1.58911 to 1.58435, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e021_vl1.584.h5\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 1.5824 - mse: 1.5090 - val_loss: 1.5843 - val_mse: 1.5111\n",
      "Epoch 22/25\n",
      "175/177 [============================>.] - ETA: 0s - loss: 1.5784 - mse: 1.5052\n",
      "Epoch 22: val_loss improved from 1.58435 to 1.57538, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e022_vl1.575.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.5772 - mse: 1.5040 - val_loss: 1.5754 - val_mse: 1.5023\n",
      "Epoch 23/25\n",
      "175/177 [============================>.] - ETA: 0s - loss: 1.5707 - mse: 1.4978\n",
      "Epoch 23: val_loss improved from 1.57538 to 1.57008, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e023_vl1.570.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.5720 - mse: 1.4991 - val_loss: 1.5701 - val_mse: 1.4973\n",
      "Epoch 24/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.5693 - mse: 1.4967\n",
      "Epoch 24: val_loss improved from 1.57008 to 1.56632, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e024_vl1.566.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.5661 - mse: 1.4936 - val_loss: 1.5663 - val_mse: 1.4939\n",
      "Epoch 25/25\n",
      "166/177 [===========================>..] - ETA: 0s - loss: 1.5647 - mse: 1.4924\n",
      "Epoch 25: val_loss improved from 1.56632 to 1.56180, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e025_vl1.562.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.5610 - mse: 1.4888 - val_loss: 1.5618 - val_mse: 1.4897\n",
      "Time elapsed to train: 26.81 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [1.731 2.244 0.892 2.484 1.802 0.873 0.847 0.603 0.527 0.570 0.855 0.301 0.271]\n",
      "<R> = [1.776 2.299 0.914 2.538 1.855 0.908 0.850 0.604 0.527 0.570 0.888 0.307 0.272]\n",
      "s_R = [0.937 1.220 0.956 1.163 1.273 1.727 0.280 0.105 0.035 0.208 5.420 0.199 0.084]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.4955006 2.9751678 6.425593  ... 2.7807698 4.1028852 4.427697 ]\n",
      "mag_pred: [3.4955006 2.9751678 6.425593  ... 2.7807698 4.1028852 4.427697 ]\n",
      "Time elapsed to make plots: 18.87 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7fc3f7ab9ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7fc3f79ee040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [44.676292  31.147114  27.910034  ...  4.0631704 33.507084  33.21861  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0204\n",
      "  1% : 0.156\n",
      "  10% : 0.336\n",
      "  50% : 0.866\n",
      "  90% : 3.62\n",
      "  99% : 86.7\n",
      "  100% : 6.69e+03\n",
      "<chi^2/d.o.f.> = 1.26\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 2698 stars (1.07%) based on chi^2/dof > 79.4\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [13.916975 32.82001  11.491635 ... 14.809401  5.042943 14.294186]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0295\n",
      "  1% : 0.152\n",
      "  10% : 0.333\n",
      "  50% : 0.869\n",
      "  90% : 3.57\n",
      "  99% : 93.7\n",
      "  100% : 4.87e+03\n",
      "<chi^2/d.o.f.> = 1.27\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 77.46 s\n",
      "learning rate = 0.0008187307394109666\n",
      "setting learning rate to 0.0006703200460356394\n",
      "Iteration 3 of 20.\n",
      "Epoch 1/25\n",
      "177/177 [==============================] - ETA: 0s - loss: 1.4760 - mse: 1.4042\n",
      "Epoch 1: val_loss improved from inf to 1.45399, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e001_vl1.454.h5\n",
      "177/177 [==============================] - 2s 7ms/step - loss: 1.4760 - mse: 1.4042 - val_loss: 1.4540 - val_mse: 1.3825\n",
      "Epoch 2/25\n",
      "168/177 [===========================>..] - ETA: 0s - loss: 1.4619 - mse: 1.3906\n",
      "Epoch 2: val_loss improved from 1.45399 to 1.44824, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e002_vl1.448.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4647 - mse: 1.3934 - val_loss: 1.4482 - val_mse: 1.3771\n",
      "Epoch 3/25\n",
      "170/177 [===========================>..] - ETA: 0s - loss: 1.4584 - mse: 1.3873\n",
      "Epoch 3: val_loss improved from 1.44824 to 1.43902, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e003_vl1.439.h5\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 1.4568 - mse: 1.3857 - val_loss: 1.4390 - val_mse: 1.3680\n",
      "Epoch 4/25\n",
      "170/177 [===========================>..] - ETA: 0s - loss: 1.4499 - mse: 1.3790\n",
      "Epoch 4: val_loss improved from 1.43902 to 1.43290, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e004_vl1.433.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4506 - mse: 1.3797 - val_loss: 1.4329 - val_mse: 1.3621\n",
      "Epoch 5/25\n",
      "169/177 [===========================>..] - ETA: 0s - loss: 1.4457 - mse: 1.3749\n",
      "Epoch 5: val_loss improved from 1.43290 to 1.42972, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e005_vl1.430.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4446 - mse: 1.3738 - val_loss: 1.4297 - val_mse: 1.3591\n",
      "Epoch 6/25\n",
      "176/177 [============================>.] - ETA: 0s - loss: 1.4389 - mse: 1.3684\n",
      "Epoch 6: val_loss improved from 1.42972 to 1.42381, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e006_vl1.424.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4387 - mse: 1.3682 - val_loss: 1.4238 - val_mse: 1.3534\n",
      "Epoch 7/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.4357 - mse: 1.3655\n",
      "Epoch 7: val_loss improved from 1.42381 to 1.41791, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e007_vl1.418.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4335 - mse: 1.3633 - val_loss: 1.4179 - val_mse: 1.3478\n",
      "Epoch 8/25\n",
      "170/177 [===========================>..] - ETA: 0s - loss: 1.4295 - mse: 1.3595\n",
      "Epoch 8: val_loss improved from 1.41791 to 1.41604, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e008_vl1.416.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4298 - mse: 1.3599 - val_loss: 1.4160 - val_mse: 1.3463\n",
      "Epoch 9/25\n",
      "175/177 [============================>.] - ETA: 0s - loss: 1.4225 - mse: 1.3530\n",
      "Epoch 9: val_loss improved from 1.41604 to 1.40717, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e009_vl1.407.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4234 - mse: 1.3539 - val_loss: 1.4072 - val_mse: 1.3378\n",
      "Epoch 10/25\n",
      "169/177 [===========================>..] - ETA: 0s - loss: 1.4216 - mse: 1.3524\n",
      "Epoch 10: val_loss improved from 1.40717 to 1.40491, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e010_vl1.405.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4187 - mse: 1.3496 - val_loss: 1.4049 - val_mse: 1.3360\n",
      "Epoch 11/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.4144 - mse: 1.3458\n",
      "Epoch 11: val_loss improved from 1.40491 to 1.39946, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e011_vl1.399.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4139 - mse: 1.3452 - val_loss: 1.3995 - val_mse: 1.3311\n",
      "Epoch 12/25\n",
      "168/177 [===========================>..] - ETA: 0s - loss: 1.4112 - mse: 1.3431\n",
      "Epoch 12: val_loss improved from 1.39946 to 1.39592, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e012_vl1.396.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4092 - mse: 1.3411 - val_loss: 1.3959 - val_mse: 1.3281\n",
      "Epoch 13/25\n",
      "173/177 [============================>.] - ETA: 0s - loss: 1.4030 - mse: 1.3355\n",
      "Epoch 13: val_loss did not improve from 1.39592\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4052 - mse: 1.3377 - val_loss: 1.3980 - val_mse: 1.3308\n",
      "Epoch 14/25\n",
      "167/177 [===========================>..] - ETA: 0s - loss: 1.3996 - mse: 1.3328\n",
      "Epoch 14: val_loss improved from 1.39592 to 1.38833, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e014_vl1.388.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.4009 - mse: 1.3341 - val_loss: 1.3883 - val_mse: 1.3219\n",
      "Epoch 15/25\n",
      "171/177 [===========================>..] - ETA: 0s - loss: 1.3963 - mse: 1.3303\n",
      "Epoch 15: val_loss improved from 1.38833 to 1.38241, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e015_vl1.382.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.3961 - mse: 1.3301 - val_loss: 1.3824 - val_mse: 1.3167\n",
      "Epoch 16/25\n",
      "166/177 [===========================>..] - ETA: 0s - loss: 1.3925 - mse: 1.3272\n",
      "Epoch 16: val_loss improved from 1.38241 to 1.37855, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e016_vl1.379.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.3912 - mse: 1.3259 - val_loss: 1.3786 - val_mse: 1.3137\n",
      "Epoch 17/25\n",
      "170/177 [===========================>..] - ETA: 0s - loss: 1.3901 - mse: 1.3257\n",
      "Epoch 17: val_loss improved from 1.37855 to 1.37449, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e017_vl1.374.h5\n",
      "177/177 [==============================] - 1s 8ms/step - loss: 1.3865 - mse: 1.3221 - val_loss: 1.3745 - val_mse: 1.3105\n",
      "Epoch 18/25\n",
      "171/177 [===========================>..] - ETA: 0s - loss: 1.3816 - mse: 1.3180\n",
      "Epoch 18: val_loss improved from 1.37449 to 1.36969, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e018_vl1.370.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.3822 - mse: 1.3186 - val_loss: 1.3697 - val_mse: 1.3064\n",
      "Epoch 19/25\n",
      "168/177 [===========================>..] - ETA: 0s - loss: 1.3771 - mse: 1.3142\n",
      "Epoch 19: val_loss improved from 1.36969 to 1.36393, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e019_vl1.364.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.3770 - mse: 1.3140 - val_loss: 1.3639 - val_mse: 1.3013\n",
      "Epoch 20/25\n",
      "173/177 [============================>.] - ETA: 0s - loss: 1.3737 - mse: 1.3114\n",
      "Epoch 20: val_loss improved from 1.36393 to 1.36145, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e020_vl1.361.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.3737 - mse: 1.3114 - val_loss: 1.3614 - val_mse: 1.2994\n",
      "Epoch 21/25\n",
      "173/177 [============================>.] - ETA: 0s - loss: 1.3675 - mse: 1.3058\n",
      "Epoch 21: val_loss did not improve from 1.36145\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.3682 - mse: 1.3064 - val_loss: 1.3619 - val_mse: 1.3005\n",
      "Epoch 22/25\n",
      "173/177 [============================>.] - ETA: 0s - loss: 1.3637 - mse: 1.3026\n",
      "Epoch 22: val_loss improved from 1.36145 to 1.35543, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e022_vl1.355.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.3630 - mse: 1.3018 - val_loss: 1.3554 - val_mse: 1.2947\n",
      "Epoch 23/25\n",
      "173/177 [============================>.] - ETA: 0s - loss: 1.3615 - mse: 1.3010\n",
      "Epoch 23: val_loss improved from 1.35543 to 1.34735, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e023_vl1.347.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.3600 - mse: 1.2994 - val_loss: 1.3473 - val_mse: 1.2869\n",
      "Epoch 24/25\n",
      "174/177 [============================>.] - ETA: 0s - loss: 1.3549 - mse: 1.2945\n",
      "Epoch 24: val_loss improved from 1.34735 to 1.34411, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e024_vl1.344.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.3551 - mse: 1.2947 - val_loss: 1.3441 - val_mse: 1.2836\n",
      "Epoch 25/25\n",
      "166/177 [===========================>..] - ETA: 0s - loss: 1.3503 - mse: 1.2898\n",
      "Epoch 25: val_loss improved from 1.34411 to 1.34309, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e025_vl1.343.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.3515 - mse: 1.2910 - val_loss: 1.3431 - val_mse: 1.2826\n",
      "Time elapsed to train: 27.61 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [1.781 2.282 1.088 2.524 1.808 0.920 0.938 0.636 0.484 0.480 0.843 0.207 0.119]\n",
      "<R> = [1.825 2.348 1.112 2.589 1.864 0.956 0.941 0.635 0.484 0.480 0.876 0.207 0.119]\n",
      "s_R = [1.040 1.938 0.738 1.898 1.755 1.703 0.062 0.033 0.000 0.000 5.178 0.011 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6008246 3.0669792 6.4251413 ... 2.7405734 4.119402  4.4363904]\n",
      "mag_pred: [3.6008246 3.0669792 6.4251413 ... 2.7405734 4.119402  4.4363904]\n",
      "Time elapsed to make plots: 19.52 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [40.118355  35.330963  25.58778   ...  3.3168044 36.556572  38.020798 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0226\n",
      "  1% : 0.141\n",
      "  10% : 0.31\n",
      "  50% : 0.808\n",
      "  90% : 3.54\n",
      "  99% : 76\n",
      "  100% : 6.87e+03\n",
      "<chi^2/d.o.f.> = 1.23\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 2867 stars (1.13%) based on chi^2/dof > 63.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [12.732682  28.462654  12.9159775 ... 10.717621   5.1481    12.796511 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0303\n",
      "  1% : 0.143\n",
      "  10% : 0.307\n",
      "  50% : 0.813\n",
      "  90% : 3.46\n",
      "  99% : 80.1\n",
      "  100% : 5.06e+03\n",
      "<chi^2/d.o.f.> = 1.22\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 78.82 s\n",
      "learning rate = 0.0006703200633637607\n",
      "setting learning rate to 0.0005488116360940264\n",
      "Iteration 4 of 20.\n",
      "Epoch 1/25\n",
      "175/177 [============================>.] - ETA: 0s - loss: 1.2973 - mse: 1.2367\n",
      "Epoch 1: val_loss improved from inf to 1.29159, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e001_vl1.292.h5\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.2964 - mse: 1.2359 - val_loss: 1.2916 - val_mse: 1.2311\n",
      "Epoch 2/25\n",
      "170/177 [===========================>..] - ETA: 0s - loss: 1.2900 - mse: 1.2295\n",
      "Epoch 2: val_loss improved from 1.29159 to 1.28761, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e002_vl1.288.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2912 - mse: 1.2307 - val_loss: 1.2876 - val_mse: 1.2271\n",
      "Epoch 3/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.2890 - mse: 1.2285\n",
      "Epoch 3: val_loss improved from 1.28761 to 1.28185, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e003_vl1.282.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2870 - mse: 1.2265 - val_loss: 1.2819 - val_mse: 1.2213\n",
      "Epoch 4/25\n",
      "169/177 [===========================>..] - ETA: 0s - loss: 1.2813 - mse: 1.2207\n",
      "Epoch 4: val_loss improved from 1.28185 to 1.28054, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e004_vl1.281.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2833 - mse: 1.2226 - val_loss: 1.2805 - val_mse: 1.2197\n",
      "Epoch 5/25\n",
      "174/177 [============================>.] - ETA: 0s - loss: 1.2809 - mse: 1.2200\n",
      "Epoch 5: val_loss improved from 1.28054 to 1.27550, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e005_vl1.276.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2797 - mse: 1.2189 - val_loss: 1.2755 - val_mse: 1.2146\n",
      "Epoch 6/25\n",
      "170/177 [===========================>..] - ETA: 0s - loss: 1.2764 - mse: 1.2154\n",
      "Epoch 6: val_loss improved from 1.27550 to 1.27155, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e006_vl1.272.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2767 - mse: 1.2158 - val_loss: 1.2716 - val_mse: 1.2105\n",
      "Epoch 7/25\n",
      "173/177 [============================>.] - ETA: 0s - loss: 1.2728 - mse: 1.2117\n",
      "Epoch 7: val_loss improved from 1.27155 to 1.26754, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e007_vl1.268.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2729 - mse: 1.2118 - val_loss: 1.2675 - val_mse: 1.2063\n",
      "Epoch 8/25\n",
      "167/177 [===========================>..] - ETA: 0s - loss: 1.2706 - mse: 1.2094\n",
      "Epoch 8: val_loss improved from 1.26754 to 1.26476, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e008_vl1.265.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2691 - mse: 1.2079 - val_loss: 1.2648 - val_mse: 1.2034\n",
      "Epoch 9/25\n",
      "166/177 [===========================>..] - ETA: 0s - loss: 1.2638 - mse: 1.2025\n",
      "Epoch 9: val_loss improved from 1.26476 to 1.26247, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e009_vl1.262.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2657 - mse: 1.2044 - val_loss: 1.2625 - val_mse: 1.2011\n",
      "Epoch 10/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.2595 - mse: 1.1981\n",
      "Epoch 10: val_loss improved from 1.26247 to 1.25798, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e010_vl1.258.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2625 - mse: 1.2010 - val_loss: 1.2580 - val_mse: 1.1966\n",
      "Epoch 11/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.2615 - mse: 1.2001\n",
      "Epoch 11: val_loss improved from 1.25798 to 1.25616, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e011_vl1.256.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2593 - mse: 1.1979 - val_loss: 1.2562 - val_mse: 1.1946\n",
      "Epoch 12/25\n",
      "177/177 [==============================] - ETA: 0s - loss: 1.2560 - mse: 1.1944\n",
      "Epoch 12: val_loss improved from 1.25616 to 1.25186, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e012_vl1.252.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2560 - mse: 1.1944 - val_loss: 1.2519 - val_mse: 1.1903\n",
      "Epoch 13/25\n",
      "169/177 [===========================>..] - ETA: 0s - loss: 1.2519 - mse: 1.1904\n",
      "Epoch 13: val_loss improved from 1.25186 to 1.24858, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e013_vl1.249.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2529 - mse: 1.1914 - val_loss: 1.2486 - val_mse: 1.1870\n",
      "Epoch 14/25\n",
      "170/177 [===========================>..] - ETA: 0s - loss: 1.2477 - mse: 1.1861\n",
      "Epoch 14: val_loss improved from 1.24858 to 1.24630, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e014_vl1.246.h5\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 1.2489 - mse: 1.1873 - val_loss: 1.2463 - val_mse: 1.1848\n",
      "Epoch 15/25\n",
      "173/177 [============================>.] - ETA: 0s - loss: 1.2449 - mse: 1.1833\n",
      "Epoch 15: val_loss improved from 1.24630 to 1.24151, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e015_vl1.242.h5\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 1.2454 - mse: 1.1839 - val_loss: 1.2415 - val_mse: 1.1801\n",
      "Epoch 16/25\n",
      "168/177 [===========================>..] - ETA: 0s - loss: 1.2412 - mse: 1.1797\n",
      "Epoch 16: val_loss improved from 1.24151 to 1.23982, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e016_vl1.240.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2419 - mse: 1.1804 - val_loss: 1.2398 - val_mse: 1.1784\n",
      "Epoch 17/25\n",
      "176/177 [============================>.] - ETA: 0s - loss: 1.2384 - mse: 1.1770\n",
      "Epoch 17: val_loss improved from 1.23982 to 1.23466, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e017_vl1.235.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2387 - mse: 1.1773 - val_loss: 1.2347 - val_mse: 1.1732\n",
      "Epoch 18/25\n",
      "168/177 [===========================>..] - ETA: 0s - loss: 1.2341 - mse: 1.1728\n",
      "Epoch 18: val_loss improved from 1.23466 to 1.23165, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e018_vl1.232.h5\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 1.2360 - mse: 1.1746 - val_loss: 1.2316 - val_mse: 1.1702\n",
      "Epoch 19/25\n",
      "171/177 [===========================>..] - ETA: 0s - loss: 1.2360 - mse: 1.1746\n",
      "Epoch 19: val_loss improved from 1.23165 to 1.22988, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e019_vl1.230.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2328 - mse: 1.1714 - val_loss: 1.2299 - val_mse: 1.1685\n",
      "Epoch 20/25\n",
      "167/177 [===========================>..] - ETA: 0s - loss: 1.2305 - mse: 1.1692\n",
      "Epoch 20: val_loss improved from 1.22988 to 1.22716, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e020_vl1.227.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2290 - mse: 1.1677 - val_loss: 1.2272 - val_mse: 1.1660\n",
      "Epoch 21/25\n",
      "168/177 [===========================>..] - ETA: 0s - loss: 1.2247 - mse: 1.1636\n",
      "Epoch 21: val_loss improved from 1.22716 to 1.22533, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e021_vl1.225.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2263 - mse: 1.1651 - val_loss: 1.2253 - val_mse: 1.1642\n",
      "Epoch 22/25\n",
      "166/177 [===========================>..] - ETA: 0s - loss: 1.2239 - mse: 1.1628\n",
      "Epoch 22: val_loss improved from 1.22533 to 1.22177, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e022_vl1.222.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2224 - mse: 1.1613 - val_loss: 1.2218 - val_mse: 1.1607\n",
      "Epoch 23/25\n",
      "166/177 [===========================>..] - ETA: 0s - loss: 1.2207 - mse: 1.1597\n",
      "Epoch 23: val_loss improved from 1.22177 to 1.21802, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e023_vl1.218.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2207 - mse: 1.1597 - val_loss: 1.2180 - val_mse: 1.1571\n",
      "Epoch 24/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.2172 - mse: 1.1563\n",
      "Epoch 24: val_loss improved from 1.21802 to 1.21463, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e024_vl1.215.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.2170 - mse: 1.1561 - val_loss: 1.2146 - val_mse: 1.1539\n",
      "Epoch 25/25\n",
      "173/177 [============================>.] - ETA: 0s - loss: 1.2135 - mse: 1.1529\n",
      "Epoch 25: val_loss improved from 1.21463 to 1.21412, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e025_vl1.214.h5\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 1.2137 - mse: 1.1531 - val_loss: 1.2141 - val_mse: 1.1536\n",
      "Time elapsed to train: 26.55 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.116 2.723 1.474 3.001 2.134 1.304 1.120 0.849 0.592 0.447 0.771 0.172 0.081]\n",
      "<R> = [2.162 2.791 1.503 3.075 2.198 1.347 1.136 0.857 0.592 0.447 0.801 0.172 0.081]\n",
      "s_R = [0.991 1.626 0.557 1.719 1.741 1.515 0.231 0.127 0.000 0.000 3.939 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6592898 2.7160573 6.4552655 ... 2.6416185 4.0255814 4.402428 ]\n",
      "mag_pred: [3.6592898 2.7160573 6.4552655 ... 2.6416185 4.0255814 4.402428 ]\n",
      "Time elapsed to make plots: 18.87 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [37.67231   32.738045  20.134665  ...  3.0677767 37.05631   38.013096 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0089\n",
      "  1% : 0.124\n",
      "  10% : 0.271\n",
      "  50% : 0.722\n",
      "  90% : 3.53\n",
      "  99% : 72\n",
      "  100% : 7e+03\n",
      "<chi^2/d.o.f.> = 1.16\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 3221 stars (1.27%) based on chi^2/dof > 50.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [10.428492  42.879036  11.222635  ...  6.1985717  4.2814474 15.353203 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00972\n",
      "  1% : 0.123\n",
      "  10% : 0.269\n",
      "  50% : 0.731\n",
      "  90% : 3.44\n",
      "  99% : 75.9\n",
      "  100% : 5.14e+03\n",
      "<chi^2/d.o.f.> = 1.16\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 78.66 s\n",
      "learning rate = 0.0005488116294145584\n",
      "setting learning rate to 0.0004493289641172216\n",
      "Iteration 5 of 20.\n",
      "Epoch 1/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.1677 - mse: 1.1071\n",
      "Epoch 1: val_loss improved from inf to 1.16126, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e001_vl1.161.h5\n",
      "177/177 [==============================] - 1s 7ms/step - loss: 1.1680 - mse: 1.1074 - val_loss: 1.1613 - val_mse: 1.1006\n",
      "Epoch 2/25\n",
      "176/177 [============================>.] - ETA: 0s - loss: 1.1640 - mse: 1.1034\n",
      "Epoch 2: val_loss improved from 1.16126 to 1.15683, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e002_vl1.157.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1640 - mse: 1.1034 - val_loss: 1.1568 - val_mse: 1.0962\n",
      "Epoch 3/25\n",
      "168/177 [===========================>..] - ETA: 0s - loss: 1.1642 - mse: 1.1036\n",
      "Epoch 3: val_loss improved from 1.15683 to 1.15393, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e003_vl1.154.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1609 - mse: 1.1004 - val_loss: 1.1539 - val_mse: 1.0934\n",
      "Epoch 4/25\n",
      "172/177 [============================>.] - ETA: 0s - loss: 1.1568 - mse: 1.0963\n",
      "Epoch 4: val_loss improved from 1.15393 to 1.14990, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e004_vl1.150.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1576 - mse: 1.0972 - val_loss: 1.1499 - val_mse: 1.0896\n",
      "Epoch 5/25\n",
      "173/177 [============================>.] - ETA: 0s - loss: 1.1549 - mse: 1.0946\n",
      "Epoch 5: val_loss improved from 1.14990 to 1.14749, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e005_vl1.147.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1542 - mse: 1.0940 - val_loss: 1.1475 - val_mse: 1.0873\n",
      "Epoch 6/25\n",
      "176/177 [============================>.] - ETA: 0s - loss: 1.1516 - mse: 1.0915\n",
      "Epoch 6: val_loss did not improve from 1.14749\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1516 - mse: 1.0916 - val_loss: 1.1482 - val_mse: 1.0883\n",
      "Epoch 7/25\n",
      "176/177 [============================>.] - ETA: 0s - loss: 1.1484 - mse: 1.0887\n",
      "Epoch 7: val_loss improved from 1.14749 to 1.13861, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e007_vl1.139.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1484 - mse: 1.0887 - val_loss: 1.1386 - val_mse: 1.0791\n",
      "Epoch 8/25\n",
      "167/177 [===========================>..] - ETA: 0s - loss: 1.1489 - mse: 1.0896\n",
      "Epoch 8: val_loss improved from 1.13861 to 1.13757, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e008_vl1.138.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1457 - mse: 1.0864 - val_loss: 1.1376 - val_mse: 1.0784\n",
      "Epoch 9/25\n",
      "165/177 [==========================>...] - ETA: 0s - loss: 1.1417 - mse: 1.0829\n",
      "Epoch 9: val_loss improved from 1.13757 to 1.13399, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e009_vl1.134.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1426 - mse: 1.0838 - val_loss: 1.1340 - val_mse: 1.0754\n",
      "Epoch 10/25\n",
      "174/177 [============================>.] - ETA: 0s - loss: 1.1409 - mse: 1.0825\n",
      "Epoch 10: val_loss improved from 1.13399 to 1.13221, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e010_vl1.132.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1399 - mse: 1.0815 - val_loss: 1.1322 - val_mse: 1.0741\n",
      "Epoch 11/25\n",
      "167/177 [===========================>..] - ETA: 0s - loss: 1.1369 - mse: 1.0792\n",
      "Epoch 11: val_loss improved from 1.13221 to 1.12926, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e011_vl1.129.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1371 - mse: 1.0794 - val_loss: 1.1293 - val_mse: 1.0720\n",
      "Epoch 12/25\n",
      "166/177 [===========================>..] - ETA: 0s - loss: 1.1340 - mse: 1.0771\n",
      "Epoch 12: val_loss improved from 1.12926 to 1.12441, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e012_vl1.124.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1341 - mse: 1.0772 - val_loss: 1.1244 - val_mse: 1.0679\n",
      "Epoch 13/25\n",
      "177/177 [==============================] - ETA: 0s - loss: 1.1310 - mse: 1.0749\n",
      "Epoch 13: val_loss improved from 1.12441 to 1.12248, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e013_vl1.122.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1310 - mse: 1.0749 - val_loss: 1.1225 - val_mse: 1.0668\n",
      "Epoch 14/25\n",
      "171/177 [===========================>..] - ETA: 0s - loss: 1.1289 - mse: 1.0737\n",
      "Epoch 14: val_loss improved from 1.12248 to 1.11810, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e014_vl1.118.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1285 - mse: 1.0734 - val_loss: 1.1181 - val_mse: 1.0634\n",
      "Epoch 15/25\n",
      "171/177 [===========================>..] - ETA: 0s - loss: 1.1250 - mse: 1.0707\n",
      "Epoch 15: val_loss improved from 1.11810 to 1.11586, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e015_vl1.116.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1254 - mse: 1.0712 - val_loss: 1.1159 - val_mse: 1.0622\n",
      "Epoch 16/25\n",
      "168/177 [===========================>..] - ETA: 0s - loss: 1.1205 - mse: 1.0673\n",
      "Epoch 16: val_loss improved from 1.11586 to 1.11322, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e016_vl1.113.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1231 - mse: 1.0700 - val_loss: 1.1132 - val_mse: 1.0607\n",
      "Epoch 17/25\n",
      "176/177 [============================>.] - ETA: 0s - loss: 1.1208 - mse: 1.0688\n",
      "Epoch 17: val_loss did not improve from 1.11322\n",
      "177/177 [==============================] - 1s 5ms/step - loss: 1.1205 - mse: 1.0685 - val_loss: 1.1158 - val_mse: 1.0645\n",
      "Epoch 18/25\n",
      "177/177 [==============================] - ETA: 0s - loss: 1.1180 - mse: 1.0672\n",
      "Epoch 18: val_loss improved from 1.11322 to 1.10921, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e018_vl1.109.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1180 - mse: 1.0672 - val_loss: 1.1092 - val_mse: 1.0591\n",
      "Epoch 19/25\n",
      "173/177 [============================>.] - ETA: 0s - loss: 1.1162 - mse: 1.0667\n",
      "Epoch 19: val_loss improved from 1.10921 to 1.10634, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e019_vl1.106.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1155 - mse: 1.0660 - val_loss: 1.1063 - val_mse: 1.0575\n",
      "Epoch 20/25\n",
      "170/177 [===========================>..] - ETA: 0s - loss: 1.1131 - mse: 1.0650\n",
      "Epoch 20: val_loss improved from 1.10634 to 1.10277, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e020_vl1.103.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1122 - mse: 1.0641 - val_loss: 1.1028 - val_mse: 1.0553\n",
      "Epoch 21/25\n",
      "169/177 [===========================>..] - ETA: 0s - loss: 1.1097 - mse: 1.0630\n",
      "Epoch 21: val_loss improved from 1.10277 to 1.10056, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e021_vl1.101.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1101 - mse: 1.0633 - val_loss: 1.1006 - val_mse: 1.0545\n",
      "Epoch 22/25\n",
      "166/177 [===========================>..] - ETA: 0s - loss: 1.1082 - mse: 1.0629\n",
      "Epoch 22: val_loss improved from 1.10056 to 1.09947, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e022_vl1.099.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1078 - mse: 1.0625 - val_loss: 1.0995 - val_mse: 1.0549\n",
      "Epoch 23/25\n",
      "169/177 [===========================>..] - ETA: 0s - loss: 1.1064 - mse: 1.0626\n",
      "Epoch 23: val_loss improved from 1.09947 to 1.09727, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e023_vl1.097.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1051 - mse: 1.0613 - val_loss: 1.0973 - val_mse: 1.0543\n",
      "Epoch 24/25\n",
      "166/177 [===========================>..] - ETA: 0s - loss: 1.1077 - mse: 1.0655\n",
      "Epoch 24: val_loss improved from 1.09727 to 1.09333, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e024_vl1.093.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1033 - mse: 1.0611 - val_loss: 1.0933 - val_mse: 1.0520\n",
      "Epoch 25/25\n",
      "176/177 [============================>.] - ETA: 0s - loss: 1.1001 - mse: 1.0594\n",
      "Epoch 25: val_loss improved from 1.09333 to 1.09001, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e025_vl1.090.h5\n",
      "177/177 [==============================] - 1s 6ms/step - loss: 1.1001 - mse: 1.0594 - val_loss: 1.0900 - val_mse: 1.0502\n",
      "Time elapsed to train: 26.76 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.595 3.320 1.852 3.650 2.609 1.904 1.446 1.153 0.797 0.536 0.556 0.245 0.160]\n",
      "<R> = [2.617 3.356 1.864 3.688 2.642 1.924 1.449 1.152 0.797 0.536 0.575 0.245 0.160]\n",
      "s_R = [0.321 0.522 0.212 0.587 0.555 0.279 0.085 0.057 0.000 0.000 1.277 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6691344 2.5111437 6.355268  ... 2.6105564 3.9647622 4.4056787]\n",
      "mag_pred: [3.6691344 2.5111437 6.355268  ... 2.6105564 3.9647622 4.4056787]\n",
      "Time elapsed to make plots: 19.32 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [37.28523   32.05024   19.037312  ...  3.1970975 35.834457  34.283195 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0124\n",
      "  1% : 0.111\n",
      "  10% : 0.249\n",
      "  50% : 0.675\n",
      "  90% : 3.31\n",
      "  99% : 67\n",
      "  100% : 6.93e+03\n",
      "<chi^2/d.o.f.> = 1.11\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 3559 stars (1.41%) based on chi^2/dof > 39.8\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [10.019504 49.416252  9.423304 ...  5.794939  5.03944  14.114521]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0154\n",
      "  1% : 0.111\n",
      "  10% : 0.248\n",
      "  50% : 0.683\n",
      "  90% : 3.26\n",
      "  99% : 72.3\n",
      "  100% : 5.18e+03\n",
      "<chi^2/d.o.f.> = 1.11\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 80.63 s\n",
      "learning rate = 0.0004493289743550122\n",
      "setting learning rate to 0.00036787944117144236\n",
      "Iteration 6 of 20.\n",
      "Epoch 1/25\n",
      "169/176 [===========================>..] - ETA: 0s - loss: 1.0287 - mse: 0.9895\n",
      "Epoch 1: val_loss improved from inf to 1.02033, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e001_vl1.020.h5\n",
      "176/176 [==============================] - 1s 7ms/step - loss: 1.0296 - mse: 0.9904 - val_loss: 1.0203 - val_mse: 0.9819\n",
      "Epoch 2/25\n",
      "172/176 [============================>.] - ETA: 0s - loss: 1.0268 - mse: 0.9891\n",
      "Epoch 2: val_loss improved from 1.02033 to 1.01809, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e002_vl1.018.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0262 - mse: 0.9885 - val_loss: 1.0181 - val_mse: 0.9810\n",
      "Epoch 3/25\n",
      "171/176 [============================>.] - ETA: 0s - loss: 1.0235 - mse: 0.9872\n",
      "Epoch 3: val_loss improved from 1.01809 to 1.01430, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e003_vl1.014.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0233 - mse: 0.9869 - val_loss: 1.0143 - val_mse: 0.9787\n",
      "Epoch 4/25\n",
      "165/176 [===========================>..] - ETA: 0s - loss: 1.0191 - mse: 0.9841\n",
      "Epoch 4: val_loss improved from 1.01430 to 1.01202, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e004_vl1.012.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0211 - mse: 0.9861 - val_loss: 1.0120 - val_mse: 0.9777\n",
      "Epoch 5/25\n",
      "166/176 [===========================>..] - ETA: 0s - loss: 1.0203 - mse: 0.9866\n",
      "Epoch 5: val_loss improved from 1.01202 to 1.01116, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e005_vl1.011.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0187 - mse: 0.9851 - val_loss: 1.0112 - val_mse: 0.9781\n",
      "Epoch 6/25\n",
      "173/176 [============================>.] - ETA: 0s - loss: 1.0172 - mse: 0.9848\n",
      "Epoch 6: val_loss improved from 1.01116 to 1.00942, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e006_vl1.009.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0167 - mse: 0.9844 - val_loss: 1.0094 - val_mse: 0.9777\n",
      "Epoch 7/25\n",
      "170/176 [===========================>..] - ETA: 0s - loss: 1.0155 - mse: 0.9844\n",
      "Epoch 7: val_loss improved from 1.00942 to 1.00546, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e007_vl1.005.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0147 - mse: 0.9836 - val_loss: 1.0055 - val_mse: 0.9750\n",
      "Epoch 8/25\n",
      "176/176 [==============================] - ETA: 0s - loss: 1.0124 - mse: 0.9825\n",
      "Epoch 8: val_loss improved from 1.00546 to 1.00530, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e008_vl1.005.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0124 - mse: 0.9825 - val_loss: 1.0053 - val_mse: 0.9759\n",
      "Epoch 9/25\n",
      "167/176 [===========================>..] - ETA: 0s - loss: 1.0090 - mse: 0.9800\n",
      "Epoch 9: val_loss improved from 1.00530 to 1.00323, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e009_vl1.003.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0108 - mse: 0.9818 - val_loss: 1.0032 - val_mse: 0.9746\n",
      "Epoch 10/25\n",
      "168/176 [===========================>..] - ETA: 0s - loss: 1.0095 - mse: 0.9812\n",
      "Epoch 10: val_loss improved from 1.00323 to 1.00184, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e010_vl1.002.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0095 - mse: 0.9813 - val_loss: 1.0018 - val_mse: 0.9739\n",
      "Epoch 11/25\n",
      "166/176 [===========================>..] - ETA: 0s - loss: 1.0103 - mse: 0.9827\n",
      "Epoch 11: val_loss improved from 1.00184 to 0.99963, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e011_vl1.000.h5\n",
      "176/176 [==============================] - 1s 7ms/step - loss: 1.0086 - mse: 0.9810 - val_loss: 0.9996 - val_mse: 0.9722\n",
      "Epoch 12/25\n",
      "173/176 [============================>.] - ETA: 0s - loss: 1.0083 - mse: 0.9810\n",
      "Epoch 12: val_loss did not improve from 0.99963\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0072 - mse: 0.9799 - val_loss: 1.0008 - val_mse: 0.9737\n",
      "Epoch 13/25\n",
      "170/176 [===========================>..] - ETA: 0s - loss: 1.0064 - mse: 0.9794\n",
      "Epoch 13: val_loss improved from 0.99963 to 0.99720, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e013_vl0.997.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0069 - mse: 0.9799 - val_loss: 0.9972 - val_mse: 0.9703\n",
      "Epoch 14/25\n",
      "172/176 [============================>.] - ETA: 0s - loss: 1.0038 - mse: 0.9770\n",
      "Epoch 14: val_loss improved from 0.99720 to 0.99680, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e014_vl0.997.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0054 - mse: 0.9786 - val_loss: 0.9968 - val_mse: 0.9702\n",
      "Epoch 15/25\n",
      "170/176 [===========================>..] - ETA: 0s - loss: 1.0053 - mse: 0.9788\n",
      "Epoch 15: val_loss did not improve from 0.99680\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0049 - mse: 0.9784 - val_loss: 0.9972 - val_mse: 0.9708\n",
      "Epoch 16/25\n",
      "169/176 [===========================>..] - ETA: 0s - loss: 1.0038 - mse: 0.9775\n",
      "Epoch 16: val_loss did not improve from 0.99680\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 1.0038 - mse: 0.9776 - val_loss: 0.9968 - val_mse: 0.9706\n",
      "Epoch 17/25\n",
      "174/176 [============================>.] - ETA: 0s - loss: 1.0043 - mse: 0.9783\n",
      "Epoch 17: val_loss improved from 0.99680 to 0.99461, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e017_vl0.995.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0034 - mse: 0.9774 - val_loss: 0.9946 - val_mse: 0.9687\n",
      "Epoch 18/25\n",
      "166/176 [===========================>..] - ETA: 0s - loss: 1.0033 - mse: 0.9774\n",
      "Epoch 18: val_loss did not improve from 0.99461\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0024 - mse: 0.9766 - val_loss: 0.9948 - val_mse: 0.9691\n",
      "Epoch 19/25\n",
      "172/176 [============================>.] - ETA: 0s - loss: 1.0011 - mse: 0.9754\n",
      "Epoch 19: val_loss did not improve from 0.99461\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0019 - mse: 0.9762 - val_loss: 0.9953 - val_mse: 0.9697\n",
      "Epoch 20/25\n",
      "167/176 [===========================>..] - ETA: 0s - loss: 1.0031 - mse: 0.9775\n",
      "Epoch 20: val_loss improved from 0.99461 to 0.99364, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e020_vl0.994.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0018 - mse: 0.9762 - val_loss: 0.9936 - val_mse: 0.9682\n",
      "Epoch 21/25\n",
      "172/176 [============================>.] - ETA: 0s - loss: 1.0010 - mse: 0.9757\n",
      "Epoch 21: val_loss improved from 0.99364 to 0.99298, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e021_vl0.993.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0012 - mse: 0.9758 - val_loss: 0.9930 - val_mse: 0.9677\n",
      "Epoch 22/25\n",
      "172/176 [============================>.] - ETA: 0s - loss: 0.9998 - mse: 0.9746\n",
      "Epoch 22: val_loss improved from 0.99298 to 0.99270, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e022_vl0.993.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 1.0002 - mse: 0.9750 - val_loss: 0.9927 - val_mse: 0.9675\n",
      "Epoch 23/25\n",
      "175/176 [============================>.] - ETA: 0s - loss: 0.9997 - mse: 0.9747\n",
      "Epoch 23: val_loss did not improve from 0.99270\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9997 - mse: 0.9746 - val_loss: 0.9947 - val_mse: 0.9699\n",
      "Epoch 24/25\n",
      "172/176 [============================>.] - ETA: 0s - loss: 1.0001 - mse: 0.9753\n",
      "Epoch 24: val_loss improved from 0.99270 to 0.99116, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e024_vl0.991.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9993 - mse: 0.9745 - val_loss: 0.9912 - val_mse: 0.9664\n",
      "Epoch 25/25\n",
      "166/176 [===========================>..] - ETA: 0s - loss: 0.9968 - mse: 0.9721\n",
      "Epoch 25: val_loss did not improve from 0.99116\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9987 - mse: 0.9741 - val_loss: 0.9924 - val_mse: 0.9680\n",
      "Time elapsed to train: 26.60 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.705 3.450 1.946 3.804 2.729 2.035 1.537 1.247 0.866 0.577 0.364 0.295 0.227]\n",
      "<R> = [2.705 3.450 1.946 3.803 2.733 2.035 1.537 1.247 0.866 0.577 0.372 0.295 0.227]\n",
      "s_R = [0.032 0.012 0.001 0.037 0.111 0.001 0.000 0.002 0.000 0.000 0.136 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6777177 2.509591  6.38026   ... 2.6445303 3.9556937 4.415564 ]\n",
      "mag_pred: [3.6777177 2.509591  6.38026   ... 2.6445303 3.9556937 4.415564 ]\n",
      "Time elapsed to make plots: 17.69 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [35.867126  30.460522  16.788166  ...  3.2669206 34.867455  28.275454 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0105\n",
      "  1% : 0.105\n",
      "  10% : 0.239\n",
      "  50% : 0.643\n",
      "  90% : 3.22\n",
      "  99% : 65.7\n",
      "  100% : 6.96e+03\n",
      "<chi^2/d.o.f.> = 1.07\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 4109 stars (1.62%) based on chi^2/dof > 31.6\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.760875 50.04823  10.138255 ...  4.622255  5.245469 13.937075]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0199\n",
      "  1% : 0.106\n",
      "  10% : 0.239\n",
      "  50% : 0.651\n",
      "  90% : 3.16\n",
      "  99% : 71\n",
      "  100% : 5.17e+03\n",
      "<chi^2/d.o.f.> = 1.07\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 76.92 s\n",
      "learning rate = 0.0003678794309962541\n",
      "setting learning rate to 0.00030119421191220205\n",
      "Iteration 7 of 20.\n",
      "Epoch 1/25\n",
      "166/176 [===========================>..] - ETA: 0s - loss: 0.9473 - mse: 0.9229\n",
      "Epoch 1: val_loss improved from inf to 0.94670, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e001_vl0.947.h5\n",
      "176/176 [==============================] - 3s 7ms/step - loss: 0.9455 - mse: 0.9211 - val_loss: 0.9467 - val_mse: 0.9223\n",
      "Epoch 2/25\n",
      "170/176 [===========================>..] - ETA: 0s - loss: 0.9453 - mse: 0.9211\n",
      "Epoch 2: val_loss improved from 0.94670 to 0.94612, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e002_vl0.946.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9445 - mse: 0.9203 - val_loss: 0.9461 - val_mse: 0.9219\n",
      "Epoch 3/25\n",
      "171/176 [============================>.] - ETA: 0s - loss: 0.9436 - mse: 0.9195\n",
      "Epoch 3: val_loss did not improve from 0.94612\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9436 - mse: 0.9196 - val_loss: 0.9462 - val_mse: 0.9223\n",
      "Epoch 4/25\n",
      "166/176 [===========================>..] - ETA: 0s - loss: 0.9426 - mse: 0.9187\n",
      "Epoch 4: val_loss improved from 0.94612 to 0.94458, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e004_vl0.945.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9435 - mse: 0.9196 - val_loss: 0.9446 - val_mse: 0.9208\n",
      "Epoch 5/25\n",
      "170/176 [===========================>..] - ETA: 0s - loss: 0.9420 - mse: 0.9184\n",
      "Epoch 5: val_loss did not improve from 0.94458\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9426 - mse: 0.9189 - val_loss: 0.9448 - val_mse: 0.9212\n",
      "Epoch 6/25\n",
      "172/176 [============================>.] - ETA: 0s - loss: 0.9412 - mse: 0.9177\n",
      "Epoch 6: val_loss improved from 0.94458 to 0.94413, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e006_vl0.944.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9423 - mse: 0.9188 - val_loss: 0.9441 - val_mse: 0.9208\n",
      "Epoch 7/25\n",
      "169/176 [===========================>..] - ETA: 0s - loss: 0.9403 - mse: 0.9170\n",
      "Epoch 7: val_loss improved from 0.94413 to 0.94315, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e007_vl0.943.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9419 - mse: 0.9186 - val_loss: 0.9431 - val_mse: 0.9199\n",
      "Epoch 8/25\n",
      "168/176 [===========================>..] - ETA: 0s - loss: 0.9408 - mse: 0.9177\n",
      "Epoch 8: val_loss did not improve from 0.94315\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9413 - mse: 0.9182 - val_loss: 0.9436 - val_mse: 0.9207\n",
      "Epoch 9/25\n",
      "171/176 [============================>.] - ETA: 0s - loss: 0.9413 - mse: 0.9184\n",
      "Epoch 9: val_loss improved from 0.94315 to 0.94238, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e009_vl0.942.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9410 - mse: 0.9181 - val_loss: 0.9424 - val_mse: 0.9196\n",
      "Epoch 10/25\n",
      "165/176 [===========================>..] - ETA: 0s - loss: 0.9387 - mse: 0.9160\n",
      "Epoch 10: val_loss improved from 0.94238 to 0.94137, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e010_vl0.941.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9404 - mse: 0.9178 - val_loss: 0.9414 - val_mse: 0.9190\n",
      "Epoch 11/25\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.9401 - mse: 0.9177\n",
      "Epoch 11: val_loss did not improve from 0.94137\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9401 - mse: 0.9177 - val_loss: 0.9414 - val_mse: 0.9192\n",
      "Epoch 12/25\n",
      "173/176 [============================>.] - ETA: 0s - loss: 0.9394 - mse: 0.9173\n",
      "Epoch 12: val_loss improved from 0.94137 to 0.94104, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e012_vl0.941.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9395 - mse: 0.9174 - val_loss: 0.9410 - val_mse: 0.9191\n",
      "Epoch 13/25\n",
      "166/176 [===========================>..] - ETA: 0s - loss: 0.9380 - mse: 0.9162\n",
      "Epoch 13: val_loss improved from 0.94104 to 0.94013, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e013_vl0.940.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9390 - mse: 0.9172 - val_loss: 0.9401 - val_mse: 0.9185\n",
      "Epoch 14/25\n",
      "171/176 [============================>.] - ETA: 0s - loss: 0.9384 - mse: 0.9169\n",
      "Epoch 14: val_loss improved from 0.94013 to 0.93940, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e014_vl0.939.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9385 - mse: 0.9170 - val_loss: 0.9394 - val_mse: 0.9181\n",
      "Epoch 15/25\n",
      "167/176 [===========================>..] - ETA: 0s - loss: 0.9373 - mse: 0.9161\n",
      "Epoch 15: val_loss improved from 0.93940 to 0.93940, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e015_vl0.939.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9380 - mse: 0.9168 - val_loss: 0.9394 - val_mse: 0.9183\n",
      "Epoch 16/25\n",
      "172/176 [============================>.] - ETA: 0s - loss: 0.9385 - mse: 0.9174\n",
      "Epoch 16: val_loss did not improve from 0.93940\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9374 - mse: 0.9164 - val_loss: 0.9404 - val_mse: 0.9194\n",
      "Epoch 17/25\n",
      "173/176 [============================>.] - ETA: 0s - loss: 0.9361 - mse: 0.9152\n",
      "Epoch 17: val_loss did not improve from 0.93940\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9373 - mse: 0.9164 - val_loss: 0.9400 - val_mse: 0.9191\n",
      "Epoch 18/25\n",
      "174/176 [============================>.] - ETA: 0s - loss: 0.9372 - mse: 0.9163\n",
      "Epoch 18: val_loss improved from 0.93940 to 0.93839, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e018_vl0.938.h5\n",
      "176/176 [==============================] - 1s 7ms/step - loss: 0.9374 - mse: 0.9166 - val_loss: 0.9384 - val_mse: 0.9175\n",
      "Epoch 19/25\n",
      "166/176 [===========================>..] - ETA: 0s - loss: 0.9369 - mse: 0.9160\n",
      "Epoch 19: val_loss did not improve from 0.93839\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9367 - mse: 0.9158 - val_loss: 0.9399 - val_mse: 0.9191\n",
      "Epoch 20/25\n",
      "166/176 [===========================>..] - ETA: 0s - loss: 0.9359 - mse: 0.9150\n",
      "Epoch 20: val_loss did not improve from 0.93839\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9368 - mse: 0.9160 - val_loss: 0.9384 - val_mse: 0.9175\n",
      "Epoch 21/25\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.9368 - mse: 0.9159\n",
      "Epoch 21: val_loss did not improve from 0.93839\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9368 - mse: 0.9159 - val_loss: 0.9396 - val_mse: 0.9187\n",
      "Epoch 22/25\n",
      "171/176 [============================>.] - ETA: 0s - loss: 0.9361 - mse: 0.9153\n",
      "Epoch 22: val_loss improved from 0.93839 to 0.93817, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e022_vl0.938.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9364 - mse: 0.9156 - val_loss: 0.9382 - val_mse: 0.9173\n",
      "Epoch 23/25\n",
      "169/176 [===========================>..] - ETA: 0s - loss: 0.9364 - mse: 0.9156\n",
      "Epoch 23: val_loss did not improve from 0.93817\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.9361 - mse: 0.9153 - val_loss: 0.9390 - val_mse: 0.9182\n",
      "Epoch 24/25\n",
      "171/176 [============================>.] - ETA: 0s - loss: 0.9356 - mse: 0.9147\n",
      "Epoch 24: val_loss did not improve from 0.93817\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9366 - mse: 0.9157 - val_loss: 0.9392 - val_mse: 0.9183\n",
      "Epoch 25/25\n",
      "169/176 [===========================>..] - ETA: 0s - loss: 0.9370 - mse: 0.9161\n",
      "Epoch 25: val_loss did not improve from 0.93817\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.9359 - mse: 0.9150 - val_loss: 0.9388 - val_mse: 0.9179\n",
      "Time elapsed to train: 28.43 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.693 3.440 1.934 3.799 2.722 2.023 1.523 1.237 0.851 0.548 0.372 0.279 0.221]\n",
      "<R> = [2.693 3.440 1.934 3.798 2.720 2.023 1.523 1.237 0.851 0.548 0.372 0.279 0.221]\n",
      "s_R = [0.040 0.012 0.002 0.046 0.095 0.002 0.001 0.001 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6874776 2.531056  6.399209  ... 2.6953468 3.9722946 4.4350953]\n",
      "mag_pred: [3.6874776 2.531056  6.399209  ... 2.6953468 3.9722946 4.4350953]\n",
      "Time elapsed to make plots: 18.03 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [37.77705   32.196754  14.880892  ...  2.9066958 37.666126  25.351032 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0117\n",
      "  1% : 0.101\n",
      "  10% : 0.225\n",
      "  50% : 0.618\n",
      "  90% : 3.2\n",
      "  99% : 64.9\n",
      "  100% : 7.01e+03\n",
      "<chi^2/d.o.f.> = 1.05\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 4799 stars (1.9%) based on chi^2/dof > 25.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.108851  53.565353  10.765212  ...  4.955608   5.6409607 13.751471 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0263\n",
      "  1% : 0.102\n",
      "  10% : 0.224\n",
      "  50% : 0.626\n",
      "  90% : 3.1\n",
      "  99% : 71.1\n",
      "  100% : 5.18e+03\n",
      "<chi^2/d.o.f.> = 1.05\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 75.77 s\n",
      "learning rate = 0.0003011942026205361\n",
      "setting learning rate to 0.00024659696394160646\n",
      "Iteration 8 of 20.\n",
      "Epoch 1/25\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.8856 - mse: 0.8648\n",
      "Epoch 1: val_loss improved from inf to 0.88887, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e001_vl0.889.h5\n",
      "176/176 [==============================] - 1s 7ms/step - loss: 0.8856 - mse: 0.8648 - val_loss: 0.8889 - val_mse: 0.8681\n",
      "Epoch 2/25\n",
      "173/176 [============================>.] - ETA: 0s - loss: 0.8847 - mse: 0.8640\n",
      "Epoch 2: val_loss improved from 0.88887 to 0.88736, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e002_vl0.887.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8851 - mse: 0.8644 - val_loss: 0.8874 - val_mse: 0.8666\n",
      "Epoch 3/25\n",
      "175/176 [============================>.] - ETA: 0s - loss: 0.8849 - mse: 0.8642\n",
      "Epoch 3: val_loss did not improve from 0.88736\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8850 - mse: 0.8642 - val_loss: 0.8874 - val_mse: 0.8667\n",
      "Epoch 4/25\n",
      "167/176 [===========================>..] - ETA: 0s - loss: 0.8833 - mse: 0.8626\n",
      "Epoch 4: val_loss improved from 0.88736 to 0.88691, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e004_vl0.887.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8850 - mse: 0.8642 - val_loss: 0.8869 - val_mse: 0.8662\n",
      "Epoch 5/25\n",
      "169/176 [===========================>..] - ETA: 0s - loss: 0.8869 - mse: 0.8662\n",
      "Epoch 5: val_loss did not improve from 0.88691\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8848 - mse: 0.8641 - val_loss: 0.8877 - val_mse: 0.8670\n",
      "Epoch 6/25\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.8848 - mse: 0.8640\n",
      "Epoch 6: val_loss did not improve from 0.88691\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8848 - mse: 0.8640 - val_loss: 0.8881 - val_mse: 0.8674\n",
      "Epoch 7/25\n",
      "173/176 [============================>.] - ETA: 0s - loss: 0.8848 - mse: 0.8640\n",
      "Epoch 7: val_loss did not improve from 0.88691\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8846 - mse: 0.8639 - val_loss: 0.8873 - val_mse: 0.8666\n",
      "Epoch 8/25\n",
      "173/176 [============================>.] - ETA: 0s - loss: 0.8855 - mse: 0.8648\n",
      "Epoch 8: val_loss did not improve from 0.88691\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8848 - mse: 0.8641 - val_loss: 0.8877 - val_mse: 0.8670\n",
      "Epoch 9/25\n",
      "169/176 [===========================>..] - ETA: 0s - loss: 0.8855 - mse: 0.8648\n",
      "Epoch 9: val_loss did not improve from 0.88691\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.8843 - mse: 0.8636 - val_loss: 0.8874 - val_mse: 0.8667\n",
      "Epoch 10/25\n",
      "167/176 [===========================>..] - ETA: 0s - loss: 0.8840 - mse: 0.8633\n",
      "Epoch 10: val_loss did not improve from 0.88691\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8841 - mse: 0.8634 - val_loss: 0.8889 - val_mse: 0.8681\n",
      "Epoch 11/25\n",
      "170/176 [===========================>..] - ETA: 0s - loss: 0.8839 - mse: 0.8632\n",
      "Epoch 11: val_loss did not improve from 0.88691\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.8846 - mse: 0.8638 - val_loss: 0.8876 - val_mse: 0.8669\n",
      "Epoch 12/25\n",
      "169/176 [===========================>..] - ETA: 0s - loss: 0.8846 - mse: 0.8639\n",
      "Epoch 12: val_loss did not improve from 0.88691\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.8840 - mse: 0.8633 - val_loss: 0.8906 - val_mse: 0.8699\n",
      "Epoch 13/25\n",
      "167/176 [===========================>..] - ETA: 0s - loss: 0.8843 - mse: 0.8636\n",
      "Epoch 13: val_loss did not improve from 0.88691\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.8839 - mse: 0.8632 - val_loss: 0.8876 - val_mse: 0.8669\n",
      "Epoch 14/25\n",
      "167/176 [===========================>..] - ETA: 0s - loss: 0.8836 - mse: 0.8629\n",
      "Epoch 14: val_loss improved from 0.88691 to 0.88630, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e014_vl0.886.h5\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.8837 - mse: 0.8630 - val_loss: 0.8863 - val_mse: 0.8656\n",
      "Epoch 15/25\n",
      "167/176 [===========================>..] - ETA: 0s - loss: 0.8833 - mse: 0.8626\n",
      "Epoch 15: val_loss did not improve from 0.88630\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8836 - mse: 0.8629 - val_loss: 0.8867 - val_mse: 0.8659\n",
      "Epoch 16/25\n",
      "165/176 [===========================>..] - ETA: 0s - loss: 0.8846 - mse: 0.8639\n",
      "Epoch 16: val_loss did not improve from 0.88630\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8836 - mse: 0.8629 - val_loss: 0.8871 - val_mse: 0.8663\n",
      "Epoch 17/25\n",
      "172/176 [============================>.] - ETA: 0s - loss: 0.8842 - mse: 0.8635\n",
      "Epoch 17: val_loss did not improve from 0.88630\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8833 - mse: 0.8626 - val_loss: 0.8876 - val_mse: 0.8669\n",
      "Epoch 18/25\n",
      "174/176 [============================>.] - ETA: 0s - loss: 0.8834 - mse: 0.8627\n",
      "Epoch 18: val_loss did not improve from 0.88630\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8833 - mse: 0.8627 - val_loss: 0.8895 - val_mse: 0.8688\n",
      "Epoch 19/25\n",
      "169/176 [===========================>..] - ETA: 0s - loss: 0.8827 - mse: 0.8620\n",
      "Epoch 19: val_loss improved from 0.88630 to 0.88568, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e019_vl0.886.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8833 - mse: 0.8626 - val_loss: 0.8857 - val_mse: 0.8650\n",
      "Epoch 20/25\n",
      "168/176 [===========================>..] - ETA: 0s - loss: 0.8839 - mse: 0.8632\n",
      "Epoch 20: val_loss improved from 0.88568 to 0.88544, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e020_vl0.885.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8831 - mse: 0.8624 - val_loss: 0.8854 - val_mse: 0.8648\n",
      "Epoch 21/25\n",
      "175/176 [============================>.] - ETA: 0s - loss: 0.8832 - mse: 0.8625\n",
      "Epoch 21: val_loss improved from 0.88544 to 0.88540, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e021_vl0.885.h5\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8831 - mse: 0.8624 - val_loss: 0.8854 - val_mse: 0.8647\n",
      "Epoch 22/25\n",
      "171/176 [============================>.] - ETA: 0s - loss: 0.8835 - mse: 0.8628\n",
      "Epoch 22: val_loss did not improve from 0.88540\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8830 - mse: 0.8623 - val_loss: 0.8860 - val_mse: 0.8653\n",
      "Epoch 23/25\n",
      "170/176 [===========================>..] - ETA: 0s - loss: 0.8824 - mse: 0.8617\n",
      "Epoch 23: val_loss did not improve from 0.88540\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8829 - mse: 0.8622 - val_loss: 0.8864 - val_mse: 0.8657\n",
      "Epoch 24/25\n",
      "175/176 [============================>.] - ETA: 0s - loss: 0.8828 - mse: 0.8621\n",
      "Epoch 24: val_loss did not improve from 0.88540\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8829 - mse: 0.8622 - val_loss: 0.8882 - val_mse: 0.8676\n",
      "Epoch 25/25\n",
      "172/176 [============================>.] - ETA: 0s - loss: 0.8831 - mse: 0.8624\n",
      "Epoch 25: val_loss did not improve from 0.88540\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.8830 - mse: 0.8623 - val_loss: 0.8883 - val_mse: 0.8676\n",
      "Time elapsed to train: 26.14 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.674 3.414 1.920 3.771 2.702 2.007 1.511 1.226 0.839 0.532 0.367 0.269 0.214]\n",
      "<R> = [2.674 3.414 1.920 3.771 2.701 2.007 1.511 1.226 0.839 0.532 0.367 0.269 0.214]\n",
      "s_R = [0.039 0.006 0.001 0.039 0.079 0.001 0.001 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6672075 2.4921446 6.398422  ... 2.7089593 3.9565957 4.4212213]\n",
      "mag_pred: [3.6672075 2.4921446 6.398422  ... 2.7089593 3.9565957 4.4212213]\n",
      "Time elapsed to make plots: 19.91 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [37.524475 29.411604 18.440533 ...  3.73414  33.53588  27.561674]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00564\n",
      "  1% : 0.104\n",
      "  10% : 0.234\n",
      "  50% : 0.64\n",
      "  90% : 3.17\n",
      "  99% : 65\n",
      "  100% : 7.04e+03\n",
      "<chi^2/d.o.f.> = 1.07\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 5617 stars (2.22%) based on chi^2/dof > 19.9\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [10.054595  56.36236   12.409643  ...  4.229723   5.2216024 14.130838 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0203\n",
      "  1% : 0.103\n",
      "  10% : 0.233\n",
      "  50% : 0.646\n",
      "  90% : 3.09\n",
      "  99% : 70.7\n",
      "  100% : 5.16e+03\n",
      "<chi^2/d.o.f.> = 1.07\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 79.24 s\n",
      "learning rate = 0.00024659695918671787\n",
      "setting learning rate to 0.00020189651799465538\n",
      "Iteration 9 of 20.\n",
      "Epoch 1/25\n",
      "171/175 [============================>.] - ETA: 0s - loss: 0.8423 - mse: 0.8216\n",
      "Epoch 1: val_loss improved from inf to 0.84396, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e001_vl0.844.h5\n",
      "175/175 [==============================] - 2s 7ms/step - loss: 0.8428 - mse: 0.8221 - val_loss: 0.8440 - val_mse: 0.8233\n",
      "Epoch 2/25\n",
      "173/175 [============================>.] - ETA: 0s - loss: 0.8424 - mse: 0.8217\n",
      "Epoch 2: val_loss improved from 0.84396 to 0.84373, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e002_vl0.844.h5\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8427 - mse: 0.8220 - val_loss: 0.8437 - val_mse: 0.8231\n",
      "Epoch 3/25\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.8426 - mse: 0.8220\n",
      "Epoch 3: val_loss improved from 0.84373 to 0.84309, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e003_vl0.843.h5\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8428 - mse: 0.8222 - val_loss: 0.8431 - val_mse: 0.8224\n",
      "Epoch 4/25\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.8425 - mse: 0.8218\n",
      "Epoch 4: val_loss improved from 0.84309 to 0.84203, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e004_vl0.842.h5\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8425 - mse: 0.8218 - val_loss: 0.8420 - val_mse: 0.8214\n",
      "Epoch 5/25\n",
      "171/175 [============================>.] - ETA: 0s - loss: 0.8428 - mse: 0.8222\n",
      "Epoch 5: val_loss did not improve from 0.84203\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8424 - mse: 0.8218 - val_loss: 0.8430 - val_mse: 0.8224\n",
      "Epoch 6/25\n",
      "168/175 [===========================>..] - ETA: 0s - loss: 0.8428 - mse: 0.8222\n",
      "Epoch 6: val_loss did not improve from 0.84203\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8426 - mse: 0.8220 - val_loss: 0.8421 - val_mse: 0.8215\n",
      "Epoch 7/25\n",
      "174/175 [============================>.] - ETA: 0s - loss: 0.8426 - mse: 0.8219\n",
      "Epoch 7: val_loss did not improve from 0.84203\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8424 - mse: 0.8217 - val_loss: 0.8432 - val_mse: 0.8225\n",
      "Epoch 8/25\n",
      "172/175 [============================>.] - ETA: 0s - loss: 0.8428 - mse: 0.8222\n",
      "Epoch 8: val_loss did not improve from 0.84203\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8423 - mse: 0.8217 - val_loss: 0.8424 - val_mse: 0.8217\n",
      "Epoch 9/25\n",
      "169/175 [===========================>..] - ETA: 0s - loss: 0.8423 - mse: 0.8216\n",
      "Epoch 9: val_loss improved from 0.84203 to 0.84125, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e009_vl0.841.h5\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.8424 - mse: 0.8218 - val_loss: 0.8412 - val_mse: 0.8206\n",
      "Epoch 10/25\n",
      "165/175 [===========================>..] - ETA: 0s - loss: 0.8429 - mse: 0.8223\n",
      "Epoch 10: val_loss did not improve from 0.84125\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8421 - mse: 0.8215 - val_loss: 0.8424 - val_mse: 0.8217\n",
      "Epoch 11/25\n",
      "173/175 [============================>.] - ETA: 0s - loss: 0.8420 - mse: 0.8214\n",
      "Epoch 11: val_loss did not improve from 0.84125\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8421 - mse: 0.8214 - val_loss: 0.8420 - val_mse: 0.8214\n",
      "Epoch 12/25\n",
      "165/175 [===========================>..] - ETA: 0s - loss: 0.8414 - mse: 0.8208\n",
      "Epoch 12: val_loss did not improve from 0.84125\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8419 - mse: 0.8213 - val_loss: 0.8413 - val_mse: 0.8206\n",
      "Epoch 13/25\n",
      "172/175 [============================>.] - ETA: 0s - loss: 0.8422 - mse: 0.8216\n",
      "Epoch 13: val_loss did not improve from 0.84125\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8421 - mse: 0.8215 - val_loss: 0.8424 - val_mse: 0.8218\n",
      "Epoch 14/25\n",
      "167/175 [===========================>..] - ETA: 0s - loss: 0.8426 - mse: 0.8220\n",
      "Epoch 14: val_loss did not improve from 0.84125\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8423 - mse: 0.8216 - val_loss: 0.8421 - val_mse: 0.8215\n",
      "Epoch 15/25\n",
      "172/175 [============================>.] - ETA: 0s - loss: 0.8415 - mse: 0.8209\n",
      "Epoch 15: val_loss did not improve from 0.84125\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8417 - mse: 0.8211 - val_loss: 0.8416 - val_mse: 0.8210\n",
      "Epoch 16/25\n",
      "169/175 [===========================>..] - ETA: 0s - loss: 0.8424 - mse: 0.8218\n",
      "Epoch 16: val_loss did not improve from 0.84125\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8417 - mse: 0.8211 - val_loss: 0.8423 - val_mse: 0.8217\n",
      "Epoch 17/25\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.8416 - mse: 0.8210\n",
      "Epoch 17: val_loss did not improve from 0.84125\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8416 - mse: 0.8210 - val_loss: 0.8414 - val_mse: 0.8208\n",
      "Epoch 18/25\n",
      "166/175 [===========================>..] - ETA: 0s - loss: 0.8417 - mse: 0.8211\n",
      "Epoch 18: val_loss improved from 0.84125 to 0.84121, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e018_vl0.841.h5\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8417 - mse: 0.8211 - val_loss: 0.8412 - val_mse: 0.8206\n",
      "Epoch 19/25\n",
      "173/175 [============================>.] - ETA: 0s - loss: 0.8417 - mse: 0.8211\n",
      "Epoch 19: val_loss improved from 0.84121 to 0.84107, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e019_vl0.841.h5\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8418 - mse: 0.8211 - val_loss: 0.8411 - val_mse: 0.8205\n",
      "Epoch 20/25\n",
      "173/175 [============================>.] - ETA: 0s - loss: 0.8418 - mse: 0.8211\n",
      "Epoch 20: val_loss did not improve from 0.84107\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8417 - mse: 0.8210 - val_loss: 0.8416 - val_mse: 0.8210\n",
      "Epoch 21/25\n",
      "167/175 [===========================>..] - ETA: 0s - loss: 0.8411 - mse: 0.8205\n",
      "Epoch 21: val_loss did not improve from 0.84107\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8413 - mse: 0.8207 - val_loss: 0.8428 - val_mse: 0.8222\n",
      "Epoch 22/25\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.8413 - mse: 0.8207\n",
      "Epoch 22: val_loss did not improve from 0.84107\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.8413 - mse: 0.8207 - val_loss: 0.8421 - val_mse: 0.8215\n",
      "Epoch 23/25\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.8413 - mse: 0.8206\n",
      "Epoch 23: val_loss did not improve from 0.84107\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8413 - mse: 0.8206 - val_loss: 0.8411 - val_mse: 0.8205\n",
      "Epoch 24/25\n",
      "171/175 [============================>.] - ETA: 0s - loss: 0.8414 - mse: 0.8208\n",
      "Epoch 24: val_loss improved from 0.84107 to 0.84059, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e024_vl0.841.h5\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8412 - mse: 0.8206 - val_loss: 0.8406 - val_mse: 0.8200\n",
      "Epoch 25/25\n",
      "173/175 [============================>.] - ETA: 0s - loss: 0.8416 - mse: 0.8210\n",
      "Epoch 25: val_loss did not improve from 0.84059\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.8412 - mse: 0.8206 - val_loss: 0.8416 - val_mse: 0.8210\n",
      "Time elapsed to train: 28.09 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.655 3.388 1.905 3.743 2.680 1.993 1.498 1.213 0.828 0.521 0.359 0.261 0.209]\n",
      "<R> = [2.655 3.388 1.905 3.742 2.680 1.993 1.498 1.213 0.828 0.521 0.359 0.261 0.209]\n",
      "s_R = [0.041 0.004 0.001 0.039 0.072 0.001 0.001 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6846461 2.4917974 6.4383817 ... 2.7539794 3.979947  4.4450235]\n",
      "mag_pred: [3.6846461 2.4917974 6.4383817 ... 2.7539794 3.979947  4.4450235]\n",
      "Time elapsed to make plots: 17.79 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [37.962303  29.47908   15.166294  ...  3.1815724 35.157894  22.953564 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00419\n",
      "  1% : 0.0993\n",
      "  10% : 0.224\n",
      "  50% : 0.614\n",
      "  90% : 3.16\n",
      "  99% : 65.2\n",
      "  100% : 7.05e+03\n",
      "<chi^2/d.o.f.> = 1.04\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 6697 stars (2.65%) based on chi^2/dof > 15.8\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.479486  57.67402   14.8909645 ...  4.205159   5.38748   13.981205 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0224\n",
      "  1% : 0.0986\n",
      "  10% : 0.223\n",
      "  50% : 0.619\n",
      "  90% : 3.04\n",
      "  99% : 70.6\n",
      "  100% : 5.17e+03\n",
      "<chi^2/d.o.f.> = 1.04\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 83.35 s\n",
      "learning rate = 0.00020189651695545763\n",
      "setting learning rate to 0.00016529888822158653\n",
      "Iteration 10 of 20.\n",
      "Epoch 1/25\n",
      "173/174 [============================>.] - ETA: 0s - loss: 0.7919 - mse: 0.7714\n",
      "Epoch 1: val_loss improved from inf to 0.79512, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e001_vl0.795.h5\n",
      "174/174 [==============================] - 1s 7ms/step - loss: 0.7921 - mse: 0.7715 - val_loss: 0.7951 - val_mse: 0.7746\n",
      "Epoch 2/25\n",
      "172/174 [============================>.] - ETA: 0s - loss: 0.7917 - mse: 0.7712\n",
      "Epoch 2: val_loss did not improve from 0.79512\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7922 - mse: 0.7716 - val_loss: 0.7958 - val_mse: 0.7753\n",
      "Epoch 3/25\n",
      "165/174 [===========================>..] - ETA: 0s - loss: 0.7916 - mse: 0.7711\n",
      "Epoch 3: val_loss did not improve from 0.79512\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7921 - mse: 0.7716 - val_loss: 0.7960 - val_mse: 0.7756\n",
      "Epoch 4/25\n",
      "167/174 [===========================>..] - ETA: 0s - loss: 0.7909 - mse: 0.7704\n",
      "Epoch 4: val_loss improved from 0.79512 to 0.79461, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e004_vl0.795.h5\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7919 - mse: 0.7714 - val_loss: 0.7946 - val_mse: 0.7741\n",
      "Epoch 5/25\n",
      "164/174 [===========================>..] - ETA: 0s - loss: 0.7915 - mse: 0.7711\n",
      "Epoch 5: val_loss did not improve from 0.79461\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7919 - mse: 0.7714 - val_loss: 0.7947 - val_mse: 0.7742\n",
      "Epoch 6/25\n",
      "170/174 [============================>.] - ETA: 0s - loss: 0.7919 - mse: 0.7714\n",
      "Epoch 6: val_loss did not improve from 0.79461\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7919 - mse: 0.7714 - val_loss: 0.7947 - val_mse: 0.7742\n",
      "Epoch 7/25\n",
      "171/174 [============================>.] - ETA: 0s - loss: 0.7922 - mse: 0.7717\n",
      "Epoch 7: val_loss did not improve from 0.79461\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7918 - mse: 0.7713 - val_loss: 0.7949 - val_mse: 0.7744\n",
      "Epoch 8/25\n",
      "171/174 [============================>.] - ETA: 0s - loss: 0.7920 - mse: 0.7715\n",
      "Epoch 8: val_loss did not improve from 0.79461\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7918 - mse: 0.7713 - val_loss: 0.7950 - val_mse: 0.7746\n",
      "Epoch 9/25\n",
      "171/174 [============================>.] - ETA: 0s - loss: 0.7919 - mse: 0.7715\n",
      "Epoch 9: val_loss did not improve from 0.79461\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7916 - mse: 0.7712 - val_loss: 0.7952 - val_mse: 0.7747\n",
      "Epoch 10/25\n",
      "172/174 [============================>.] - ETA: 0s - loss: 0.7918 - mse: 0.7713\n",
      "Epoch 10: val_loss did not improve from 0.79461\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7915 - mse: 0.7711 - val_loss: 0.7947 - val_mse: 0.7743\n",
      "Epoch 11/25\n",
      "167/174 [===========================>..] - ETA: 0s - loss: 0.7921 - mse: 0.7717\n",
      "Epoch 11: val_loss improved from 0.79461 to 0.79440, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e011_vl0.794.h5\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7917 - mse: 0.7713 - val_loss: 0.7944 - val_mse: 0.7740\n",
      "Epoch 12/25\n",
      "167/174 [===========================>..] - ETA: 0s - loss: 0.7913 - mse: 0.7708\n",
      "Epoch 12: val_loss improved from 0.79440 to 0.79411, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e012_vl0.794.h5\n",
      "174/174 [==============================] - 1s 9ms/step - loss: 0.7916 - mse: 0.7712 - val_loss: 0.7941 - val_mse: 0.7737\n",
      "Epoch 13/25\n",
      "174/174 [==============================] - ETA: 0s - loss: 0.7914 - mse: 0.7710\n",
      "Epoch 13: val_loss did not improve from 0.79411\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7914 - mse: 0.7710 - val_loss: 0.7944 - val_mse: 0.7739\n",
      "Epoch 14/25\n",
      "171/174 [============================>.] - ETA: 0s - loss: 0.7915 - mse: 0.7710\n",
      "Epoch 14: val_loss improved from 0.79411 to 0.79400, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e014_vl0.794.h5\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7913 - mse: 0.7708 - val_loss: 0.7940 - val_mse: 0.7736\n",
      "Epoch 15/25\n",
      "168/174 [===========================>..] - ETA: 0s - loss: 0.7905 - mse: 0.7701\n",
      "Epoch 15: val_loss did not improve from 0.79400\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7913 - mse: 0.7709 - val_loss: 0.7951 - val_mse: 0.7747\n",
      "Epoch 16/25\n",
      "171/174 [============================>.] - ETA: 0s - loss: 0.7909 - mse: 0.7705\n",
      "Epoch 16: val_loss improved from 0.79400 to 0.79397, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e016_vl0.794.h5\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7913 - mse: 0.7709 - val_loss: 0.7940 - val_mse: 0.7736\n",
      "Epoch 17/25\n",
      "170/174 [============================>.] - ETA: 0s - loss: 0.7906 - mse: 0.7702\n",
      "Epoch 17: val_loss did not improve from 0.79397\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7913 - mse: 0.7709 - val_loss: 0.7943 - val_mse: 0.7739\n",
      "Epoch 18/25\n",
      "172/174 [============================>.] - ETA: 0s - loss: 0.7912 - mse: 0.7709\n",
      "Epoch 18: val_loss did not improve from 0.79397\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7911 - mse: 0.7707 - val_loss: 0.7947 - val_mse: 0.7743\n",
      "Epoch 19/25\n",
      "166/174 [===========================>..] - ETA: 0s - loss: 0.7917 - mse: 0.7713\n",
      "Epoch 19: val_loss did not improve from 0.79397\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7911 - mse: 0.7707 - val_loss: 0.7941 - val_mse: 0.7737\n",
      "Epoch 20/25\n",
      "169/174 [============================>.] - ETA: 0s - loss: 0.7910 - mse: 0.7706\n",
      "Epoch 20: val_loss improved from 0.79397 to 0.79367, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e020_vl0.794.h5\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7910 - mse: 0.7707 - val_loss: 0.7937 - val_mse: 0.7733\n",
      "Epoch 21/25\n",
      "166/174 [===========================>..] - ETA: 0s - loss: 0.7911 - mse: 0.7707\n",
      "Epoch 21: val_loss did not improve from 0.79367\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7909 - mse: 0.7706 - val_loss: 0.7939 - val_mse: 0.7735\n",
      "Epoch 22/25\n",
      "172/174 [============================>.] - ETA: 0s - loss: 0.7908 - mse: 0.7705\n",
      "Epoch 22: val_loss did not improve from 0.79367\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7909 - mse: 0.7705 - val_loss: 0.7942 - val_mse: 0.7738\n",
      "Epoch 23/25\n",
      "170/174 [============================>.] - ETA: 0s - loss: 0.7903 - mse: 0.7700\n",
      "Epoch 23: val_loss did not improve from 0.79367\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.7908 - mse: 0.7705 - val_loss: 0.7943 - val_mse: 0.7740\n",
      "Epoch 24/25\n",
      "169/174 [============================>.] - ETA: 0s - loss: 0.7908 - mse: 0.7705\n",
      "Epoch 24: val_loss did not improve from 0.79367\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7911 - mse: 0.7707 - val_loss: 0.7937 - val_mse: 0.7734\n",
      "Epoch 25/25\n",
      "169/174 [============================>.] - ETA: 0s - loss: 0.7909 - mse: 0.7705\n",
      "Epoch 25: val_loss did not improve from 0.79367\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.7910 - mse: 0.7707 - val_loss: 0.7938 - val_mse: 0.7734\n",
      "Time elapsed to train: 27.52 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.634 3.363 1.890 3.715 2.661 1.977 1.486 1.201 0.820 0.513 0.352 0.255 0.205]\n",
      "<R> = [2.634 3.363 1.890 3.715 2.660 1.977 1.486 1.201 0.820 0.513 0.352 0.255 0.205]\n",
      "s_R = [0.040 0.003 0.001 0.034 0.065 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.681912  2.4915311 6.44247   ... 2.778284  3.9777358 4.4418683]\n",
      "mag_pred: [3.681912  2.4915311 6.44247   ... 2.778284  3.9777358 4.4418683]\n",
      "Time elapsed to make plots: 21.01 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [38.188713  30.054775  16.153416  ...  3.3031807 34.973972  23.40704  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.011\n",
      "  1% : 0.0977\n",
      "  10% : 0.223\n",
      "  50% : 0.615\n",
      "  90% : 3.15\n",
      "  99% : 65.2\n",
      "  100% : 7.04e+03\n",
      "<chi^2/d.o.f.> = 1.04\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 7977 stars (3.15%) based on chi^2/dof > 12.6\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.646573  59.795242  14.375669  ...  3.8787065  5.580944  13.228693 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0226\n",
      "  1% : 0.0964\n",
      "  10% : 0.223\n",
      "  50% : 0.622\n",
      "  90% : 3.05\n",
      "  99% : 70.7\n",
      "  100% : 5.17e+03\n",
      "<chi^2/d.o.f.> = 1.04\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 80.90 s\n",
      "learning rate = 0.00016529888671357185\n",
      "setting learning rate to 0.0001353352832366127\n",
      "Iteration 11 of 20.\n",
      "Epoch 1/25\n",
      "172/173 [============================>.] - ETA: 0s - loss: 0.7509 - mse: 0.7306\n",
      "Epoch 1: val_loss improved from inf to 0.74877, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e001_vl0.749.h5\n",
      "173/173 [==============================] - 2s 7ms/step - loss: 0.7507 - mse: 0.7304 - val_loss: 0.7488 - val_mse: 0.7285\n",
      "Epoch 2/25\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.7507 - mse: 0.7304\n",
      "Epoch 2: val_loss improved from 0.74877 to 0.74853, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e002_vl0.749.h5\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7507 - mse: 0.7304 - val_loss: 0.7485 - val_mse: 0.7282\n",
      "Epoch 3/25\n",
      "172/173 [============================>.] - ETA: 0s - loss: 0.7507 - mse: 0.7304\n",
      "Epoch 3: val_loss improved from 0.74853 to 0.74831, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e003_vl0.748.h5\n",
      "173/173 [==============================] - 1s 7ms/step - loss: 0.7507 - mse: 0.7304 - val_loss: 0.7483 - val_mse: 0.7280\n",
      "Epoch 4/25\n",
      "164/173 [===========================>..] - ETA: 0s - loss: 0.7513 - mse: 0.7311\n",
      "Epoch 4: val_loss did not improve from 0.74831\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7507 - mse: 0.7304 - val_loss: 0.7488 - val_mse: 0.7285\n",
      "Epoch 5/25\n",
      "171/173 [============================>.] - ETA: 0s - loss: 0.7510 - mse: 0.7307\n",
      "Epoch 5: val_loss did not improve from 0.74831\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7505 - mse: 0.7302 - val_loss: 0.7487 - val_mse: 0.7284\n",
      "Epoch 6/25\n",
      "163/173 [===========================>..] - ETA: 0s - loss: 0.7505 - mse: 0.7302\n",
      "Epoch 6: val_loss improved from 0.74831 to 0.74813, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e006_vl0.748.h5\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7505 - mse: 0.7302 - val_loss: 0.7481 - val_mse: 0.7278\n",
      "Epoch 7/25\n",
      "166/173 [===========================>..] - ETA: 0s - loss: 0.7500 - mse: 0.7298\n",
      "Epoch 7: val_loss did not improve from 0.74813\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7505 - mse: 0.7303 - val_loss: 0.7481 - val_mse: 0.7279\n",
      "Epoch 8/25\n",
      "170/173 [============================>.] - ETA: 0s - loss: 0.7506 - mse: 0.7304\n",
      "Epoch 8: val_loss did not improve from 0.74813\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7506 - mse: 0.7303 - val_loss: 0.7483 - val_mse: 0.7281\n",
      "Epoch 9/25\n",
      "162/173 [===========================>..] - ETA: 0s - loss: 0.7492 - mse: 0.7289\n",
      "Epoch 9: val_loss did not improve from 0.74813\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7504 - mse: 0.7302 - val_loss: 0.7482 - val_mse: 0.7280\n",
      "Epoch 10/25\n",
      "168/173 [============================>.] - ETA: 0s - loss: 0.7502 - mse: 0.7299\n",
      "Epoch 10: val_loss did not improve from 0.74813\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7506 - mse: 0.7303 - val_loss: 0.7483 - val_mse: 0.7280\n",
      "Epoch 11/25\n",
      "165/173 [===========================>..] - ETA: 0s - loss: 0.7495 - mse: 0.7292\n",
      "Epoch 11: val_loss improved from 0.74813 to 0.74813, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e011_vl0.748.h5\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7504 - mse: 0.7301 - val_loss: 0.7481 - val_mse: 0.7279\n",
      "Epoch 12/25\n",
      "166/173 [===========================>..] - ETA: 0s - loss: 0.7502 - mse: 0.7300\n",
      "Epoch 12: val_loss did not improve from 0.74813\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7503 - mse: 0.7300 - val_loss: 0.7486 - val_mse: 0.7284\n",
      "Epoch 13/25\n",
      "163/173 [===========================>..] - ETA: 0s - loss: 0.7508 - mse: 0.7306\n",
      "Epoch 13: val_loss improved from 0.74813 to 0.74789, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e013_vl0.748.h5\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7503 - mse: 0.7301 - val_loss: 0.7479 - val_mse: 0.7276\n",
      "Epoch 14/25\n",
      "169/173 [============================>.] - ETA: 0s - loss: 0.7500 - mse: 0.7298\n",
      "Epoch 14: val_loss did not improve from 0.74789\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7502 - mse: 0.7300 - val_loss: 0.7480 - val_mse: 0.7278\n",
      "Epoch 15/25\n",
      "171/173 [============================>.] - ETA: 0s - loss: 0.7500 - mse: 0.7297\n",
      "Epoch 15: val_loss did not improve from 0.74789\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7502 - mse: 0.7300 - val_loss: 0.7482 - val_mse: 0.7280\n",
      "Epoch 16/25\n",
      "168/173 [============================>.] - ETA: 0s - loss: 0.7497 - mse: 0.7295\n",
      "Epoch 16: val_loss did not improve from 0.74789\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7502 - mse: 0.7300 - val_loss: 0.7480 - val_mse: 0.7277\n",
      "Epoch 17/25\n",
      "172/173 [============================>.] - ETA: 0s - loss: 0.7500 - mse: 0.7298\n",
      "Epoch 17: val_loss did not improve from 0.74789\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7500 - mse: 0.7298 - val_loss: 0.7485 - val_mse: 0.7282\n",
      "Epoch 18/25\n",
      "168/173 [============================>.] - ETA: 0s - loss: 0.7500 - mse: 0.7298\n",
      "Epoch 18: val_loss did not improve from 0.74789\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7502 - mse: 0.7300 - val_loss: 0.7479 - val_mse: 0.7277\n",
      "Epoch 19/25\n",
      "163/173 [===========================>..] - ETA: 0s - loss: 0.7507 - mse: 0.7304\n",
      "Epoch 19: val_loss did not improve from 0.74789\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7501 - mse: 0.7299 - val_loss: 0.7483 - val_mse: 0.7281\n",
      "Epoch 20/25\n",
      "162/173 [===========================>..] - ETA: 0s - loss: 0.7496 - mse: 0.7294\n",
      "Epoch 20: val_loss did not improve from 0.74789\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7500 - mse: 0.7298 - val_loss: 0.7481 - val_mse: 0.7278\n",
      "Epoch 21/25\n",
      "168/173 [============================>.] - ETA: 0s - loss: 0.7509 - mse: 0.7307\n",
      "Epoch 21: val_loss did not improve from 0.74789\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7503 - mse: 0.7301 - val_loss: 0.7479 - val_mse: 0.7277\n",
      "Epoch 22/25\n",
      "165/173 [===========================>..] - ETA: 0s - loss: 0.7495 - mse: 0.7293\n",
      "Epoch 22: val_loss improved from 0.74789 to 0.74788, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e022_vl0.748.h5\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7500 - mse: 0.7298 - val_loss: 0.7479 - val_mse: 0.7277\n",
      "Epoch 23/25\n",
      "165/173 [===========================>..] - ETA: 0s - loss: 0.7498 - mse: 0.7297\n",
      "Epoch 23: val_loss improved from 0.74788 to 0.74773, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e023_vl0.748.h5\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7500 - mse: 0.7298 - val_loss: 0.7477 - val_mse: 0.7275\n",
      "Epoch 24/25\n",
      "171/173 [============================>.] - ETA: 0s - loss: 0.7501 - mse: 0.7299\n",
      "Epoch 24: val_loss improved from 0.74773 to 0.74765, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e024_vl0.748.h5\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7501 - mse: 0.7299 - val_loss: 0.7476 - val_mse: 0.7275\n",
      "Epoch 25/25\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.7499 - mse: 0.7297\n",
      "Epoch 25: val_loss did not improve from 0.74765\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.7499 - mse: 0.7297 - val_loss: 0.7480 - val_mse: 0.7278\n",
      "Time elapsed to train: 27.06 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.618 3.339 1.877 3.691 2.640 1.964 1.475 1.191 0.813 0.507 0.348 0.250 0.201]\n",
      "<R> = [2.618 3.339 1.877 3.691 2.640 1.964 1.475 1.191 0.813 0.507 0.348 0.250 0.201]\n",
      "s_R = [0.039 0.003 0.001 0.033 0.058 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6823473 2.4677463 6.4573913 ... 2.7925415 3.9822578 4.4449706]\n",
      "mag_pred: [3.6823473 2.4677463 6.4573913 ... 2.7925415 3.9822578 4.4449706]\n",
      "Time elapsed to make plots: 17.78 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [38.637283  29.563396  15.706118  ...  3.0950265 34.942566  21.84702  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00953\n",
      "  1% : 0.097\n",
      "  10% : 0.221\n",
      "  50% : 0.61\n",
      "  90% : 3.12\n",
      "  99% : 65.5\n",
      "  100% : 7.03e+03\n",
      "<chi^2/d.o.f.> = 1.04\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 9534 stars (3.77%) based on chi^2/dof > 10.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.649609  62.065193  14.439014  ...  3.7146878  5.4431515 13.342821 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0178\n",
      "  1% : 0.0971\n",
      "  10% : 0.221\n",
      "  50% : 0.614\n",
      "  90% : 3.02\n",
      "  99% : 71\n",
      "  100% : 5.17e+03\n",
      "<chi^2/d.o.f.> = 1.03\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 78.50 s\n",
      "learning rate = 0.00013533528544940054\n",
      "setting learning rate to 0.00011080315836233387\n",
      "Iteration 12 of 20.\n",
      "Epoch 1/25\n",
      "172/172 [==============================] - ETA: 0s - loss: 0.7064 - mse: 0.6863\n",
      "Epoch 1: val_loss improved from inf to 0.70478, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e001_vl0.705.h5\n",
      "172/172 [==============================] - 1s 7ms/step - loss: 0.7064 - mse: 0.6863 - val_loss: 0.7048 - val_mse: 0.6846\n",
      "Epoch 2/25\n",
      "163/172 [===========================>..] - ETA: 0s - loss: 0.7062 - mse: 0.6861\n",
      "Epoch 2: val_loss did not improve from 0.70478\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7064 - mse: 0.6863 - val_loss: 0.7049 - val_mse: 0.6848\n",
      "Epoch 3/25\n",
      "169/172 [============================>.] - ETA: 0s - loss: 0.7061 - mse: 0.6860\n",
      "Epoch 3: val_loss did not improve from 0.70478\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7062 - mse: 0.6861 - val_loss: 0.7049 - val_mse: 0.6848\n",
      "Epoch 4/25\n",
      "168/172 [============================>.] - ETA: 0s - loss: 0.7070 - mse: 0.6869\n",
      "Epoch 4: val_loss improved from 0.70478 to 0.70464, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e004_vl0.705.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7064 - mse: 0.6863 - val_loss: 0.7046 - val_mse: 0.6845\n",
      "Epoch 5/25\n",
      "167/172 [============================>.] - ETA: 0s - loss: 0.7063 - mse: 0.6862\n",
      "Epoch 5: val_loss did not improve from 0.70464\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7061 - mse: 0.6860 - val_loss: 0.7048 - val_mse: 0.6847\n",
      "Epoch 6/25\n",
      "171/172 [============================>.] - ETA: 0s - loss: 0.7061 - mse: 0.6861\n",
      "Epoch 6: val_loss improved from 0.70464 to 0.70449, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e006_vl0.704.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7062 - mse: 0.6861 - val_loss: 0.7045 - val_mse: 0.6844\n",
      "Epoch 7/25\n",
      "167/172 [============================>.] - ETA: 0s - loss: 0.7060 - mse: 0.6859\n",
      "Epoch 7: val_loss did not improve from 0.70449\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7061 - mse: 0.6860 - val_loss: 0.7055 - val_mse: 0.6854\n",
      "Epoch 8/25\n",
      "161/172 [===========================>..] - ETA: 0s - loss: 0.7061 - mse: 0.6860\n",
      "Epoch 8: val_loss did not improve from 0.70449\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7061 - mse: 0.6860 - val_loss: 0.7050 - val_mse: 0.6849\n",
      "Epoch 9/25\n",
      "168/172 [============================>.] - ETA: 0s - loss: 0.7061 - mse: 0.6861\n",
      "Epoch 9: val_loss did not improve from 0.70449\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7061 - mse: 0.6860 - val_loss: 0.7052 - val_mse: 0.6852\n",
      "Epoch 10/25\n",
      "166/172 [===========================>..] - ETA: 0s - loss: 0.7061 - mse: 0.6861\n",
      "Epoch 10: val_loss did not improve from 0.70449\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7061 - mse: 0.6860 - val_loss: 0.7046 - val_mse: 0.6846\n",
      "Epoch 11/25\n",
      "169/172 [============================>.] - ETA: 0s - loss: 0.7060 - mse: 0.6859\n",
      "Epoch 11: val_loss did not improve from 0.70449\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7060 - mse: 0.6860 - val_loss: 0.7050 - val_mse: 0.6849\n",
      "Epoch 12/25\n",
      "170/172 [============================>.] - ETA: 0s - loss: 0.7057 - mse: 0.6857\n",
      "Epoch 12: val_loss improved from 0.70449 to 0.70430, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e012_vl0.704.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7059 - mse: 0.6859 - val_loss: 0.7043 - val_mse: 0.6843\n",
      "Epoch 13/25\n",
      "164/172 [===========================>..] - ETA: 0s - loss: 0.7055 - mse: 0.6855\n",
      "Epoch 13: val_loss did not improve from 0.70430\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7058 - mse: 0.6858 - val_loss: 0.7046 - val_mse: 0.6845\n",
      "Epoch 14/25\n",
      "172/172 [==============================] - ETA: 0s - loss: 0.7059 - mse: 0.6859\n",
      "Epoch 14: val_loss improved from 0.70430 to 0.70418, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e014_vl0.704.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7059 - mse: 0.6859 - val_loss: 0.7042 - val_mse: 0.6841\n",
      "Epoch 15/25\n",
      "164/172 [===========================>..] - ETA: 0s - loss: 0.7061 - mse: 0.6861\n",
      "Epoch 15: val_loss did not improve from 0.70418\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7058 - mse: 0.6858 - val_loss: 0.7044 - val_mse: 0.6844\n",
      "Epoch 16/25\n",
      "170/172 [============================>.] - ETA: 0s - loss: 0.7059 - mse: 0.6859\n",
      "Epoch 16: val_loss did not improve from 0.70418\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7058 - mse: 0.6858 - val_loss: 0.7046 - val_mse: 0.6846\n",
      "Epoch 17/25\n",
      "166/172 [===========================>..] - ETA: 0s - loss: 0.7055 - mse: 0.6855\n",
      "Epoch 17: val_loss did not improve from 0.70418\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7059 - mse: 0.6859 - val_loss: 0.7049 - val_mse: 0.6849\n",
      "Epoch 18/25\n",
      "167/172 [============================>.] - ETA: 0s - loss: 0.7058 - mse: 0.6858\n",
      "Epoch 18: val_loss did not improve from 0.70418\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7060 - mse: 0.6860 - val_loss: 0.7048 - val_mse: 0.6848\n",
      "Epoch 19/25\n",
      "166/172 [===========================>..] - ETA: 0s - loss: 0.7058 - mse: 0.6859\n",
      "Epoch 19: val_loss improved from 0.70418 to 0.70406, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e019_vl0.704.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7058 - mse: 0.6858 - val_loss: 0.7041 - val_mse: 0.6841\n",
      "Epoch 20/25\n",
      "167/172 [============================>.] - ETA: 0s - loss: 0.7057 - mse: 0.6857\n",
      "Epoch 20: val_loss did not improve from 0.70406\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7057 - mse: 0.6857 - val_loss: 0.7043 - val_mse: 0.6843\n",
      "Epoch 21/25\n",
      "165/172 [===========================>..] - ETA: 0s - loss: 0.7056 - mse: 0.6856\n",
      "Epoch 21: val_loss improved from 0.70406 to 0.70403, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e021_vl0.704.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7057 - mse: 0.6857 - val_loss: 0.7040 - val_mse: 0.6841\n",
      "Epoch 22/25\n",
      "165/172 [===========================>..] - ETA: 0s - loss: 0.7071 - mse: 0.6871\n",
      "Epoch 22: val_loss did not improve from 0.70403\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 0.7058 - mse: 0.6858 - val_loss: 0.7042 - val_mse: 0.6842\n",
      "Epoch 23/25\n",
      "168/172 [============================>.] - ETA: 0s - loss: 0.7055 - mse: 0.6856\n",
      "Epoch 23: val_loss did not improve from 0.70403\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7056 - mse: 0.6856 - val_loss: 0.7047 - val_mse: 0.6847\n",
      "Epoch 24/25\n",
      "168/172 [============================>.] - ETA: 0s - loss: 0.7053 - mse: 0.6853\n",
      "Epoch 24: val_loss improved from 0.70403 to 0.70385, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e024_vl0.704.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7055 - mse: 0.6856 - val_loss: 0.7038 - val_mse: 0.6839\n",
      "Epoch 25/25\n",
      "172/172 [==============================] - ETA: 0s - loss: 0.7056 - mse: 0.6856\n",
      "Epoch 25: val_loss did not improve from 0.70385\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 0.7056 - mse: 0.6856 - val_loss: 0.7041 - val_mse: 0.6841\n",
      "Time elapsed to train: 25.79 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.601 3.316 1.865 3.665 2.622 1.951 1.465 1.182 0.807 0.502 0.345 0.247 0.200]\n",
      "<R> = [2.601 3.316 1.865 3.665 2.622 1.951 1.465 1.182 0.807 0.502 0.345 0.247 0.200]\n",
      "s_R = [0.042 0.002 0.000 0.031 0.052 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6807752 2.4590297 6.463845  ... 2.8082547 3.9833314 4.4437485]\n",
      "mag_pred: [3.6807752 2.4590297 6.463845  ... 2.8082547 3.9833314 4.4437485]\n",
      "Time elapsed to make plots: 20.39 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [38.289703 29.840496 14.956943 ...  3.118012 34.943665 20.559511]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00846\n",
      "  1% : 0.0961\n",
      "  10% : 0.219\n",
      "  50% : 0.603\n",
      "  90% : 3.09\n",
      "  99% : 65.6\n",
      "  100% : 7.02e+03\n",
      "<chi^2/d.o.f.> = 1.03\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 11416 stars (4.51%) based on chi^2/dof > 7.9\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.538206  63.85846   14.245817  ...  3.573185   5.4765606 12.984028 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0171\n",
      "  1% : 0.0953\n",
      "  10% : 0.219\n",
      "  50% : 0.609\n",
      "  90% : 2.96\n",
      "  99% : 71.2\n",
      "  100% : 5.17e+03\n",
      "<chi^2/d.o.f.> = 1.02\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 79.79 s\n",
      "learning rate = 0.00011080315744038671\n",
      "setting learning rate to 9.071795328941248e-05\n",
      "Iteration 13 of 20.\n",
      "Epoch 1/25\n",
      "161/171 [===========================>..] - ETA: 0s - loss: 0.6666 - mse: 0.6467\n",
      "Epoch 1: val_loss improved from inf to 0.66507, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e001_vl0.665.h5\n",
      "171/171 [==============================] - 1s 7ms/step - loss: 0.6661 - mse: 0.6462 - val_loss: 0.6651 - val_mse: 0.6452\n",
      "Epoch 2/25\n",
      "164/171 [===========================>..] - ETA: 0s - loss: 0.6658 - mse: 0.6459\n",
      "Epoch 2: val_loss improved from 0.66507 to 0.66407, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e002_vl0.664.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6661 - mse: 0.6462 - val_loss: 0.6641 - val_mse: 0.6442\n",
      "Epoch 3/25\n",
      "161/171 [===========================>..] - ETA: 0s - loss: 0.6663 - mse: 0.6464\n",
      "Epoch 3: val_loss did not improve from 0.66407\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6660 - mse: 0.6461 - val_loss: 0.6641 - val_mse: 0.6442\n",
      "Epoch 4/25\n",
      "168/171 [============================>.] - ETA: 0s - loss: 0.6658 - mse: 0.6459\n",
      "Epoch 4: val_loss did not improve from 0.66407\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6660 - mse: 0.6461 - val_loss: 0.6644 - val_mse: 0.6445\n",
      "Epoch 5/25\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 0.6656 - mse: 0.6457\n",
      "Epoch 5: val_loss improved from 0.66407 to 0.66407, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e005_vl0.664.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6660 - mse: 0.6461 - val_loss: 0.6641 - val_mse: 0.6442\n",
      "Epoch 6/25\n",
      "164/171 [===========================>..] - ETA: 0s - loss: 0.6661 - mse: 0.6463\n",
      "Epoch 6: val_loss did not improve from 0.66407\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6660 - mse: 0.6461 - val_loss: 0.6642 - val_mse: 0.6443\n",
      "Epoch 7/25\n",
      "166/171 [============================>.] - ETA: 0s - loss: 0.6656 - mse: 0.6458\n",
      "Epoch 7: val_loss did not improve from 0.66407\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6659 - mse: 0.6460 - val_loss: 0.6641 - val_mse: 0.6442\n",
      "Epoch 8/25\n",
      "163/171 [===========================>..] - ETA: 0s - loss: 0.6662 - mse: 0.6463\n",
      "Epoch 8: val_loss did not improve from 0.66407\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6660 - mse: 0.6462 - val_loss: 0.6643 - val_mse: 0.6444\n",
      "Epoch 9/25\n",
      "169/171 [============================>.] - ETA: 0s - loss: 0.6659 - mse: 0.6461\n",
      "Epoch 9: val_loss improved from 0.66407 to 0.66402, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e009_vl0.664.h5\n",
      "171/171 [==============================] - 1s 7ms/step - loss: 0.6659 - mse: 0.6461 - val_loss: 0.6640 - val_mse: 0.6442\n",
      "Epoch 10/25\n",
      "161/171 [===========================>..] - ETA: 0s - loss: 0.6659 - mse: 0.6461\n",
      "Epoch 10: val_loss did not improve from 0.66402\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6657 - mse: 0.6459 - val_loss: 0.6641 - val_mse: 0.6443\n",
      "Epoch 11/25\n",
      "163/171 [===========================>..] - ETA: 0s - loss: 0.6658 - mse: 0.6460\n",
      "Epoch 11: val_loss did not improve from 0.66402\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6658 - mse: 0.6459 - val_loss: 0.6642 - val_mse: 0.6444\n",
      "Epoch 12/25\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.6654 - mse: 0.6456\n",
      "Epoch 12: val_loss improved from 0.66402 to 0.66399, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e012_vl0.664.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6658 - mse: 0.6460 - val_loss: 0.6640 - val_mse: 0.6442\n",
      "Epoch 13/25\n",
      "162/171 [===========================>..] - ETA: 0s - loss: 0.6655 - mse: 0.6457\n",
      "Epoch 13: val_loss did not improve from 0.66399\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.6658 - mse: 0.6460 - val_loss: 0.6645 - val_mse: 0.6447\n",
      "Epoch 14/25\n",
      "162/171 [===========================>..] - ETA: 0s - loss: 0.6651 - mse: 0.6453\n",
      "Epoch 14: val_loss did not improve from 0.66399\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6657 - mse: 0.6459 - val_loss: 0.6641 - val_mse: 0.6443\n",
      "Epoch 15/25\n",
      "168/171 [============================>.] - ETA: 0s - loss: 0.6654 - mse: 0.6456\n",
      "Epoch 15: val_loss improved from 0.66399 to 0.66384, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e015_vl0.664.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6658 - mse: 0.6460 - val_loss: 0.6638 - val_mse: 0.6440\n",
      "Epoch 16/25\n",
      "169/171 [============================>.] - ETA: 0s - loss: 0.6659 - mse: 0.6461\n",
      "Epoch 16: val_loss did not improve from 0.66384\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.6658 - mse: 0.6460 - val_loss: 0.6639 - val_mse: 0.6441\n",
      "Epoch 17/25\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.6656 - mse: 0.6458\n",
      "Epoch 17: val_loss did not improve from 0.66384\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6657 - mse: 0.6459 - val_loss: 0.6640 - val_mse: 0.6443\n",
      "Epoch 18/25\n",
      "162/171 [===========================>..] - ETA: 0s - loss: 0.6654 - mse: 0.6457\n",
      "Epoch 18: val_loss improved from 0.66384 to 0.66383, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e018_vl0.664.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6656 - mse: 0.6458 - val_loss: 0.6638 - val_mse: 0.6441\n",
      "Epoch 19/25\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 0.6658 - mse: 0.6460\n",
      "Epoch 19: val_loss improved from 0.66383 to 0.66371, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e019_vl0.664.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6656 - mse: 0.6458 - val_loss: 0.6637 - val_mse: 0.6439\n",
      "Epoch 20/25\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 0.6655 - mse: 0.6458\n",
      "Epoch 20: val_loss did not improve from 0.66371\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6656 - mse: 0.6459 - val_loss: 0.6647 - val_mse: 0.6449\n",
      "Epoch 21/25\n",
      "163/171 [===========================>..] - ETA: 0s - loss: 0.6655 - mse: 0.6457\n",
      "Epoch 21: val_loss improved from 0.66371 to 0.66363, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e021_vl0.664.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6656 - mse: 0.6458 - val_loss: 0.6636 - val_mse: 0.6439\n",
      "Epoch 22/25\n",
      "164/171 [===========================>..] - ETA: 0s - loss: 0.6655 - mse: 0.6457\n",
      "Epoch 22: val_loss did not improve from 0.66363\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6655 - mse: 0.6458 - val_loss: 0.6644 - val_mse: 0.6446\n",
      "Epoch 23/25\n",
      "164/171 [===========================>..] - ETA: 0s - loss: 0.6652 - mse: 0.6454\n",
      "Epoch 23: val_loss improved from 0.66363 to 0.66357, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e023_vl0.664.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6654 - mse: 0.6456 - val_loss: 0.6636 - val_mse: 0.6438\n",
      "Epoch 24/25\n",
      "163/171 [===========================>..] - ETA: 0s - loss: 0.6650 - mse: 0.6453\n",
      "Epoch 24: val_loss did not improve from 0.66357\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6654 - mse: 0.6457 - val_loss: 0.6636 - val_mse: 0.6439\n",
      "Epoch 25/25\n",
      "169/171 [============================>.] - ETA: 0s - loss: 0.6656 - mse: 0.6459\n",
      "Epoch 25: val_loss did not improve from 0.66357\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 0.6655 - mse: 0.6458 - val_loss: 0.6636 - val_mse: 0.6439\n",
      "Time elapsed to train: 25.64 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.584 3.296 1.853 3.642 2.604 1.939 1.456 1.173 0.801 0.499 0.343 0.245 0.200]\n",
      "<R> = [2.584 3.296 1.853 3.642 2.604 1.939 1.456 1.173 0.801 0.499 0.342 0.245 0.200]\n",
      "s_R = [0.044 0.004 0.000 0.028 0.045 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6852942 2.453304  6.4810705 ... 2.8267035 3.9929872 4.4517527]\n",
      "mag_pred: [3.6852942 2.453304  6.4810705 ... 2.8267035 3.9929872 4.4517527]\n",
      "Time elapsed to make plots: 18.28 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [38.437183 29.292301 13.586348 ...  3.183083 34.72521  18.36377 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00811\n",
      "  1% : 0.0951\n",
      "  10% : 0.216\n",
      "  50% : 0.595\n",
      "  90% : 3.07\n",
      "  99% : 66\n",
      "  100% : 7.01e+03\n",
      "<chi^2/d.o.f.> = 1.02\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 13752 stars (5.43%) based on chi^2/dof > 6.3\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.675824  65.22065   14.324881  ...  3.5572178  5.484874  13.270029 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0193\n",
      "  1% : 0.0942\n",
      "  10% : 0.218\n",
      "  50% : 0.601\n",
      "  90% : 2.93\n",
      "  99% : 71.1\n",
      "  100% : 5.17e+03\n",
      "<chi^2/d.o.f.> = 1.01\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 73.72 s\n",
      "learning rate = 9.071795648196712e-05\n",
      "setting learning rate to 7.427357821433387e-05\n",
      "Iteration 14 of 20.\n",
      "Epoch 1/25\n",
      "162/169 [===========================>..] - ETA: 0s - loss: 0.6251 - mse: 0.6054\n",
      "Epoch 1: val_loss improved from inf to 0.62331, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e001_vl0.623.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6251 - mse: 0.6053 - val_loss: 0.6233 - val_mse: 0.6036\n",
      "Epoch 2/25\n",
      "164/169 [============================>.] - ETA: 0s - loss: 0.6248 - mse: 0.6051\n",
      "Epoch 2: val_loss did not improve from 0.62331\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6250 - mse: 0.6053 - val_loss: 0.6235 - val_mse: 0.6038\n",
      "Epoch 3/25\n",
      "163/169 [===========================>..] - ETA: 0s - loss: 0.6259 - mse: 0.6062\n",
      "Epoch 3: val_loss did not improve from 0.62331\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6251 - mse: 0.6054 - val_loss: 0.6235 - val_mse: 0.6039\n",
      "Epoch 4/25\n",
      "163/169 [===========================>..] - ETA: 0s - loss: 0.6253 - mse: 0.6057\n",
      "Epoch 4: val_loss improved from 0.62331 to 0.62297, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e004_vl0.623.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6250 - mse: 0.6053 - val_loss: 0.6230 - val_mse: 0.6033\n",
      "Epoch 5/25\n",
      "159/169 [===========================>..] - ETA: 0s - loss: 0.6244 - mse: 0.6047\n",
      "Epoch 5: val_loss improved from 0.62297 to 0.62279, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e005_vl0.623.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6249 - mse: 0.6053 - val_loss: 0.6228 - val_mse: 0.6031\n",
      "Epoch 6/25\n",
      "158/169 [===========================>..] - ETA: 0s - loss: 0.6249 - mse: 0.6053\n",
      "Epoch 6: val_loss did not improve from 0.62279\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6250 - mse: 0.6053 - val_loss: 0.6232 - val_mse: 0.6036\n",
      "Epoch 7/25\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.6248 - mse: 0.6052\n",
      "Epoch 7: val_loss did not improve from 0.62279\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6249 - mse: 0.6052 - val_loss: 0.6230 - val_mse: 0.6034\n",
      "Epoch 8/25\n",
      "161/169 [===========================>..] - ETA: 0s - loss: 0.6240 - mse: 0.6043\n",
      "Epoch 8: val_loss did not improve from 0.62279\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6249 - mse: 0.6053 - val_loss: 0.6232 - val_mse: 0.6036\n",
      "Epoch 9/25\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.6246 - mse: 0.6050\n",
      "Epoch 9: val_loss did not improve from 0.62279\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6249 - mse: 0.6053 - val_loss: 0.6228 - val_mse: 0.6032\n",
      "Epoch 10/25\n",
      "162/169 [===========================>..] - ETA: 0s - loss: 0.6252 - mse: 0.6056\n",
      "Epoch 10: val_loss did not improve from 0.62279\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6249 - mse: 0.6052 - val_loss: 0.6229 - val_mse: 0.6033\n",
      "Epoch 11/25\n",
      "158/169 [===========================>..] - ETA: 0s - loss: 0.6248 - mse: 0.6052\n",
      "Epoch 11: val_loss did not improve from 0.62279\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6248 - mse: 0.6051 - val_loss: 0.6228 - val_mse: 0.6032\n",
      "Epoch 12/25\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.6248 - mse: 0.6052\n",
      "Epoch 12: val_loss did not improve from 0.62279\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6248 - mse: 0.6052 - val_loss: 0.6231 - val_mse: 0.6035\n",
      "Epoch 13/25\n",
      "161/169 [===========================>..] - ETA: 0s - loss: 0.6247 - mse: 0.6052\n",
      "Epoch 13: val_loss did not improve from 0.62279\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.6248 - mse: 0.6052 - val_loss: 0.6228 - val_mse: 0.6032\n",
      "Epoch 14/25\n",
      "158/169 [===========================>..] - ETA: 0s - loss: 0.6251 - mse: 0.6055\n",
      "Epoch 14: val_loss did not improve from 0.62279\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.6247 - mse: 0.6051 - val_loss: 0.6229 - val_mse: 0.6033\n",
      "Epoch 15/25\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.6248 - mse: 0.6052\n",
      "Epoch 15: val_loss did not improve from 0.62279\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6247 - mse: 0.6051 - val_loss: 0.6232 - val_mse: 0.6036\n",
      "Epoch 16/25\n",
      "165/169 [============================>.] - ETA: 0s - loss: 0.6248 - mse: 0.6052\n",
      "Epoch 16: val_loss improved from 0.62279 to 0.62276, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e016_vl0.623.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6247 - mse: 0.6051 - val_loss: 0.6228 - val_mse: 0.6032\n",
      "Epoch 17/25\n",
      "164/169 [============================>.] - ETA: 0s - loss: 0.6246 - mse: 0.6051\n",
      "Epoch 17: val_loss did not improve from 0.62276\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6247 - mse: 0.6051 - val_loss: 0.6229 - val_mse: 0.6034\n",
      "Epoch 18/25\n",
      "163/169 [===========================>..] - ETA: 0s - loss: 0.6244 - mse: 0.6049\n",
      "Epoch 18: val_loss did not improve from 0.62276\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.6246 - mse: 0.6051 - val_loss: 0.6229 - val_mse: 0.6034\n",
      "Epoch 19/25\n",
      "158/169 [===========================>..] - ETA: 0s - loss: 0.6249 - mse: 0.6054\n",
      "Epoch 19: val_loss improved from 0.62276 to 0.62271, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e019_vl0.623.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6247 - mse: 0.6052 - val_loss: 0.6227 - val_mse: 0.6032\n",
      "Epoch 20/25\n",
      "162/169 [===========================>..] - ETA: 0s - loss: 0.6249 - mse: 0.6054\n",
      "Epoch 20: val_loss did not improve from 0.62271\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6247 - mse: 0.6051 - val_loss: 0.6229 - val_mse: 0.6034\n",
      "Epoch 21/25\n",
      "165/169 [============================>.] - ETA: 0s - loss: 0.6244 - mse: 0.6048\n",
      "Epoch 21: val_loss did not improve from 0.62271\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6246 - mse: 0.6050 - val_loss: 0.6228 - val_mse: 0.6033\n",
      "Epoch 22/25\n",
      "164/169 [============================>.] - ETA: 0s - loss: 0.6239 - mse: 0.6043\n",
      "Epoch 22: val_loss improved from 0.62271 to 0.62264, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e022_vl0.623.h5\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.6246 - mse: 0.6051 - val_loss: 0.6226 - val_mse: 0.6031\n",
      "Epoch 23/25\n",
      "162/169 [===========================>..] - ETA: 0s - loss: 0.6248 - mse: 0.6053\n",
      "Epoch 23: val_loss did not improve from 0.62264\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6246 - mse: 0.6051 - val_loss: 0.6229 - val_mse: 0.6034\n",
      "Epoch 24/25\n",
      "159/169 [===========================>..] - ETA: 0s - loss: 0.6245 - mse: 0.6050\n",
      "Epoch 24: val_loss improved from 0.62264 to 0.62258, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e024_vl0.623.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6246 - mse: 0.6051 - val_loss: 0.6226 - val_mse: 0.6031\n",
      "Epoch 25/25\n",
      "166/169 [============================>.] - ETA: 0s - loss: 0.6250 - mse: 0.6055\n",
      "Epoch 25: val_loss did not improve from 0.62258\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6246 - mse: 0.6051 - val_loss: 0.6227 - val_mse: 0.6032\n",
      "Time elapsed to train: 24.95 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.569 3.275 1.842 3.619 2.589 1.927 1.447 1.164 0.796 0.496 0.341 0.244 0.201]\n",
      "<R> = [2.569 3.275 1.842 3.619 2.588 1.927 1.447 1.164 0.796 0.496 0.341 0.244 0.201]\n",
      "s_R = [0.047 0.010 0.000 0.022 0.036 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6852467 2.4384446 6.4880443 ... 2.8242393 3.997912  4.454368 ]\n",
      "mag_pred: [3.6852467 2.4384446 6.4880443 ... 2.8242393 3.997912  4.454368 ]\n",
      "Time elapsed to make plots: 21.15 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [38.65002  29.422392 12.46842  ...  3.04987  34.88607  16.517204]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00792\n",
      "  1% : 0.0937\n",
      "  10% : 0.213\n",
      "  50% : 0.585\n",
      "  90% : 3.04\n",
      "  99% : 66\n",
      "  100% : 7e+03\n",
      "<chi^2/d.o.f.> = 1.01\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 16541 stars (6.54%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.713859 66.668365 14.163528 ...  3.46342   5.623357 13.09394 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0154\n",
      "  1% : 0.0924\n",
      "  10% : 0.214\n",
      "  50% : 0.592\n",
      "  90% : 2.91\n",
      "  99% : 71.2\n",
      "  100% : 5.17e+03\n",
      "<chi^2/d.o.f.> = 1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 75.72 s\n",
      "learning rate = 7.427357923006639e-05\n",
      "setting learning rate to 6.0810062625217954e-05\n",
      "Iteration 15 of 20.\n",
      "Epoch 1/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 0.5862 - mse: 0.5667\n",
      "Epoch 1: val_loss improved from inf to 0.58386, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e001_vl0.584.h5\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.5862 - mse: 0.5667 - val_loss: 0.5839 - val_mse: 0.5644\n",
      "Epoch 2/25\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5862 - mse: 0.5667\n",
      "Epoch 2: val_loss improved from 0.58386 to 0.58344, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e002_vl0.583.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5862 - mse: 0.5667 - val_loss: 0.5834 - val_mse: 0.5640\n",
      "Epoch 3/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 0.5865 - mse: 0.5671\n",
      "Epoch 3: val_loss did not improve from 0.58344\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5862 - mse: 0.5668 - val_loss: 0.5836 - val_mse: 0.5641\n",
      "Epoch 4/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.5864 - mse: 0.5670\n",
      "Epoch 4: val_loss improved from 0.58344 to 0.58335, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e004_vl0.583.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5861 - mse: 0.5667 - val_loss: 0.5833 - val_mse: 0.5639\n",
      "Epoch 5/25\n",
      "161/167 [===========================>..] - ETA: 0s - loss: 0.5863 - mse: 0.5669\n",
      "Epoch 5: val_loss improved from 0.58335 to 0.58332, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e005_vl0.583.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5861 - mse: 0.5667 - val_loss: 0.5833 - val_mse: 0.5639\n",
      "Epoch 6/25\n",
      "158/167 [===========================>..] - ETA: 0s - loss: 0.5864 - mse: 0.5669\n",
      "Epoch 6: val_loss did not improve from 0.58332\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5861 - mse: 0.5667 - val_loss: 0.5834 - val_mse: 0.5640\n",
      "Epoch 7/25\n",
      "160/167 [===========================>..] - ETA: 0s - loss: 0.5864 - mse: 0.5670\n",
      "Epoch 7: val_loss did not improve from 0.58332\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5861 - mse: 0.5667 - val_loss: 0.5834 - val_mse: 0.5640\n",
      "Epoch 8/25\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.5862 - mse: 0.5668\n",
      "Epoch 8: val_loss improved from 0.58332 to 0.58331, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e008_vl0.583.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5861 - mse: 0.5666 - val_loss: 0.5833 - val_mse: 0.5639\n",
      "Epoch 9/25\n",
      "156/167 [===========================>..] - ETA: 0s - loss: 0.5867 - mse: 0.5673\n",
      "Epoch 9: val_loss did not improve from 0.58331\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.5861 - mse: 0.5667 - val_loss: 0.5834 - val_mse: 0.5640\n",
      "Epoch 10/25\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5860 - mse: 0.5666\n",
      "Epoch 10: val_loss did not improve from 0.58331\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5860 - mse: 0.5666 - val_loss: 0.5833 - val_mse: 0.5639\n",
      "Epoch 11/25\n",
      "161/167 [===========================>..] - ETA: 0s - loss: 0.5865 - mse: 0.5671\n",
      "Epoch 11: val_loss improved from 0.58331 to 0.58323, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e011_vl0.583.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5861 - mse: 0.5667 - val_loss: 0.5832 - val_mse: 0.5638\n",
      "Epoch 12/25\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.5858 - mse: 0.5664\n",
      "Epoch 12: val_loss did not improve from 0.58323\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5860 - mse: 0.5666 - val_loss: 0.5836 - val_mse: 0.5642\n",
      "Epoch 13/25\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.5860 - mse: 0.5666\n",
      "Epoch 13: val_loss did not improve from 0.58323\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5860 - mse: 0.5666 - val_loss: 0.5834 - val_mse: 0.5640\n",
      "Epoch 14/25\n",
      "157/167 [===========================>..] - ETA: 0s - loss: 0.5859 - mse: 0.5666\n",
      "Epoch 14: val_loss did not improve from 0.58323\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5860 - mse: 0.5666 - val_loss: 0.5835 - val_mse: 0.5642\n",
      "Epoch 15/25\n",
      "163/167 [============================>.] - ETA: 0s - loss: 0.5856 - mse: 0.5663\n",
      "Epoch 15: val_loss improved from 0.58323 to 0.58322, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e015_vl0.583.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5859 - mse: 0.5665 - val_loss: 0.5832 - val_mse: 0.5639\n",
      "Epoch 16/25\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5860 - mse: 0.5666\n",
      "Epoch 16: val_loss improved from 0.58322 to 0.58314, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e016_vl0.583.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5860 - mse: 0.5666 - val_loss: 0.5831 - val_mse: 0.5638\n",
      "Epoch 17/25\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5858 - mse: 0.5665\n",
      "Epoch 17: val_loss did not improve from 0.58314\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5858 - mse: 0.5665 - val_loss: 0.5834 - val_mse: 0.5640\n",
      "Epoch 18/25\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5859 - mse: 0.5666\n",
      "Epoch 18: val_loss did not improve from 0.58314\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5859 - mse: 0.5666 - val_loss: 0.5833 - val_mse: 0.5639\n",
      "Epoch 19/25\n",
      "162/167 [============================>.] - ETA: 0s - loss: 0.5858 - mse: 0.5665\n",
      "Epoch 19: val_loss did not improve from 0.58314\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5858 - mse: 0.5665 - val_loss: 0.5834 - val_mse: 0.5640\n",
      "Epoch 20/25\n",
      "161/167 [===========================>..] - ETA: 0s - loss: 0.5858 - mse: 0.5665\n",
      "Epoch 20: val_loss did not improve from 0.58314\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.5859 - mse: 0.5665 - val_loss: 0.5832 - val_mse: 0.5639\n",
      "Epoch 21/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.5854 - mse: 0.5661\n",
      "Epoch 21: val_loss improved from 0.58314 to 0.58309, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e021_vl0.583.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5858 - mse: 0.5665 - val_loss: 0.5831 - val_mse: 0.5638\n",
      "Epoch 22/25\n",
      "158/167 [===========================>..] - ETA: 0s - loss: 0.5857 - mse: 0.5664\n",
      "Epoch 22: val_loss did not improve from 0.58309\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5858 - mse: 0.5665 - val_loss: 0.5832 - val_mse: 0.5639\n",
      "Epoch 23/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 0.5858 - mse: 0.5665\n",
      "Epoch 23: val_loss did not improve from 0.58309\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5858 - mse: 0.5665 - val_loss: 0.5832 - val_mse: 0.5639\n",
      "Epoch 24/25\n",
      "157/167 [===========================>..] - ETA: 0s - loss: 0.5857 - mse: 0.5665\n",
      "Epoch 24: val_loss improved from 0.58309 to 0.58306, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e024_vl0.583.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5858 - mse: 0.5665 - val_loss: 0.5831 - val_mse: 0.5638\n",
      "Epoch 25/25\n",
      "158/167 [===========================>..] - ETA: 0s - loss: 0.5859 - mse: 0.5666\n",
      "Epoch 25: val_loss did not improve from 0.58306\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5858 - mse: 0.5665 - val_loss: 0.5832 - val_mse: 0.5639\n",
      "Time elapsed to train: 25.03 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.554 3.255 1.832 3.595 2.573 1.916 1.438 1.157 0.792 0.495 0.341 0.245 0.203]\n",
      "<R> = [2.554 3.255 1.832 3.595 2.573 1.916 1.438 1.157 0.792 0.495 0.341 0.245 0.203]\n",
      "s_R = [0.050 0.015 0.000 0.015 0.028 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6797576 2.4272351 6.490979  ... 2.828417  3.9991949 4.4512854]\n",
      "mag_pred: [3.6797576 2.4272351 6.490979  ... 2.828417  3.9991949 4.4512854]\n",
      "Time elapsed to make plots: 18.17 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [38.99803   29.745401  11.804258  ...  3.0991693 34.974865  15.690889 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0102\n",
      "  1% : 0.0923\n",
      "  10% : 0.21\n",
      "  50% : 0.578\n",
      "  90% : 3.02\n",
      "  99% : 66.1\n",
      "  100% : 7e+03\n",
      "<chi^2/d.o.f.> = 0.997\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 16475 stars (6.51%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.761984  67.88031   13.741949  ...  3.4686766  5.5842032 13.313174 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0135\n",
      "  1% : 0.092\n",
      "  10% : 0.211\n",
      "  50% : 0.586\n",
      "  90% : 2.89\n",
      "  99% : 71.2\n",
      "  100% : 5.17e+03\n",
      "<chi^2/d.o.f.> = 0.993\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 79.07 s\n",
      "learning rate = 6.0810063587268814e-05\n",
      "setting learning rate to 4.9787068367863945e-05\n",
      "Iteration 16 of 20.\n",
      "Epoch 1/25\n",
      "161/167 [===========================>..] - ETA: 0s - loss: 0.5833 - mse: 0.5640\n",
      "Epoch 1: val_loss improved from inf to 0.58055, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e001_vl0.581.h5\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.5832 - mse: 0.5639 - val_loss: 0.5806 - val_mse: 0.5613\n",
      "Epoch 2/25\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.5835 - mse: 0.5642\n",
      "Epoch 2: val_loss improved from 0.58055 to 0.58055, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e002_vl0.581.h5\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.5833 - mse: 0.5640 - val_loss: 0.5805 - val_mse: 0.5613\n",
      "Epoch 3/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.5834 - mse: 0.5642\n",
      "Epoch 3: val_loss did not improve from 0.58055\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5832 - mse: 0.5639 - val_loss: 0.5806 - val_mse: 0.5613\n",
      "Epoch 4/25\n",
      "155/167 [==========================>...] - ETA: 0s - loss: 0.5834 - mse: 0.5642\n",
      "Epoch 4: val_loss did not improve from 0.58055\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.5832 - mse: 0.5639 - val_loss: 0.5806 - val_mse: 0.5613\n",
      "Epoch 5/25\n",
      "156/167 [===========================>..] - ETA: 0s - loss: 0.5826 - mse: 0.5633\n",
      "Epoch 5: val_loss improved from 0.58055 to 0.58054, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e005_vl0.581.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5831 - mse: 0.5639 - val_loss: 0.5805 - val_mse: 0.5613\n",
      "Epoch 6/25\n",
      "158/167 [===========================>..] - ETA: 0s - loss: 0.5828 - mse: 0.5636\n",
      "Epoch 6: val_loss did not improve from 0.58054\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5831 - mse: 0.5639 - val_loss: 0.5806 - val_mse: 0.5614\n",
      "Epoch 7/25\n",
      "160/167 [===========================>..] - ETA: 0s - loss: 0.5827 - mse: 0.5634\n",
      "Epoch 7: val_loss improved from 0.58054 to 0.58048, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e007_vl0.580.h5\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.5831 - mse: 0.5639 - val_loss: 0.5805 - val_mse: 0.5612\n",
      "Epoch 8/25\n",
      "162/167 [============================>.] - ETA: 0s - loss: 0.5830 - mse: 0.5638\n",
      "Epoch 8: val_loss did not improve from 0.58048\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.5831 - mse: 0.5638 - val_loss: 0.5806 - val_mse: 0.5614\n",
      "Epoch 9/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 0.5833 - mse: 0.5640\n",
      "Epoch 9: val_loss improved from 0.58048 to 0.58047, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e009_vl0.580.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5831 - mse: 0.5638 - val_loss: 0.5805 - val_mse: 0.5612\n",
      "Epoch 10/25\n",
      "163/167 [============================>.] - ETA: 0s - loss: 0.5829 - mse: 0.5637\n",
      "Epoch 10: val_loss did not improve from 0.58047\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5831 - mse: 0.5639 - val_loss: 0.5808 - val_mse: 0.5616\n",
      "Epoch 11/25\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5831 - mse: 0.5639\n",
      "Epoch 11: val_loss improved from 0.58047 to 0.58045, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e011_vl0.580.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5831 - mse: 0.5639 - val_loss: 0.5804 - val_mse: 0.5612\n",
      "Epoch 12/25\n",
      "156/167 [===========================>..] - ETA: 0s - loss: 0.5829 - mse: 0.5637\n",
      "Epoch 12: val_loss did not improve from 0.58045\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5831 - mse: 0.5639 - val_loss: 0.5806 - val_mse: 0.5614\n",
      "Epoch 13/25\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.5831 - mse: 0.5639\n",
      "Epoch 13: val_loss did not improve from 0.58045\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5831 - mse: 0.5639 - val_loss: 0.5809 - val_mse: 0.5617\n",
      "Epoch 14/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.5831 - mse: 0.5639\n",
      "Epoch 14: val_loss did not improve from 0.58045\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5830 - mse: 0.5638 - val_loss: 0.5806 - val_mse: 0.5614\n",
      "Epoch 15/25\n",
      "160/167 [===========================>..] - ETA: 0s - loss: 0.5834 - mse: 0.5642\n",
      "Epoch 15: val_loss did not improve from 0.58045\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5831 - mse: 0.5639 - val_loss: 0.5810 - val_mse: 0.5618\n",
      "Epoch 16/25\n",
      "156/167 [===========================>..] - ETA: 0s - loss: 0.5836 - mse: 0.5645\n",
      "Epoch 16: val_loss did not improve from 0.58045\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5831 - mse: 0.5639 - val_loss: 0.5806 - val_mse: 0.5614\n",
      "Epoch 17/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.5829 - mse: 0.5637\n",
      "Epoch 17: val_loss improved from 0.58045 to 0.58041, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e017_vl0.580.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5830 - mse: 0.5638 - val_loss: 0.5804 - val_mse: 0.5612\n",
      "Epoch 18/25\n",
      "160/167 [===========================>..] - ETA: 0s - loss: 0.5831 - mse: 0.5639\n",
      "Epoch 18: val_loss improved from 0.58041 to 0.58036, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e018_vl0.580.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5829 - mse: 0.5638 - val_loss: 0.5804 - val_mse: 0.5612\n",
      "Epoch 19/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.5831 - mse: 0.5640\n",
      "Epoch 19: val_loss did not improve from 0.58036\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5829 - mse: 0.5638 - val_loss: 0.5805 - val_mse: 0.5613\n",
      "Epoch 20/25\n",
      "157/167 [===========================>..] - ETA: 0s - loss: 0.5830 - mse: 0.5638\n",
      "Epoch 20: val_loss did not improve from 0.58036\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5830 - mse: 0.5638 - val_loss: 0.5805 - val_mse: 0.5614\n",
      "Epoch 21/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 0.5831 - mse: 0.5639\n",
      "Epoch 21: val_loss did not improve from 0.58036\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5830 - mse: 0.5638 - val_loss: 0.5804 - val_mse: 0.5612\n",
      "Epoch 22/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.5827 - mse: 0.5636\n",
      "Epoch 22: val_loss did not improve from 0.58036\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5829 - mse: 0.5638 - val_loss: 0.5804 - val_mse: 0.5612\n",
      "Epoch 23/25\n",
      "160/167 [===========================>..] - ETA: 0s - loss: 0.5828 - mse: 0.5636\n",
      "Epoch 23: val_loss did not improve from 0.58036\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5829 - mse: 0.5637 - val_loss: 0.5804 - val_mse: 0.5613\n",
      "Epoch 24/25\n",
      "159/167 [===========================>..] - ETA: 0s - loss: 0.5824 - mse: 0.5633\n",
      "Epoch 24: val_loss improved from 0.58036 to 0.58035, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e024_vl0.580.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5829 - mse: 0.5637 - val_loss: 0.5803 - val_mse: 0.5612\n",
      "Epoch 25/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.5829 - mse: 0.5638\n",
      "Epoch 25: val_loss did not improve from 0.58035\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5829 - mse: 0.5638 - val_loss: 0.5806 - val_mse: 0.5615\n",
      "Time elapsed to train: 25.41 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.542 3.240 1.823 3.579 2.562 1.907 1.432 1.151 0.789 0.494 0.341 0.245 0.203]\n",
      "<R> = [2.543 3.240 1.823 3.579 2.562 1.907 1.432 1.151 0.789 0.494 0.341 0.245 0.203]\n",
      "s_R = [0.051 0.016 0.000 0.012 0.026 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.680677  2.4280214 6.4930277 ... 2.840517  4.0001206 4.450685 ]\n",
      "mag_pred: [3.680677  2.4280214 6.4930277 ... 2.840517  4.0001206 4.450685 ]\n",
      "Time elapsed to make plots: 17.86 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [39.026817  30.354595  11.965556  ...  2.9830585 35.625008  15.766894 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0144\n",
      "  1% : 0.0922\n",
      "  10% : 0.209\n",
      "  50% : 0.576\n",
      "  90% : 3.02\n",
      "  99% : 66.4\n",
      "  100% : 7e+03\n",
      "<chi^2/d.o.f.> = 0.995\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 16472 stars (6.51%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.636254 68.29297  13.090837 ...  3.515237  5.54755  13.237238]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0113\n",
      "  1% : 0.093\n",
      "  10% : 0.209\n",
      "  50% : 0.582\n",
      "  90% : 2.89\n",
      "  99% : 71.4\n",
      "  100% : 5.17e+03\n",
      "<chi^2/d.o.f.> = 0.991\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 79.06 s\n",
      "learning rate = 4.978706783731468e-05\n",
      "setting learning rate to 4.0762203978366214e-05\n",
      "Iteration 17 of 20.\n",
      "Epoch 1/25\n",
      "158/167 [===========================>..] - ETA: 0s - loss: 0.5825 - mse: 0.5634\n",
      "Epoch 1: val_loss improved from inf to 0.58062, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e001_vl0.581.h5\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.5826 - mse: 0.5635 - val_loss: 0.5806 - val_mse: 0.5615\n",
      "Epoch 2/25\n",
      "162/167 [============================>.] - ETA: 0s - loss: 0.5824 - mse: 0.5633\n",
      "Epoch 2: val_loss did not improve from 0.58062\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5826 - mse: 0.5635 - val_loss: 0.5808 - val_mse: 0.5617\n",
      "Epoch 3/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 0.5827 - mse: 0.5636\n",
      "Epoch 3: val_loss improved from 0.58062 to 0.58049, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e003_vl0.580.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5826 - mse: 0.5635 - val_loss: 0.5805 - val_mse: 0.5614\n",
      "Epoch 4/25\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.5825 - mse: 0.5634\n",
      "Epoch 4: val_loss did not improve from 0.58049\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5825 - mse: 0.5634 - val_loss: 0.5806 - val_mse: 0.5615\n",
      "Epoch 5/25\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.5826 - mse: 0.5635\n",
      "Epoch 5: val_loss did not improve from 0.58049\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5825 - mse: 0.5634 - val_loss: 0.5805 - val_mse: 0.5614\n",
      "Epoch 6/25\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.5825 - mse: 0.5634\n",
      "Epoch 6: val_loss did not improve from 0.58049\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5825 - mse: 0.5634 - val_loss: 0.5808 - val_mse: 0.5617\n",
      "Epoch 7/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.5825 - mse: 0.5634\n",
      "Epoch 7: val_loss did not improve from 0.58049\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5826 - mse: 0.5635 - val_loss: 0.5810 - val_mse: 0.5619\n",
      "Epoch 8/25\n",
      "161/167 [===========================>..] - ETA: 0s - loss: 0.5825 - mse: 0.5634\n",
      "Epoch 8: val_loss did not improve from 0.58049\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5826 - mse: 0.5635 - val_loss: 0.5806 - val_mse: 0.5615\n",
      "Epoch 9/25\n",
      "160/167 [===========================>..] - ETA: 0s - loss: 0.5829 - mse: 0.5638\n",
      "Epoch 9: val_loss did not improve from 0.58049\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5826 - mse: 0.5635 - val_loss: 0.5806 - val_mse: 0.5615\n",
      "Epoch 10/25\n",
      "159/167 [===========================>..] - ETA: 0s - loss: 0.5829 - mse: 0.5638\n",
      "Epoch 10: val_loss did not improve from 0.58049\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5825 - mse: 0.5634 - val_loss: 0.5806 - val_mse: 0.5615\n",
      "Epoch 11/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.5828 - mse: 0.5637\n",
      "Epoch 11: val_loss did not improve from 0.58049\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5825 - mse: 0.5634 - val_loss: 0.5807 - val_mse: 0.5616\n",
      "Epoch 12/25\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5825 - mse: 0.5634\n",
      "Epoch 12: val_loss improved from 0.58049 to 0.58047, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e012_vl0.580.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5825 - mse: 0.5634 - val_loss: 0.5805 - val_mse: 0.5614\n",
      "Epoch 13/25\n",
      "157/167 [===========================>..] - ETA: 0s - loss: 0.5826 - mse: 0.5635\n",
      "Epoch 13: val_loss did not improve from 0.58047\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5825 - mse: 0.5634 - val_loss: 0.5805 - val_mse: 0.5615\n",
      "Epoch 14/25\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5825 - mse: 0.5634\n",
      "Epoch 14: val_loss improved from 0.58047 to 0.58041, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e014_vl0.580.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5825 - mse: 0.5634 - val_loss: 0.5804 - val_mse: 0.5614\n",
      "Epoch 15/25\n",
      "160/167 [===========================>..] - ETA: 0s - loss: 0.5822 - mse: 0.5631\n",
      "Epoch 15: val_loss did not improve from 0.58041\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5824 - mse: 0.5634 - val_loss: 0.5805 - val_mse: 0.5615\n",
      "Epoch 16/25\n",
      "159/167 [===========================>..] - ETA: 0s - loss: 0.5820 - mse: 0.5630\n",
      "Epoch 16: val_loss did not improve from 0.58041\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5824 - mse: 0.5634 - val_loss: 0.5806 - val_mse: 0.5615\n",
      "Epoch 17/25\n",
      "158/167 [===========================>..] - ETA: 0s - loss: 0.5831 - mse: 0.5640\n",
      "Epoch 17: val_loss did not improve from 0.58041\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5824 - mse: 0.5634 - val_loss: 0.5805 - val_mse: 0.5614\n",
      "Epoch 18/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 0.5827 - mse: 0.5637\n",
      "Epoch 18: val_loss did not improve from 0.58041\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5824 - mse: 0.5634 - val_loss: 0.5804 - val_mse: 0.5614\n",
      "Epoch 19/25\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.5824 - mse: 0.5634\n",
      "Epoch 19: val_loss did not improve from 0.58041\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5823 - mse: 0.5633 - val_loss: 0.5805 - val_mse: 0.5615\n",
      "Epoch 20/25\n",
      "163/167 [============================>.] - ETA: 0s - loss: 0.5824 - mse: 0.5634\n",
      "Epoch 20: val_loss did not improve from 0.58041\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.5824 - mse: 0.5634 - val_loss: 0.5807 - val_mse: 0.5617\n",
      "Epoch 21/25\n",
      "160/167 [===========================>..] - ETA: 0s - loss: 0.5825 - mse: 0.5635\n",
      "Epoch 21: val_loss did not improve from 0.58041\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5824 - mse: 0.5634 - val_loss: 0.5805 - val_mse: 0.5615\n",
      "Epoch 22/25\n",
      "158/167 [===========================>..] - ETA: 0s - loss: 0.5823 - mse: 0.5633\n",
      "Epoch 22: val_loss did not improve from 0.58041\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5823 - mse: 0.5633 - val_loss: 0.5809 - val_mse: 0.5619\n",
      "Epoch 23/25\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5824 - mse: 0.5634\n",
      "Epoch 23: val_loss did not improve from 0.58041\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5824 - mse: 0.5634 - val_loss: 0.5805 - val_mse: 0.5615\n",
      "Epoch 24/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 0.5823 - mse: 0.5633\n",
      "Epoch 24: val_loss did not improve from 0.58041\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5824 - mse: 0.5634 - val_loss: 0.5805 - val_mse: 0.5615\n",
      "Epoch 25/25\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.5824 - mse: 0.5634\n",
      "Epoch 25: val_loss did not improve from 0.58041\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5824 - mse: 0.5633 - val_loss: 0.5804 - val_mse: 0.5614\n",
      "Time elapsed to train: 26.19 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.534 3.230 1.818 3.567 2.553 1.901 1.427 1.147 0.786 0.493 0.341 0.245 0.204]\n",
      "<R> = [2.535 3.230 1.818 3.567 2.553 1.901 1.427 1.147 0.786 0.493 0.341 0.245 0.204]\n",
      "s_R = [0.051 0.017 0.000 0.011 0.025 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6822414 2.4289382 6.499544  ... 2.8464112 4.0018196 4.4520063]\n",
      "mag_pred: [3.6822414 2.4289382 6.499544  ... 2.8464112 4.0018196 4.4520063]\n",
      "Time elapsed to make plots: 21.60 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [38.593822  29.777803  11.745582  ...  3.0716171 35.289665  15.297807 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0109\n",
      "  1% : 0.0916\n",
      "  10% : 0.208\n",
      "  50% : 0.575\n",
      "  90% : 3.01\n",
      "  99% : 66.4\n",
      "  100% : 7e+03\n",
      "<chi^2/d.o.f.> = 0.993\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 16466 stars (6.51%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.576551  68.54367   13.332141  ...  3.6367183  5.5338073 13.295656 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0127\n",
      "  1% : 0.0916\n",
      "  10% : 0.21\n",
      "  50% : 0.582\n",
      "  90% : 2.88\n",
      "  99% : 71.4\n",
      "  100% : 5.17e+03\n",
      "<chi^2/d.o.f.> = 0.989\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 79.02 s\n",
      "learning rate = 4.076220284332521e-05\n",
      "setting learning rate to 3.337326996032607e-05\n",
      "Iteration 18 of 20.\n",
      "Epoch 1/25\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.5822 - mse: 0.5632\n",
      "Epoch 1: val_loss improved from inf to 0.57992, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e001_vl0.580.h5\n",
      "167/167 [==============================] - 2s 7ms/step - loss: 0.5822 - mse: 0.5632 - val_loss: 0.5799 - val_mse: 0.5609\n",
      "Epoch 2/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 0.5819 - mse: 0.5629\n",
      "Epoch 2: val_loss improved from 0.57992 to 0.57984, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e002_vl0.580.h5\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.5822 - mse: 0.5632 - val_loss: 0.5798 - val_mse: 0.5609\n",
      "Epoch 3/25\n",
      "160/167 [===========================>..] - ETA: 0s - loss: 0.5830 - mse: 0.5640\n",
      "Epoch 3: val_loss did not improve from 0.57984\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5823 - mse: 0.5633 - val_loss: 0.5798 - val_mse: 0.5609\n",
      "Epoch 4/25\n",
      "158/167 [===========================>..] - ETA: 0s - loss: 0.5821 - mse: 0.5631\n",
      "Epoch 4: val_loss did not improve from 0.57984\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5822 - mse: 0.5633 - val_loss: 0.5801 - val_mse: 0.5611\n",
      "Epoch 5/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 0.5823 - mse: 0.5633\n",
      "Epoch 5: val_loss improved from 0.57984 to 0.57984, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e005_vl0.580.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5822 - mse: 0.5632 - val_loss: 0.5798 - val_mse: 0.5609\n",
      "Epoch 6/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 0.5821 - mse: 0.5631\n",
      "Epoch 6: val_loss improved from 0.57984 to 0.57978, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e006_vl0.580.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5822 - mse: 0.5632 - val_loss: 0.5798 - val_mse: 0.5608\n",
      "Epoch 7/25\n",
      "159/167 [===========================>..] - ETA: 0s - loss: 0.5816 - mse: 0.5626\n",
      "Epoch 7: val_loss did not improve from 0.57978\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5822 - mse: 0.5633 - val_loss: 0.5799 - val_mse: 0.5609\n",
      "Epoch 8/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 0.5824 - mse: 0.5634\n",
      "Epoch 8: val_loss did not improve from 0.57978\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5822 - mse: 0.5632 - val_loss: 0.5799 - val_mse: 0.5609\n",
      "Epoch 9/25\n",
      "159/167 [===========================>..] - ETA: 0s - loss: 0.5821 - mse: 0.5632\n",
      "Epoch 9: val_loss did not improve from 0.57978\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5822 - mse: 0.5632 - val_loss: 0.5801 - val_mse: 0.5612\n",
      "Epoch 10/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 0.5822 - mse: 0.5632\n",
      "Epoch 10: val_loss did not improve from 0.57978\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5822 - mse: 0.5632 - val_loss: 0.5799 - val_mse: 0.5610\n",
      "Epoch 11/25\n",
      "157/167 [===========================>..] - ETA: 0s - loss: 0.5818 - mse: 0.5628\n",
      "Epoch 11: val_loss did not improve from 0.57978\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5822 - mse: 0.5632 - val_loss: 0.5798 - val_mse: 0.5608\n",
      "Epoch 12/25\n",
      "161/167 [===========================>..] - ETA: 0s - loss: 0.5824 - mse: 0.5635\n",
      "Epoch 12: val_loss did not improve from 0.57978\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5821 - mse: 0.5632 - val_loss: 0.5799 - val_mse: 0.5609\n",
      "Epoch 13/25\n",
      "157/167 [===========================>..] - ETA: 0s - loss: 0.5827 - mse: 0.5638\n",
      "Epoch 13: val_loss did not improve from 0.57978\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5821 - mse: 0.5632 - val_loss: 0.5798 - val_mse: 0.5608\n",
      "Epoch 14/25\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.5821 - mse: 0.5631\n",
      "Epoch 14: val_loss did not improve from 0.57978\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5821 - mse: 0.5632 - val_loss: 0.5800 - val_mse: 0.5610\n",
      "Epoch 15/25\n",
      "159/167 [===========================>..] - ETA: 0s - loss: 0.5823 - mse: 0.5633\n",
      "Epoch 15: val_loss improved from 0.57978 to 0.57975, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e015_vl0.580.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5821 - mse: 0.5632 - val_loss: 0.5798 - val_mse: 0.5608\n",
      "Epoch 16/25\n",
      "157/167 [===========================>..] - ETA: 0s - loss: 0.5813 - mse: 0.5624\n",
      "Epoch 16: val_loss did not improve from 0.57975\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5821 - mse: 0.5632 - val_loss: 0.5799 - val_mse: 0.5610\n",
      "Epoch 17/25\n",
      "161/167 [===========================>..] - ETA: 0s - loss: 0.5819 - mse: 0.5630\n",
      "Epoch 17: val_loss did not improve from 0.57975\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5822 - mse: 0.5632 - val_loss: 0.5799 - val_mse: 0.5610\n",
      "Epoch 18/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.5822 - mse: 0.5633\n",
      "Epoch 18: val_loss did not improve from 0.57975\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5821 - mse: 0.5632 - val_loss: 0.5801 - val_mse: 0.5611\n",
      "Epoch 19/25\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5821 - mse: 0.5632\n",
      "Epoch 19: val_loss did not improve from 0.57975\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5821 - mse: 0.5632 - val_loss: 0.5798 - val_mse: 0.5609\n",
      "Epoch 20/25\n",
      "159/167 [===========================>..] - ETA: 0s - loss: 0.5817 - mse: 0.5628\n",
      "Epoch 20: val_loss did not improve from 0.57975\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5821 - mse: 0.5632 - val_loss: 0.5798 - val_mse: 0.5609\n",
      "Epoch 21/25\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.5819 - mse: 0.5630\n",
      "Epoch 21: val_loss did not improve from 0.57975\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5821 - mse: 0.5632 - val_loss: 0.5798 - val_mse: 0.5608\n",
      "Epoch 22/25\n",
      "161/167 [===========================>..] - ETA: 0s - loss: 0.5822 - mse: 0.5633\n",
      "Epoch 22: val_loss did not improve from 0.57975\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5820 - mse: 0.5631 - val_loss: 0.5801 - val_mse: 0.5612\n",
      "Epoch 23/25\n",
      "156/167 [===========================>..] - ETA: 0s - loss: 0.5817 - mse: 0.5628\n",
      "Epoch 23: val_loss improved from 0.57975 to 0.57972, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e023_vl0.580.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5821 - mse: 0.5632 - val_loss: 0.5797 - val_mse: 0.5608\n",
      "Epoch 24/25\n",
      "163/167 [============================>.] - ETA: 0s - loss: 0.5818 - mse: 0.5629\n",
      "Epoch 24: val_loss did not improve from 0.57972\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5820 - mse: 0.5631 - val_loss: 0.5798 - val_mse: 0.5609\n",
      "Epoch 25/25\n",
      "161/167 [===========================>..] - ETA: 0s - loss: 0.5821 - mse: 0.5632\n",
      "Epoch 25: val_loss improved from 0.57972 to 0.57966, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e025_vl0.580.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5821 - mse: 0.5632 - val_loss: 0.5797 - val_mse: 0.5608\n",
      "Time elapsed to train: 25.92 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.528 3.222 1.813 3.559 2.547 1.897 1.424 1.144 0.785 0.492 0.340 0.245 0.204]\n",
      "<R> = [2.529 3.222 1.813 3.559 2.547 1.897 1.424 1.144 0.785 0.492 0.340 0.245 0.204]\n",
      "s_R = [0.052 0.018 0.000 0.010 0.025 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6836216 2.4274876 6.5040984 ... 2.8482125 4.0032225 4.4529357]\n",
      "mag_pred: [3.6836216 2.4274876 6.5040984 ... 2.8482125 4.0032225 4.4529357]\n",
      "Time elapsed to make plots: 17.95 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [38.690742  29.529896  11.665728  ...  3.1021936 35.076088  15.056444 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0108\n",
      "  1% : 0.0921\n",
      "  10% : 0.209\n",
      "  50% : 0.575\n",
      "  90% : 3\n",
      "  99% : 66.7\n",
      "  100% : 7e+03\n",
      "<chi^2/d.o.f.> = 0.992\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 16422 stars (6.49%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.764087  68.63494   13.292007  ...  3.4506178  5.460268  13.487878 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0144\n",
      "  1% : 0.0916\n",
      "  10% : 0.21\n",
      "  50% : 0.581\n",
      "  90% : 2.87\n",
      "  99% : 71.4\n",
      "  100% : 5.17e+03\n",
      "<chi^2/d.o.f.> = 0.988\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 78.80 s\n",
      "learning rate = 3.337327143526636e-05\n",
      "setting learning rate to 2.732372244729256e-05\n",
      "Iteration 19 of 20.\n",
      "Epoch 1/25\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5823 - mse: 0.5634\n",
      "Epoch 1: val_loss improved from inf to 0.57990, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e001_vl0.580.h5\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.5823 - mse: 0.5634 - val_loss: 0.5799 - val_mse: 0.5610\n",
      "Epoch 2/25\n",
      "163/167 [============================>.] - ETA: 0s - loss: 0.5818 - mse: 0.5629\n",
      "Epoch 2: val_loss did not improve from 0.57990\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5822 - mse: 0.5633 - val_loss: 0.5800 - val_mse: 0.5611\n",
      "Epoch 3/25\n",
      "163/167 [============================>.] - ETA: 0s - loss: 0.5820 - mse: 0.5631\n",
      "Epoch 3: val_loss improved from 0.57990 to 0.57976, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e003_vl0.580.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5822 - mse: 0.5633 - val_loss: 0.5798 - val_mse: 0.5609\n",
      "Epoch 4/25\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5822 - mse: 0.5633\n",
      "Epoch 4: val_loss did not improve from 0.57976\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5822 - mse: 0.5633 - val_loss: 0.5798 - val_mse: 0.5609\n",
      "Epoch 5/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 0.5821 - mse: 0.5633\n",
      "Epoch 5: val_loss did not improve from 0.57976\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5822 - mse: 0.5633 - val_loss: 0.5799 - val_mse: 0.5610\n",
      "Epoch 6/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 0.5821 - mse: 0.5632\n",
      "Epoch 6: val_loss did not improve from 0.57976\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5822 - mse: 0.5633 - val_loss: 0.5798 - val_mse: 0.5610\n",
      "Epoch 7/25\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5822 - mse: 0.5633\n",
      "Epoch 7: val_loss did not improve from 0.57976\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5822 - mse: 0.5633 - val_loss: 0.5798 - val_mse: 0.5609\n",
      "Epoch 8/25\n",
      "159/167 [===========================>..] - ETA: 0s - loss: 0.5819 - mse: 0.5630\n",
      "Epoch 8: val_loss did not improve from 0.57976\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5822 - mse: 0.5633 - val_loss: 0.5800 - val_mse: 0.5611\n",
      "Epoch 9/25\n",
      "159/167 [===========================>..] - ETA: 0s - loss: 0.5822 - mse: 0.5633\n",
      "Epoch 9: val_loss did not improve from 0.57976\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5822 - mse: 0.5633 - val_loss: 0.5798 - val_mse: 0.5609\n",
      "Epoch 10/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 0.5820 - mse: 0.5631\n",
      "Epoch 10: val_loss did not improve from 0.57976\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5822 - mse: 0.5633 - val_loss: 0.5798 - val_mse: 0.5609\n",
      "Epoch 11/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 0.5823 - mse: 0.5635\n",
      "Epoch 11: val_loss did not improve from 0.57976\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5822 - mse: 0.5633 - val_loss: 0.5798 - val_mse: 0.5610\n",
      "Epoch 12/25\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.5822 - mse: 0.5633\n",
      "Epoch 12: val_loss did not improve from 0.57976\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5822 - mse: 0.5633 - val_loss: 0.5798 - val_mse: 0.5609\n",
      "Epoch 13/25\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5821 - mse: 0.5633\n",
      "Epoch 13: val_loss improved from 0.57976 to 0.57973, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e013_vl0.580.h5\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.5821 - mse: 0.5633 - val_loss: 0.5797 - val_mse: 0.5609\n",
      "Epoch 14/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 0.5823 - mse: 0.5634\n",
      "Epoch 14: val_loss did not improve from 0.57973\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5821 - mse: 0.5633 - val_loss: 0.5798 - val_mse: 0.5609\n",
      "Epoch 15/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.5824 - mse: 0.5635\n",
      "Epoch 15: val_loss did not improve from 0.57973\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5822 - mse: 0.5633 - val_loss: 0.5800 - val_mse: 0.5611\n",
      "Epoch 16/25\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5821 - mse: 0.5633\n",
      "Epoch 16: val_loss did not improve from 0.57973\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.5821 - mse: 0.5633 - val_loss: 0.5798 - val_mse: 0.5610\n",
      "Epoch 17/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.5822 - mse: 0.5633\n",
      "Epoch 17: val_loss improved from 0.57973 to 0.57969, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e017_vl0.580.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5821 - mse: 0.5633 - val_loss: 0.5797 - val_mse: 0.5608\n",
      "Epoch 18/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 0.5821 - mse: 0.5632\n",
      "Epoch 18: val_loss did not improve from 0.57969\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5821 - mse: 0.5633 - val_loss: 0.5797 - val_mse: 0.5609\n",
      "Epoch 19/25\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5821 - mse: 0.5633\n",
      "Epoch 19: val_loss did not improve from 0.57969\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5821 - mse: 0.5633 - val_loss: 0.5797 - val_mse: 0.5609\n",
      "Epoch 20/25\n",
      "162/167 [============================>.] - ETA: 0s - loss: 0.5824 - mse: 0.5636\n",
      "Epoch 20: val_loss did not improve from 0.57969\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5821 - mse: 0.5633 - val_loss: 0.5798 - val_mse: 0.5609\n",
      "Epoch 21/25\n",
      "158/167 [===========================>..] - ETA: 0s - loss: 0.5821 - mse: 0.5632\n",
      "Epoch 21: val_loss did not improve from 0.57969\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.5821 - mse: 0.5633 - val_loss: 0.5797 - val_mse: 0.5609\n",
      "Epoch 22/25\n",
      "157/167 [===========================>..] - ETA: 0s - loss: 0.5822 - mse: 0.5633\n",
      "Epoch 22: val_loss did not improve from 0.57969\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.5821 - mse: 0.5633 - val_loss: 0.5797 - val_mse: 0.5609\n",
      "Epoch 23/25\n",
      "163/167 [============================>.] - ETA: 0s - loss: 0.5823 - mse: 0.5634\n",
      "Epoch 23: val_loss did not improve from 0.57969\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.5821 - mse: 0.5633 - val_loss: 0.5797 - val_mse: 0.5609\n",
      "Epoch 24/25\n",
      "161/167 [===========================>..] - ETA: 0s - loss: 0.5822 - mse: 0.5634\n",
      "Epoch 24: val_loss improved from 0.57969 to 0.57968, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e024_vl0.580.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5821 - mse: 0.5633 - val_loss: 0.5797 - val_mse: 0.5609\n",
      "Epoch 25/25\n",
      "161/167 [===========================>..] - ETA: 0s - loss: 0.5819 - mse: 0.5631\n",
      "Epoch 25: val_loss improved from 0.57968 to 0.57967, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e025_vl0.580.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5821 - mse: 0.5633 - val_loss: 0.5797 - val_mse: 0.5608\n",
      "Time elapsed to train: 25.06 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.524 3.216 1.810 3.552 2.543 1.893 1.421 1.141 0.783 0.491 0.340 0.244 0.204]\n",
      "<R> = [2.524 3.216 1.810 3.552 2.543 1.893 1.421 1.141 0.783 0.491 0.340 0.244 0.204]\n",
      "s_R = [0.051 0.018 0.000 0.009 0.024 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6800184 2.4224172 6.502566  ... 2.846282  3.998924  4.448448 ]\n",
      "mag_pred: [3.6800184 2.4224172 6.502566  ... 2.846282  3.998924  4.448448 ]\n",
      "Time elapsed to make plots: 18.17 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [38.513657  29.371038  11.937424  ...  3.1555676 34.717598  15.314489 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0099\n",
      "  1% : 0.0924\n",
      "  10% : 0.21\n",
      "  50% : 0.577\n",
      "  90% : 2.99\n",
      "  99% : 66.6\n",
      "  100% : 7e+03\n",
      "<chi^2/d.o.f.> = 0.992\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 16369 stars (6.47%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.8693905 69.0333    13.184446  ...  3.4811964  5.376386  13.377382 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0141\n",
      "  1% : 0.0915\n",
      "  10% : 0.21\n",
      "  50% : 0.583\n",
      "  90% : 2.86\n",
      "  99% : 71.3\n",
      "  100% : 5.17e+03\n",
      "<chi^2/d.o.f.> = 0.988\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 77.63 s\n",
      "learning rate = 2.732372195168864e-05\n",
      "setting learning rate to 2.2370771856165592e-05\n",
      "Iteration 20 of 20.\n",
      "Epoch 1/25\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5827 - mse: 0.5639\n",
      "Epoch 1: val_loss improved from inf to 0.58039, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e001_vl0.580.h5\n",
      "167/167 [==============================] - 2s 8ms/step - loss: 0.5827 - mse: 0.5639 - val_loss: 0.5804 - val_mse: 0.5616\n",
      "Epoch 2/25\n",
      "162/167 [============================>.] - ETA: 0s - loss: 0.5829 - mse: 0.5641\n",
      "Epoch 2: val_loss did not improve from 0.58039\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5827 - mse: 0.5639 - val_loss: 0.5804 - val_mse: 0.5616\n",
      "Epoch 3/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.5830 - mse: 0.5642\n",
      "Epoch 3: val_loss did not improve from 0.58039\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5827 - mse: 0.5639 - val_loss: 0.5805 - val_mse: 0.5617\n",
      "Epoch 4/25\n",
      "161/167 [===========================>..] - ETA: 0s - loss: 0.5828 - mse: 0.5640\n",
      "Epoch 4: val_loss did not improve from 0.58039\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5827 - mse: 0.5639 - val_loss: 0.5806 - val_mse: 0.5618\n",
      "Epoch 5/25\n",
      "160/167 [===========================>..] - ETA: 0s - loss: 0.5829 - mse: 0.5641\n",
      "Epoch 5: val_loss did not improve from 0.58039\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5827 - mse: 0.5639 - val_loss: 0.5804 - val_mse: 0.5616\n",
      "Epoch 6/25\n",
      "158/167 [===========================>..] - ETA: 0s - loss: 0.5824 - mse: 0.5636\n",
      "Epoch 6: val_loss did not improve from 0.58039\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5826 - mse: 0.5638 - val_loss: 0.5804 - val_mse: 0.5616\n",
      "Epoch 7/25\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.5826 - mse: 0.5638\n",
      "Epoch 7: val_loss did not improve from 0.58039\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5827 - mse: 0.5639 - val_loss: 0.5805 - val_mse: 0.5617\n",
      "Epoch 8/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.5830 - mse: 0.5642\n",
      "Epoch 8: val_loss did not improve from 0.58039\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5827 - mse: 0.5638 - val_loss: 0.5805 - val_mse: 0.5617\n",
      "Epoch 9/25\n",
      "163/167 [============================>.] - ETA: 0s - loss: 0.5832 - mse: 0.5644\n",
      "Epoch 9: val_loss did not improve from 0.58039\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5826 - mse: 0.5638 - val_loss: 0.5804 - val_mse: 0.5616\n",
      "Epoch 10/25\n",
      "157/167 [===========================>..] - ETA: 0s - loss: 0.5826 - mse: 0.5638\n",
      "Epoch 10: val_loss did not improve from 0.58039\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5826 - mse: 0.5638 - val_loss: 0.5805 - val_mse: 0.5617\n",
      "Epoch 11/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.5826 - mse: 0.5638\n",
      "Epoch 11: val_loss improved from 0.58039 to 0.58038, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e011_vl0.580.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5827 - mse: 0.5639 - val_loss: 0.5804 - val_mse: 0.5616\n",
      "Epoch 12/25\n",
      "163/167 [============================>.] - ETA: 0s - loss: 0.5830 - mse: 0.5642\n",
      "Epoch 12: val_loss improved from 0.58038 to 0.58035, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e012_vl0.580.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5826 - mse: 0.5638 - val_loss: 0.5804 - val_mse: 0.5616\n",
      "Epoch 13/25\n",
      "156/167 [===========================>..] - ETA: 0s - loss: 0.5824 - mse: 0.5636\n",
      "Epoch 13: val_loss did not improve from 0.58035\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5826 - mse: 0.5638 - val_loss: 0.5804 - val_mse: 0.5616\n",
      "Epoch 14/25\n",
      "163/167 [============================>.] - ETA: 0s - loss: 0.5825 - mse: 0.5637\n",
      "Epoch 14: val_loss did not improve from 0.58035\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5826 - mse: 0.5638 - val_loss: 0.5804 - val_mse: 0.5616\n",
      "Epoch 15/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.5827 - mse: 0.5639\n",
      "Epoch 15: val_loss did not improve from 0.58035\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.5826 - mse: 0.5638 - val_loss: 0.5804 - val_mse: 0.5616\n",
      "Epoch 16/25\n",
      "159/167 [===========================>..] - ETA: 0s - loss: 0.5816 - mse: 0.5629\n",
      "Epoch 16: val_loss improved from 0.58035 to 0.58033, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e016_vl0.580.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5826 - mse: 0.5638 - val_loss: 0.5803 - val_mse: 0.5615\n",
      "Epoch 17/25\n",
      "163/167 [============================>.] - ETA: 0s - loss: 0.5825 - mse: 0.5638\n",
      "Epoch 17: val_loss did not improve from 0.58033\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5826 - mse: 0.5638 - val_loss: 0.5804 - val_mse: 0.5616\n",
      "Epoch 18/25\n",
      "158/167 [===========================>..] - ETA: 0s - loss: 0.5820 - mse: 0.5633\n",
      "Epoch 18: val_loss improved from 0.58033 to 0.58031, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e018_vl0.580.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5826 - mse: 0.5638 - val_loss: 0.5803 - val_mse: 0.5615\n",
      "Epoch 19/25\n",
      "161/167 [===========================>..] - ETA: 0s - loss: 0.5823 - mse: 0.5635\n",
      "Epoch 19: val_loss did not improve from 0.58031\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5826 - mse: 0.5638 - val_loss: 0.5804 - val_mse: 0.5616\n",
      "Epoch 20/25\n",
      "159/167 [===========================>..] - ETA: 0s - loss: 0.5824 - mse: 0.5636\n",
      "Epoch 20: val_loss did not improve from 0.58031\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5826 - mse: 0.5638 - val_loss: 0.5804 - val_mse: 0.5616\n",
      "Epoch 21/25\n",
      "157/167 [===========================>..] - ETA: 0s - loss: 0.5828 - mse: 0.5640\n",
      "Epoch 21: val_loss did not improve from 0.58031\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5826 - mse: 0.5638 - val_loss: 0.5804 - val_mse: 0.5616\n",
      "Epoch 22/25\n",
      "157/167 [===========================>..] - ETA: 0s - loss: 0.5821 - mse: 0.5633\n",
      "Epoch 22: val_loss did not improve from 0.58031\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5826 - mse: 0.5638 - val_loss: 0.5804 - val_mse: 0.5616\n",
      "Epoch 23/25\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5826 - mse: 0.5638\n",
      "Epoch 23: val_loss did not improve from 0.58031\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5826 - mse: 0.5638 - val_loss: 0.5804 - val_mse: 0.5616\n",
      "Epoch 24/25\n",
      "159/167 [===========================>..] - ETA: 0s - loss: 0.5828 - mse: 0.5640\n",
      "Epoch 24: val_loss improved from 0.58031 to 0.58030, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e024_vl0.580.h5\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.5826 - mse: 0.5638 - val_loss: 0.5803 - val_mse: 0.5615\n",
      "Epoch 25/25\n",
      "161/167 [===========================>..] - ETA: 0s - loss: 0.5827 - mse: 0.5639\n",
      "Epoch 25: val_loss did not improve from 0.58030\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.5825 - mse: 0.5638 - val_loss: 0.5803 - val_mse: 0.5616\n",
      "Time elapsed to train: 25.63 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.520 3.212 1.807 3.547 2.539 1.891 1.419 1.140 0.782 0.490 0.340 0.244 0.204]\n",
      "<R> = [2.521 3.212 1.807 3.547 2.539 1.891 1.419 1.140 0.782 0.490 0.340 0.244 0.204]\n",
      "s_R = [0.052 0.018 0.000 0.009 0.024 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6840925 2.4257514 6.508064  ... 2.8511994 4.0018706 4.4518375]\n",
      "mag_pred: [3.6840925 2.4257514 6.508064  ... 2.8511994 4.0018706 4.4518375]\n",
      "Time elapsed to make plots: 22.41 s\n"
     ]
    }
   ],
   "source": [
    "for k in range(0, n_iterations):\n",
    "    # Transform data to inputs and outputs\n",
    "    # On subsequent iterations, inflate errors using\n",
    "    # gradients dM/dtheta from trained model, and derive new\n",
    "    # estimates of the reddenings of the stars.\n",
    "    t0 = time()\n",
    "    io_train = get_inputs_outputs(\n",
    "        d_train,\n",
    "        pretrained_model=None if k == 0 else nn_model,\n",
    "        recalc_reddening=True,\n",
    "        rchisq_max=rchisq_max[k]\n",
    "    )                                                                         \n",
    "    io_test = get_inputs_outputs(                                                      #\n",
    "        d_test,                                                                        #\n",
    "        pretrained_model=None if k == 0 else nn_model,                                 #\n",
    "        recalc_reddening=True,                                                         #\n",
    "    )                                                                                  #                                                                        \n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to prepare data: {t1-t0:.2f} s')\n",
    "\n",
    "    # Set learning rate based on the iteration\n",
    "    lr = 0.001 * np.exp(-0.2*k)\n",
    "    print('learning rate = {}'.format(K.get_value(nn_model.optimizer.lr)))\n",
    "    print('setting learning rate to {}'.format(lr))\n",
    "    K.set_value(nn_model.optimizer.lr, lr)\n",
    "\n",
    "    # Train the model\n",
    "    print('Iteration {} of {}.'.format(k+1, n_iterations))\n",
    "    t0 = time()\n",
    "    train_model(\n",
    "        nn_model,\n",
    "        io_train,\n",
    "        k,\n",
    "        n_iterations,\n",
    "        epochs=25,\n",
    "        checkpoint_fn='{:s}_{:d}hidden_it{:d}'.format(\n",
    "            nn_name, n_hidden, k\n",
    "        ),\n",
    "        batch_size=batch_size,\n",
    "        suff='{:s}_{:d}hidden_it{:d}'.format(nn_name, n_hidden, k)\n",
    "    )\n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to train: {t1-t0:.2f} s')\n",
    "    nn_model.save(\n",
    "        'models/{:s}_{:d}hidden_it{:d}.h5'.format(\n",
    "            nn_name, n_hidden, k\n",
    "        )\n",
    "    )\n",
    "    nn_model = keras.models.load_model(                                                #\n",
    "       'models/{:s}_{:d}hidden_it{:d}.h5'.format(nn_name, n_hidden, k)                 #\n",
    "    )                                                                                  #\n",
    "                                                                                       #\n",
    "    # Plot results on test set                                                         #\n",
    "    print('Diagnostic plots ...')                                                      #\n",
    "    t0 = time()                                                                        #\n",
    "    diagnostic_plots(                                                                  #\n",
    "       nn_model,                                                                       #\n",
    "       io_test,                                                                        #\n",
    "       d_test,                                                                         #\n",
    "       #io_train,                                                                      #\n",
    "       #d_train,                                                                       #\n",
    "       suffix='{:s}_{:d}hidden_it{:d}'.format(nn_name, n_hidden, k)                    #\n",
    "    )                                                                                  #\n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to make plots: {t1-t0:.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1d8de09-5d9d-43a1-b6ad-5aa70393a40a",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating covariances and reddening estimates of test dataset ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.718401  68.883255  13.393291  ...  3.5571046  5.377717  13.589398 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0153\n",
      "  1% : 0.0917\n",
      "  10% : 0.209\n",
      "  50% : 0.582\n",
      "  90% : 2.87\n",
      "  99% : 71.2\n",
      "  100% : 5.17e+03\n",
      "<chi^2/d.o.f.> = 0.988\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to update covariances and reddenings: 8.08 s\n"
     ]
    }
   ],
   "source": [
    "print('Updating covariances and reddening estimates of test dataset ...')\n",
    "t0 = time()\n",
    "io_test = get_inputs_outputs(\n",
    "    d_test,\n",
    "    pretrained_model=nn_model,\n",
    "    recalc_reddening=True\n",
    ")\n",
    "t1 = time()\n",
    "print(f'Time elapsed to update covariances and reddenings: {t1-t0:.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fe20ad0-6076-42e4-b5fa-0a8b44b55833",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: [0.5778622031211853, 0.5590957999229431]\n",
      "train loss: [0.5819011926651001, 0.5631348490715027]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance on (train, validation and test sets)\n",
    "loss = {}\n",
    "for n,io_eval in (('test',io_test), ('train',io_train)):\n",
    "    loss[n] = evaluate_model(\n",
    "        nn_model,\n",
    "        io_eval,\n",
    "        batch_size=batch_size,\n",
    "        rchisq_max=rchisq_max[-1]\n",
    "    )\n",
    "    print(f'{n} loss: {loss[n]}')\n",
    "fname = 'loss_{:s}_{:d}hidden_it{:d}.json'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "with open(fname, 'w') as f:\n",
    "    json.dump(loss, f, indent=2, sort_keys=True)\n",
    "\n",
    "fname = 'predictions_{:s}_{:d}hidden_it{:d}.h5'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "save_predictions(fname, nn_model, d_test, io_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ef83a49-55d7-41f4-be9e-87606f86734e",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving covariance components for small subset of test dataset ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 1000 bad. Replacing with 14.23750.\n",
      "Band 1: 0 of 1000 bad. Replacing with 14.61455.\n",
      "Band 2: 0 of 1000 bad. Replacing with 13.69537.\n",
      "Band 3: 147 of 1000 bad. Replacing with 14.96300.\n",
      "Band 4: 250 of 1000 bad. Replacing with 14.65440.\n",
      "Band 5: 310 of 1000 bad. Replacing with 14.59245.\n",
      "Band 6: 192 of 1000 bad. Replacing with 14.30900.\n",
      "Band 7: 33 of 1000 bad. Replacing with 14.03010.\n",
      "Band 8: 0 of 1000 bad. Replacing with 13.05500.\n",
      "Band 9: 1 of 1000 bad. Replacing with 12.69000.\n",
      "Band 10: 4 of 1000 bad. Replacing with 12.60650.\n",
      "Band 11: 1 of 1000 bad. Replacing with 15.26814.\n",
      "Band 12: 2 of 1000 bad. Replacing with 15.92215.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 1000 of 1000 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [6.18347073e+00 9.39991856e+00 1.19382610e+01 9.41270351e+00\n",
      " 6.93494463e+00 2.08895950e+01 1.03112526e+01 1.22609726e+02\n",
      " 9.10791779e+01 4.99939346e+00 2.51829796e+01 2.02065611e+00\n",
      " 7.05638647e+00 3.99391251e+01 9.98366737e+00 4.90641737e+00\n",
      " 1.25135016e+00 2.11246037e+00 1.65129623e+01 9.10662079e+00\n",
      " 2.26725388e+01 1.29326677e+00 4.36681023e+01 3.65495563e+00\n",
      " 7.10360050e+00 7.19487333e+00 1.11963880e+00 1.94014664e+01\n",
      " 3.91751766e+00 3.29726362e+00 2.63355541e+00 1.21184978e+01\n",
      " 5.47383003e+01 3.89661636e+01 5.42105484e+00 3.19331312e+00\n",
      " 3.24788237e+00 6.38653803e+00 1.36912422e+01 3.21149635e+00\n",
      " 8.01734467e+01 1.25852448e+02 8.71716690e+00 6.89061642e+00\n",
      " 2.31192064e+00 4.52206945e+00 6.69824123e+00 7.32302380e+00\n",
      " 1.57621038e+00 1.98715472e+00 8.21914768e+00 2.28322554e+00\n",
      " 9.63793755e-01 1.14643106e+01 5.27530909e+00 6.77197266e+00\n",
      " 5.92504025e+00 7.24084139e+00 6.66027546e+00 7.31545353e+00\n",
      " 5.91248798e+00 3.82478905e+00 7.34583092e+00 1.55245361e+01\n",
      " 9.56855714e-01 2.37410021e+00 2.48738551e+00 1.82300496e+00\n",
      " 7.54131079e+00 2.56512604e+01 1.21731186e+01 6.81356144e+00\n",
      " 3.58675432e+00 1.09088755e+01 4.15367699e+00 4.93864298e+00\n",
      " 2.35429115e+01 6.23378992e+00 3.41666679e+01 1.37962112e+01\n",
      " 5.94508219e+00 1.49910355e+01 7.63136816e+00 9.79884911e+00\n",
      " 8.24855328e+00 1.67586956e+01 1.47712851e+01 4.81962156e+00\n",
      " 6.81936836e+00 2.98036027e+00 2.06343765e+01 6.72067785e+00\n",
      " 7.45754623e+00 5.33579636e+00 4.58866405e+00 7.72316265e+00\n",
      " 4.26688337e+00 2.96502066e+00 6.92638683e+00 3.40283966e+00\n",
      " 5.93692398e+00 1.49968491e+01 6.70650787e+01 1.00651541e+01\n",
      " 1.53089027e+01 6.98649836e+00 2.18390198e+01 2.56373048e+00\n",
      " 4.45990448e+01 6.27688360e+00 1.05442238e+01 3.45988417e+00\n",
      " 4.90480757e+00 5.86912727e+00 2.66489077e+00 9.82250595e+00\n",
      " 6.70543385e+00 3.63468790e+00 2.79165268e+00 5.32569647e+00\n",
      " 2.33121967e+00 1.13921537e+01 4.60449934e+00 6.35837793e+00\n",
      " 4.02686691e+00 2.88340187e+00 1.99446983e+01 3.34719086e+00\n",
      " 3.24233704e+01 1.84700203e+00 2.20108581e+00 8.82196617e+00\n",
      " 1.54676557e+00 1.36996496e+00 5.27718496e+00 4.30332136e+00\n",
      " 6.35302830e+00 1.87994938e+01 9.33128738e+00 4.08730841e+00\n",
      " 6.04571486e+00 4.66297436e+00 1.21477890e+01 2.94117546e+00\n",
      " 2.41814499e+01 1.08222031e+02 1.68747687e+00 7.28455200e+01\n",
      " 2.13743553e+01 1.21467054e+00 2.92156482e+00 7.65284586e+00\n",
      " 2.44811363e+01 5.37460022e+01 4.12370682e+00 7.00805950e+00\n",
      " 3.02609301e+00 1.02611637e+01 3.03429937e+00 2.69193916e+01\n",
      " 5.14270878e+00 1.04306126e+00 6.26199722e+00 2.74411278e+01\n",
      " 1.64185467e+01 5.24037218e+00 1.33430939e+02 7.63782930e+00\n",
      " 6.72819662e+00 1.28462563e+01 7.23437190e-01 6.01770306e+00\n",
      " 7.87075424e+00 9.63852024e+00 4.52489138e+00 2.67739105e+00\n",
      " 4.53834677e+00 1.24485458e+02 8.91090298e+00 7.38508320e+00\n",
      " 5.88530636e+00 2.04479980e+01 2.25946808e+00 6.24936152e+00\n",
      " 6.25181103e+00 4.17865610e+00 7.56815815e+00 1.63695099e+02\n",
      " 1.69641113e+00 2.63194351e+01 4.77775145e+00 5.05444241e+00\n",
      " 7.40350389e+00 5.08923292e+00 2.85413313e+00 5.87528610e+00\n",
      " 1.37358917e+02 2.01409626e+01 4.47560120e+00 2.42777920e+00\n",
      " 6.43607855e+00 7.25104046e+00 2.87032890e+00 1.47795887e+01\n",
      " 9.43440437e+00 7.54147863e+00 6.58665752e+00 3.35905337e+00\n",
      " 9.75415587e-01 6.13812542e+00 4.22636700e+00 5.47781801e+00\n",
      " 9.49512482e+00 4.94729137e+00 6.48791599e+00 2.21321821e+00\n",
      " 2.09260607e+00 1.08052235e+01 8.01493764e-01 8.75815749e-01\n",
      " 6.70813751e+00 1.13204269e+01 2.42685394e+01 1.31048222e+01\n",
      " 2.44196010e+00 3.12827039e+00 1.08797264e+01 1.64887390e+01\n",
      " 3.19589972e-01 1.80580273e+01 5.28886414e+00 3.72407898e+02\n",
      " 7.47564983e+00 5.44544315e+00 6.65740061e+00 4.25658321e+00\n",
      " 5.60380459e+00 5.37670517e+00 7.23507261e+00 2.40832901e+01\n",
      " 1.43872547e+00 1.26351585e+01 3.38148260e+00 6.18452148e+02\n",
      " 6.08142900e+00 4.81486416e+00 4.95725155e+00 1.12531643e+01\n",
      " 5.86105299e+00 2.22888613e+00 9.39094925e+00 2.01663208e+00\n",
      " 6.79914904e+00 3.09502125e+00 2.09687157e+01 9.23532772e+00\n",
      " 1.02663288e+01 9.47050571e+00 7.41504550e-01 6.68473053e+01\n",
      " 3.40717102e+02 6.74411535e+00 4.19979286e+00 6.05793571e+00\n",
      " 1.10410137e+01 5.65968657e+00 4.95061684e+00 3.15574598e+00\n",
      " 2.51044807e+01 4.45487547e+00 1.97815299e+00 3.60198069e+00\n",
      " 4.06054688e+00 3.79166722e+00 1.79274750e+01 8.57877159e+00\n",
      " 6.39592505e+00 3.26851225e+00 2.69692307e+01 2.14714360e+00\n",
      " 2.37541885e+01 1.04866161e+01 4.10733652e+00 1.29471359e+01\n",
      " 3.98503609e+01 4.83757639e+00 8.21501446e+00 1.45647883e+00\n",
      " 5.51013279e+00 7.11589289e+00 8.22599983e+00 1.62953968e+01\n",
      " 5.39625740e+00 1.09413586e+01 4.45771942e+01 2.39658666e+00\n",
      " 1.41085091e+01 6.62913847e+00 2.56864738e+01 2.34690022e+00\n",
      " 2.86519384e+00 1.43232870e+00 1.13622751e+01 3.03152585e+00\n",
      " 5.59242630e+00 4.39921999e+00 2.44669461e+00 6.67669725e+00\n",
      " 2.03301477e+00 8.64995193e+00 4.73601379e+01 1.80348625e+01\n",
      " 2.56196156e+01 1.75393162e+01 6.19649363e+00 1.37725294e+00\n",
      " 2.52473211e+00 5.77400303e+00 4.32505178e+00 3.36100030e+00\n",
      " 3.80888414e+00 8.80491161e+00 3.47805333e+00 2.38757191e+01\n",
      " 3.61042023e+00 2.24446917e+00 4.26554251e+00 2.49047732e+00\n",
      " 3.75959420e+00 5.33037567e+00 6.35192060e+00 6.27634525e+00\n",
      " 6.74554348e+00 2.63522005e+00 1.71416998e+00 2.72275209e+00\n",
      " 2.06959534e+00 2.83630714e+01 4.98651695e+00 1.10310173e+02\n",
      " 2.46236897e+00 3.10750103e+00 9.16575470e+01 5.66492796e+00\n",
      " 1.66409874e+00 6.02345991e+00 5.86790657e+00 2.68605232e+01\n",
      " 8.31329286e-01 6.00193119e+00 1.10617886e+01 1.00317991e+00\n",
      " 1.98384056e+01 3.10489631e+00 5.06681854e+02 8.34928894e+00\n",
      " 3.83511047e+01 3.55710459e+00 6.93642712e+00 1.34885578e+01\n",
      " 4.87406826e+00 4.54163933e+00 1.73930206e+01 2.75667858e+00\n",
      " 2.59351749e+01 5.23042488e+00 1.48197422e+01 2.30340242e+00\n",
      " 9.48927939e-01 7.13993263e+00 5.77241611e+00 2.16902905e+01\n",
      " 1.08573599e+01 6.66426277e+00 5.93497562e+00 6.49978828e+00\n",
      " 6.21997738e+00 1.94755096e+01 9.27395630e+00 2.58211493e+00\n",
      " 1.32120392e+02 3.89579916e+00 2.95810623e+01 2.92783785e+00\n",
      " 3.70632291e+00 5.07293606e+00 3.04983211e+00 1.03517628e+00\n",
      " 4.99167538e+00 2.44962406e+00 4.76855659e+00 9.61431980e+00\n",
      " 7.91984034e+00 3.61151433e+00 9.53508186e+00 4.02287231e+02\n",
      " 8.20798874e+00 1.08279533e+01 9.38472843e+00 7.38156462e+00\n",
      " 1.01917992e+01 1.67041931e+01 2.06545410e+01 1.37846434e+00\n",
      " 1.34979463e+00 2.29970264e+00 2.67285204e+00 4.50825453e+00\n",
      " 3.04337049e+00 2.83820868e+00 4.90521765e+00 1.57074738e+00\n",
      " 5.89383602e+00 2.36581738e+03 8.50058258e-01 5.36987114e+00\n",
      " 8.93345032e+01 1.67538548e+01 1.67839909e+00 1.48564026e+02\n",
      " 5.13569689e+00 7.99707365e+00 3.63031936e+00 9.89227829e+01\n",
      " 8.61204681e+01 2.66672516e+00 7.84531069e+00 4.15293550e+00\n",
      " 9.14758396e+00 1.48653393e+01 2.03910542e+00 8.95788097e+00\n",
      " 3.12945328e+01 1.56539850e+01 8.96569252e+00 1.25333786e+01\n",
      " 1.03698568e+01 2.44816780e+01 1.01744871e+01 7.29199886e+00\n",
      " 7.25630283e+00 5.75990152e+00 2.56469870e+00 1.05255318e+01\n",
      " 6.26544619e+00 7.59332514e+00 5.28506947e+00 2.41211939e+00\n",
      " 4.21629105e+01 7.61783371e+01 3.12308478e+00 3.84405684e+00\n",
      " 1.69244461e+01 4.40340519e+00 4.01762199e+00 2.40602422e+00\n",
      " 1.36248875e+00 5.98704338e+00 9.03880835e-01 8.57113361e+00\n",
      " 8.83943176e+00 6.25305462e+00 6.28335524e+00 1.99118710e+00\n",
      " 4.54419518e+01 3.43740749e+00 5.53512096e+00 4.06605721e+00\n",
      " 2.80692024e+01 3.49277425e+00 7.74712133e+00 1.00619555e+00\n",
      " 2.56534290e+00 6.61714792e+00 9.42176044e-01 2.25362730e+00\n",
      " 4.90931015e+01 4.43602562e+00 2.34930840e+01 4.37552109e+01\n",
      " 1.94019909e+01 1.32871723e+01 8.02420044e+00 5.23703223e+03\n",
      " 8.73295116e+00 7.26599503e+00 1.55285048e+00 2.77851391e+00\n",
      " 3.16630173e+00 1.13685560e+01 5.28604221e+00 2.69762039e+00\n",
      " 2.84775281e+00 4.33346415e+00 5.97970009e+00 2.36296916e+00\n",
      " 2.58662844e+00 2.54947448e+00 5.19472885e+00 5.68819046e+00\n",
      " 5.36816788e+00 1.16627769e+01 7.84327698e+00 2.88997698e+00\n",
      " 1.96476269e+01 5.35691404e+00 5.90117550e+00 4.80879688e+00\n",
      " 7.01415157e+00 8.51808357e+00 1.88022594e+01 1.99154186e+00\n",
      " 7.30526781e+00 6.02101612e+00 7.88513708e+00 8.85179520e+00\n",
      " 1.36196003e+01 7.16519833e+00 1.19070654e+01 1.47599030e+01\n",
      " 4.01476479e+00 8.15990162e+00 6.70727396e+00 3.95777655e+00\n",
      " 3.02700496e+00 4.53622532e+00 5.35251198e+01 3.37394094e+00\n",
      " 5.35756588e+00 4.66492424e+01 8.06600952e+00 3.52808046e+00\n",
      " 1.30781116e+01 3.70857596e+00 4.61830997e+00 4.29011488e+00\n",
      " 7.85269141e-01 6.38351488e+00 1.50501223e+01 4.16569710e+00\n",
      " 1.87375393e+01 1.33604240e+01 3.07526898e+00 2.50712585e+01\n",
      " 1.52309999e+01 2.65124273e+00 1.71411400e+01 4.45066929e+00\n",
      " 2.49102974e+00 2.13564777e+00 2.85789871e+00 7.80651474e+00\n",
      " 1.61045399e+01 6.40025482e+01 1.75408649e+00 1.08246565e+01\n",
      " 3.15645905e+01 1.10064182e+01 1.38575821e+01 7.44271088e+00\n",
      " 2.39542055e+00 6.20868504e-01 1.96751900e+01 6.66328907e+00\n",
      " 1.66365230e+00 1.91785896e+00 5.40160894e+00 4.09037971e+00\n",
      " 3.08870435e+00 1.75650907e+00 6.70007420e+00 3.85077548e+00\n",
      " 8.65699768e+00 2.74855560e+02 1.17085371e+01 1.87461319e+01\n",
      " 6.36832047e+00 6.76175766e+01 2.23848457e+01 1.43351114e+00\n",
      " 2.49681878e+00 1.28473606e+01 6.64472675e+00 3.16543150e+00\n",
      " 8.25514889e+00 7.12297344e+00 1.44155884e+00 4.13659191e+00\n",
      " 2.58047600e+01 3.74766779e+00 9.87264061e+00 2.77848339e+00\n",
      " 3.89439917e+00 3.25436640e+00 7.62004185e+00 4.78206110e+00\n",
      " 6.75569916e+00 3.10323691e+00 8.96696167e+01 1.22595024e+01\n",
      " 1.32856464e+01 2.19336758e+01 3.84866691e+00 8.83368969e+00\n",
      " 1.57355175e+01 6.89138126e+00 9.59801292e+00 7.08568478e+00\n",
      " 1.36986542e+01 1.59236938e+02 3.50492764e+00 7.13581753e+00\n",
      " 9.25488892e+01 5.40778046e+01 5.89132738e+00 4.98983288e+00\n",
      " 7.10293674e+00 8.39136314e+00 9.19148064e+00 1.58896577e+00\n",
      " 1.91024482e+00 2.91190128e+01 5.60058212e+00 2.32131553e+00\n",
      " 1.01567745e+01 2.84189963e+00 8.76821232e+00 1.83676891e+01\n",
      " 3.81543970e+00 4.42288361e+01 1.07376938e+01 1.17450523e+01\n",
      " 8.57198524e+00 2.10654259e+01 3.27063227e+00 5.48984814e+00\n",
      " 1.28612299e+01 7.28498077e+00 3.78084755e+00 4.53971434e+00\n",
      " 3.22225037e+01 2.98644400e+00 7.91955614e+00 1.50082512e+01\n",
      " 2.89343491e+01 2.04214439e+01 1.24100094e+01 2.31995535e+00\n",
      " 3.72066355e+00 6.46891403e+00 4.94982386e+00 1.35212049e+01\n",
      " 9.18085098e+00 1.19606743e+01 7.37307596e+00 2.31712704e+01\n",
      " 9.38728523e+00 1.05135560e+00 5.78940186e+03 4.12722015e+00\n",
      " 3.00171518e+00 5.79772282e+00 3.82206321e+00 7.20378399e+00\n",
      " 6.81427288e+00 2.13153577e+00 3.71669006e+00 2.03923492e+01\n",
      " 1.42812777e+01 6.21970749e+00 1.93636703e+00 1.21592350e+01\n",
      " 4.37246857e+01 9.38323402e+00 6.85067673e+01 1.35911703e+00\n",
      " 2.49832439e+00 3.65168810e+00 7.96695099e+01 2.31952209e+01\n",
      " 7.57736158e+00 9.06037521e+00 2.00906334e+01 6.55713320e+00\n",
      " 5.04942989e+00 9.99776077e+00 1.90404396e+01 7.93865013e+00\n",
      " 1.76147795e+00 7.64439964e+00 5.78187370e+00 4.90739822e+00\n",
      " 2.39998199e+02 5.50439692e+00 1.59566803e+01 4.10392857e+00\n",
      " 3.62062025e+00 4.06874514e+00 7.21531153e+00 9.90523529e+00\n",
      " 1.28929014e+01 9.66478729e+00 1.26452112e+00 2.25741053e+00\n",
      " 1.37314110e+01 2.41984070e+02 7.04423666e+00 8.26092339e+00\n",
      " 9.67288613e-01 1.01974649e+01 4.40775490e+00 1.27960235e-01\n",
      " 1.24842644e+02 6.83355272e-01 1.59471951e+01 2.40511513e+01\n",
      " 4.15289354e+00 2.98723173e+00 7.47299576e+00 5.74502373e+00\n",
      " 1.36883378e+00 7.78610802e+00 1.36580982e+01 1.49377871e+01\n",
      " 2.14326763e+00 1.67884769e+01 9.08146572e+00 5.84698963e+00\n",
      " 3.32776108e+01 6.06057434e+01 2.47732210e+00 1.75816803e+01\n",
      " 2.08493843e+01 3.77632928e+00 6.93935251e+00 5.09486341e+00\n",
      " 4.84951735e+00 3.09585533e+01 8.06350517e+00 3.65618115e+03\n",
      " 5.35204315e+00 4.23834181e+00 4.08596134e+00 7.35012007e+00\n",
      " 7.58342552e+00 8.39323425e+00 4.87578773e+00 1.04042912e+01\n",
      " 2.09908128e+00 3.13030005e+00 1.21540365e+01 2.69131327e+00\n",
      " 6.69774342e+00 9.73702621e+00 3.44865082e+02 4.75499201e+00\n",
      " 3.29438448e+00 1.18791771e+01 1.46867456e+01 1.95293677e+00\n",
      " 1.03046675e+01 5.89907503e+00 4.53745699e+00 6.07861853e+00\n",
      " 6.64575577e+00 5.75800085e+00 4.80474901e+00 5.35306644e+00\n",
      " 7.09229660e+00 1.85866489e+01 1.53169613e+01 6.86921120e+00\n",
      " 9.08363914e+00 1.18152313e+01 2.48875885e+01 1.57032514e+00\n",
      " 2.99470639e+00 1.43070593e+01 3.74803209e+00 1.28077621e+01\n",
      " 5.86722803e+00 3.50728273e+00 6.94573975e+01 9.00715828e+00\n",
      " 3.97193074e+00 2.85265255e+00 7.99528360e+00 2.33692527e+00\n",
      " 3.96295953e+00 1.92619896e+01 5.37569141e+00 1.12560329e+01\n",
      " 1.58348866e+01 9.45569706e+00 1.34920864e+01 4.80337677e+01\n",
      " 1.06567221e+01 5.58817530e+00 1.90921230e+01 3.58735895e+00\n",
      " 4.84631271e+01 6.85173702e+00 1.20719795e+01 2.66076994e+00\n",
      " 6.71170616e+00 1.39346683e+00 3.51553202e+00 2.04195118e+00\n",
      " 9.46349144e+00 1.59480429e+01 4.22209454e+00 3.01692009e+00\n",
      " 3.88441396e+00 2.44104385e+00 1.43139420e+01 1.57852354e+01\n",
      " 4.16948509e+00 1.56623278e+01 2.28048968e+00 5.47903347e+00\n",
      " 4.30822182e+01 2.39423132e+00 5.21436157e+02 1.46308107e+01\n",
      " 5.07165074e-01 5.70112038e+00 7.09961557e+00 4.37551975e+00\n",
      " 2.92291565e+01 1.42228231e+01 9.85197163e+00 1.58318530e+03\n",
      " 9.32665920e+00 7.41842318e+00 8.07748318e+00 5.11791563e+00\n",
      " 2.64780092e+00 6.10677338e+00 1.07435102e+01 3.98879170e+00\n",
      " 2.87849503e+01 1.24648447e+01 2.30184484e+00 3.30713425e+01\n",
      " 1.98392735e+01 9.87802887e+00 1.11876802e+01 6.87210751e+00\n",
      " 9.83358002e+00 1.61141052e+02 9.41360092e+00 7.78788090e+00\n",
      " 8.02505493e+00 3.30995154e+00 1.70299988e+01 1.57061052e+01\n",
      " 4.25151405e+01 1.05188189e+01 4.61598492e+00 1.72020376e+00\n",
      " 5.95125246e+00 5.53903580e+00 5.22981873e+01 3.43919992e+00\n",
      " 6.43961716e+00 2.72462821e+00 7.79218292e+00 2.86970663e+00\n",
      " 3.92511487e+00 2.30346889e+01 7.80845737e+00 9.78027439e+00\n",
      " 1.33051634e+00 7.76463509e+00 1.13635181e+03 6.24560165e+00\n",
      " 5.97574463e+01 4.77058640e+01 1.42109060e+00 2.57989883e+01\n",
      " 2.12544327e+01 4.32611275e+00 7.86893082e+00 1.81534348e+01\n",
      " 6.97801971e+01 6.33985472e+00 6.30358086e+01 1.14716473e+01\n",
      " 1.51885486e+00 4.17238426e+00 2.74984431e+00 2.80428619e+01\n",
      " 1.11765461e+01 8.09981155e+01 4.44391537e+00 7.46032910e+03\n",
      " 3.13122606e+00 3.55024576e+00 1.91807902e+00 3.08176193e+01\n",
      " 2.79262590e+00 2.32916021e+00 4.23693962e+01 1.00365372e+01\n",
      " 3.81280279e+00 4.05587692e+01 3.64152002e+00 2.27393994e+03\n",
      " 1.28873253e+00 2.61017776e+00 1.19961901e+01 4.05878210e+00\n",
      " 7.07012796e+00 5.09975481e+00 5.26002026e+00 5.76117086e+00\n",
      " 4.11893034e+00 5.63464355e+00 5.07059526e+00 3.65534363e+01\n",
      " 5.78670263e+00 2.86575365e+00 2.93313742e+00 4.37006149e+01\n",
      " 4.81262159e+00 3.55963588e+00 9.61904621e+00 6.79319477e+00\n",
      " 4.58301812e-01 5.92556190e+00 3.16295528e+00 8.30944061e+00\n",
      " 2.64584274e+01 2.90354176e+01 8.04708242e-01 1.37464142e+00\n",
      " 9.90830326e+00 4.09726334e+00 2.07739830e+00 2.15437603e+00\n",
      " 3.27089953e+00 8.50846291e+00 3.89785099e+00 2.02282791e+01\n",
      " 5.17248535e+00 4.25373411e+00 2.19208431e+00 7.03579092e+00\n",
      " 5.14109253e+02 3.57466483e+00 2.42333350e+03 1.20479946e+01\n",
      " 2.63961792e+00 5.56713247e+00 1.80000458e+02 2.24965935e+01\n",
      " 3.58636475e+00 2.90759301e+00 1.07102757e+01 2.46350718e+00\n",
      " 2.37306244e+02 4.71889771e+02 9.02351856e+00 7.94456339e+00\n",
      " 1.44274464e+01 4.01013708e+00 2.37524033e+00 5.91459778e+02\n",
      " 8.25741196e+00 6.35106850e+00 3.51908326e+00 4.22240791e+01\n",
      " 2.47860408e+00 7.47251606e+00 1.98298383e+00 2.44196320e+00\n",
      " 5.14674759e+00 2.33967805e+00 6.17226028e+00 1.78119326e+00\n",
      " 6.37939835e+00 2.17737274e+01 2.68617964e+00 2.21627903e+00\n",
      " 4.76205158e+00 5.76778841e+00 9.94668484e+00 5.27250338e+00\n",
      " 4.01893806e+00 2.55612602e+01 4.35775948e+01 3.03196740e+00\n",
      " 2.32724056e+01 9.43868351e+00 4.47800970e+00 1.10430422e+01\n",
      " 4.12537718e+00 2.84338260e+00 7.04969788e+00 5.22638988e+00]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0183\n",
      "  1% : 0.0803\n",
      "  10% : 0.203\n",
      "  50% : 0.566\n",
      "  90% : 2.77\n",
      "  99% : 51.9\n",
      "  100% : 746\n",
      "<chi^2/d.o.f.> = 1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n"
     ]
    }
   ],
   "source": [
    "print('Saving covariance components for small subset of test dataset ...')\n",
    "# Fix random seed (same subset every run)\n",
    "np.random.seed(3)\n",
    "idx = np.arange(d_test.size)\n",
    "np.random.shuffle(idx)\n",
    "idx = idx[:1000]\n",
    "d_comp = d_test[idx]\n",
    "io_comp = get_inputs_outputs(\n",
    "    d_comp,\n",
    "    pretrained_model=nn_model,\n",
    "    recalc_reddening=True,\n",
    "    return_cov_components=True\n",
    ")\n",
    "fname = 'predictions_{:s}_{:d}hidden_it{:d}_comp.h5'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "save_predictions(fname, nn_model, d_comp, io_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bf3ec27-6103-4713-9c21-1222e68e39f1",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data and reddening estimates of subset of test dataset ...\n"
     ]
    }
   ],
   "source": [
    "print('Saving data and reddening estimates of subset of test dataset ...')\n",
    "np.random.seed(5)\n",
    "idx = np.arange(d_test.size)\n",
    "np.random.shuffle(idx)\n",
    "idx = idx[:10000]\n",
    "d_small = d_test[idx]\n",
    "r_fit_small = io_test['r'][idx]\n",
    "r_var_small = io_test['r_var'][idx]\n",
    "fname = 'test_data_small_{:s}_{:d}hidden.h5'.format(\n",
    "    nn_name, n_hidden\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82da0ebc-697f-4f8b-ae07-05ba4f0e7217",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving subset to test_data_small_ext_0h_l1n2_2hidden.h5 ...\n"
     ]
    }
   ],
   "source": [
    "print(f'Saving subset to {fname} ...')\n",
    "with h5py.File(fname, 'w') as f:\n",
    "    dset = f.create_dataset(\n",
    "        'data',\n",
    "        data=d_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )\n",
    "    for key in d_attrs:\n",
    "        dset.attrs[key] = d_attrs[key]\n",
    "\n",
    "    # Store updated reddening estimates\n",
    "    dset = f.create_dataset(\n",
    "        'r_fit',\n",
    "        data=r_fit_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )\n",
    "    dset = f.create_dataset(\n",
    "        'r_var',\n",
    "        data=r_var_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 2,
      "defaultCellHeight": 40,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
