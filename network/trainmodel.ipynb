{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b43db49-f88d-44af-8188-9c546a2bb2e1",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "source": [
    "Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12337364-915d-45e0-aa68-ff9ad349e998",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "# # Tell Tensorflow not to allocate all GPU memory right away.\n",
    "# # This is very important in shared environments!\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU') \n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from glob import glob\n",
    "from time import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b0b4d-d609-4535-82f4-76f5979bb893",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### The dataloder used by Green+2020 which will be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f39968a5-1090-448f-a6dc-b53829db1f41",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def load_data(fname, return_attrs=False):\n",
    "    print(f'Loading {fname} ...')\n",
    "    attrs = {}\n",
    "    with h5py.File(fname, 'r') as f:\n",
    "        dset = f['io_data']\n",
    "        for key in dset.attrs.keys():\n",
    "            attrs[key] = dset.attrs[key]\n",
    "        d = dset[:]\n",
    "    \n",
    "    if return_attrs:\n",
    "        return d, attrs\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a7c2e5-f232-46ff-b235-d6604c1b5d35",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Obtaining a correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e0eccc-4ffd-4904-a210-7b430692c477",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def get_corr_matrix(cov):\n",
    "    rho = cov.copy()\n",
    "    sqrt_cov_diag = np.sqrt(cov[np.diag_indices(cov.shape[0])])\n",
    "    rho /= sqrt_cov_diag[:,None]\n",
    "    rho /= sqrt_cov_diag[None,:]\n",
    "    rho[np.diag_indices(cov.shape[0])] = sqrt_cov_diag\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f2ec3-9dba-4970-ab73-494dddd61534",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Cannot be explained in one markdown cell above, need to look through it more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72257ca9-2c06-4d52-9589-9b9086876356",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def get_inputs_outputs(d, pretrained_model=None,\n",
    "                          recalc_reddening=False,\n",
    "                          rchisq_max=None,\n",
    "                          return_cov_components=False):\n",
    "    n_bands = 13 # Gaia (G, BP, RP), PS1 (grizy), 2MASS (JHK), unWISE (W1,W2)\n",
    "    n_atm_params = 3 # (T_eff, logg, [M/H])\n",
    "    \n",
    "    large_err = 999.\n",
    "\n",
    "    # Stellar spectroscopic parameters\n",
    "    print('Fill in stellar atmospheric parameters ...')\n",
    "    x = np.empty((d.size,3), dtype='f4')\n",
    "    x[:] = d['atm_param'][:]\n",
    "\n",
    "    x_p = np.empty((d.size,3), dtype='f4')\n",
    "    x_p = d['atm_param_p'][:]\n",
    "\n",
    "    # Magnitudes\n",
    "    print('Fill in stellar magnitudes ...')\n",
    "    y = np.empty((d.size,n_bands), dtype='f4')\n",
    "    y[:] = d['mag'][:]\n",
    "\n",
    "    # Covariance of y\n",
    "    print('Empty covariance matrix ...')\n",
    "    cov_y = np.zeros((d.size,n_bands,n_bands), dtype='f4')\n",
    "\n",
    "    # \\delta m\n",
    "    print('Covariance: \\delta m ...')\n",
    "    for i in range(n_bands):\n",
    "        cov_y[:,i,i] = d['mag_err'][:,i]**2\n",
    "\n",
    "    # Replace NaN magnitudes with median (in each band).\n",
    "    # Also set corresponding variances to large number.\n",
    "    print('Replace NaN magnitudes ...')\n",
    "    for b in range(n_bands):\n",
    "        idx = (\n",
    "              ~np.isfinite(y[:,b])\n",
    "            | ~np.isfinite(cov_y[:,b,b])\n",
    "        )\n",
    "        n_bad = np.count_nonzero(idx)\n",
    "        n_tot = idx.size\n",
    "        y0 = np.median(y[~idx,b])\n",
    "        if np.isnan(y0):\n",
    "            y0 = 0.\n",
    "        print(f'Band {b}: {n_bad} of {n_tot} bad. Replacing with {y0:.5f}.')\n",
    "        y[idx,b] = y0\n",
    "        cov_y[idx,b,b] = large_err**2.\n",
    "\n",
    "    # Transform both y and its covariance\n",
    "    B = np.identity(n_bands, dtype='f4')\n",
    "    B[1:,0] = -1.\n",
    "    \n",
    "    print('Transform y -> B y ...')\n",
    "    y = np.einsum('ij,nj->ni', B, y) # y' = B y\n",
    "    print('Transform C -> B C B^T ...')\n",
    "    #cov_y = np.einsum('ik,nkl,jl->nij', B, cov_y, B) # C' = B C B^T\n",
    "    cov_y = np.einsum('nik,jk->nij', cov_y, B)\n",
    "    cov_y = np.einsum('ik,nkj->nij', B, cov_y)\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp = {\n",
    "            'delta_m': cov_y.copy()\n",
    "        }\n",
    "    \n",
    "    # Add in dM/dtheta and dR/dtheta terms\n",
    "    if pretrained_model is not None:\n",
    "        print('Calculate J = dM/dtheta ...')\n",
    "        J_M = calc_dmag_color_dtheta(pretrained_model, x_p)\n",
    "        cov_x = d['atm_param_cov_p']\n",
    "        print('Covariance: J C_theta J^T ...')\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_M)\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['dM/dtheta'] = np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_M)\n",
    "\n",
    "    # If pretrained model provided, could calculate reduced chi^2\n",
    "    # with maximum-likelihood (mu, E) here.\n",
    "\n",
    "    # \\delta \\mu (must be added in after transformation,\n",
    "    #             due to possibly infinite terms).\n",
    "    print('{:d} NaN parallaxes'.format(\n",
    "        np.count_nonzero(np.isnan(d['parallax']))\n",
    "    ))\n",
    "    err_over_plx = d['parallax_err'] / d['parallax']\n",
    "    print('Covariance: DM uncertainty term ...')\n",
    "    cov_y[:,0,0] += (5./np.log(10.) * err_over_plx)**2.\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp['dm'] = np.zeros_like(cov_y)\n",
    "        cov_comp['dm'][:,0,0] = (5./np.log(10.) * err_over_plx)**2.\n",
    "\n",
    "    # Subtract distance modulus from m_G\n",
    "    #dm = -5. * (np.log10(d['parallax']) - 2.)\n",
    "    #dm_corr = 0.5 * err_over_plx**2 + 0.75 * err_over_plx**4\n",
    "    #dm_corr_pct = np.percentile(dm_corr, [1., 5., 10., 50., 90., 95., 99.])\n",
    "    #print(dm_corr_pct)\n",
    "\n",
    "    print('Estimate DM ...')\n",
    "    dm = 10. - 5.*np.log10(d['parallax'])# + 5./np.log(10.)*dm_corr\n",
    "    y[:,0] -= dm\n",
    "\n",
    "    # Don't attempt to predict M_G for poor plx/err or when plx < 0\n",
    "    print('Filter out M_G for poor parallax measurements ...')\n",
    "    idx = (\n",
    "          (err_over_plx > 0.2)\n",
    "        | (d['parallax'] < 1.e-8)\n",
    "        | ~np.isfinite(d['parallax'])\n",
    "        | ~np.isfinite(d['parallax_err'])\n",
    "    )\n",
    "    n_use = idx.size - np.count_nonzero(idx)\n",
    "    print(r'Using {:d} of {:d} ({:.3f}%) of stellar parallaxes.'.format(\n",
    "        n_use, idx.size, n_use/idx.size*100.\n",
    "    ))\n",
    "    cov_y[idx,0,0] = large_err**2\n",
    "    y[idx,0] = np.nanmedian(y[:,0])\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp['dm'][idx,0,0] = large_err**2\n",
    "\n",
    "    # Reddenings\n",
    "    print('Copy reddenings ...')\n",
    "    r = np.empty((d.size,), dtype='f4')\n",
    "    r[:] = d['r'][:]\n",
    "    \n",
    "    if pretrained_model is None:\n",
    "        # If R has not yet been estimated, then\n",
    "        # cut out stars with sigma_r > 0.2 mag.\n",
    "        idx = (d['r_err'] > 0.2)\n",
    "        print(f'Cutting {np.count_nonzero(idx)} stars with large sigma_r.')\n",
    "        for k in range(cov_y.shape[1]):\n",
    "            cov_y[idx,k,k] += large_err**2\n",
    "\n",
    "    if pretrained_model is not None:\n",
    "        # Update reddenings, based on vector R and (y_obs - y_pred).\n",
    "        # Use provided reddenings as a prior.\n",
    "\n",
    "        # First, need to calculate inv_cov_y\n",
    "        print('Invert C_y matrices ...')\n",
    "        inv_cov_y = np.stack([np.linalg.inv(c) for c in cov_y])\n",
    "\n",
    "        # Predict M & R for each star based on atm. params\n",
    "        M_pred = predict_M(pretrained_model, x_p)\n",
    "        R = predict_R(pretrained_model, x_p)\n",
    "        \n",
    "        r_var = d['r_err']**2\n",
    "        \n",
    "        # Calculate posterior on reddening\n",
    "        if recalc_reddening:\n",
    "            print('Calculate posterior on reddening ...')\n",
    "            r_pred, r_var = update_reddenings(\n",
    "                M_pred, R, y,\n",
    "                inv_cov_y,\n",
    "                r, r_var\n",
    "            )\n",
    "            \n",
    "            # Clip mean and variance of reddenings\n",
    "            print('Clip reddenings and reddening variances ...')\n",
    "            r[:] = np.clip(r_pred, 0., 10.) # TODO: Update upper limit?\n",
    "        \n",
    "        # TODO: Different lower bounds on error for different sources?\n",
    "        r_var[:] = np.clip(r_var, 0.02**2 + (0.1*r)**2, 10.**2)\n",
    "        \n",
    "        # Reddening uncertainty term in covariance of y\n",
    "        print('Covariance: reddening uncertainty term ...')\n",
    "        cov_y += r_var[:,None,None] * R[:,:,None]*R[:,None,:]\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['r'] = r_var[:,None,None] * R[:,:,None]*R[:,None,:]\n",
    "        \n",
    "        # Propagate uncertainty in theta to uncertainty in R\n",
    "        print('Calculate J = dA/dtheta ...')\n",
    "        J_A = calc_dext_red_dtheta(pretrained_model, x_p, r)\n",
    "        cov_x = d['atm_param_cov_p']\n",
    "        print('Covariance: J C_theta J^T ...')\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_A)\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_A)\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_M)\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['dA/dtheta'] = np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_A)\n",
    "            cov_comp['dMA/dtheta'] = np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_A)\n",
    "            cov_comp['dAM/dtheta'] = np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_M)\n",
    "        \n",
    "        # Calculate chi^2 for each star\n",
    "        chisq = calc_chisq(M_pred+r[:,None]*R-y, inv_cov_y)\n",
    "        print('chisq =', chisq)\n",
    "\n",
    "        # Calculate d.o.f. of each star\n",
    "        print('Calculate d.o.f. of each star ...')\n",
    "        n_dof = np.zeros(d.size, dtype='i4')\n",
    "        for k in range(n_bands):\n",
    "            n_dof += (cov_y[:,k,k] < (large_err-1.)**2).astype('i4')\n",
    "        #print('n_dof =', n_dof)\n",
    "\n",
    "        # Calculate reduced chi^2 for each star\n",
    "        print('Calculate chi^2/d.o.f. for each star ...')\n",
    "        rchisq = chisq / (n_dof - 1.)\n",
    "        pct = (0., 1., 10., 50., 90., 99., 100.)\n",
    "        rchisq_pct = np.percentile(rchisq[np.isfinite(rchisq)], pct)\n",
    "        print('chi^2/dof percentiles:')\n",
    "        for p,rc in zip(pct,rchisq_pct):\n",
    "            print(rf'  {p:.0f}% : {rc:.3g}')\n",
    "        idx_rchisq = (rchisq < 10.)\n",
    "        print(f'<chi^2/d.o.f.> = {np.mean(rchisq[idx_rchisq]):.3g}')\n",
    "        \n",
    "        # Filter on reduced chi^2\n",
    "        if rchisq_max is not None:\n",
    "            print('Filter on chi^2/d.o.f. ...')\n",
    "            idx = np.isfinite(rchisq) & (rchisq > 0.) & (rchisq < rchisq_max)\n",
    "            n_filt = np.count_nonzero(~idx)\n",
    "            pct_filt = 100. * n_filt / idx.size\n",
    "            print(\n",
    "                rf'Filtering {n_filt:d} stars ({pct_filt:.3g}%) ' +\n",
    "                rf'based on chi^2/dof > {rchisq_max:.1f}'\n",
    "            )\n",
    "            x = x[idx]\n",
    "            x_p = x_p[idx]\n",
    "            r = r[idx]\n",
    "            y = y[idx]\n",
    "            cov_y = cov_y[idx]\n",
    "            r_var = r_var[idx]\n",
    "            rchisq = rchisq[idx]\n",
    "            \n",
    "            if return_cov_components:\n",
    "                for key in cov_comp:\n",
    "                    cov_comp[key] = cov_comp[key][idx]\n",
    "\n",
    "    # Cholesky transform of inverse covariance: L L^T = C^(-1).\n",
    "    print('Cholesky transform of each stellar covariance matrix ...')\n",
    "    LT = np.empty_like(cov_y)\n",
    "    inv_cov_y = np.empty_like(cov_y)\n",
    "    for k,c in enumerate(cov_y):\n",
    "        try:\n",
    "            # Inflate diagonal of cov slightly, to ensure\n",
    "            # positive-definiteness\n",
    "            c_diag = c[np.diag_indices_from(c)]\n",
    "            c[np.diag_indices_from(c)] += 1.e-4 + 1.e-3 * c_diag\n",
    "            \n",
    "            inv_cov_y[k] = np.linalg.inv(c)\n",
    "            LT[k] = np.linalg.cholesky(inv_cov_y[k]).T\n",
    "            #ic = np.linalg.inv(c)\n",
    "            #LT.append(np.linalg.cholesky(ic).T)\n",
    "            #inv_cov_y.append(ic)\n",
    "        except np.linalg.LinAlgError as e:\n",
    "            rho = get_corr_matrix(c)\n",
    "            print('Offending correlation matrix:')\n",
    "            print(np.array2string(\n",
    "                rho[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >7.4f}'.format(z)}\n",
    "            ))\n",
    "            print('Offending covariance matrix:')\n",
    "            print(np.array2string(\n",
    "                c[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >9.6f}'.format(z)}\n",
    "            ))\n",
    "            print('Covariance matrix of (normed) atmospheric parameters:')\n",
    "            print(d['atm_param_cov_p'][k])\n",
    "            if pretrained_model is not None:\n",
    "                print(f'Variance of r: {r_var[k]:.8f}')\n",
    "            \n",
    "            # Inflate errors along the diagonal and try again\n",
    "            c_diag = c[np.diag_indices_from(c)]\n",
    "            c[np.diag_indices_from(c)] += 0.02 + 0.02 * c_diag\n",
    "            rho = get_corr_matrix(c)\n",
    "            print('Inflated correlation matrix:')\n",
    "            print(np.array2string(\n",
    "                rho[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >7.4f}'.format(z)}\n",
    "            ))\n",
    "            \n",
    "            inv_cov_y[k] = np.linalg.inv(c)\n",
    "            LT[k] = np.linalg.cholesky(inv_cov_y[k]).T\n",
    "            #raise e\n",
    "\n",
    "    #print('Stack L^T matrices ...')\n",
    "    #LT = np.stack(LT)\n",
    "    #print('Stack C^(-1) matrices ...')\n",
    "    #inv_cov_y = np.stack(inv_cov_y)\n",
    "\n",
    "    # L^T y\n",
    "    print('Calculate L^T y ...')\n",
    "    LTy = np.einsum('nij,nj->ni', LT, y)\n",
    "\n",
    "    print('Gather inputs and outputs and return ...')\n",
    "    inputs_outputs = {\n",
    "        'x':x, 'x_p':x_p, 'r':r, 'y':y,\n",
    "        'LT':LT, 'LTy':LTy,\n",
    "        'cov_y':cov_y, 'inv_cov_y':inv_cov_y,\n",
    "    }\n",
    "    \n",
    "    if return_cov_components:\n",
    "        inputs_outputs['cov_comp'] = cov_comp\n",
    "    \n",
    "    if pretrained_model is not None:\n",
    "        inputs_outputs['r_var'] = r_var\n",
    "        inputs_outputs['rchisq'] = rchisq\n",
    "\n",
    "    # Check that there are no NaNs or Infs in results\n",
    "    for key in inputs_outputs:\n",
    "        if isinstance(inputs_outputs[key], dict):\n",
    "            continue\n",
    "        if key == 'rchisq': # Infs appear when d.o.f. = 1\n",
    "            continue\n",
    "        if np.any(~np.isfinite(inputs_outputs[key])):\n",
    "            raise ValueError(f'NaNs or Infs detected in {key}.')\n",
    "\n",
    "    return inputs_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caad35d-51ad-4e5f-8e27-57ac56e80468",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Predicts the absolute magnitude in the Gaia G-band and the colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb5329ec-4d17-4a14-9ec3-936b60844ca9",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def predict_M(nn_model, x_p):\n",
    "    \"\"\"\n",
    "    Predicts (absmag0,color1,color2,...) for input\n",
    "    normalized stellar parameters.\n",
    "\n",
    "    Inputs:\n",
    "        nn_model (keras.Model): Neural network model.\n",
    "        x_p (np.ndarray): Normalized stellar parameters.\n",
    "            Shape = (n_stars, 3).\n",
    "    \n",
    "    Outputs:\n",
    "        M (np.ndarray): Shape = (n_stars, n_bands).\n",
    "    \"\"\"\n",
    "    inputs = nn_model.get_layer(name='theta').input\n",
    "    outputs = nn_model.get_layer(name='BM').output\n",
    "    mag_color_model = keras.Model(inputs, outputs)\n",
    "    M = mag_color_model.predict(x_p)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14482c31-4986-4451-b4f7-295c2b3530b0",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Predicting the redenning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b36fc92-d995-4531-a1e4-994b63a9a954",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def predict_R(nn_model, x_p=None):\n",
    "    inputs = nn_model.get_layer(name='theta').input\n",
    "    outputs = nn_model.get_layer(name='R').output\n",
    "    R_model = keras.Model(inputs, outputs)\n",
    "    if x_p is None:\n",
    "        R = R_model.predict(np.array([[0.,0.,0.]]))[0]\n",
    "        R[1:] -= R[0]\n",
    "    else:\n",
    "        R = R_model.predict(x_p)\n",
    "        R[:,1:] -= R[:,0][:,None]\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2cab63-a66c-4c34-a7f1-50cb9568337b",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Saving the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52ee4e30-e866-45c2-a60f-37f5d8996b9f",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def save_predictions(fname, nn_model, d_test, io_test):\n",
    "    M_pred = predict_M(nn_model, io_test['x_p'])\n",
    "    R_pred = predict_R(nn_model, io_test['x_p'])\n",
    "    R0 = predict_R(nn_model)\n",
    "    \n",
    "    with h5py.File(fname, 'w') as f:\n",
    "        f.create_dataset('/data', data=d_test, chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/y_obs', data=io_test['y'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/cov_y', data=io_test['cov_y'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/r_fit', data=io_test['r'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/M_pred', data=M_pred, chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/R_pred', data=R_pred, chunks=True,\n",
    "                        compression='gzip', compression_opts=3)\n",
    "        f.attrs['R0'] = R0\n",
    "        \n",
    "        if 'cov_comp' in io_test:\n",
    "            for key in io_test['cov_comp']:\n",
    "                f.create_dataset(\n",
    "                    f'/cov_comp/{key.replace(r\"/\",\"_\")}',\n",
    "                    data=io_test['cov_comp'][key],\n",
    "                    chunks=True,\n",
    "                    compression='gzip',\n",
    "                    compression_opts=3\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9dbfb5-0fa8-47b6-b59e-5507d8182916",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Updates the redenning, as in the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12ce532d-8584-46ea-b538-a65837b35597",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def update_reddenings(M_pred, R, y_obs, inv_cov_y, r0, r_var0):\n",
    "    \"\"\"\n",
    "    Updates the posterior on reddening of each star, given\n",
    "    the predicted absolute magnitudes, reddening vector,\n",
    "    observed magnitudes, inverse covariance matrix, and priors on\n",
    "    reddening.\n",
    "    \n",
    "    The model is given by\n",
    "    \n",
    "        y_obs = M_pred + R r,\n",
    "    \n",
    "    with the uncertainties in y_obs described by inv_cov_y, and\n",
    "    with a prior on r described by (r0, r_var0). We solve for\n",
    "    the Gaussian posterior on r: p(r|y_obs,M_pred,R,r0,r_var0).\n",
    "    \n",
    "    Let n = # of bands, k = # of stars.\n",
    "\n",
    "    Inputs:\n",
    "        M_pred (np.ndarray): Shape-(k,n) array containing predicted\n",
    "            zero-reddening asbolute magnitude & colors for each star.\n",
    "        R (np.ndarray): Shape-(k,n) array containing reddening vector\n",
    "            for each star.\n",
    "        inv_cov_y (np.ndarray): Shape-(k,n,n) array containing\n",
    "            covariance matrix of y_obs-y_pred for each star.\n",
    "        y_obs (np.ndarray): Shape-(k,n) array containing observed\n",
    "            magnitude (minus distance modulus) & colors for each star.\n",
    "        r0 (np.ndarray): Shape-(k,) array containing mean of prior on\n",
    "            reddening for each star.\n",
    "        r_var0 (np.ndarray): Shape-(k,) array containing variance of\n",
    "            prior on reddening for each star.\n",
    "\n",
    "    Outputs:\n",
    "        r_mean (np.ndarray): Shape-(k,) array containing mean posterior\n",
    "            reddening of each star.\n",
    "        r_var (np.ndarray): Shape-(k,) array containing variance of\n",
    "            reddening posterior for each star.\n",
    "    \"\"\"\n",
    "    print('Updating reddenings:')\n",
    "    print('  * R^T C_y^(-1) ...')\n",
    "    RT_Cinv = np.einsum('ni,nij->nj', R, inv_cov_y)\n",
    "    print('  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...')\n",
    "    num = r0/r_var0 + np.einsum('ni,ni->n', RT_Cinv, y_obs - M_pred)\n",
    "    print('  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...')\n",
    "    den = np.einsum('ni,ni->n', RT_Cinv, R) + 1./r_var0\n",
    "    print('  * r_mean, r_var ...')\n",
    "    r_mean = num / den\n",
    "    r_var = 1. / den\n",
    "\n",
    "    return r_mean, r_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d6a72-37ab-4d7a-bfb3-cd329804a9ca",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### calculates the chi^2, as in docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c76cf577-6ee4-41db-a3ea-bada40e97afb",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def calc_chisq(dy, inv_cov_y):\n",
    "    \"\"\"\n",
    "    Returns the chi^2 for each observation, given\n",
    "    an array of residuals and inverse covariance matrices.\n",
    "    \n",
    "        chi^2 = dy^T C^{-1} dy.\n",
    "    \n",
    "    Inputs:\n",
    "        dy (np.ndarray): Residual values. Shape = (n_obs, n_dim),\n",
    "            where n_obs is the number of observations, and n_dim is\n",
    "            the dimensionality of the vector space.\n",
    "        inv_cov_y (np.ndarray): Inverse covariance matrices.\n",
    "            Shape = (n_obs, n_dim, n_dim).\n",
    "    \n",
    "    Returns:\n",
    "        chisq (np.ndarray): Chi^2 for each observation. Shape=(n_obs,).\n",
    "    \"\"\"\n",
    "    C_inv_dy = np.einsum('nij,nj->ni', inv_cov_y, dy)\n",
    "    chisq = np.einsum('ni,ni->n', dy, C_inv_dy)\n",
    "    return chisq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50c262-4e28-419e-83d5-8b75ec32470b",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Creates the architecture of the NN as described in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45204db0-8dfb-448f-879b-11102036d543",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def get_nn_model(n_hidden_layers=1, hidden_size=32, l1=1.e0, l2=1.e-4, n_bands=13):\n",
    "    # Stellar model: B M(theta)\n",
    "    atm = keras.Input(shape=(3,), name='theta')\n",
    "    x = atm\n",
    "    for i in range(n_hidden_layers):\n",
    "        x = keras.layers.Dense(\n",
    "            hidden_size,\n",
    "            activation='sigmoid',\n",
    "            kernel_regularizer=keras.regularizers.l2(l=l2),\n",
    "            name=f'stellar_model_hidden_{i+1}'\n",
    "        )(x)\n",
    "    mag_color = keras.layers.Dense(n_bands, name='BM')(x)\n",
    "\n",
    "    # Reddening measurement E\n",
    "    red = keras.Input(shape=(1,), name='E')\n",
    "    \n",
    "    # Extinction vector: R(theta)\n",
    "    r = atm\n",
    "    #for i in range(n_hidden_layers):\n",
    "    #    r = keras.layers.Dense(\n",
    "    #        6,\n",
    "    #        use_bias=True,\n",
    "    #        activation='sigmoid',\n",
    "    #        kernel_regularizer=keras.regularizers.l2(l=l2),\n",
    "    #        name=f'extinction_model_hidden_{i+1}'\n",
    "    #    )(r)\n",
    "    ext_vec = keras.layers.Dense(\n",
    "        n_bands,\n",
    "        use_bias=True,\n",
    "        activation='exponential',\n",
    "        #kernel_regularizer=keras.regularizers.l1_l2(l1=1.e0, l2=1.e0),\n",
    "        kernel_regularizer=keras.regularizers.l1(l=l1),\n",
    "        name='R'\n",
    "    )(r)\n",
    "    \n",
    "    # Extinction A = ER\n",
    "    ext = keras.layers.Multiply(name='A')([red, ext_vec])\n",
    "    \n",
    "    # Transform extinction to extinction,reddening using B: BA\n",
    "    B = np.identity(n_bands, dtype='f4')\n",
    "    B[1:,0] = -1.\n",
    "    ext_red = keras.layers.Dense(\n",
    "        n_bands,\n",
    "        use_bias=False,\n",
    "        trainable=False,\n",
    "        weights=[B.T],\n",
    "        name='BA'\n",
    "    )(ext)\n",
    "\n",
    "    # Predicted mag,color, B(M+A)\n",
    "    y = keras.layers.Add(name='B_M_plus_A')([mag_color, ext_red])\n",
    "\n",
    "    # Cholesky decomposition of inverse covariance matrix, L L^T = C^(-1)\n",
    "    LT = keras.Input(shape=(n_bands,n_bands), name='LT')\n",
    "\n",
    "    # Multiply y_pred by L^T, since loss is given by |L^T (y_pred - y_obs)|^2,\n",
    "    # where y_pred = B(M+A), and y_obs = B(m-mu).\n",
    "    LTy = keras.layers.Dot((2,1), name='LT_B_M_plus_A')([LT, y])\n",
    "\n",
    "    # Compile model\n",
    "    model = keras.Model(\n",
    "        inputs=[atm,red,LT],\n",
    "        outputs=LTy,\n",
    "        name='stellar_photometry_model'\n",
    "    )\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer='Adam',\n",
    "        metrics=['mse']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c98052-09ff-4591-830a-446eedd1c701",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### splits the dataset according to a fraction selected by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f096cf60-242d-4eef-8d91-59430a2672dc",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def split_dataset(frac, *args):\n",
    "    assert len(args) != 0\n",
    "\n",
    "    n_tot = args[0].shape[0]\n",
    "    idx = np.arange(n_tot)\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    n = int(frac * n_tot)\n",
    "    idx_left = idx[:n]\n",
    "    idx_right = idx[n:]\n",
    "\n",
    "    left, right = [], []\n",
    "\n",
    "    for x in args:\n",
    "        left.append(x[idx_left])\n",
    "        right.append(x[idx_right])\n",
    "    \n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a650c5-2ed5-4cfd-bd99-92ff0587e213",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d4f6eac-a9dd-4e9d-9d27-f9995997b7a2",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def train_model(nn_model, io_train, epochs=100,\n",
    "                checkpoint_fn='checkpoint', batch_size=32):\n",
    "    checkpoint_fn = (\n",
    "          'checkpoints/'\n",
    "        + checkpoint_fn\n",
    "        + '.e{epoch:03d}_vl{val_loss:.3f}.h5'\n",
    "    )\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_fn,\n",
    "            save_best_only=True,\n",
    "            monitor='val_loss',\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    inputs = [io_train['x_p'], io_train['r'], io_train['LT']]\n",
    "    outputs = io_train['LTy']\n",
    "    nn_model.fit(\n",
    "        inputs, outputs,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.25/0.9,\n",
    "        callbacks=callbacks,\n",
    "        batch_size=batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d76b11-59a7-41ca-a531-13411c1a6ce9",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### tests and makes sure the loss is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eb14a0f-a62d-4d46-ab6d-4b33476566da",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(nn_model, io_eval, batch_size=32, rchisq_max=None):\n",
    "    \"\"\"\n",
    "    Runs the model on the given inputs and outputs, and returns the\n",
    "    MSE and loss.\n",
    "    \n",
    "    Inputs:\n",
    "        nn_model (keras.Model): The neural network model.\n",
    "        io_eval (dict): A dictionary containing, among other things,\n",
    "            x_p, r, LT and LTy. If rchisq_max is provided, then the\n",
    "            dictionary must also contain rchisq.\n",
    "        batch_size (int): Defaults to 32.\n",
    "        rchisq_max (float): Stars with greater than this reduced chi^2\n",
    "            will not be included in the calculation. Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "        A list containing the MSE and loss.\n",
    "    \"\"\"\n",
    "    inputs = [io_eval['x_p'], io_eval['r'], io_eval['LT']]\n",
    "    outputs = io_eval['LTy']\n",
    "    \n",
    "    if rchisq_max is not None:\n",
    "        idx = (io_eval['rchisq'] < rchisq_max)\n",
    "        inputs = [x[idx] for x in inputs]\n",
    "        outputs = outputs[idx]\n",
    "    \n",
    "    loss = nn_model.evaluate(\n",
    "        inputs,\n",
    "        outputs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    loss = [float(x) for x in loss] # Make JSON serializable\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd030e3e-55e6-419d-9a07-ce0a6baeb62c",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### plots? follow up here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d65e396c-7677-41d8-b229-8c3b2377a7b6",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def diagnostic_plots(nn_model, io_test, d_test, suffix=None):\n",
    "    if suffix is None:\n",
    "        suff = ''\n",
    "    else:\n",
    "        suff = '_' + suffix\n",
    "    \n",
    "    inputs = [\n",
    "        nn_model.get_layer(name='theta').input,\n",
    "        nn_model.get_layer(name='E').input\n",
    "    ]\n",
    "    outputs = nn_model.get_layer(name='B_M_plus_A').output\n",
    "    absmag_model = keras.Model(inputs, outputs)\n",
    "\n",
    "    # Predict y for the test dataset\n",
    "    test_pred = {\n",
    "        'y': absmag_model.predict([\n",
    "            io_test['x_p'],\n",
    "            io_test['r']\n",
    "        ]),\n",
    "        'y_dered': absmag_model.predict([\n",
    "            io_test['x_p'],\n",
    "            np.zeros_like(io_test['r'])\n",
    "        ])\n",
    "    }\n",
    "    test_pred['y_resid'] = io_test['y'] - test_pred['y']\n",
    "\n",
    "    # Get the extinction vector\n",
    "    R = predict_R(nn_model)\n",
    "    R[1:] += R[0]\n",
    "    print(\n",
    "          'R(<theta>) = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,R)))\n",
    "        + ']'\n",
    "    )\n",
    "    R_all = predict_R(nn_model, io_test['x_p'])\n",
    "    R_all[:,1:] += R_all[:,0][:,None]\n",
    "    print(\n",
    "          '<R> = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,np.median(R_all,axis=0))))\n",
    "        + ']'\n",
    "    )\n",
    "    print(\n",
    "          's_R = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,np.std(R_all,axis=0))))\n",
    "        + ']'\n",
    "    )\n",
    "\n",
    "    # Read out colors, magnitudes\n",
    "    g = io_test['y'][:,3] + io_test['y'][:,0]\n",
    "    ri = io_test['y'][:,4] - io_test['y'][:,5]\n",
    "    gr = io_test['y'][:,3] - io_test['y'][:,4]\n",
    "    g_pred = test_pred['y'][:,3] + test_pred['y'][:,0]\n",
    "    ri_pred = test_pred['y'][:,4] - test_pred['y'][:,5]\n",
    "    gr_pred = test_pred['y'][:,3] - test_pred['y'][:,4]\n",
    "    g_pred_dered = test_pred['y_dered'][:,3] + test_pred['y_dered'][:,0]\n",
    "    ri_pred_dered = test_pred['y_dered'][:,4] - test_pred['y_dered'][:,5]\n",
    "    gr_pred_dered = test_pred['y_dered'][:,3] - test_pred['y_dered'][:,4]\n",
    "    A_g = 0.25 * R[3]\n",
    "    E_ri = 0.25 * (R[4] - R[5])\n",
    "    E_gr = 0.25 * (R[3] - R[4])\n",
    "\n",
    "    gaia_g = io_test['y'][:,0]\n",
    "    bp_rp = io_test['y'][:,1] - io_test['y'][:,2]\n",
    "    gaia_g_pred = test_pred['y'][:,0]\n",
    "    bp_rp_pred = test_pred['y'][:,1] - test_pred['y'][:,2]\n",
    "    gaia_g_pred_dered = test_pred['y_dered'][:,0]\n",
    "    gaia_bp_rp_pred_dered = test_pred['y_dered'][:,1] - test_pred['y_dered'][:,2]\n",
    "    A_gaia_g = 0.25 * R[0]\n",
    "    E_bp_rp = 0.25 * (R[1] - R[2])\n",
    "\n",
    "    print('g =', g)\n",
    "    print('ri =', ri)\n",
    "    print('gr =', gr)\n",
    "    print('gaia_g =', gaia_g)\n",
    "    print('bp_rp =', bp_rp)\n",
    "\n",
    "    # Plot HRD\n",
    "    params = {\n",
    "        'density': (None, r'$N$', (None, None)),\n",
    "        'teff': (d_test['atm_param'][:,0], r'$T_{\\mathrm{eff}}$', (4000., 8000.)),\n",
    "        'logg': (d_test['atm_param'][:,1], r'$\\log \\left( g \\right)$', (0., 5.)),\n",
    "        'mh': (d_test['atm_param'][:,2], r'$\\left[ \\mathrm{M} / \\mathrm{H} \\right]$', (-2.5, 0.5))\n",
    "    }\n",
    "\n",
    "    plot_spec = [\n",
    "        {\n",
    "            'colors': [(1,2), (4,5)],\n",
    "            'mag': 0\n",
    "        },\n",
    "        {\n",
    "            'colors': [(3,4), (4,5)],\n",
    "            'mag': 0\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    idx_goodobs = np.isfinite(d_test['mag_err'])\n",
    "    idx_goodobs &= (np.abs(io_test['cov_y'][:,0,0]) < 90.)[:,None]\n",
    "    idx_goodobs = idx_goodobs.T\n",
    "\n",
    "    def scatter_or_hexbin(ax, x, y, c, vmin, vmax, extent):\n",
    "        if p == 'density':\n",
    "            im = ax.hexbin(\n",
    "                x, y,\n",
    "                extent=extent,\n",
    "                bins='log',\n",
    "                rasterized=True\n",
    "            )\n",
    "        else:\n",
    "            im = ax.scatter(\n",
    "                x,\n",
    "                y,\n",
    "                c=c,\n",
    "                edgecolors='none',\n",
    "                alpha=0.1,\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "                rasterized=True\n",
    "            )\n",
    "        return im\n",
    "\n",
    "    def get_lim(*args, **kwargs):\n",
    "        expand = kwargs.get('expand', 0.4)\n",
    "        expand_low = kwargs.get('expand_low', expand)\n",
    "        expand_high = kwargs.get('expand_high', expand)\n",
    "        pct = kwargs.get('pct', 1.)\n",
    "        lim = [np.inf, -np.inf]\n",
    "        for a in args:\n",
    "            a0,a1 = np.nanpercentile(a, [pct, 100.-pct])\n",
    "            lim[0] = min(a0, lim[0])\n",
    "            lim[1] = max(a1, lim[1])\n",
    "        w = lim[1] - lim[0]\n",
    "        lim[0] -= expand_low * w\n",
    "        lim[1] += expand_high * w\n",
    "        return lim\n",
    "\n",
    "    labels = ['G', 'BP', 'RP', 'g', 'r', 'i', 'z', 'y']\n",
    "\n",
    "    for ps in plot_spec:\n",
    "        mag_label = r'$M_{{ {} }}$'.format(labels[ps['mag']])\n",
    "        mag_obs = io_test['y'][:,ps['mag']]\n",
    "        mag_pred = test_pred['y'][:,ps['mag']]\n",
    "        mag_pred_dered = test_pred['y_dered'][:,ps['mag']]\n",
    "        A_vec = 0.25 * R[ps['mag']]\n",
    "        print('mag_pred:',mag_pred)\n",
    "\n",
    "        if ps['mag'] != 0:\n",
    "            mag_obs += io_test['y'][:,0]\n",
    "            mag_pred += io_test['y'][:,0]\n",
    "            mag_pred_dered += io_test['y'][:,0]\n",
    "            A_vec += 0.25 * R[0]\n",
    "\n",
    "        color_labels = []\n",
    "        colors_obs = []\n",
    "        colors_pred = []\n",
    "        colors_pred_dered = []\n",
    "        idx_colors_obs = []\n",
    "        E_vec = []\n",
    "        for i1,i2 in ps['colors']:\n",
    "            color_labels.append(r'${} - {}$'.format(labels[i1], labels[i2]))\n",
    "            colors_obs.append(io_test['y'][:,i1] - io_test['y'][:,i2])\n",
    "            colors_pred.append(test_pred['y'][:,i1] - test_pred['y'][:,i2])\n",
    "            colors_pred_dered.append(\n",
    "                test_pred['y_dered'][:,i1] - test_pred['y_dered'][:,i2]\n",
    "            )\n",
    "            idx_colors_obs.append(idx_goodobs[i1] & idx_goodobs[i2])\n",
    "            E_vec.append(0.25 * (R[i1] - R[i2]))\n",
    "\n",
    "        mag_lim = get_lim(\n",
    "            mag_obs[idx_goodobs[ps['mag']]],\n",
    "            pct=2.\n",
    "        )[::-1]\n",
    "        color_lim = [\n",
    "            get_lim(c[idx_colors_obs[k]], expand_low=0.5, expand_high=0.4)\n",
    "            for k,c in enumerate(colors_obs)\n",
    "        ]\n",
    "        \n",
    "        for p in params.keys():\n",
    "            c, label, (vmin,vmax) = params[p]\n",
    "            \n",
    "            fig = plt.figure(figsize=(14,4.5), dpi=150)\n",
    "            fig.patch.set_alpha(0.)\n",
    "            gs = GridSpec(\n",
    "                1,4,\n",
    "                width_ratios=[1,1,1,0.1],\n",
    "                left=0.07, right=0.93,\n",
    "                bottom=0.10, top=0.92\n",
    "            )\n",
    "            ax_obs = fig.add_subplot(gs[0,0], facecolor='gray')\n",
    "            ax_pred = fig.add_subplot(gs[0,1], facecolor='gray')\n",
    "            ax_dered = fig.add_subplot(gs[0,2], facecolor='gray')\n",
    "            cax = fig.add_subplot(gs[0,3], facecolor='w')\n",
    "\n",
    "            extent = color_lim[0] + mag_lim\n",
    "\n",
    "            idx = (\n",
    "                  idx_goodobs[ps['mag']]\n",
    "                & idx_goodobs[ps['colors'][0][0]]\n",
    "                & idx_goodobs[ps['colors'][0][1]]\n",
    "            )\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_obs,\n",
    "                colors_obs[0][idx],\n",
    "                mag_obs[idx],\n",
    "                c if c is None else c[idx],\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "                #(-0.3,1.0,11.5,-2.0)\n",
    "            )\n",
    "\n",
    "            ax_obs.set_xlim(color_lim[0])\n",
    "            ax_obs.set_ylim(mag_lim)\n",
    "            ax_obs.set_xlabel(color_labels[0])\n",
    "            ax_obs.set_ylabel(mag_label)\n",
    "            ax_obs.grid('on', alpha=0.3)\n",
    "            ax_obs.set_title(r'$\\mathrm{Observed}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_pred,\n",
    "                colors_pred[0],\n",
    "                mag_pred,\n",
    "                c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "\n",
    "            ax_pred.set_xlim(color_lim[0])\n",
    "            ax_pred.set_ylim(mag_lim)\n",
    "            ax_pred.set_xlabel(color_labels[0])\n",
    "            ax_pred.grid('on', alpha=0.3)\n",
    "            ax_pred.set_title(r'$\\mathrm{Predicted}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_dered,\n",
    "                colors_pred_dered[0],\n",
    "                mag_pred_dered,\n",
    "                c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "\n",
    "            ax_dered.set_xlim(color_lim[0])\n",
    "            ax_dered.set_ylim(mag_lim)\n",
    "            ax_dered.set_xlabel(color_labels[0])\n",
    "            ax_dered.grid('on', alpha=0.3)\n",
    "            ax_dered.set_title(r'$\\mathrm{Predicted+Dereddened}$')\n",
    "\n",
    "            ax_dered.annotate(\n",
    "                '',\n",
    "                xy=(0.35+E_vec[0], 1.+A_vec),\n",
    "                xytext=(0.35, 1.),\n",
    "                arrowprops=dict(color='r', width=1., headwidth=5., headlength=5.)\n",
    "            )\n",
    "\n",
    "            cb = fig.colorbar(im, cax=cax)\n",
    "            cb.set_label(label)\n",
    "            cb.set_alpha(1.)\n",
    "            cb.draw_all()\n",
    "\n",
    "            cm_desc = '{}_vs_{}{}'.format(\n",
    "                labels[ps['mag']],\n",
    "                labels[ps['colors'][0][0]],\n",
    "                labels[ps['colors'][0][1]]\n",
    "            )\n",
    "            fig.savefig(\n",
    "                '/arc/home/aydanmckay/networkplots/nn_predictions_'+cm_desc+'_'+p+suff+'.svg',\n",
    "                dpi=150,\n",
    "                facecolor=fig.get_facecolor(),\n",
    "                edgecolor='none'\n",
    "            )\n",
    "            plt.close(fig)\n",
    "\n",
    "            # Color-color diagrams\n",
    "            fig = plt.figure(figsize=(14,4.5), dpi=150)\n",
    "            fig.patch.set_alpha(0.)\n",
    "            gs = GridSpec(\n",
    "                1,4,\n",
    "                width_ratios=[1,1,1,0.1],\n",
    "                left=0.07, right=0.93,\n",
    "                bottom=0.10, top=0.92\n",
    "            )\n",
    "            ax_obs = fig.add_subplot(gs[0,0], facecolor='gray')\n",
    "            ax_pred = fig.add_subplot(gs[0,1], facecolor='gray')\n",
    "            ax_dered = fig.add_subplot(gs[0,2], facecolor='gray')\n",
    "            cax = fig.add_subplot(gs[0,3], facecolor='w')\n",
    "\n",
    "            extent = color_lim[0] + color_lim[1]\n",
    "\n",
    "            idx = (\n",
    "                  idx_goodobs[ps['colors'][0][0]]\n",
    "                & idx_goodobs[ps['colors'][0][1]]\n",
    "                & idx_goodobs[ps['colors'][1][0]]\n",
    "                & idx_goodobs[ps['colors'][1][1]]\n",
    "            )\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_obs,\n",
    "                colors_obs[0][idx],\n",
    "                colors_obs[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "                #(-0.2,1.5,-0.15,0.8)\n",
    "            )\n",
    "            ax_obs.set_xlim(color_lim[0])\n",
    "            ax_obs.set_ylim(color_lim[1])\n",
    "            ax_obs.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_obs.set_ylabel(color_labels[1], fontsize=14)\n",
    "            ax_obs.grid('on', alpha=0.3)\n",
    "            ax_obs.set_title(r'$\\mathrm{Observed}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_pred,\n",
    "                colors_pred[0][idx],\n",
    "                colors_pred[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                #c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "            ax_pred.set_xlim(color_lim[0])\n",
    "            ax_pred.set_ylim(color_lim[1])\n",
    "            ax_pred.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_pred.grid('on', alpha=0.3)\n",
    "            ax_pred.set_title(r'$\\mathrm{Predicted}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_dered,\n",
    "                colors_pred_dered[0][idx],\n",
    "                colors_pred_dered[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                #c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "            ax_dered.set_xlim(color_lim[0])\n",
    "            ax_dered.set_ylim(color_lim[1])\n",
    "            ax_dered.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_dered.grid('on', alpha=0.3)\n",
    "            ax_dered.set_title(r'$\\mathrm{Predicted+Dereddened}$')\n",
    "\n",
    "            ax_dered.annotate(\n",
    "                '',\n",
    "                xy=(0.4+E_vec[0], 0.3+E_vec[1]),\n",
    "                xytext=(0.4, 0.3),\n",
    "                arrowprops=dict(color='r', width=1., headwidth=5., headlength=5.)\n",
    "            )\n",
    "\n",
    "            cb = fig.colorbar(im, cax=cax)\n",
    "            cb.set_label(label, fontsize=14)\n",
    "            cb.set_alpha(1.)\n",
    "            cb.draw_all()\n",
    "\n",
    "            cc_desc = '{}{}_vs_{}{}'.format(\n",
    "                labels[ps['colors'][0][0]],\n",
    "                labels[ps['colors'][0][1]],\n",
    "                labels[ps['colors'][1][0]],\n",
    "                labels[ps['colors'][1][1]]\n",
    "            )\n",
    "            fig.savefig(\n",
    "                '/arc/home/aydanmckay/networkplots/test_'+cc_desc+'_'+p+suff+'.svg',\n",
    "                dpi=150,\n",
    "                facecolor=fig.get_facecolor(),\n",
    "                edgecolor='none'\n",
    "            )\n",
    "            plt.close(fig)\n",
    "    \n",
    "    # Plot histograms of residuals\n",
    "    dr = (io_test['r'] - d_test['r'])/np.hypot(np.nanstd(d_test['r']),.01)\n",
    "    # dmag = (io_test['LTy'] - d_test['mag'])\n",
    "    # dm1,dm2,dm3,dm4,dm5,dm6,dm7,dm8,dm9,dm10,dm11,dm12,dm13 = dmag.T\n",
    "    names = ['G','(BP-G)','(RP-G)','(g-G)','(r-G)','(i-G)','(z-G)','(y-G)','(J-G)','(H-G)','(K_s-G)','(W_1-G)','(W_2-G)']\n",
    "    # ds = [dm1,dm2,dm3,dm4,dm5,dm6,dm7,dm8,dm9,dm10,dm11,dm12,dm13]\n",
    "    fig = plt.figure(figsize=(12,18))\n",
    "    ax = fig.add_subplot(5,3,1)\n",
    "    dr_mean = np.nanmean(dr)\n",
    "    dr_std = np.nanstd(dr)\n",
    "    ax.hist(dr, bins=50)\n",
    "    dr_skew = scipy.stats.moment(dr, moment=3, nan_policy='omit')\n",
    "    dr_txt = r'$\\Delta E = {:+.3f} \\pm {:.3f}$'.format(dr_mean, dr_std)\n",
    "    dr_skew /= (dr_std**1.5 + 1.e-5)\n",
    "    dr_txt += '\\n' + r'$\\tilde{{\\mu}}_3 = {:+.3f}$'.format(dr_skew)\n",
    "    ax.text(0.05, 0.95, dr_txt, ha='left', va='top', transform=ax.transAxes)\n",
    "    ax.set_xlabel(r'$\\Delta E \\ \\left( \\mathrm{estimated} - \\mathrm{Bayestar19} \\right)$',fontsize=10)\n",
    "    for it,(io,dm,name) in enumerate(zip(io_test['LTy'].T,d_test['mag'].T,names)):\n",
    "        dd = (io - dm)/np.hypot(np.nanstd(dm),.01)\n",
    "        ax = fig.add_subplot(5,3,it+2)\n",
    "        dd_mean = np.nanmean(dd)\n",
    "        dd_std = np.nanstd(dd)\n",
    "        ax.hist(dd, bins=50)\n",
    "        dd_skew = scipy.stats.moment(dd, moment=3, nan_policy='omit')\n",
    "        dd_txt = r'$\\Delta '+name+r' = {:+.3f} \\pm {:.3f}$'.format(dd_mean, dd_std)\n",
    "        dd_skew /= (dd_std**1.5 + 1.e-5)\n",
    "        dd_txt += '\\n' + r'$\\tilde{{\\mu}}_3 = {:+.3f}$'.format(dd_skew)\n",
    "        ax.text(0.05, 0.95, dd_txt, ha='left', va='top', transform=ax.transAxes)\n",
    "        ax.set_xlabel(r'$\\Delta '+name+r'\\ \\left( \\mathrm{estimated} - \\mathrm{observed} \\right)$',fontsize=10)\n",
    "    fig.savefig('/arc/home/aydanmckay/networkplots/test_z-score_dE'+suff+'.svg', dpi=150)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc50d23-d49f-4732-87e4-a7e1ec8fc816",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Calculates the derivative of the stellar model portion for gradient descent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8c296da-d523-4953-87b3-738be2e038fe",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def calc_dmag_color_dtheta(nn_model, x_p):\n",
    "    m = keras.Model(\n",
    "        inputs=nn_model.get_layer(name='theta').input,\n",
    "        outputs=nn_model.get_layer(name='BM').output\n",
    "    )\n",
    "    with tf.GradientTape() as g:\n",
    "        x_p = tf.constant(x_p)\n",
    "        g.watch(x_p)\n",
    "        mag_color = m(x_p)\n",
    "    J = g.batch_jacobian(mag_color, x_p).numpy()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb05c4c2-5d82-4311-b6f2-b46532797a41",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Calculates the derivative of the extinction model portion for gradient descent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2af63500-d06a-4ba6-bcc1-5fd5c3df6247",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def calc_dext_red_dtheta(nn_model, x_p, r):\n",
    "    A_model = keras.Model(\n",
    "        inputs=[\n",
    "            nn_model.get_layer(name='theta').input,\n",
    "            nn_model.get_layer(name='E').input\n",
    "        ],\n",
    "        outputs=nn_model.get_layer(name='BA').output\n",
    "    )\n",
    "    r = tf.constant(np.reshape(r, (r.size,1)))\n",
    "    #r = tf.reshape(r, (tf.size(r), 1))\n",
    "    with tf.GradientTape() as g:\n",
    "        x_p = tf.constant(x_p)\n",
    "        g.watch(x_p)\n",
    "        A = A_model([x_p, r])\n",
    "    J = g.batch_jacobian(A, x_p).numpy()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fb7f2c-5df5-4b99-aae0-39035aa43797",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Saves the normalizations, which seen in the tutorial is useful for scaling and shifting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86cef280-6cca-48f4-93ce-a8f4b7336300",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def save_theta_norm(d_attrs, fname):\n",
    "    d = {\n",
    "        'theta_med': d_attrs['atm_param_med'].tolist(),\n",
    "        'theta_std': d_attrs['atm_param_std'].tolist()\n",
    "    }\n",
    "    with open(fname, 'w') as f:\n",
    "        json.dump(d, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab8ecb-d1c9-438d-8794-1ff0b7eceef3",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### start of main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b834ddb7-6836-4e26-b7d7-81ce6cf146fd",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"stellar_photometry_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " theta (InputLayer)             [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " stellar_model_hidden_1 (Dense)  (None, 32)          128         ['theta[0][0]']                  \n",
      "                                                                                                  \n",
      " E (InputLayer)                 [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " R (Dense)                      (None, 13)           52          ['theta[0][0]']                  \n",
      "                                                                                                  \n",
      " stellar_model_hidden_2 (Dense)  (None, 32)          1056        ['stellar_model_hidden_1[0][0]'] \n",
      "                                                                                                  \n",
      " A (Multiply)                   (None, 13)           0           ['E[0][0]',                      \n",
      "                                                                  'R[0][0]']                      \n",
      "                                                                                                  \n",
      " BM (Dense)                     (None, 13)           429         ['stellar_model_hidden_2[0][0]'] \n",
      "                                                                                                  \n",
      " BA (Dense)                     (None, 13)           169         ['A[0][0]']                      \n",
      "                                                                                                  \n",
      " LT (InputLayer)                [(None, 13, 13)]     0           []                               \n",
      "                                                                                                  \n",
      " B_M_plus_A (Add)               (None, 13)           0           ['BM[0][0]',                     \n",
      "                                                                  'BA[0][0]']                     \n",
      "                                                                                                  \n",
      " LT_B_M_plus_A (Dot)            (None, 13)           0           ['LT[0][0]',                     \n",
      "                                                                  'B_M_plus_A[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,834\n",
      "Trainable params: 1,665\n",
      "Non-trainable params: 169\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load/create neural network\n",
    "nn_name = 'ext_0h_l1n2'\n",
    "n_hidden = 2\n",
    "nn_model = get_nn_model(n_hidden_layers=n_hidden, l2=1.e-4, l1=1.e-2)\n",
    "#nn_model = keras.models.load_model(\n",
    "#    'models/{:s}_{:d}hidden_it14.h5'.format(nn_name, n_hidden)\n",
    "#)\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07e4514b-44a8-4a5c-8512-e7feaa15e94e",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Loading /arc/home/aydanmckay/ml/network/data.h5 ...\n"
     ]
    }
   ],
   "source": [
    "# Load stellar data\n",
    "print('Loading data ...')\n",
    "fname = '/arc/home/aydanmckay/ml/network/data.h5'\n",
    "d, d_attrs = load_data(fname, return_attrs=True)\n",
    "#d = d[::25]\n",
    "save_theta_norm(d_attrs, 'theta_normalization.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d54baa9f-60d9-4fc0-acb7-e4c49cd83a66",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    253053 training/validation stars.\n",
      "     28118 test stars.\n"
     ]
    }
   ],
   "source": [
    "# (training+validation) / test split\n",
    "# Fix random seed (same split every run)\n",
    "np.random.seed(7)\n",
    "(d_train,), (d_test,) = split_dataset(0.9, d)\n",
    "np.random.shuffle(d_train) # Want d_train to be in random order\n",
    "print(f'{d_train.size: >10d} training/validation stars.')\n",
    "print(f'{d_test.size: >10d} test stars.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa8b04a6-3b93-4b72-9d3f-8855c3111e8c",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi^2/dof = [None, 100.00000000000004, 79.41833348134496, 63.07271692954115, 50.09130066684769, 39.78167620874025, 31.593944275926187, 25.091384024965357, 19.927159040031896, 15.825817619770502, 12.56860061341878, 9.981773149103292, 7.927357886906197, 6.295775522882865, 4.999999999999999, 5.0, 5.0, 5.0, 5.0, 5.0]\n"
     ]
    }
   ],
   "source": [
    "# Iteratively update dM/dtheta contribution to uncertainties,\n",
    "# reddening estimates and reduced chi^2 cut, and retrain.\n",
    "n_iterations = 20\n",
    "\n",
    "# On GPU, use large batch sizes for memory transfer efficiency\n",
    "batch_size = 1024\n",
    "\n",
    "rchisq_max_init = 100.\n",
    "rchisq_max_final = 5.\n",
    "rchisq_max = np.exp(np.linspace(\n",
    "    np.log(rchisq_max_init),\n",
    "    np.log(rchisq_max_final),\n",
    "    n_iterations-6\n",
    "))\n",
    "rchisq_max = [None] + rchisq_max.tolist() + 5*[rchisq_max_final]\n",
    "print('chi^2/dof = {}'.format(rchisq_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b3ee798-6cee-458d-b5e3-e6f014c0c873",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Cutting 0 stars with large sigma_r.\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Cutting 0 stars with large sigma_r.\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 42.36 s\n",
      "learning rate = 0.0010000000474974513\n",
      "setting learning rate to 0.001\n",
      "Iteration 1 of 20.\n",
      "Epoch 1/25\n",
      "177/179 [============================>.] - ETA: 0s - loss: 34387.7852 - mse: 34387.6758\n",
      "Epoch 1: val_loss improved from inf to 16127.03320, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e001_vl16127.033.h5\n",
      "179/179 [==============================] - 2s 8ms/step - loss: 34235.4922 - mse: 34235.3828 - val_loss: 16127.0332 - val_mse: 16126.9131\n",
      "Epoch 2/25\n",
      "171/179 [===========================>..] - ETA: 0s - loss: 9432.2061 - mse: 9432.0840\n",
      "Epoch 2: val_loss improved from 16127.03320 to 5376.64258, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e002_vl5376.643.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 9270.9502 - mse: 9270.8271 - val_loss: 5376.6426 - val_mse: 5376.5244\n",
      "Epoch 3/25\n",
      "172/179 [===========================>..] - ETA: 0s - loss: 3946.2358 - mse: 3946.1211\n",
      "Epoch 3: val_loss improved from 5376.64258 to 2770.23828, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e003_vl2770.238.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 3903.7769 - mse: 3903.6624 - val_loss: 2770.2383 - val_mse: 2770.1250\n",
      "Epoch 4/25\n",
      "169/179 [===========================>..] - ETA: 0s - loss: 2052.5518 - mse: 2052.4402\n",
      "Epoch 4: val_loss improved from 2770.23828 to 1408.30542, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e004_vl1408.305.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 2018.0402 - mse: 2017.9286 - val_loss: 1408.3054 - val_mse: 1408.1954\n",
      "Epoch 5/25\n",
      "179/179 [==============================] - ETA: 0s - loss: 1058.8063 - mse: 1058.6978\n",
      "Epoch 5: val_loss improved from 1408.30542 to 788.78302, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e005_vl788.783.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 1058.8063 - mse: 1058.6978 - val_loss: 788.7830 - val_mse: 788.6757\n",
      "Epoch 6/25\n",
      "172/179 [===========================>..] - ETA: 0s - loss: 661.7094 - mse: 661.6024\n",
      "Epoch 6: val_loss improved from 788.78302 to 554.31531, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e006_vl554.315.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 658.6953 - mse: 658.5883 - val_loss: 554.3153 - val_mse: 554.2084\n",
      "Epoch 7/25\n",
      "168/179 [===========================>..] - ETA: 0s - loss: 510.7412 - mse: 510.6346\n",
      "Epoch 7: val_loss improved from 554.31531 to 464.22134, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e007_vl464.221.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 507.7216 - mse: 507.6149 - val_loss: 464.2213 - val_mse: 464.1150\n",
      "Epoch 8/25\n",
      "177/179 [============================>.] - ETA: 0s - loss: 452.5432 - mse: 452.4372\n",
      "Epoch 8: val_loss improved from 464.22134 to 435.73151, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e008_vl435.732.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 452.3712 - mse: 452.2652 - val_loss: 435.7315 - val_mse: 435.6257\n",
      "Epoch 9/25\n",
      "170/179 [===========================>..] - ETA: 0s - loss: 434.0630 - mse: 433.9574\n",
      "Epoch 9: val_loss improved from 435.73151 to 423.83932, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e009_vl423.839.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 434.1143 - mse: 434.0087 - val_loss: 423.8393 - val_mse: 423.7336\n",
      "Epoch 10/25\n",
      "176/179 [============================>.] - ETA: 0s - loss: 423.8976 - mse: 423.7919\n",
      "Epoch 10: val_loss improved from 423.83932 to 414.86038, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e010_vl414.860.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 423.8323 - mse: 423.7267 - val_loss: 414.8604 - val_mse: 414.7549\n",
      "Epoch 11/25\n",
      "176/179 [============================>.] - ETA: 0s - loss: 414.8349 - mse: 414.7298\n",
      "Epoch 11: val_loss improved from 414.86038 to 406.17783, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e011_vl406.178.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 414.6429 - mse: 414.5377 - val_loss: 406.1778 - val_mse: 406.0727\n",
      "Epoch 12/25\n",
      "179/179 [==============================] - ETA: 0s - loss: 404.8785 - mse: 404.7737\n",
      "Epoch 12: val_loss improved from 406.17783 to 395.98892, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e012_vl395.989.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 404.8785 - mse: 404.7737 - val_loss: 395.9889 - val_mse: 395.8846\n",
      "Epoch 13/25\n",
      "173/179 [===========================>..] - ETA: 0s - loss: 394.0414 - mse: 393.9372\n",
      "Epoch 13: val_loss improved from 395.98892 to 384.28149, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e013_vl384.281.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 393.6328 - mse: 393.5286 - val_loss: 384.2815 - val_mse: 384.1777\n",
      "Epoch 14/25\n",
      "168/179 [===========================>..] - ETA: 0s - loss: 380.6739 - mse: 380.5701\n",
      "Epoch 14: val_loss improved from 384.28149 to 371.00342, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e014_vl371.003.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 380.6710 - mse: 380.5672 - val_loss: 371.0034 - val_mse: 370.9003\n",
      "Epoch 15/25\n",
      "170/179 [===========================>..] - ETA: 0s - loss: 366.7882 - mse: 366.6857\n",
      "Epoch 15: val_loss improved from 371.00342 to 357.45001, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e015_vl357.450.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 366.6320 - mse: 366.5294 - val_loss: 357.4500 - val_mse: 357.3476\n",
      "Epoch 16/25\n",
      "177/179 [============================>.] - ETA: 0s - loss: 353.5736 - mse: 353.4718\n",
      "Epoch 16: val_loss improved from 357.45001 to 345.71878, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e016_vl345.719.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 353.5040 - mse: 353.4022 - val_loss: 345.7188 - val_mse: 345.6173\n",
      "Epoch 17/25\n",
      "169/179 [===========================>..] - ETA: 0s - loss: 343.3558 - mse: 343.2548\n",
      "Epoch 17: val_loss improved from 345.71878 to 336.92776, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e017_vl336.928.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 343.0192 - mse: 342.9182 - val_loss: 336.9278 - val_mse: 336.8276\n",
      "Epoch 18/25\n",
      "169/179 [===========================>..] - ETA: 0s - loss: 336.0629 - mse: 335.9631\n",
      "Epoch 18: val_loss improved from 336.92776 to 330.78339, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e018_vl330.783.h5\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 335.4662 - mse: 335.3664 - val_loss: 330.7834 - val_mse: 330.6840\n",
      "Epoch 19/25\n",
      "175/179 [============================>.] - ETA: 0s - loss: 330.2518 - mse: 330.1527\n",
      "Epoch 19: val_loss improved from 330.78339 to 326.18057, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e019_vl326.181.h5\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 329.9930 - mse: 329.8940 - val_loss: 326.1806 - val_mse: 326.0814\n",
      "Epoch 20/25\n",
      "165/179 [==========================>...] - ETA: 0s - loss: 325.7987 - mse: 325.6999\n",
      "Epoch 20: val_loss improved from 326.18057 to 322.37521, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e020_vl322.375.h5\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 325.6888 - mse: 325.5899 - val_loss: 322.3752 - val_mse: 322.2767\n",
      "Epoch 21/25\n",
      "165/179 [==========================>...] - ETA: 0s - loss: 322.6015 - mse: 322.5031\n",
      "Epoch 21: val_loss improved from 322.37521 to 319.22580, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e021_vl319.226.h5\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 322.0322 - mse: 321.9339 - val_loss: 319.2258 - val_mse: 319.1283\n",
      "Epoch 22/25\n",
      "172/179 [===========================>..] - ETA: 0s - loss: 318.8732 - mse: 318.7756\n",
      "Epoch 22: val_loss improved from 319.22580 to 316.07419, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e022_vl316.074.h5\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 318.6629 - mse: 318.5654 - val_loss: 316.0742 - val_mse: 315.9773\n",
      "Epoch 23/25\n",
      "173/179 [===========================>..] - ETA: 0s - loss: 315.5624 - mse: 315.4656\n",
      "Epoch 23: val_loss improved from 316.07419 to 312.86420, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e023_vl312.864.h5\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 315.4155 - mse: 315.3187 - val_loss: 312.8642 - val_mse: 312.7678\n",
      "Epoch 24/25\n",
      "175/179 [============================>.] - ETA: 0s - loss: 312.2845 - mse: 312.1888\n",
      "Epoch 24: val_loss improved from 312.86420 to 309.76523, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e024_vl309.765.h5\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 312.1740 - mse: 312.0785 - val_loss: 309.7652 - val_mse: 309.6696\n",
      "Epoch 25/25\n",
      "179/179 [==============================] - ETA: 0s - loss: 308.8003 - mse: 308.7050\n",
      "Epoch 25: val_loss improved from 309.76523 to 306.48978, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e025_vl306.490.h5\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 308.8003 - mse: 308.7050 - val_loss: 306.4898 - val_mse: 306.3949\n",
      "Time elapsed to train: 26.39 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [0.925 1.659 1.203 1.751 1.492 1.177 1.022 0.909 0.855 1.090 1.146 0.671 0.717]\n",
      "<R> = [0.939 1.668 1.195 1.755 1.496 1.180 1.026 0.875 0.841 1.074 1.090 0.658 0.712]\n",
      "s_R = [0.922 0.670 0.388 0.836 0.581 0.620 0.688 1.308 0.480 0.594 0.835 0.890 0.423]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [4.0698085 4.2320213 6.52553   ... 4.3662663 4.396028  4.4578753]\n",
      "mag_pred: [4.0698085 4.2320213 6.52553   ... 4.3662663 4.396028  4.4578753]\n",
      "Time elapsed to make plots: 19.50 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 284.30292  149.30446  341.08087 ...  138.79868   72.62637 4440.464  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 1.55\n",
      "  1% : 3.96\n",
      "  10% : 7.01\n",
      "  50% : 19.2\n",
      "  90% : 102\n",
      "  99% : 465\n",
      "  100% : 8.48e+03\n",
      "<chi^2/d.o.f.> = 7.1\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 25838 stars (10.2%) based on chi^2/dof > 100.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [281.48575 121.58467 887.62146 ... 320.145   243.1619  222.55814]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 2.15\n",
      "  1% : 3.95\n",
      "  10% : 6.98\n",
      "  50% : 19.1\n",
      "  90% : 102\n",
      "  99% : 497\n",
      "  100% : 4.2e+03\n",
      "<chi^2/d.o.f.> = 7.08\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 79.31 s\n",
      "learning rate = 0.0010000000474974513\n",
      "setting learning rate to 0.0008187307530779819\n",
      "Iteration 2 of 20.\n",
      "Epoch 1/25\n",
      "156/161 [============================>.] - ETA: 0s - loss: 17.7419 - mse: 17.6471\n",
      "Epoch 1: val_loss improved from inf to 17.21317, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e001_vl17.213.h5\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 17.7259 - mse: 17.6311 - val_loss: 17.2132 - val_mse: 17.1184\n",
      "Epoch 2/25\n",
      "156/161 [============================>.] - ETA: 0s - loss: 17.1520 - mse: 17.0572\n",
      "Epoch 2: val_loss improved from 17.21317 to 16.79054, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e002_vl16.791.h5\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 17.1358 - mse: 17.0410 - val_loss: 16.7905 - val_mse: 16.6958\n",
      "Epoch 3/25\n",
      "157/161 [============================>.] - ETA: 0s - loss: 16.7682 - mse: 16.6736\n",
      "Epoch 3: val_loss improved from 16.79054 to 16.46809, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e003_vl16.468.h5\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 16.7672 - mse: 16.6725 - val_loss: 16.4681 - val_mse: 16.3735\n",
      "Epoch 4/25\n",
      "154/161 [===========================>..] - ETA: 0s - loss: 16.4922 - mse: 16.3976\n",
      "Epoch 4: val_loss improved from 16.46809 to 16.19844, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e004_vl16.198.h5\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 16.4719 - mse: 16.3774 - val_loss: 16.1984 - val_mse: 16.1040\n",
      "Epoch 5/25\n",
      "154/161 [===========================>..] - ETA: 0s - loss: 16.2330 - mse: 16.1386\n",
      "Epoch 5: val_loss improved from 16.19844 to 15.96294, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e005_vl15.963.h5\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 16.2191 - mse: 16.1248 - val_loss: 15.9629 - val_mse: 15.8687\n",
      "Epoch 6/25\n",
      "150/161 [==========================>...] - ETA: 0s - loss: 15.9911 - mse: 15.8970\n",
      "Epoch 6: val_loss improved from 15.96294 to 15.75446, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e006_vl15.754.h5\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 15.9980 - mse: 15.9039 - val_loss: 15.7545 - val_mse: 15.6605\n",
      "Epoch 7/25\n",
      "159/161 [============================>.] - ETA: 0s - loss: 15.7983 - mse: 15.7044\n",
      "Epoch 7: val_loss improved from 15.75446 to 15.57241, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e007_vl15.572.h5\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 15.8030 - mse: 15.7091 - val_loss: 15.5724 - val_mse: 15.4787\n",
      "Epoch 8/25\n",
      "158/161 [============================>.] - ETA: 0s - loss: 15.6340 - mse: 15.5405\n",
      "Epoch 8: val_loss improved from 15.57241 to 15.40990, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e008_vl15.410.h5\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 15.6307 - mse: 15.5371 - val_loss: 15.4099 - val_mse: 15.3165\n",
      "Epoch 9/25\n",
      "155/161 [===========================>..] - ETA: 0s - loss: 15.4854 - mse: 15.3922\n",
      "Epoch 9: val_loss improved from 15.40990 to 15.27056, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e009_vl15.271.h5\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 15.4786 - mse: 15.3854 - val_loss: 15.2706 - val_mse: 15.1776\n",
      "Epoch 10/25\n",
      "154/161 [===========================>..] - ETA: 0s - loss: 15.3490 - mse: 15.2563\n",
      "Epoch 10: val_loss improved from 15.27056 to 15.14703, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e010_vl15.147.h5\n",
      "161/161 [==============================] - 1s 7ms/step - loss: 15.3470 - mse: 15.2543 - val_loss: 15.1470 - val_mse: 15.0545\n",
      "Epoch 11/25\n",
      "159/161 [============================>.] - ETA: 0s - loss: 15.2343 - mse: 15.1420\n",
      "Epoch 11: val_loss improved from 15.14703 to 15.03711, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e011_vl15.037.h5\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 15.2313 - mse: 15.1390 - val_loss: 15.0371 - val_mse: 14.9451\n",
      "Epoch 12/25\n",
      "158/161 [============================>.] - ETA: 0s - loss: 15.1321 - mse: 15.0404\n",
      "Epoch 12: val_loss improved from 15.03711 to 14.94373, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e012_vl14.944.h5\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 15.1322 - mse: 15.0405 - val_loss: 14.9437 - val_mse: 14.8523\n",
      "Epoch 13/25\n",
      "158/161 [============================>.] - ETA: 0s - loss: 15.0463 - mse: 14.9551\n",
      "Epoch 13: val_loss improved from 14.94373 to 14.86113, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e013_vl14.861.h5\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 15.0433 - mse: 14.9521 - val_loss: 14.8611 - val_mse: 14.7703\n",
      "Epoch 14/25\n",
      "159/161 [============================>.] - ETA: 0s - loss: 14.9669 - mse: 14.8764\n",
      "Epoch 14: val_loss improved from 14.86113 to 14.78757, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e014_vl14.788.h5\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 14.9670 - mse: 14.8765 - val_loss: 14.7876 - val_mse: 14.6974\n",
      "Epoch 15/25\n",
      "158/161 [============================>.] - ETA: 0s - loss: 14.9016 - mse: 14.8117\n",
      "Epoch 15: val_loss improved from 14.78757 to 14.72115, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e015_vl14.721.h5\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 14.8969 - mse: 14.8070 - val_loss: 14.7212 - val_mse: 14.6316\n",
      "Epoch 16/25\n",
      "158/161 [============================>.] - ETA: 0s - loss: 14.8407 - mse: 14.7514\n",
      "Epoch 16: val_loss improved from 14.72115 to 14.67015, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e016_vl14.670.h5\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 14.8371 - mse: 14.7479 - val_loss: 14.6701 - val_mse: 14.5812\n",
      "Epoch 17/25\n",
      "156/161 [============================>.] - ETA: 0s - loss: 14.7839 - mse: 14.6952\n",
      "Epoch 17: val_loss improved from 14.67015 to 14.61061, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e017_vl14.611.h5\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 14.7821 - mse: 14.6934 - val_loss: 14.6106 - val_mse: 14.5221\n",
      "Epoch 18/25\n",
      "150/161 [==========================>...] - ETA: 0s - loss: 14.7186 - mse: 14.6303\n",
      "Epoch 18: val_loss improved from 14.61061 to 14.57219, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e018_vl14.572.h5\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 14.7307 - mse: 14.6424 - val_loss: 14.5722 - val_mse: 14.4842\n",
      "Epoch 19/25\n",
      "156/161 [============================>.] - ETA: 0s - loss: 14.6898 - mse: 14.6020\n",
      "Epoch 19: val_loss improved from 14.57219 to 14.52122, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e019_vl14.521.h5\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 14.6851 - mse: 14.5973 - val_loss: 14.5212 - val_mse: 14.4337\n",
      "Epoch 20/25\n",
      "154/161 [===========================>..] - ETA: 0s - loss: 14.6504 - mse: 14.5631\n",
      "Epoch 20: val_loss improved from 14.52122 to 14.47658, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e020_vl14.477.h5\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 14.6402 - mse: 14.5530 - val_loss: 14.4766 - val_mse: 14.3897\n",
      "Epoch 21/25\n",
      "154/161 [===========================>..] - ETA: 0s - loss: 14.5848 - mse: 14.4981\n",
      "Epoch 21: val_loss improved from 14.47658 to 14.43395, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e021_vl14.434.h5\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 14.5968 - mse: 14.5101 - val_loss: 14.4340 - val_mse: 14.3476\n",
      "Epoch 22/25\n",
      "157/161 [============================>.] - ETA: 0s - loss: 14.5564 - mse: 14.4704\n",
      "Epoch 22: val_loss improved from 14.43395 to 14.39435, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e022_vl14.394.h5\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 14.5574 - mse: 14.4714 - val_loss: 14.3943 - val_mse: 14.3086\n",
      "Epoch 23/25\n",
      "160/161 [============================>.] - ETA: 0s - loss: 14.5173 - mse: 14.4320\n",
      "Epoch 23: val_loss improved from 14.39435 to 14.34921, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e023_vl14.349.h5\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 14.5169 - mse: 14.4316 - val_loss: 14.3492 - val_mse: 14.2642\n",
      "Epoch 24/25\n",
      "155/161 [===========================>..] - ETA: 0s - loss: 14.4939 - mse: 14.4092\n",
      "Epoch 24: val_loss improved from 14.34921 to 14.32247, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e024_vl14.322.h5\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 14.4797 - mse: 14.3950 - val_loss: 14.3225 - val_mse: 14.2381\n",
      "Epoch 25/25\n",
      "152/161 [===========================>..] - ETA: 0s - loss: 14.4403 - mse: 14.3563\n",
      "Epoch 25: val_loss improved from 14.32247 to 14.27983, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e025_vl14.280.h5\n",
      "161/161 [==============================] - 1s 6ms/step - loss: 14.4442 - mse: 14.3602 - val_loss: 14.2798 - val_mse: 14.1962\n",
      "Time elapsed to train: 25.01 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [0.969 1.616 1.197 1.947 1.281 1.011 0.745 0.904 0.844 0.950 0.971 0.657 0.701]\n",
      "<R> = [0.982 1.619 1.197 1.947 1.288 1.011 0.746 0.870 0.846 0.940 0.918 0.644 0.696]\n",
      "s_R = [0.987 0.481 0.095 0.791 0.267 0.139 0.328 1.286 0.466 0.581 0.923 0.766 0.377]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [4.1014566 3.5833359 6.6953826 ... 3.9813342 4.799158  4.988276 ]\n",
      "mag_pred: [4.1014566 3.5833359 6.6953826 ... 3.9813342 4.799158  4.988276 ]\n",
      "Time elapsed to make plots: 18.67 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7efed1bde5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7efed1be3820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 248.94186    26.053257  355.68713  ...   61.385708   33.03371\n",
      " 2264.4138  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0562\n",
      "  1% : 0.655\n",
      "  10% : 1.63\n",
      "  50% : 8.34\n",
      "  90% : 47.9\n",
      "  99% : 331\n",
      "  100% : 7.95e+03\n",
      "<chi^2/d.o.f.> = 4.34\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 14941 stars (5.9%) based on chi^2/dof > 79.4\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [139.0397    68.122955 487.49664  ...  64.02063  150.92102   35.3055  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.211\n",
      "  1% : 0.658\n",
      "  10% : 1.61\n",
      "  50% : 8.19\n",
      "  90% : 48\n",
      "  99% : 355\n",
      "  100% : 5.22e+03\n",
      "<chi^2/d.o.f.> = 4.31\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 76.99 s\n",
      "learning rate = 0.0008187307394109666\n",
      "setting learning rate to 0.0006703200460356394\n",
      "Iteration 3 of 20.\n",
      "Epoch 1/25\n",
      "164/168 [============================>.] - ETA: 0s - loss: 9.6980 - mse: 9.6144\n",
      "Epoch 1: val_loss improved from inf to 9.64172, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e001_vl9.642.h5\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 9.7018 - mse: 9.6182 - val_loss: 9.6417 - val_mse: 9.5584\n",
      "Epoch 2/25\n",
      "163/168 [============================>.] - ETA: 0s - loss: 9.5939 - mse: 9.5108\n",
      "Epoch 2: val_loss improved from 9.64172 to 9.56813, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e002_vl9.568.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.5912 - mse: 9.5081 - val_loss: 9.5681 - val_mse: 9.4853\n",
      "Epoch 3/25\n",
      "168/168 [==============================] - ETA: 0s - loss: 9.5328 - mse: 9.4501\n",
      "Epoch 3: val_loss improved from 9.56813 to 9.51646, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e003_vl9.516.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.5328 - mse: 9.4501 - val_loss: 9.5165 - val_mse: 9.4341\n",
      "Epoch 4/25\n",
      "165/168 [============================>.] - ETA: 0s - loss: 9.4805 - mse: 9.3984\n",
      "Epoch 4: val_loss improved from 9.51646 to 9.47843, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e004_vl9.478.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.4896 - mse: 9.4075 - val_loss: 9.4784 - val_mse: 9.3966\n",
      "Epoch 5/25\n",
      "161/168 [===========================>..] - ETA: 0s - loss: 9.4462 - mse: 9.3647\n",
      "Epoch 5: val_loss improved from 9.47843 to 9.44962, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e005_vl9.450.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.4550 - mse: 9.3735 - val_loss: 9.4496 - val_mse: 9.3685\n",
      "Epoch 6/25\n",
      "166/168 [============================>.] - ETA: 0s - loss: 9.4281 - mse: 9.3473\n",
      "Epoch 6: val_loss improved from 9.44962 to 9.42356, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e006_vl9.424.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.4242 - mse: 9.3434 - val_loss: 9.4236 - val_mse: 9.3431\n",
      "Epoch 7/25\n",
      "160/168 [===========================>..] - ETA: 0s - loss: 9.4089 - mse: 9.3289\n",
      "Epoch 7: val_loss improved from 9.42356 to 9.38775, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e007_vl9.388.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.3969 - mse: 9.3169 - val_loss: 9.3878 - val_mse: 9.3081\n",
      "Epoch 8/25\n",
      "163/168 [============================>.] - ETA: 0s - loss: 9.3688 - mse: 9.2895\n",
      "Epoch 8: val_loss improved from 9.38775 to 9.36593, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e008_vl9.366.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.3684 - mse: 9.2891 - val_loss: 9.3659 - val_mse: 9.2871\n",
      "Epoch 9/25\n",
      "164/168 [============================>.] - ETA: 0s - loss: 9.3461 - mse: 9.2677\n",
      "Epoch 9: val_loss improved from 9.36593 to 9.33635, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e009_vl9.336.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.3431 - mse: 9.2647 - val_loss: 9.3364 - val_mse: 9.2583\n",
      "Epoch 10/25\n",
      "157/168 [===========================>..] - ETA: 0s - loss: 9.3068 - mse: 9.2292\n",
      "Epoch 10: val_loss improved from 9.33635 to 9.31192, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e010_vl9.312.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.3167 - mse: 9.2391 - val_loss: 9.3119 - val_mse: 9.2346\n",
      "Epoch 11/25\n",
      "168/168 [==============================] - ETA: 0s - loss: 9.2923 - mse: 9.2154\n",
      "Epoch 11: val_loss improved from 9.31192 to 9.29633, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e011_vl9.296.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.2923 - mse: 9.2154 - val_loss: 9.2963 - val_mse: 9.2198\n",
      "Epoch 12/25\n",
      "165/168 [============================>.] - ETA: 0s - loss: 9.2681 - mse: 9.1919\n",
      "Epoch 12: val_loss improved from 9.29633 to 9.26382, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e012_vl9.264.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.2690 - mse: 9.1928 - val_loss: 9.2638 - val_mse: 9.1879\n",
      "Epoch 13/25\n",
      "159/168 [===========================>..] - ETA: 0s - loss: 9.2521 - mse: 9.1764\n",
      "Epoch 13: val_loss improved from 9.26382 to 9.24459, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e013_vl9.245.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.2457 - mse: 9.1700 - val_loss: 9.2446 - val_mse: 9.1692\n",
      "Epoch 14/25\n",
      "159/168 [===========================>..] - ETA: 0s - loss: 9.2145 - mse: 9.1394\n",
      "Epoch 14: val_loss improved from 9.24459 to 9.22465, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e014_vl9.225.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.2236 - mse: 9.1484 - val_loss: 9.2246 - val_mse: 9.1498\n",
      "Epoch 15/25\n",
      "166/168 [============================>.] - ETA: 0s - loss: 9.1969 - mse: 9.1223\n",
      "Epoch 15: val_loss improved from 9.22465 to 9.20578, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e015_vl9.206.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.1992 - mse: 9.1246 - val_loss: 9.2058 - val_mse: 9.1313\n",
      "Epoch 16/25\n",
      "160/168 [===========================>..] - ETA: 0s - loss: 9.1788 - mse: 9.1045\n",
      "Epoch 16: val_loss improved from 9.20578 to 9.18169, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e016_vl9.182.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.1787 - mse: 9.1044 - val_loss: 9.1817 - val_mse: 9.1075\n",
      "Epoch 17/25\n",
      "165/168 [============================>.] - ETA: 0s - loss: 9.1625 - mse: 9.0884\n",
      "Epoch 17: val_loss improved from 9.18169 to 9.16239, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e017_vl9.162.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.1572 - mse: 9.0831 - val_loss: 9.1624 - val_mse: 9.0885\n",
      "Epoch 18/25\n",
      "163/168 [============================>.] - ETA: 0s - loss: 9.1363 - mse: 9.0625\n",
      "Epoch 18: val_loss improved from 9.16239 to 9.13660, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e018_vl9.137.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.1366 - mse: 9.0628 - val_loss: 9.1366 - val_mse: 9.0629\n",
      "Epoch 19/25\n",
      "159/168 [===========================>..] - ETA: 0s - loss: 9.1063 - mse: 9.0328\n",
      "Epoch 19: val_loss improved from 9.13660 to 9.12054, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e019_vl9.121.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.1170 - mse: 9.0435 - val_loss: 9.1205 - val_mse: 9.0471\n",
      "Epoch 20/25\n",
      "166/168 [============================>.] - ETA: 0s - loss: 9.0905 - mse: 9.0173\n",
      "Epoch 20: val_loss improved from 9.12054 to 9.10117, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e020_vl9.101.h5\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 9.0941 - mse: 9.0208 - val_loss: 9.1012 - val_mse: 9.0280\n",
      "Epoch 21/25\n",
      "167/168 [============================>.] - ETA: 0s - loss: 9.0761 - mse: 9.0031\n",
      "Epoch 21: val_loss improved from 9.10117 to 9.08298, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e021_vl9.083.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.0752 - mse: 9.0022 - val_loss: 9.0830 - val_mse: 9.0101\n",
      "Epoch 22/25\n",
      "168/168 [==============================] - ETA: 0s - loss: 9.0533 - mse: 8.9805\n",
      "Epoch 22: val_loss improved from 9.08298 to 9.05974, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e022_vl9.060.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.0533 - mse: 8.9805 - val_loss: 9.0597 - val_mse: 8.9871\n",
      "Epoch 23/25\n",
      "166/168 [============================>.] - ETA: 0s - loss: 9.0424 - mse: 8.9698\n",
      "Epoch 23: val_loss did not improve from 9.05974\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.0351 - mse: 8.9626 - val_loss: 9.0615 - val_mse: 8.9890\n",
      "Epoch 24/25\n",
      "157/168 [===========================>..] - ETA: 0s - loss: 9.0293 - mse: 8.9570\n",
      "Epoch 24: val_loss improved from 9.05974 to 9.03216, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e024_vl9.032.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.0161 - mse: 8.9438 - val_loss: 9.0322 - val_mse: 8.9599\n",
      "Epoch 25/25\n",
      "165/168 [============================>.] - ETA: 0s - loss: 8.9934 - mse: 8.9212\n",
      "Epoch 25: val_loss improved from 9.03216 to 9.00450, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e025_vl9.005.h5\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 8.9956 - mse: 8.9234 - val_loss: 9.0045 - val_mse: 8.9325\n",
      "Time elapsed to train: 25.73 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [1.157 1.769 1.085 1.879 1.271 0.998 0.766 0.886 0.678 0.664 0.675 0.475 0.584]\n",
      "<R> = [1.168 1.771 1.085 1.877 1.272 0.999 0.766 0.853 0.681 0.667 0.653 0.471 0.577]\n",
      "s_R = [1.125 0.624 0.118 0.875 0.293 0.049 0.002 1.205 0.315 0.625 1.142 0.304 0.187]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.9165123 3.5088549 6.5619407 ... 3.9740715 4.484684  4.6734066]\n",
      "mag_pred: [3.9165123 3.5088549 6.5619407 ... 3.9740715 4.484684  4.6734066]\n",
      "Time elapsed to make plots: 18.28 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 348.58322    33.747673  191.6922   ...   41.751816   37.92569\n",
      " 1287.424   ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0665\n",
      "  1% : 0.386\n",
      "  10% : 1.04\n",
      "  50% : 5.83\n",
      "  90% : 30.7\n",
      "  99% : 244\n",
      "  100% : 8.99e+03\n",
      "<chi^2/d.o.f.> = 3.94\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 12275 stars (4.85%) based on chi^2/dof > 63.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 84.8928    49.464027 340.36395  ...  83.615036  99.415405  21.071796]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.106\n",
      "  1% : 0.384\n",
      "  10% : 1.03\n",
      "  50% : 5.74\n",
      "  90% : 30.8\n",
      "  99% : 259\n",
      "  100% : 6.11e+03\n",
      "<chi^2/d.o.f.> = 3.92\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 81.42 s\n",
      "learning rate = 0.0006703200633637607\n",
      "setting learning rate to 0.0005488116360940264\n",
      "Iteration 4 of 20.\n",
      "Epoch 1/25\n",
      "164/170 [===========================>..] - ETA: 0s - loss: 6.5495 - mse: 6.4765\n",
      "Epoch 1: val_loss improved from inf to 6.51128, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e001_vl6.511.h5\n",
      "170/170 [==============================] - 1s 7ms/step - loss: 6.5524 - mse: 6.4793 - val_loss: 6.5113 - val_mse: 6.4382\n",
      "Epoch 2/25\n",
      "161/170 [===========================>..] - ETA: 0s - loss: 6.5128 - mse: 6.4400\n",
      "Epoch 2: val_loss improved from 6.51128 to 6.48239, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e002_vl6.482.h5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 6.5097 - mse: 6.4369 - val_loss: 6.4824 - val_mse: 6.4100\n",
      "Epoch 3/25\n",
      "161/170 [===========================>..] - ETA: 0s - loss: 6.4746 - mse: 6.4025\n",
      "Epoch 3: val_loss improved from 6.48239 to 6.45534, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e003_vl6.455.h5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 6.4833 - mse: 6.4111 - val_loss: 6.4553 - val_mse: 6.3834\n",
      "Epoch 4/25\n",
      "162/170 [===========================>..] - ETA: 0s - loss: 6.4585 - mse: 6.3868\n",
      "Epoch 4: val_loss improved from 6.45534 to 6.42952, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e004_vl6.430.h5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 6.4583 - mse: 6.3866 - val_loss: 6.4295 - val_mse: 6.3580\n",
      "Epoch 5/25\n",
      "161/170 [===========================>..] - ETA: 0s - loss: 6.4337 - mse: 6.3624\n",
      "Epoch 5: val_loss improved from 6.42952 to 6.41117, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e005_vl6.411.h5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 6.4363 - mse: 6.3650 - val_loss: 6.4112 - val_mse: 6.3400\n",
      "Epoch 6/25\n",
      "159/170 [===========================>..] - ETA: 0s - loss: 6.4109 - mse: 6.3399\n",
      "Epoch 6: val_loss improved from 6.41117 to 6.38895, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e006_vl6.389.h5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 6.4142 - mse: 6.3432 - val_loss: 6.3890 - val_mse: 6.3182\n",
      "Epoch 7/25\n",
      "170/170 [==============================] - ETA: 0s - loss: 6.3930 - mse: 6.3224\n",
      "Epoch 7: val_loss improved from 6.38895 to 6.36732, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e007_vl6.367.h5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 6.3930 - mse: 6.3224 - val_loss: 6.3673 - val_mse: 6.2968\n",
      "Epoch 8/25\n",
      "170/170 [==============================] - ETA: 0s - loss: 6.3744 - mse: 6.3041\n",
      "Epoch 8: val_loss improved from 6.36732 to 6.35119, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e008_vl6.351.h5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 6.3744 - mse: 6.3041 - val_loss: 6.3512 - val_mse: 6.2810\n",
      "Epoch 9/25\n",
      "168/170 [============================>.] - ETA: 0s - loss: 6.3535 - mse: 6.2835\n",
      "Epoch 9: val_loss improved from 6.35119 to 6.33824, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e009_vl6.338.h5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 6.3556 - mse: 6.2856 - val_loss: 6.3382 - val_mse: 6.2683\n",
      "Epoch 10/25\n",
      "161/170 [===========================>..] - ETA: 0s - loss: 6.3431 - mse: 6.2732\n",
      "Epoch 10: val_loss improved from 6.33824 to 6.31245, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e010_vl6.312.h5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 6.3381 - mse: 6.2682 - val_loss: 6.3124 - val_mse: 6.2429\n",
      "Epoch 11/25\n",
      "170/170 [==============================] - ETA: 0s - loss: 6.3211 - mse: 6.2517\n",
      "Epoch 11: val_loss improved from 6.31245 to 6.29955, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e011_vl6.300.h5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 6.3211 - mse: 6.2517 - val_loss: 6.2996 - val_mse: 6.2302\n",
      "Epoch 12/25\n",
      "170/170 [==============================] - ETA: 0s - loss: 6.3045 - mse: 6.2353\n",
      "Epoch 12: val_loss improved from 6.29955 to 6.28062, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e012_vl6.281.h5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 6.3045 - mse: 6.2353 - val_loss: 6.2806 - val_mse: 6.2117\n",
      "Epoch 13/25\n",
      "170/170 [==============================] - ETA: 0s - loss: 6.2895 - mse: 6.2207\n",
      "Epoch 13: val_loss improved from 6.28062 to 6.27070, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e013_vl6.271.h5\n",
      "170/170 [==============================] - 1s 5ms/step - loss: 6.2895 - mse: 6.2207 - val_loss: 6.2707 - val_mse: 6.2020\n",
      "Epoch 14/25\n",
      "164/170 [===========================>..] - ETA: 0s - loss: 6.2737 - mse: 6.2053\n",
      "Epoch 14: val_loss improved from 6.27070 to 6.25472, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e014_vl6.255.h5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 6.2772 - mse: 6.2087 - val_loss: 6.2547 - val_mse: 6.1864\n",
      "Epoch 15/25\n",
      "163/170 [===========================>..] - ETA: 0s - loss: 6.2636 - mse: 6.1955\n",
      "Epoch 15: val_loss improved from 6.25472 to 6.23883, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e015_vl6.239.h5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 6.2594 - mse: 6.1913 - val_loss: 6.2388 - val_mse: 6.1710\n",
      "Epoch 16/25\n",
      "170/170 [==============================] - ETA: 0s - loss: 6.2454 - mse: 6.1777\n",
      "Epoch 16: val_loss improved from 6.23883 to 6.22568, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e016_vl6.226.h5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 6.2454 - mse: 6.1777 - val_loss: 6.2257 - val_mse: 6.1581\n",
      "Epoch 17/25\n",
      "161/170 [===========================>..] - ETA: 0s - loss: 6.2334 - mse: 6.1660\n",
      "Epoch 17: val_loss improved from 6.22568 to 6.21860, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e017_vl6.219.h5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 6.2344 - mse: 6.1671 - val_loss: 6.2186 - val_mse: 6.1515\n",
      "Epoch 18/25\n",
      "160/170 [===========================>..] - ETA: 0s - loss: 6.2180 - mse: 6.1511\n",
      "Epoch 18: val_loss improved from 6.21860 to 6.20459, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e018_vl6.205.h5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 6.2196 - mse: 6.1527 - val_loss: 6.2046 - val_mse: 6.1380\n",
      "Epoch 19/25\n",
      "164/170 [===========================>..] - ETA: 0s - loss: 6.2061 - mse: 6.1397\n",
      "Epoch 19: val_loss improved from 6.20459 to 6.19130, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e019_vl6.191.h5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 6.2080 - mse: 6.1416 - val_loss: 6.1913 - val_mse: 6.1251\n",
      "Epoch 20/25\n",
      "169/170 [============================>.] - ETA: 0s - loss: 6.1974 - mse: 6.1315\n",
      "Epoch 20: val_loss improved from 6.19130 to 6.17794, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e020_vl6.178.h5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 6.1964 - mse: 6.1305 - val_loss: 6.1779 - val_mse: 6.1124\n",
      "Epoch 21/25\n",
      "167/170 [============================>.] - ETA: 0s - loss: 6.1846 - mse: 6.1195\n",
      "Epoch 21: val_loss improved from 6.17794 to 6.17022, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e021_vl6.170.h5\n",
      "170/170 [==============================] - 1s 5ms/step - loss: 6.1836 - mse: 6.1185 - val_loss: 6.1702 - val_mse: 6.1055\n",
      "Epoch 22/25\n",
      "166/170 [============================>.] - ETA: 0s - loss: 6.1779 - mse: 6.1135\n",
      "Epoch 22: val_loss improved from 6.17022 to 6.15814, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e022_vl6.158.h5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 6.1752 - mse: 6.1108 - val_loss: 6.1581 - val_mse: 6.0942\n",
      "Epoch 23/25\n",
      "164/170 [===========================>..] - ETA: 0s - loss: 6.1637 - mse: 6.1002\n",
      "Epoch 23: val_loss improved from 6.15814 to 6.15175, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e023_vl6.152.h5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 6.1636 - mse: 6.1001 - val_loss: 6.1517 - val_mse: 6.0887\n",
      "Epoch 24/25\n",
      "163/170 [===========================>..] - ETA: 0s - loss: 6.1570 - mse: 6.0944\n",
      "Epoch 24: val_loss improved from 6.15175 to 6.14021, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e024_vl6.140.h5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 6.1548 - mse: 6.0922 - val_loss: 6.1402 - val_mse: 6.0782\n",
      "Epoch 25/25\n",
      "166/170 [============================>.] - ETA: 0s - loss: 6.1457 - mse: 6.0843\n",
      "Epoch 25: val_loss improved from 6.14021 to 6.12598, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e025_vl6.126.h5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 6.1428 - mse: 6.0814 - val_loss: 6.1260 - val_mse: 6.0650\n",
      "Time elapsed to train: 25.35 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [1.850 2.263 1.255 2.431 1.639 1.208 0.853 0.839 0.537 0.314 0.336 0.299 0.324]\n",
      "<R> = [1.850 2.267 1.254 2.434 1.645 1.207 0.852 0.813 0.538 0.315 0.335 0.300 0.326]\n",
      "s_R = [1.022 0.749 0.211 0.911 0.316 0.061 0.046 0.886 0.059 0.335 0.476 0.126 0.149]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.8764067 3.0697508 6.3880515 ... 3.382219  4.3066    4.5155196]\n",
      "mag_pred: [3.8764067 3.0697508 6.3880515 ... 3.382219  4.3066    4.5155196]\n",
      "Time elapsed to make plots: 18.71 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 792.2668     35.50416    67.23615  ...   39.871624   37.4978\n",
      " 1157.0504  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.042\n",
      "  1% : 0.272\n",
      "  10% : 0.846\n",
      "  50% : 5.39\n",
      "  90% : 31.4\n",
      "  99% : 246\n",
      "  100% : 1.05e+04\n",
      "<chi^2/d.o.f.> = 3.7\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 15926 stars (6.29%) based on chi^2/dof > 50.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 75.18741   54.557625 358.54446  ... 126.74782   98.63775   15.583414]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0523\n",
      "  1% : 0.267\n",
      "  10% : 0.837\n",
      "  50% : 5.32\n",
      "  90% : 31.3\n",
      "  99% : 258\n",
      "  100% : 6.42e+03\n",
      "<chi^2/d.o.f.> = 3.66\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 77.90 s\n",
      "learning rate = 0.0005488116294145584\n",
      "setting learning rate to 0.0004493289641172216\n",
      "Iteration 5 of 20.\n",
      "Epoch 1/25\n",
      "161/168 [===========================>..] - ETA: 0s - loss: 5.8513 - mse: 5.7895\n",
      "Epoch 1: val_loss improved from inf to 5.82028, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e001_vl5.820.h5\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 5.8418 - mse: 5.7799 - val_loss: 5.8203 - val_mse: 5.7587\n",
      "Epoch 2/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 5.8015 - mse: 5.7404\n",
      "Epoch 2: val_loss improved from 5.82028 to 5.79562, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e002_vl5.796.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.8026 - mse: 5.7415 - val_loss: 5.7956 - val_mse: 5.7351\n",
      "Epoch 3/25\n",
      "165/168 [============================>.] - ETA: 0s - loss: 5.7852 - mse: 5.7254\n",
      "Epoch 3: val_loss improved from 5.79562 to 5.78238, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e003_vl5.782.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.7849 - mse: 5.7250 - val_loss: 5.7824 - val_mse: 5.7231\n",
      "Epoch 4/25\n",
      "166/168 [============================>.] - ETA: 0s - loss: 5.7722 - mse: 5.7134\n",
      "Epoch 4: val_loss improved from 5.78238 to 5.76725, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e004_vl5.767.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.7716 - mse: 5.7128 - val_loss: 5.7672 - val_mse: 5.7088\n",
      "Epoch 5/25\n",
      "157/168 [===========================>..] - ETA: 0s - loss: 5.7640 - mse: 5.7059\n",
      "Epoch 5: val_loss improved from 5.76725 to 5.75388, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e005_vl5.754.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.7605 - mse: 5.7025 - val_loss: 5.7539 - val_mse: 5.6963\n",
      "Epoch 6/25\n",
      "165/168 [============================>.] - ETA: 0s - loss: 5.7528 - mse: 5.6956\n",
      "Epoch 6: val_loss improved from 5.75388 to 5.74538, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e006_vl5.745.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.7511 - mse: 5.6939 - val_loss: 5.7454 - val_mse: 5.6887\n",
      "Epoch 7/25\n",
      "160/168 [===========================>..] - ETA: 0s - loss: 5.7406 - mse: 5.6843\n",
      "Epoch 7: val_loss improved from 5.74538 to 5.74048, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e007_vl5.740.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.7412 - mse: 5.6850 - val_loss: 5.7405 - val_mse: 5.6849\n",
      "Epoch 8/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 5.7316 - mse: 5.6765\n",
      "Epoch 8: val_loss improved from 5.74048 to 5.72826, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e008_vl5.728.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.7328 - mse: 5.6776 - val_loss: 5.7283 - val_mse: 5.6737\n",
      "Epoch 9/25\n",
      "164/168 [============================>.] - ETA: 0s - loss: 5.7220 - mse: 5.6680\n",
      "Epoch 9: val_loss improved from 5.72826 to 5.72122, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e009_vl5.721.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.7253 - mse: 5.6713 - val_loss: 5.7212 - val_mse: 5.6678\n",
      "Epoch 10/25\n",
      "165/168 [============================>.] - ETA: 0s - loss: 5.7169 - mse: 5.6640\n",
      "Epoch 10: val_loss improved from 5.72122 to 5.71467, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e010_vl5.715.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.7183 - mse: 5.6654 - val_loss: 5.7147 - val_mse: 5.6623\n",
      "Epoch 11/25\n",
      "163/168 [============================>.] - ETA: 0s - loss: 5.7119 - mse: 5.6602\n",
      "Epoch 11: val_loss improved from 5.71467 to 5.70697, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e011_vl5.707.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.7105 - mse: 5.6588 - val_loss: 5.7070 - val_mse: 5.6559\n",
      "Epoch 12/25\n",
      "167/168 [============================>.] - ETA: 0s - loss: 5.7041 - mse: 5.6535\n",
      "Epoch 12: val_loss improved from 5.70697 to 5.70478, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e012_vl5.705.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.7033 - mse: 5.6527 - val_loss: 5.7048 - val_mse: 5.6548\n",
      "Epoch 13/25\n",
      "167/168 [============================>.] - ETA: 0s - loss: 5.6947 - mse: 5.6454\n",
      "Epoch 13: val_loss improved from 5.70478 to 5.68902, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e013_vl5.689.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.6955 - mse: 5.6462 - val_loss: 5.6890 - val_mse: 5.6403\n",
      "Epoch 14/25\n",
      "168/168 [==============================] - ETA: 0s - loss: 5.6899 - mse: 5.6417\n",
      "Epoch 14: val_loss did not improve from 5.68902\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 5.6899 - mse: 5.6417 - val_loss: 5.6949 - val_mse: 5.6474\n",
      "Epoch 15/25\n",
      "163/168 [============================>.] - ETA: 0s - loss: 5.6867 - mse: 5.6399\n",
      "Epoch 15: val_loss improved from 5.68902 to 5.67807, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e015_vl5.678.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.6846 - mse: 5.6379 - val_loss: 5.6781 - val_mse: 5.6319\n",
      "Epoch 16/25\n",
      "167/168 [============================>.] - ETA: 0s - loss: 5.6748 - mse: 5.6294\n",
      "Epoch 16: val_loss improved from 5.67807 to 5.67778, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e016_vl5.678.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.6756 - mse: 5.6302 - val_loss: 5.6778 - val_mse: 5.6330\n",
      "Epoch 17/25\n",
      "166/168 [============================>.] - ETA: 0s - loss: 5.6712 - mse: 5.6271\n",
      "Epoch 17: val_loss improved from 5.67778 to 5.66248, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e017_vl5.662.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.6715 - mse: 5.6274 - val_loss: 5.6625 - val_mse: 5.6192\n",
      "Epoch 18/25\n",
      "161/168 [===========================>..] - ETA: 0s - loss: 5.6628 - mse: 5.6201\n",
      "Epoch 18: val_loss did not improve from 5.66248\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.6621 - mse: 5.6195 - val_loss: 5.6675 - val_mse: 5.6255\n",
      "Epoch 19/25\n",
      "161/168 [===========================>..] - ETA: 0s - loss: 5.6583 - mse: 5.6171\n",
      "Epoch 19: val_loss improved from 5.66248 to 5.65990, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e019_vl5.660.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.6590 - mse: 5.6178 - val_loss: 5.6599 - val_mse: 5.6195\n",
      "Epoch 20/25\n",
      "166/168 [============================>.] - ETA: 0s - loss: 5.6514 - mse: 5.6117\n",
      "Epoch 20: val_loss improved from 5.65990 to 5.64796, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e020_vl5.648.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.6509 - mse: 5.6113 - val_loss: 5.6480 - val_mse: 5.6090\n",
      "Epoch 21/25\n",
      "163/168 [============================>.] - ETA: 0s - loss: 5.6443 - mse: 5.6060\n",
      "Epoch 21: val_loss improved from 5.64796 to 5.64552, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e021_vl5.646.h5\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 5.6448 - mse: 5.6066 - val_loss: 5.6455 - val_mse: 5.6079\n",
      "Epoch 22/25\n",
      "166/168 [============================>.] - ETA: 0s - loss: 5.6411 - mse: 5.6043\n",
      "Epoch 22: val_loss improved from 5.64552 to 5.63424, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e022_vl5.634.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.6391 - mse: 5.6023 - val_loss: 5.6342 - val_mse: 5.5980\n",
      "Epoch 23/25\n",
      "160/168 [===========================>..] - ETA: 0s - loss: 5.6316 - mse: 5.5958\n",
      "Epoch 23: val_loss improved from 5.63424 to 5.62835, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e023_vl5.628.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.6331 - mse: 5.5974 - val_loss: 5.6283 - val_mse: 5.5932\n",
      "Epoch 24/25\n",
      "158/168 [===========================>..] - ETA: 0s - loss: 5.6286 - mse: 5.5941\n",
      "Epoch 24: val_loss improved from 5.62835 to 5.62653, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e024_vl5.627.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.6267 - mse: 5.5921 - val_loss: 5.6265 - val_mse: 5.5927\n",
      "Epoch 25/25\n",
      "161/168 [===========================>..] - ETA: 0s - loss: 5.6206 - mse: 5.5873\n",
      "Epoch 25: val_loss improved from 5.62653 to 5.62578, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e025_vl5.626.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.6216 - mse: 5.5883 - val_loss: 5.6258 - val_mse: 5.5931\n",
      "Time elapsed to train: 25.38 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.341 2.981 1.599 3.242 2.188 1.661 1.228 1.084 0.653 0.161 0.164 0.160 0.145]\n",
      "<R> = [2.339 2.979 1.598 3.236 2.193 1.660 1.228 1.080 0.653 0.161 0.164 0.160 0.145]\n",
      "s_R = [0.295 0.431 0.126 0.562 0.309 0.129 0.108 0.257 0.000 0.022 0.025 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.914637  2.9070578 6.246076  ... 3.129194  4.193356  4.4820848]\n",
      "mag_pred: [3.914637  2.9070578 6.246076  ... 3.129194  4.193356  4.4820848]\n",
      "Time elapsed to make plots: 19.31 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 784.40814    43.3816     36.582848 ...   44.86036    50.479424\n",
      " 1490.3228  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0349\n",
      "  1% : 0.248\n",
      "  10% : 0.862\n",
      "  50% : 6.03\n",
      "  90% : 45.1\n",
      "  99% : 375\n",
      "  100% : 6.89e+03\n",
      "<chi^2/d.o.f.> = 3.61\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 28581 stars (11.3%) based on chi^2/dof > 39.8\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 89.454605  50.12284  917.5104   ... 177.3676   122.99498   24.449408]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0633\n",
      "  1% : 0.242\n",
      "  10% : 0.839\n",
      "  50% : 5.95\n",
      "  90% : 44.1\n",
      "  99% : 394\n",
      "  100% : 5.32e+03\n",
      "<chi^2/d.o.f.> = 3.58\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 76.60 s\n",
      "learning rate = 0.0004493289743550122\n",
      "setting learning rate to 0.00036787944117144236\n",
      "Iteration 6 of 20.\n",
      "Epoch 1/25\n",
      "154/159 [============================>.] - ETA: 0s - loss: 5.6981 - mse: 5.6651\n",
      "Epoch 1: val_loss improved from inf to 5.68906, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e001_vl5.689.h5\n",
      "159/159 [==============================] - 2s 8ms/step - loss: 5.6978 - mse: 5.6648 - val_loss: 5.6891 - val_mse: 5.6564\n",
      "Epoch 2/25\n",
      "152/159 [===========================>..] - ETA: 0s - loss: 5.6718 - mse: 5.6396\n",
      "Epoch 2: val_loss improved from 5.68906 to 5.67354, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e002_vl5.674.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 5.6769 - mse: 5.6447 - val_loss: 5.6735 - val_mse: 5.6418\n",
      "Epoch 3/25\n",
      "158/159 [============================>.] - ETA: 0s - loss: 5.6660 - mse: 5.6348\n",
      "Epoch 3: val_loss improved from 5.67354 to 5.66715, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e003_vl5.667.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 5.6660 - mse: 5.6347 - val_loss: 5.6672 - val_mse: 5.6365\n",
      "Epoch 4/25\n",
      "155/159 [============================>.] - ETA: 0s - loss: 5.6559 - mse: 5.6258\n",
      "Epoch 4: val_loss improved from 5.66715 to 5.65623, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e004_vl5.656.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 5.6562 - mse: 5.6261 - val_loss: 5.6562 - val_mse: 5.6265\n",
      "Epoch 5/25\n",
      "159/159 [==============================] - ETA: 0s - loss: 5.6466 - mse: 5.6171\n",
      "Epoch 5: val_loss improved from 5.65623 to 5.65563, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e005_vl5.656.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 5.6466 - mse: 5.6171 - val_loss: 5.6556 - val_mse: 5.6263\n",
      "Epoch 6/25\n",
      "150/159 [===========================>..] - ETA: 0s - loss: 5.6410 - mse: 5.6115\n",
      "Epoch 6: val_loss improved from 5.65563 to 5.64478, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e006_vl5.645.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 5.6405 - mse: 5.6110 - val_loss: 5.6448 - val_mse: 5.6151\n",
      "Epoch 7/25\n",
      "151/159 [===========================>..] - ETA: 0s - loss: 5.6360 - mse: 5.6062\n",
      "Epoch 7: val_loss improved from 5.64478 to 5.63709, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e007_vl5.637.h5\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 5.6337 - mse: 5.6039 - val_loss: 5.6371 - val_mse: 5.6072\n",
      "Epoch 8/25\n",
      "156/159 [============================>.] - ETA: 0s - loss: 5.6294 - mse: 5.5993\n",
      "Epoch 8: val_loss improved from 5.63709 to 5.63699, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e008_vl5.637.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 5.6298 - mse: 5.5996 - val_loss: 5.6370 - val_mse: 5.6066\n",
      "Epoch 9/25\n",
      "155/159 [============================>.] - ETA: 0s - loss: 5.6244 - mse: 5.5940\n",
      "Epoch 9: val_loss improved from 5.63699 to 5.62526, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e009_vl5.625.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 5.6241 - mse: 5.5936 - val_loss: 5.6253 - val_mse: 5.5945\n",
      "Epoch 10/25\n",
      "158/159 [============================>.] - ETA: 0s - loss: 5.6173 - mse: 5.5864\n",
      "Epoch 10: val_loss improved from 5.62526 to 5.62479, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e010_vl5.625.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 5.6170 - mse: 5.5861 - val_loss: 5.6248 - val_mse: 5.5937\n",
      "Epoch 11/25\n",
      "156/159 [============================>.] - ETA: 0s - loss: 5.6159 - mse: 5.5846\n",
      "Epoch 11: val_loss improved from 5.62479 to 5.61890, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e011_vl5.619.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 5.6136 - mse: 5.5824 - val_loss: 5.6189 - val_mse: 5.5875\n",
      "Epoch 12/25\n",
      "154/159 [============================>.] - ETA: 0s - loss: 5.6062 - mse: 5.5744\n",
      "Epoch 12: val_loss improved from 5.61890 to 5.61416, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e012_vl5.614.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 5.6086 - mse: 5.5768 - val_loss: 5.6142 - val_mse: 5.5821\n",
      "Epoch 13/25\n",
      "153/159 [===========================>..] - ETA: 0s - loss: 5.6067 - mse: 5.5744\n",
      "Epoch 13: val_loss improved from 5.61416 to 5.61347, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e013_vl5.613.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 5.6058 - mse: 5.5734 - val_loss: 5.6135 - val_mse: 5.5809\n",
      "Epoch 14/25\n",
      "153/159 [===========================>..] - ETA: 0s - loss: 5.6069 - mse: 5.5741\n",
      "Epoch 14: val_loss improved from 5.61347 to 5.61314, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e014_vl5.613.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 5.6023 - mse: 5.5695 - val_loss: 5.6131 - val_mse: 5.5801\n",
      "Epoch 15/25\n",
      "159/159 [==============================] - ETA: 0s - loss: 5.5997 - mse: 5.5665\n",
      "Epoch 15: val_loss did not improve from 5.61314\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 5.5997 - mse: 5.5665 - val_loss: 5.6241 - val_mse: 5.5906\n",
      "Epoch 16/25\n",
      "155/159 [============================>.] - ETA: 0s - loss: 5.5952 - mse: 5.5615\n",
      "Epoch 16: val_loss improved from 5.61314 to 5.60745, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e016_vl5.607.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 5.5982 - mse: 5.5645 - val_loss: 5.6075 - val_mse: 5.5735\n",
      "Epoch 17/25\n",
      "157/159 [============================>.] - ETA: 0s - loss: 5.5956 - mse: 5.5615\n",
      "Epoch 17: val_loss improved from 5.60745 to 5.60382, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e017_vl5.604.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 5.5946 - mse: 5.5605 - val_loss: 5.6038 - val_mse: 5.5695\n",
      "Epoch 18/25\n",
      "156/159 [============================>.] - ETA: 0s - loss: 5.5960 - mse: 5.5615\n",
      "Epoch 18: val_loss improved from 5.60382 to 5.60077, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e018_vl5.601.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 5.5936 - mse: 5.5591 - val_loss: 5.6008 - val_mse: 5.5661\n",
      "Epoch 19/25\n",
      "148/159 [==========================>...] - ETA: 0s - loss: 5.5938 - mse: 5.5590\n",
      "Epoch 19: val_loss did not improve from 5.60077\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 5.5900 - mse: 5.5552 - val_loss: 5.6045 - val_mse: 5.5695\n",
      "Epoch 20/25\n",
      "150/159 [===========================>..] - ETA: 0s - loss: 5.5894 - mse: 5.5543\n",
      "Epoch 20: val_loss improved from 5.60077 to 5.59820, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e020_vl5.598.h5\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 5.5902 - mse: 5.5551 - val_loss: 5.5982 - val_mse: 5.5630\n",
      "Epoch 21/25\n",
      "156/159 [============================>.] - ETA: 0s - loss: 5.5905 - mse: 5.5551\n",
      "Epoch 21: val_loss did not improve from 5.59820\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 5.5863 - mse: 5.5509 - val_loss: 5.6000 - val_mse: 5.5645\n",
      "Epoch 22/25\n",
      "159/159 [==============================] - ETA: 0s - loss: 5.5854 - mse: 5.5497\n",
      "Epoch 22: val_loss improved from 5.59820 to 5.59558, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e022_vl5.596.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 5.5854 - mse: 5.5497 - val_loss: 5.5956 - val_mse: 5.5599\n",
      "Epoch 23/25\n",
      "152/159 [===========================>..] - ETA: 0s - loss: 5.5810 - mse: 5.5453\n",
      "Epoch 23: val_loss improved from 5.59558 to 5.59361, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e023_vl5.594.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 5.5816 - mse: 5.5459 - val_loss: 5.5936 - val_mse: 5.5577\n",
      "Epoch 24/25\n",
      "157/159 [============================>.] - ETA: 0s - loss: 5.5810 - mse: 5.5450\n",
      "Epoch 24: val_loss improved from 5.59361 to 5.58836, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e024_vl5.588.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 5.5808 - mse: 5.5448 - val_loss: 5.5884 - val_mse: 5.5523\n",
      "Epoch 25/25\n",
      "155/159 [============================>.] - ETA: 0s - loss: 5.5794 - mse: 5.5432\n",
      "Epoch 25: val_loss improved from 5.58836 to 5.58720, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e025_vl5.587.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 5.5775 - mse: 5.5413 - val_loss: 5.5872 - val_mse: 5.5509\n",
      "Time elapsed to train: 23.96 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.965 3.791 2.099 4.197 2.858 2.231 1.711 1.383 0.921 0.172 0.196 0.062 0.055]\n",
      "<R> = [2.960 3.783 2.095 4.188 2.854 2.228 1.709 1.381 0.919 0.172 0.196 0.062 0.055]\n",
      "s_R = [0.480 0.753 0.355 1.030 0.603 0.375 0.323 0.292 0.187 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.8677819 2.982307  6.0752153 ... 2.9755435 4.1136384 4.4693694]\n",
      "mag_pred: [3.8677819 2.982307  6.0752153 ... 2.9755435 4.1136384 4.4693694]\n",
      "Time elapsed to make plots: 17.90 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 577.0116     53.868916   27.825237 ...   46.62367    58.472725\n",
      " 1800.3062  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0274\n",
      "  1% : 0.244\n",
      "  10% : 0.849\n",
      "  50% : 6.14\n",
      "  90% : 48.6\n",
      "  99% : 374\n",
      "  100% : 9.13e+03\n",
      "<chi^2/d.o.f.> = 3.6\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 37347 stars (14.8%) based on chi^2/dof > 31.6\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  98.140045   39.6661   1000.6334   ...  204.0992    132.43414\n",
      "   31.997086]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0631\n",
      "  1% : 0.246\n",
      "  10% : 0.824\n",
      "  50% : 6.01\n",
      "  90% : 47.4\n",
      "  99% : 385\n",
      "  100% : 5.31e+03\n",
      "<chi^2/d.o.f.> = 3.56\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 75.68 s\n",
      "learning rate = 0.0003678794309962541\n",
      "setting learning rate to 0.00030119421191220205\n",
      "Iteration 7 of 20.\n",
      "Epoch 1/25\n",
      "148/153 [============================>.] - ETA: 0s - loss: 5.0357 - mse: 4.9991\n",
      "Epoch 1: val_loss improved from inf to 5.03984, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e001_vl5.040.h5\n",
      "153/153 [==============================] - 1s 7ms/step - loss: 5.0351 - mse: 4.9985 - val_loss: 5.0398 - val_mse: 5.0031\n",
      "Epoch 2/25\n",
      "143/153 [===========================>..] - ETA: 0s - loss: 5.0278 - mse: 4.9910\n",
      "Epoch 2: val_loss improved from 5.03984 to 5.03725, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e002_vl5.037.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.0253 - mse: 4.9885 - val_loss: 5.0373 - val_mse: 5.0002\n",
      "Epoch 3/25\n",
      "143/153 [===========================>..] - ETA: 0s - loss: 5.0236 - mse: 4.9865\n",
      "Epoch 3: val_loss improved from 5.03725 to 5.03703, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e003_vl5.037.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.0241 - mse: 4.9870 - val_loss: 5.0370 - val_mse: 4.9998\n",
      "Epoch 4/25\n",
      "144/153 [===========================>..] - ETA: 0s - loss: 5.0187 - mse: 4.9813\n",
      "Epoch 4: val_loss improved from 5.03703 to 5.03417, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e004_vl5.034.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.0201 - mse: 4.9827 - val_loss: 5.0342 - val_mse: 4.9967\n",
      "Epoch 5/25\n",
      "149/153 [============================>.] - ETA: 0s - loss: 5.0175 - mse: 4.9800\n",
      "Epoch 5: val_loss improved from 5.03417 to 5.02918, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e005_vl5.029.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.0182 - mse: 4.9807 - val_loss: 5.0292 - val_mse: 4.9916\n",
      "Epoch 6/25\n",
      "146/153 [===========================>..] - ETA: 0s - loss: 5.0152 - mse: 4.9775\n",
      "Epoch 6: val_loss did not improve from 5.02918\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.0157 - mse: 4.9781 - val_loss: 5.0293 - val_mse: 4.9916\n",
      "Epoch 7/25\n",
      "147/153 [===========================>..] - ETA: 0s - loss: 5.0202 - mse: 4.9824\n",
      "Epoch 7: val_loss did not improve from 5.02918\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.0144 - mse: 4.9766 - val_loss: 5.0318 - val_mse: 4.9938\n",
      "Epoch 8/25\n",
      "147/153 [===========================>..] - ETA: 0s - loss: 5.0061 - mse: 4.9681\n",
      "Epoch 8: val_loss improved from 5.02918 to 5.02610, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e008_vl5.026.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.0122 - mse: 4.9742 - val_loss: 5.0261 - val_mse: 4.9880\n",
      "Epoch 9/25\n",
      "151/153 [============================>.] - ETA: 0s - loss: 5.0093 - mse: 4.9711\n",
      "Epoch 9: val_loss improved from 5.02610 to 5.02570, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e009_vl5.026.h5\n",
      "153/153 [==============================] - 1s 5ms/step - loss: 5.0097 - mse: 4.9715 - val_loss: 5.0257 - val_mse: 4.9875\n",
      "Epoch 10/25\n",
      "146/153 [===========================>..] - ETA: 0s - loss: 5.0118 - mse: 4.9735\n",
      "Epoch 10: val_loss improved from 5.02570 to 5.02165, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e010_vl5.022.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.0097 - mse: 4.9713 - val_loss: 5.0216 - val_mse: 4.9832\n",
      "Epoch 11/25\n",
      "152/153 [============================>.] - ETA: 0s - loss: 5.0080 - mse: 4.9694\n",
      "Epoch 11: val_loss improved from 5.02165 to 5.02082, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e011_vl5.021.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.0077 - mse: 4.9692 - val_loss: 5.0208 - val_mse: 4.9822\n",
      "Epoch 12/25\n",
      "147/153 [===========================>..] - ETA: 0s - loss: 5.0055 - mse: 4.9667\n",
      "Epoch 12: val_loss did not improve from 5.02082\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.0057 - mse: 4.9669 - val_loss: 5.0266 - val_mse: 4.9877\n",
      "Epoch 13/25\n",
      "146/153 [===========================>..] - ETA: 0s - loss: 5.0063 - mse: 4.9673\n",
      "Epoch 13: val_loss improved from 5.02082 to 5.02061, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e013_vl5.021.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.0056 - mse: 4.9666 - val_loss: 5.0206 - val_mse: 4.9816\n",
      "Epoch 14/25\n",
      "149/153 [============================>.] - ETA: 0s - loss: 5.0036 - mse: 4.9644\n",
      "Epoch 14: val_loss did not improve from 5.02061\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.0039 - mse: 4.9647 - val_loss: 5.0240 - val_mse: 4.9847\n",
      "Epoch 15/25\n",
      "143/153 [===========================>..] - ETA: 0s - loss: 5.0032 - mse: 4.9638\n",
      "Epoch 15: val_loss improved from 5.02061 to 5.01668, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e015_vl5.017.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.0002 - mse: 4.9607 - val_loss: 5.0167 - val_mse: 4.9771\n",
      "Epoch 16/25\n",
      "142/153 [==========================>...] - ETA: 0s - loss: 5.0041 - mse: 4.9644\n",
      "Epoch 16: val_loss improved from 5.01668 to 5.01187, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e016_vl5.012.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.0003 - mse: 4.9605 - val_loss: 5.0119 - val_mse: 4.9721\n",
      "Epoch 17/25\n",
      "143/153 [===========================>..] - ETA: 0s - loss: 5.0024 - mse: 4.9624\n",
      "Epoch 17: val_loss did not improve from 5.01187\n",
      "153/153 [==============================] - 1s 5ms/step - loss: 4.9993 - mse: 4.9593 - val_loss: 5.0144 - val_mse: 4.9744\n",
      "Epoch 18/25\n",
      "149/153 [============================>.] - ETA: 0s - loss: 4.9948 - mse: 4.9546\n",
      "Epoch 18: val_loss did not improve from 5.01187\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 4.9961 - mse: 4.9559 - val_loss: 5.0230 - val_mse: 4.9825\n",
      "Epoch 19/25\n",
      "145/153 [===========================>..] - ETA: 0s - loss: 4.9943 - mse: 4.9537\n",
      "Epoch 19: val_loss improved from 5.01187 to 5.00866, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e019_vl5.009.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 4.9950 - mse: 4.9544 - val_loss: 5.0087 - val_mse: 4.9679\n",
      "Epoch 20/25\n",
      "143/153 [===========================>..] - ETA: 0s - loss: 4.9905 - mse: 4.9495\n",
      "Epoch 20: val_loss did not improve from 5.00866\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 4.9930 - mse: 4.9520 - val_loss: 5.0148 - val_mse: 4.9736\n",
      "Epoch 21/25\n",
      "153/153 [==============================] - ETA: 0s - loss: 4.9932 - mse: 4.9517\n",
      "Epoch 21: val_loss improved from 5.00866 to 5.00544, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e021_vl5.005.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 4.9932 - mse: 4.9517 - val_loss: 5.0054 - val_mse: 4.9636\n",
      "Epoch 22/25\n",
      "152/153 [============================>.] - ETA: 0s - loss: 4.9897 - mse: 4.9476\n",
      "Epoch 22: val_loss improved from 5.00544 to 5.00480, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e022_vl5.005.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 4.9892 - mse: 4.9471 - val_loss: 5.0048 - val_mse: 4.9624\n",
      "Epoch 23/25\n",
      "145/153 [===========================>..] - ETA: 0s - loss: 4.9874 - mse: 4.9447\n",
      "Epoch 23: val_loss improved from 5.00480 to 5.00226, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e023_vl5.002.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 4.9885 - mse: 4.9457 - val_loss: 5.0023 - val_mse: 4.9591\n",
      "Epoch 24/25\n",
      "144/153 [===========================>..] - ETA: 0s - loss: 4.9895 - mse: 4.9460\n",
      "Epoch 24: val_loss improved from 5.00226 to 5.00128, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e024_vl5.001.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 4.9869 - mse: 4.9434 - val_loss: 5.0013 - val_mse: 4.9573\n",
      "Epoch 25/25\n",
      "142/153 [==========================>...] - ETA: 0s - loss: 4.9868 - mse: 4.9425\n",
      "Epoch 25: val_loss improved from 5.00128 to 4.99738, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e025_vl4.997.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 4.9839 - mse: 4.9395 - val_loss: 4.9974 - val_mse: 4.9526\n",
      "Time elapsed to train: 23.08 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [3.287 4.147 2.439 4.606 3.244 2.588 2.051 1.696 1.178 0.375 0.401 0.030 0.025]\n",
      "<R> = [3.282 4.138 2.434 4.590 3.237 2.583 2.048 1.693 1.175 0.374 0.399 0.030 0.025]\n",
      "s_R = [0.590 0.929 0.536 1.338 0.721 0.508 0.500 0.530 0.377 0.093 0.151 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.8338385 2.9714215 5.9814916 ... 2.9695134 4.0917645 4.4819074]\n",
      "mag_pred: [3.8338385 2.9714215 5.9814916 ... 2.9695134 4.0917645 4.4819074]\n",
      "Time elapsed to make plots: 19.23 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 488.39005    62.38099    30.032242 ...   37.286232   62.728897\n",
      " 1715.0098  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.038\n",
      "  1% : 0.231\n",
      "  10% : 0.812\n",
      "  50% : 5.7\n",
      "  90% : 47.8\n",
      "  99% : 373\n",
      "  100% : 9.24e+03\n",
      "<chi^2/d.o.f.> = 3.52\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 44019 stars (17.4%) based on chi^2/dof > 25.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  83.30957    43.701355 1068.2568   ...  225.98994   118.491005\n",
      "   33.046963]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.052\n",
      "  1% : 0.231\n",
      "  10% : 0.794\n",
      "  50% : 5.62\n",
      "  90% : 46.8\n",
      "  99% : 380\n",
      "  100% : 5.35e+03\n",
      "<chi^2/d.o.f.> = 3.48\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 75.87 s\n",
      "learning rate = 0.0003011942026205361\n",
      "setting learning rate to 0.00024659696394160646\n",
      "Iteration 8 of 20.\n",
      "Epoch 1/25\n",
      "138/148 [==========================>...] - ETA: 0s - loss: 4.3433 - mse: 4.2982\n",
      "Epoch 1: val_loss improved from inf to 4.34950, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e001_vl4.350.h5\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 4.3413 - mse: 4.2962 - val_loss: 4.3495 - val_mse: 4.3040\n",
      "Epoch 2/25\n",
      "142/148 [===========================>..] - ETA: 0s - loss: 4.3354 - mse: 4.2895\n",
      "Epoch 2: val_loss improved from 4.34950 to 4.34741, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e002_vl4.347.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3352 - mse: 4.2893 - val_loss: 4.3474 - val_mse: 4.3011\n",
      "Epoch 3/25\n",
      "138/148 [==========================>...] - ETA: 0s - loss: 4.3320 - mse: 4.2852\n",
      "Epoch 3: val_loss improved from 4.34741 to 4.34215, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e003_vl4.342.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3323 - mse: 4.2854 - val_loss: 4.3421 - val_mse: 4.2949\n",
      "Epoch 4/25\n",
      "148/148 [==============================] - ETA: 0s - loss: 4.3289 - mse: 4.2812\n",
      "Epoch 4: val_loss improved from 4.34215 to 4.33758, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e004_vl4.338.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3289 - mse: 4.2812 - val_loss: 4.3376 - val_mse: 4.2893\n",
      "Epoch 5/25\n",
      "148/148 [==============================] - ETA: 0s - loss: 4.3229 - mse: 4.2742\n",
      "Epoch 5: val_loss improved from 4.33758 to 4.33218, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e005_vl4.332.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3229 - mse: 4.2742 - val_loss: 4.3322 - val_mse: 4.2829\n",
      "Epoch 6/25\n",
      "147/148 [============================>.] - ETA: 0s - loss: 4.3187 - mse: 4.2690\n",
      "Epoch 6: val_loss improved from 4.33218 to 4.33010, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e006_vl4.330.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3194 - mse: 4.2697 - val_loss: 4.3301 - val_mse: 4.2799\n",
      "Epoch 7/25\n",
      "147/148 [============================>.] - ETA: 0s - loss: 4.3156 - mse: 4.2650\n",
      "Epoch 7: val_loss improved from 4.33010 to 4.32560, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e007_vl4.326.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3152 - mse: 4.2646 - val_loss: 4.3256 - val_mse: 4.2745\n",
      "Epoch 8/25\n",
      "139/148 [===========================>..] - ETA: 0s - loss: 4.3113 - mse: 4.2598\n",
      "Epoch 8: val_loss improved from 4.32560 to 4.32178, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e008_vl4.322.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3114 - mse: 4.2598 - val_loss: 4.3218 - val_mse: 4.2697\n",
      "Epoch 9/25\n",
      "141/148 [===========================>..] - ETA: 0s - loss: 4.3110 - mse: 4.2586\n",
      "Epoch 9: val_loss improved from 4.32178 to 4.31728, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e009_vl4.317.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3064 - mse: 4.2540 - val_loss: 4.3173 - val_mse: 4.2644\n",
      "Epoch 10/25\n",
      "142/148 [===========================>..] - ETA: 0s - loss: 4.3026 - mse: 4.2494\n",
      "Epoch 10: val_loss improved from 4.31728 to 4.31335, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e010_vl4.313.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3040 - mse: 4.2508 - val_loss: 4.3134 - val_mse: 4.2597\n",
      "Epoch 11/25\n",
      "140/148 [===========================>..] - ETA: 0s - loss: 4.2959 - mse: 4.2420\n",
      "Epoch 11: val_loss improved from 4.31335 to 4.31229, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e011_vl4.312.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3002 - mse: 4.2463 - val_loss: 4.3123 - val_mse: 4.2580\n",
      "Epoch 12/25\n",
      "147/148 [============================>.] - ETA: 0s - loss: 4.2977 - mse: 4.2431\n",
      "Epoch 12: val_loss improved from 4.31229 to 4.30769, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e012_vl4.308.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.2975 - mse: 4.2429 - val_loss: 4.3077 - val_mse: 4.2528\n",
      "Epoch 13/25\n",
      "145/148 [============================>.] - ETA: 0s - loss: 4.2942 - mse: 4.2391\n",
      "Epoch 13: val_loss improved from 4.30769 to 4.30558, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e013_vl4.306.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.2945 - mse: 4.2394 - val_loss: 4.3056 - val_mse: 4.2502\n",
      "Epoch 14/25\n",
      "145/148 [============================>.] - ETA: 0s - loss: 4.2935 - mse: 4.2379\n",
      "Epoch 14: val_loss improved from 4.30558 to 4.30460, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e014_vl4.305.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.2925 - mse: 4.2368 - val_loss: 4.3046 - val_mse: 4.2487\n",
      "Epoch 15/25\n",
      "142/148 [===========================>..] - ETA: 0s - loss: 4.2875 - mse: 4.2314\n",
      "Epoch 15: val_loss improved from 4.30460 to 4.30089, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e015_vl4.301.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.2906 - mse: 4.2345 - val_loss: 4.3009 - val_mse: 4.2446\n",
      "Epoch 16/25\n",
      "147/148 [============================>.] - ETA: 0s - loss: 4.2874 - mse: 4.2308\n",
      "Epoch 16: val_loss did not improve from 4.30089\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.2887 - mse: 4.2321 - val_loss: 4.3015 - val_mse: 4.2448\n",
      "Epoch 17/25\n",
      "142/148 [===========================>..] - ETA: 0s - loss: 4.2831 - mse: 4.2263\n",
      "Epoch 17: val_loss improved from 4.30089 to 4.29913, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e017_vl4.299.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.2867 - mse: 4.2299 - val_loss: 4.2991 - val_mse: 4.2421\n",
      "Epoch 18/25\n",
      "145/148 [============================>.] - ETA: 0s - loss: 4.2849 - mse: 4.2277\n",
      "Epoch 18: val_loss improved from 4.29913 to 4.29728, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e018_vl4.297.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.2846 - mse: 4.2274 - val_loss: 4.2973 - val_mse: 4.2399\n",
      "Epoch 19/25\n",
      "142/148 [===========================>..] - ETA: 0s - loss: 4.2833 - mse: 4.2258\n",
      "Epoch 19: val_loss improved from 4.29728 to 4.29546, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e019_vl4.295.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.2831 - mse: 4.2256 - val_loss: 4.2955 - val_mse: 4.2377\n",
      "Epoch 20/25\n",
      "144/148 [============================>.] - ETA: 0s - loss: 4.2831 - mse: 4.2253\n",
      "Epoch 20: val_loss did not improve from 4.29546\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.2812 - mse: 4.2234 - val_loss: 4.2961 - val_mse: 4.2382\n",
      "Epoch 21/25\n",
      "138/148 [==========================>...] - ETA: 0s - loss: 4.2774 - mse: 4.2193\n",
      "Epoch 21: val_loss improved from 4.29546 to 4.29155, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e021_vl4.292.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.2796 - mse: 4.2215 - val_loss: 4.2915 - val_mse: 4.2333\n",
      "Epoch 22/25\n",
      "144/148 [============================>.] - ETA: 0s - loss: 4.2782 - mse: 4.2198\n",
      "Epoch 22: val_loss did not improve from 4.29155\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.2780 - mse: 4.2196 - val_loss: 4.2966 - val_mse: 4.2381\n",
      "Epoch 23/25\n",
      "143/148 [===========================>..] - ETA: 0s - loss: 4.2801 - mse: 4.2214\n",
      "Epoch 23: val_loss improved from 4.29155 to 4.28960, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e023_vl4.290.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.2775 - mse: 4.2188 - val_loss: 4.2896 - val_mse: 4.2309\n",
      "Epoch 24/25\n",
      "140/148 [===========================>..] - ETA: 0s - loss: 4.2747 - mse: 4.2158\n",
      "Epoch 24: val_loss did not improve from 4.28960\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.2759 - mse: 4.2170 - val_loss: 4.2912 - val_mse: 4.2322\n",
      "Epoch 25/25\n",
      "139/148 [===========================>..] - ETA: 0s - loss: 4.2685 - mse: 4.2095\n",
      "Epoch 25: val_loss improved from 4.28960 to 4.28625, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e025_vl4.286.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.2733 - mse: 4.2142 - val_loss: 4.2862 - val_mse: 4.2270\n",
      "Time elapsed to train: 23.05 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [3.577 4.408 2.743 4.839 3.558 2.872 2.345 1.997 1.500 0.721 0.733 0.017 0.015]\n",
      "<R> = [3.572 4.405 2.735 4.828 3.551 2.863 2.336 1.988 1.492 0.716 0.726 0.017 0.015]\n",
      "s_R = [0.813 0.929 0.916 1.108 0.913 0.846 0.979 1.192 1.544 4.729 4.414 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.8161795 2.9598906 5.8876505 ... 2.9885945 4.068912  4.4884014]\n",
      "mag_pred: [3.8161795 2.9598906 5.8876505 ... 2.9885945 4.068912  4.4884014]\n",
      "Time elapsed to make plots: 19.59 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 432.35324    65.70044    36.529606 ...   34.957516   61.78765\n",
      " 1677.7391  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0301\n",
      "  1% : 0.218\n",
      "  10% : 0.763\n",
      "  50% : 5.32\n",
      "  90% : 47.6\n",
      "  99% : 377\n",
      "  100% : 7.45e+03\n",
      "<chi^2/d.o.f.> = 3.45\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 50860 stars (20.1%) based on chi^2/dof > 19.9\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 78.89615   47.812744 807.4072   ... 221.12029  108.71297   33.905586]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0577\n",
      "  1% : 0.215\n",
      "  10% : 0.759\n",
      "  50% : 5.24\n",
      "  90% : 46.8\n",
      "  99% : 370\n",
      "  100% : 5.36e+03\n",
      "<chi^2/d.o.f.> = 3.42\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 75.69 s\n",
      "learning rate = 0.00024659695918671787\n",
      "setting learning rate to 0.00020189651799465538\n",
      "Iteration 9 of 20.\n",
      "Epoch 1/25\n",
      "139/143 [============================>.] - ETA: 0s - loss: 3.8646 - mse: 3.8046\n",
      "Epoch 1: val_loss improved from inf to 3.87653, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e001_vl3.877.h5\n",
      "143/143 [==============================] - 1s 7ms/step - loss: 3.8623 - mse: 3.8023 - val_loss: 3.8765 - val_mse: 3.8157\n",
      "Epoch 2/25\n",
      "135/143 [===========================>..] - ETA: 0s - loss: 3.8315 - mse: 3.7701\n",
      "Epoch 2: val_loss improved from 3.87653 to 3.86107, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e002_vl3.861.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.8327 - mse: 3.7713 - val_loss: 3.8611 - val_mse: 3.7990\n",
      "Epoch 3/25\n",
      "132/143 [==========================>...] - ETA: 0s - loss: 3.8198 - mse: 3.7573\n",
      "Epoch 3: val_loss improved from 3.86107 to 3.85432, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e003_vl3.854.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.8213 - mse: 3.7587 - val_loss: 3.8543 - val_mse: 3.7914\n",
      "Epoch 4/25\n",
      "141/143 [============================>.] - ETA: 0s - loss: 3.8142 - mse: 3.7509\n",
      "Epoch 4: val_loss improved from 3.85432 to 3.84874, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e004_vl3.849.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.8145 - mse: 3.7512 - val_loss: 3.8487 - val_mse: 3.7851\n",
      "Epoch 5/25\n",
      "136/143 [===========================>..] - ETA: 0s - loss: 3.8171 - mse: 3.7533\n",
      "Epoch 5: val_loss improved from 3.84874 to 3.84571, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e005_vl3.846.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.8112 - mse: 3.7474 - val_loss: 3.8457 - val_mse: 3.7816\n",
      "Epoch 6/25\n",
      "134/143 [===========================>..] - ETA: 0s - loss: 3.8082 - mse: 3.7439\n",
      "Epoch 6: val_loss improved from 3.84571 to 3.84102, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e006_vl3.841.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.8084 - mse: 3.7442 - val_loss: 3.8410 - val_mse: 3.7766\n",
      "Epoch 7/25\n",
      "134/143 [===========================>..] - ETA: 0s - loss: 3.8068 - mse: 3.7423\n",
      "Epoch 7: val_loss improved from 3.84102 to 3.83870, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e007_vl3.839.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.8049 - mse: 3.7403 - val_loss: 3.8387 - val_mse: 3.7740\n",
      "Epoch 8/25\n",
      "143/143 [==============================] - ETA: 0s - loss: 3.8027 - mse: 3.7379\n",
      "Epoch 8: val_loss improved from 3.83870 to 3.83753, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e008_vl3.838.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.8027 - mse: 3.7379 - val_loss: 3.8375 - val_mse: 3.7726\n",
      "Epoch 9/25\n",
      "134/143 [===========================>..] - ETA: 0s - loss: 3.7954 - mse: 3.7305\n",
      "Epoch 9: val_loss improved from 3.83753 to 3.83570, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e009_vl3.836.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.8004 - mse: 3.7354 - val_loss: 3.8357 - val_mse: 3.7706\n",
      "Epoch 10/25\n",
      "140/143 [============================>.] - ETA: 0s - loss: 3.7990 - mse: 3.7339\n",
      "Epoch 10: val_loss improved from 3.83570 to 3.83380, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e010_vl3.834.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.7985 - mse: 3.7334 - val_loss: 3.8338 - val_mse: 3.7686\n",
      "Epoch 11/25\n",
      "143/143 [==============================] - ETA: 0s - loss: 3.7964 - mse: 3.7312\n",
      "Epoch 11: val_loss improved from 3.83380 to 3.83153, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e011_vl3.832.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.7964 - mse: 3.7312 - val_loss: 3.8315 - val_mse: 3.7662\n",
      "Epoch 12/25\n",
      "142/143 [============================>.] - ETA: 0s - loss: 3.7946 - mse: 3.7293\n",
      "Epoch 12: val_loss improved from 3.83153 to 3.83058, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e012_vl3.831.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.7948 - mse: 3.7294 - val_loss: 3.8306 - val_mse: 3.7651\n",
      "Epoch 13/25\n",
      "137/143 [===========================>..] - ETA: 0s - loss: 3.7925 - mse: 3.7270\n",
      "Epoch 13: val_loss did not improve from 3.83058\n",
      "143/143 [==============================] - 1s 5ms/step - loss: 3.7937 - mse: 3.7282 - val_loss: 3.8314 - val_mse: 3.7659\n",
      "Epoch 14/25\n",
      "138/143 [===========================>..] - ETA: 0s - loss: 3.7949 - mse: 3.7294\n",
      "Epoch 14: val_loss improved from 3.83058 to 3.82773, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e014_vl3.828.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.7925 - mse: 3.7270 - val_loss: 3.8277 - val_mse: 3.7621\n",
      "Epoch 15/25\n",
      "133/143 [==========================>...] - ETA: 0s - loss: 3.7909 - mse: 3.7252\n",
      "Epoch 15: val_loss improved from 3.82773 to 3.82449, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e015_vl3.824.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.7901 - mse: 3.7244 - val_loss: 3.8245 - val_mse: 3.7588\n",
      "Epoch 16/25\n",
      "139/143 [============================>.] - ETA: 0s - loss: 3.7882 - mse: 3.7225\n",
      "Epoch 16: val_loss improved from 3.82449 to 3.82334, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e016_vl3.823.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.7892 - mse: 3.7236 - val_loss: 3.8233 - val_mse: 3.7576\n",
      "Epoch 17/25\n",
      "140/143 [============================>.] - ETA: 0s - loss: 3.7891 - mse: 3.7233\n",
      "Epoch 17: val_loss did not improve from 3.82334\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.7877 - mse: 3.7218 - val_loss: 3.8243 - val_mse: 3.7585\n",
      "Epoch 18/25\n",
      "134/143 [===========================>..] - ETA: 0s - loss: 3.7856 - mse: 3.7197\n",
      "Epoch 18: val_loss improved from 3.82334 to 3.82215, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e018_vl3.822.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.7867 - mse: 3.7209 - val_loss: 3.8221 - val_mse: 3.7563\n",
      "Epoch 19/25\n",
      "132/143 [==========================>...] - ETA: 0s - loss: 3.7822 - mse: 3.7163\n",
      "Epoch 19: val_loss improved from 3.82215 to 3.81980, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e019_vl3.820.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.7854 - mse: 3.7195 - val_loss: 3.8198 - val_mse: 3.7538\n",
      "Epoch 20/25\n",
      "137/143 [===========================>..] - ETA: 0s - loss: 3.7844 - mse: 3.7184\n",
      "Epoch 20: val_loss improved from 3.81980 to 3.81931, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e020_vl3.819.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.7842 - mse: 3.7182 - val_loss: 3.8193 - val_mse: 3.7533\n",
      "Epoch 21/25\n",
      "142/143 [============================>.] - ETA: 0s - loss: 3.7818 - mse: 3.7157\n",
      "Epoch 21: val_loss did not improve from 3.81931\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.7821 - mse: 3.7160 - val_loss: 3.8206 - val_mse: 3.7545\n",
      "Epoch 22/25\n",
      "142/143 [============================>.] - ETA: 0s - loss: 3.7821 - mse: 3.7160\n",
      "Epoch 22: val_loss improved from 3.81931 to 3.81754, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e022_vl3.818.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.7824 - mse: 3.7163 - val_loss: 3.8175 - val_mse: 3.7514\n",
      "Epoch 23/25\n",
      "139/143 [============================>.] - ETA: 0s - loss: 3.7828 - mse: 3.7166\n",
      "Epoch 23: val_loss improved from 3.81754 to 3.81645, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e023_vl3.816.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.7797 - mse: 3.7135 - val_loss: 3.8165 - val_mse: 3.7503\n",
      "Epoch 24/25\n",
      "134/143 [===========================>..] - ETA: 0s - loss: 3.7790 - mse: 3.7128\n",
      "Epoch 24: val_loss improved from 3.81645 to 3.81597, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e024_vl3.816.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.7792 - mse: 3.7130 - val_loss: 3.8160 - val_mse: 3.7497\n",
      "Epoch 25/25\n",
      "133/143 [==========================>...] - ETA: 0s - loss: 3.7793 - mse: 3.7131\n",
      "Epoch 25: val_loss improved from 3.81597 to 3.81429, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e025_vl3.814.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.7796 - mse: 3.7133 - val_loss: 3.8143 - val_mse: 3.7480\n",
      "Time elapsed to train: 21.81 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [3.649 4.429 2.877 4.798 3.618 2.965 2.487 2.174 1.735 0.991 1.014 0.010 0.009]\n",
      "<R> = [3.643 4.438 2.867 4.812 3.613 2.954 2.479 2.165 1.727 0.986 1.010 0.010 0.009]\n",
      "s_R = [0.895 0.880 1.109 0.945 0.976 1.013 1.271 1.625 2.559 9.842 8.604 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.79615   2.9609838 5.834209  ... 3.0158188 4.030318  4.46387  ]\n",
      "mag_pred: [3.79615   2.9609838 5.834209  ... 3.0158188 4.030318  4.46387  ]\n",
      "Time elapsed to make plots: 17.65 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 375.4248     65.17645    64.241135 ...   28.538383   62.17567\n",
      " 1702.802   ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00894\n",
      "  1% : 0.202\n",
      "  10% : 0.706\n",
      "  50% : 4.86\n",
      "  90% : 47.5\n",
      "  99% : 377\n",
      "  100% : 7.07e+03\n",
      "<chi^2/d.o.f.> = 3.34\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 57908 stars (22.9%) based on chi^2/dof > 15.8\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 66.978615  54.217297 699.0426   ... 238.30878  100.62274   31.919514]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0416\n",
      "  1% : 0.198\n",
      "  10% : 0.702\n",
      "  50% : 4.8\n",
      "  90% : 47.1\n",
      "  99% : 359\n",
      "  100% : 5.38e+03\n",
      "<chi^2/d.o.f.> = 3.31\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 75.04 s\n",
      "learning rate = 0.00020189651695545763\n",
      "setting learning rate to 0.00016529888822158653\n",
      "Iteration 10 of 20.\n",
      "Epoch 1/25\n",
      "137/138 [============================>.] - ETA: 0s - loss: 3.2486 - mse: 3.1824\n",
      "Epoch 1: val_loss improved from inf to 3.27910, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e001_vl3.279.h5\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 3.2488 - mse: 3.1827 - val_loss: 3.2791 - val_mse: 3.2130\n",
      "Epoch 2/25\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 3.2440 - mse: 3.1779\n",
      "Epoch 2: val_loss improved from 3.27910 to 3.27798, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e002_vl3.278.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.2456 - mse: 3.1795 - val_loss: 3.2780 - val_mse: 3.2119\n",
      "Epoch 3/25\n",
      "128/138 [==========================>...] - ETA: 0s - loss: 3.2424 - mse: 3.1763\n",
      "Epoch 3: val_loss did not improve from 3.27798\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.2448 - mse: 3.1787 - val_loss: 3.2784 - val_mse: 3.2123\n",
      "Epoch 4/25\n",
      "136/138 [============================>.] - ETA: 0s - loss: 3.2428 - mse: 3.1767\n",
      "Epoch 4: val_loss did not improve from 3.27798\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.2437 - mse: 3.1775 - val_loss: 3.2797 - val_mse: 3.2136\n",
      "Epoch 5/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.2437 - mse: 3.1776\n",
      "Epoch 5: val_loss improved from 3.27798 to 3.27434, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e005_vl3.274.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.2437 - mse: 3.1776 - val_loss: 3.2743 - val_mse: 3.2082\n",
      "Epoch 6/25\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 3.2437 - mse: 3.1776\n",
      "Epoch 6: val_loss improved from 3.27434 to 3.27360, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e006_vl3.274.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.2423 - mse: 3.1762 - val_loss: 3.2736 - val_mse: 3.2075\n",
      "Epoch 7/25\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 3.2415 - mse: 3.1754\n",
      "Epoch 7: val_loss improved from 3.27360 to 3.27290, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e007_vl3.273.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.2414 - mse: 3.1753 - val_loss: 3.2729 - val_mse: 3.2068\n",
      "Epoch 8/25\n",
      "134/138 [============================>.] - ETA: 0s - loss: 3.2419 - mse: 3.1758\n",
      "Epoch 8: val_loss did not improve from 3.27290\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.2410 - mse: 3.1749 - val_loss: 3.2739 - val_mse: 3.2078\n",
      "Epoch 9/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.2398 - mse: 3.1737\n",
      "Epoch 9: val_loss improved from 3.27290 to 3.27091, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e009_vl3.271.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.2398 - mse: 3.1737 - val_loss: 3.2709 - val_mse: 3.2048\n",
      "Epoch 10/25\n",
      "136/138 [============================>.] - ETA: 0s - loss: 3.2367 - mse: 3.1706\n",
      "Epoch 10: val_loss improved from 3.27091 to 3.27020, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e010_vl3.270.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.2389 - mse: 3.1728 - val_loss: 3.2702 - val_mse: 3.2041\n",
      "Epoch 11/25\n",
      "135/138 [============================>.] - ETA: 0s - loss: 3.2388 - mse: 3.1727\n",
      "Epoch 11: val_loss improved from 3.27020 to 3.27015, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e011_vl3.270.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.2391 - mse: 3.1729 - val_loss: 3.2702 - val_mse: 3.2040\n",
      "Epoch 12/25\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 3.2363 - mse: 3.1702\n",
      "Epoch 12: val_loss improved from 3.27015 to 3.27011, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e012_vl3.270.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.2379 - mse: 3.1718 - val_loss: 3.2701 - val_mse: 3.2041\n",
      "Epoch 13/25\n",
      "134/138 [============================>.] - ETA: 0s - loss: 3.2380 - mse: 3.1720\n",
      "Epoch 13: val_loss improved from 3.27011 to 3.26862, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e013_vl3.269.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.2370 - mse: 3.1709 - val_loss: 3.2686 - val_mse: 3.2026\n",
      "Epoch 14/25\n",
      "128/138 [==========================>...] - ETA: 0s - loss: 3.2379 - mse: 3.1719\n",
      "Epoch 14: val_loss did not improve from 3.26862\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.2367 - mse: 3.1707 - val_loss: 3.2693 - val_mse: 3.2032\n",
      "Epoch 15/25\n",
      "136/138 [============================>.] - ETA: 0s - loss: 3.2367 - mse: 3.1707\n",
      "Epoch 15: val_loss improved from 3.26862 to 3.26762, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e015_vl3.268.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.2355 - mse: 3.1695 - val_loss: 3.2676 - val_mse: 3.2016\n",
      "Epoch 16/25\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 3.2338 - mse: 3.1678\n",
      "Epoch 16: val_loss improved from 3.26762 to 3.26590, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e016_vl3.266.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.2353 - mse: 3.1693 - val_loss: 3.2659 - val_mse: 3.1999\n",
      "Epoch 17/25\n",
      "127/138 [==========================>...] - ETA: 0s - loss: 3.2371 - mse: 3.1711\n",
      "Epoch 17: val_loss improved from 3.26590 to 3.26534, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e017_vl3.265.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.2348 - mse: 3.1688 - val_loss: 3.2653 - val_mse: 3.1994\n",
      "Epoch 18/25\n",
      "128/138 [==========================>...] - ETA: 0s - loss: 3.2339 - mse: 3.1679\n",
      "Epoch 18: val_loss improved from 3.26534 to 3.26411, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e018_vl3.264.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.2336 - mse: 3.1676 - val_loss: 3.2641 - val_mse: 3.1982\n",
      "Epoch 19/25\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 3.2318 - mse: 3.1658\n",
      "Epoch 19: val_loss did not improve from 3.26411\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.2330 - mse: 3.1671 - val_loss: 3.2645 - val_mse: 3.1986\n",
      "Epoch 20/25\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 3.2353 - mse: 3.1694\n",
      "Epoch 20: val_loss improved from 3.26411 to 3.26380, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e020_vl3.264.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.2329 - mse: 3.1670 - val_loss: 3.2638 - val_mse: 3.1979\n",
      "Epoch 21/25\n",
      "134/138 [============================>.] - ETA: 0s - loss: 3.2312 - mse: 3.1654\n",
      "Epoch 21: val_loss improved from 3.26380 to 3.26320, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e021_vl3.263.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.2319 - mse: 3.1661 - val_loss: 3.2632 - val_mse: 3.1973\n",
      "Epoch 22/25\n",
      "129/138 [===========================>..] - ETA: 0s - loss: 3.2292 - mse: 3.1634\n",
      "Epoch 22: val_loss did not improve from 3.26320\n",
      "138/138 [==============================] - 1s 5ms/step - loss: 3.2315 - mse: 3.1656 - val_loss: 3.2644 - val_mse: 3.1985\n",
      "Epoch 23/25\n",
      "129/138 [===========================>..] - ETA: 0s - loss: 3.2277 - mse: 3.1619\n",
      "Epoch 23: val_loss improved from 3.26320 to 3.26132, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e023_vl3.261.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.2309 - mse: 3.1651 - val_loss: 3.2613 - val_mse: 3.1955\n",
      "Epoch 24/25\n",
      "134/138 [============================>.] - ETA: 0s - loss: 3.2313 - mse: 3.1655\n",
      "Epoch 24: val_loss improved from 3.26132 to 3.26084, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e024_vl3.261.h5\n",
      "138/138 [==============================] - 1s 5ms/step - loss: 3.2297 - mse: 3.1639 - val_loss: 3.2608 - val_mse: 3.1951\n",
      "Epoch 25/25\n",
      "136/138 [============================>.] - ETA: 0s - loss: 3.2288 - mse: 3.1630\n",
      "Epoch 25: val_loss did not improve from 3.26084\n",
      "138/138 [==============================] - 1s 5ms/step - loss: 3.2291 - mse: 3.1633 - val_loss: 3.2628 - val_mse: 3.1971\n",
      "Time elapsed to train: 21.09 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [3.769 4.533 2.992 4.862 3.735 3.074 2.590 2.285 1.858 1.158 1.158 0.007 0.007]\n",
      "<R> = [3.762 4.546 2.981 4.882 3.729 3.063 2.580 2.276 1.849 1.153 1.153 0.007 0.007]\n",
      "s_R = [1.018 1.000 1.225 1.052 1.108 1.141 1.391 1.718 2.637 8.307 8.036 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.782399  2.9406285 5.8461876 ... 2.972071  4.022073  4.462113 ]\n",
      "mag_pred: [3.782399  2.9406285 5.8461876 ... 2.972071  4.022073  4.462113 ]\n",
      "Time elapsed to make plots: 21.09 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 377.42178    59.546318   93.16388  ...   26.192036   57.164474\n",
      " 1918.0781  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0147\n",
      "  1% : 0.197\n",
      "  10% : 0.673\n",
      "  50% : 4.62\n",
      "  90% : 48.6\n",
      "  99% : 386\n",
      "  100% : 7.08e+03\n",
      "<chi^2/d.o.f.> = 3.25\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 67335 stars (26.6%) based on chi^2/dof > 12.6\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 63.024117  60.481678 658.36115  ... 264.237     92.32428   30.425745]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0449\n",
      "  1% : 0.198\n",
      "  10% : 0.671\n",
      "  50% : 4.54\n",
      "  90% : 48.1\n",
      "  99% : 368\n",
      "  100% : 5.38e+03\n",
      "<chi^2/d.o.f.> = 3.23\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 69.90 s\n",
      "learning rate = 0.00016529888671357185\n",
      "setting learning rate to 0.0001353352832366127\n",
      "Iteration 11 of 20.\n",
      "Epoch 1/25\n",
      "131/131 [==============================] - ETA: 0s - loss: 2.8040 - mse: 2.7384\n",
      "Epoch 1: val_loss improved from inf to 2.81205, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e001_vl2.812.h5\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 2.8040 - mse: 2.7384 - val_loss: 2.8121 - val_mse: 2.7466\n",
      "Epoch 2/25\n",
      "127/131 [============================>.] - ETA: 0s - loss: 2.8024 - mse: 2.7369\n",
      "Epoch 2: val_loss improved from 2.81205 to 2.80978, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e002_vl2.810.h5\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.8024 - mse: 2.7369 - val_loss: 2.8098 - val_mse: 2.7444\n",
      "Epoch 3/25\n",
      "123/131 [===========================>..] - ETA: 0s - loss: 2.8002 - mse: 2.7348\n",
      "Epoch 3: val_loss did not improve from 2.80978\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.8017 - mse: 2.7364 - val_loss: 2.8111 - val_mse: 2.7458\n",
      "Epoch 4/25\n",
      "130/131 [============================>.] - ETA: 0s - loss: 2.8012 - mse: 2.7360\n",
      "Epoch 4: val_loss improved from 2.80978 to 2.80961, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e004_vl2.810.h5\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.8008 - mse: 2.7356 - val_loss: 2.8096 - val_mse: 2.7445\n",
      "Epoch 5/25\n",
      "128/131 [============================>.] - ETA: 0s - loss: 2.8001 - mse: 2.7350\n",
      "Epoch 5: val_loss improved from 2.80961 to 2.80787, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e005_vl2.808.h5\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.8005 - mse: 2.7354 - val_loss: 2.8079 - val_mse: 2.7428\n",
      "Epoch 6/25\n",
      "124/131 [===========================>..] - ETA: 0s - loss: 2.7960 - mse: 2.7310\n",
      "Epoch 6: val_loss improved from 2.80787 to 2.80780, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e006_vl2.808.h5\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.7997 - mse: 2.7347 - val_loss: 2.8078 - val_mse: 2.7429\n",
      "Epoch 7/25\n",
      "125/131 [===========================>..] - ETA: 0s - loss: 2.7963 - mse: 2.7315\n",
      "Epoch 7: val_loss improved from 2.80780 to 2.80696, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e007_vl2.807.h5\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.7988 - mse: 2.7340 - val_loss: 2.8070 - val_mse: 2.7422\n",
      "Epoch 8/25\n",
      "121/131 [==========================>...] - ETA: 0s - loss: 2.7978 - mse: 2.7331\n",
      "Epoch 8: val_loss improved from 2.80696 to 2.80675, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e008_vl2.807.h5\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.7992 - mse: 2.7344 - val_loss: 2.8067 - val_mse: 2.7421\n",
      "Epoch 9/25\n",
      "125/131 [===========================>..] - ETA: 0s - loss: 2.7977 - mse: 2.7330\n",
      "Epoch 9: val_loss did not improve from 2.80675\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.7976 - mse: 2.7330 - val_loss: 2.8071 - val_mse: 2.7425\n",
      "Epoch 10/25\n",
      "124/131 [===========================>..] - ETA: 0s - loss: 2.7975 - mse: 2.7330\n",
      "Epoch 10: val_loss improved from 2.80675 to 2.80660, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e010_vl2.807.h5\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.7976 - mse: 2.7330 - val_loss: 2.8066 - val_mse: 2.7421\n",
      "Epoch 11/25\n",
      "126/131 [===========================>..] - ETA: 0s - loss: 2.7954 - mse: 2.7309\n",
      "Epoch 11: val_loss improved from 2.80660 to 2.80456, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e011_vl2.805.h5\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.7972 - mse: 2.7328 - val_loss: 2.8046 - val_mse: 2.7402\n",
      "Epoch 12/25\n",
      "131/131 [==============================] - ETA: 0s - loss: 2.7967 - mse: 2.7323\n",
      "Epoch 12: val_loss did not improve from 2.80456\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.7967 - mse: 2.7323 - val_loss: 2.8047 - val_mse: 2.7404\n",
      "Epoch 13/25\n",
      "124/131 [===========================>..] - ETA: 0s - loss: 2.7966 - mse: 2.7324\n",
      "Epoch 13: val_loss improved from 2.80456 to 2.80332, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e013_vl2.803.h5\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.7959 - mse: 2.7317 - val_loss: 2.8033 - val_mse: 2.7391\n",
      "Epoch 14/25\n",
      "130/131 [============================>.] - ETA: 0s - loss: 2.7960 - mse: 2.7318\n",
      "Epoch 14: val_loss did not improve from 2.80332\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.7962 - mse: 2.7320 - val_loss: 2.8039 - val_mse: 2.7398\n",
      "Epoch 15/25\n",
      "126/131 [===========================>..] - ETA: 0s - loss: 2.7974 - mse: 2.7333\n",
      "Epoch 15: val_loss improved from 2.80332 to 2.80307, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e015_vl2.803.h5\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.7953 - mse: 2.7313 - val_loss: 2.8031 - val_mse: 2.7390\n",
      "Epoch 16/25\n",
      "121/131 [==========================>...] - ETA: 0s - loss: 2.7920 - mse: 2.7280\n",
      "Epoch 16: val_loss did not improve from 2.80307\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.7953 - mse: 2.7313 - val_loss: 2.8036 - val_mse: 2.7397\n",
      "Epoch 17/25\n",
      "128/131 [============================>.] - ETA: 0s - loss: 2.7953 - mse: 2.7315\n",
      "Epoch 17: val_loss did not improve from 2.80307\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.7947 - mse: 2.7309 - val_loss: 2.8036 - val_mse: 2.7398\n",
      "Epoch 18/25\n",
      "122/131 [==========================>...] - ETA: 0s - loss: 2.7940 - mse: 2.7302\n",
      "Epoch 18: val_loss improved from 2.80307 to 2.80181, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e018_vl2.802.h5\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.7939 - mse: 2.7302 - val_loss: 2.8018 - val_mse: 2.7380\n",
      "Epoch 19/25\n",
      "128/131 [============================>.] - ETA: 0s - loss: 2.7927 - mse: 2.7289\n",
      "Epoch 19: val_loss did not improve from 2.80181\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.7939 - mse: 2.7302 - val_loss: 2.8033 - val_mse: 2.7396\n",
      "Epoch 20/25\n",
      "123/131 [===========================>..] - ETA: 0s - loss: 2.7929 - mse: 2.7293\n",
      "Epoch 20: val_loss improved from 2.80181 to 2.80105, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e020_vl2.801.h5\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.7932 - mse: 2.7296 - val_loss: 2.8011 - val_mse: 2.7375\n",
      "Epoch 21/25\n",
      "131/131 [==============================] - ETA: 0s - loss: 2.7929 - mse: 2.7294\n",
      "Epoch 21: val_loss improved from 2.80105 to 2.80104, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e021_vl2.801.h5\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.7929 - mse: 2.7294 - val_loss: 2.8010 - val_mse: 2.7376\n",
      "Epoch 22/25\n",
      "129/131 [============================>.] - ETA: 0s - loss: 2.7923 - mse: 2.7289\n",
      "Epoch 22: val_loss improved from 2.80104 to 2.79970, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e022_vl2.800.h5\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.7922 - mse: 2.7287 - val_loss: 2.7997 - val_mse: 2.7363\n",
      "Epoch 23/25\n",
      "122/131 [==========================>...] - ETA: 0s - loss: 2.7936 - mse: 2.7302\n",
      "Epoch 23: val_loss did not improve from 2.79970\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.7923 - mse: 2.7289 - val_loss: 2.8019 - val_mse: 2.7386\n",
      "Epoch 24/25\n",
      "128/131 [============================>.] - ETA: 0s - loss: 2.7888 - mse: 2.7255\n",
      "Epoch 24: val_loss improved from 2.79970 to 2.79947, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e024_vl2.799.h5\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.7918 - mse: 2.7286 - val_loss: 2.7995 - val_mse: 2.7362\n",
      "Epoch 25/25\n",
      "121/131 [==========================>...] - ETA: 0s - loss: 2.7896 - mse: 2.7264\n",
      "Epoch 25: val_loss improved from 2.79947 to 2.79941, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e025_vl2.799.h5\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.7917 - mse: 2.7285 - val_loss: 2.7994 - val_mse: 2.7363\n",
      "Time elapsed to train: 20.38 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [3.853 4.611 3.084 4.943 3.825 3.163 2.683 2.383 1.971 1.291 1.281 0.005 0.005]\n",
      "<R> = [3.851 4.627 3.073 4.965 3.824 3.152 2.671 2.372 1.960 1.284 1.273 0.005 0.005]\n",
      "s_R = [1.067 1.055 1.260 1.125 1.142 1.170 1.413 1.708 2.476 6.279 6.408 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7847977 2.9181805 5.869458  ... 2.966066  4.0180717 4.46724  ]\n",
      "mag_pred: [3.7847977 2.9181805 5.869458  ... 2.966066  4.0180717 4.46724  ]\n",
      "Time elapsed to make plots: 17.75 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 391.13632    57.66189   122.36962  ...   22.195374   57.79094\n",
      " 2127.1748  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0168\n",
      "  1% : 0.184\n",
      "  10% : 0.637\n",
      "  50% : 4.38\n",
      "  90% : 48.7\n",
      "  99% : 385\n",
      "  100% : 7.1e+03\n",
      "<chi^2/d.o.f.> = 3.17\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 76958 stars (30.4%) based on chi^2/dof > 10.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 55.900505  62.73978  643.65845  ... 288.1129    80.67758   30.308079]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0404\n",
      "  1% : 0.185\n",
      "  10% : 0.633\n",
      "  50% : 4.31\n",
      "  90% : 48.4\n",
      "  99% : 363\n",
      "  100% : 5.39e+03\n",
      "<chi^2/d.o.f.> = 3.14\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 70.59 s\n",
      "learning rate = 0.00013533528544940054\n",
      "setting learning rate to 0.00011080315836233387\n",
      "Iteration 12 of 20.\n",
      "Epoch 1/25\n",
      "116/125 [==========================>...] - ETA: 0s - loss: 2.4054 - mse: 2.3423\n",
      "Epoch 1: val_loss improved from inf to 2.40380, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e001_vl2.404.h5\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 2.4056 - mse: 2.3426 - val_loss: 2.4038 - val_mse: 2.3409\n",
      "Epoch 2/25\n",
      "119/125 [===========================>..] - ETA: 0s - loss: 2.4046 - mse: 2.3418\n",
      "Epoch 2: val_loss did not improve from 2.40380\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.4040 - mse: 2.3412 - val_loss: 2.4054 - val_mse: 2.3426\n",
      "Epoch 3/25\n",
      "118/125 [===========================>..] - ETA: 0s - loss: 2.4016 - mse: 2.3389\n",
      "Epoch 3: val_loss improved from 2.40380 to 2.40241, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e003_vl2.402.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.4032 - mse: 2.3405 - val_loss: 2.4024 - val_mse: 2.3398\n",
      "Epoch 4/25\n",
      "122/125 [============================>.] - ETA: 0s - loss: 2.4026 - mse: 2.3401\n",
      "Epoch 4: val_loss improved from 2.40241 to 2.40170, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e004_vl2.402.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.4032 - mse: 2.3407 - val_loss: 2.4017 - val_mse: 2.3392\n",
      "Epoch 5/25\n",
      "123/125 [============================>.] - ETA: 0s - loss: 2.4024 - mse: 2.3399\n",
      "Epoch 5: val_loss improved from 2.40170 to 2.40125, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e005_vl2.401.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.4023 - mse: 2.3399 - val_loss: 2.4012 - val_mse: 2.3389\n",
      "Epoch 6/25\n",
      "124/125 [============================>.] - ETA: 0s - loss: 2.4019 - mse: 2.3397\n",
      "Epoch 6: val_loss did not improve from 2.40125\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.4023 - mse: 2.3400 - val_loss: 2.4030 - val_mse: 2.3408\n",
      "Epoch 7/25\n",
      "119/125 [===========================>..] - ETA: 0s - loss: 2.3995 - mse: 2.3373\n",
      "Epoch 7: val_loss improved from 2.40125 to 2.40075, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e007_vl2.401.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.4021 - mse: 2.3400 - val_loss: 2.4007 - val_mse: 2.3386\n",
      "Epoch 8/25\n",
      "118/125 [===========================>..] - ETA: 0s - loss: 2.4005 - mse: 2.3385\n",
      "Epoch 8: val_loss improved from 2.40075 to 2.40028, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e008_vl2.400.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.4017 - mse: 2.3397 - val_loss: 2.4003 - val_mse: 2.3383\n",
      "Epoch 9/25\n",
      "121/125 [============================>.] - ETA: 0s - loss: 2.4015 - mse: 2.3396\n",
      "Epoch 9: val_loss did not improve from 2.40028\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.4016 - mse: 2.3397 - val_loss: 2.4022 - val_mse: 2.3403\n",
      "Epoch 10/25\n",
      "120/125 [===========================>..] - ETA: 0s - loss: 2.3999 - mse: 2.3380\n",
      "Epoch 10: val_loss improved from 2.40028 to 2.40024, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e010_vl2.400.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.4012 - mse: 2.3393 - val_loss: 2.4002 - val_mse: 2.3385\n",
      "Epoch 11/25\n",
      "118/125 [===========================>..] - ETA: 0s - loss: 2.4023 - mse: 2.3406\n",
      "Epoch 11: val_loss improved from 2.40024 to 2.39909, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e011_vl2.399.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.4006 - mse: 2.3389 - val_loss: 2.3991 - val_mse: 2.3374\n",
      "Epoch 12/25\n",
      "121/125 [============================>.] - ETA: 0s - loss: 2.4014 - mse: 2.3398\n",
      "Epoch 12: val_loss improved from 2.39909 to 2.39894, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e012_vl2.399.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.4007 - mse: 2.3391 - val_loss: 2.3989 - val_mse: 2.3374\n",
      "Epoch 13/25\n",
      "122/125 [============================>.] - ETA: 0s - loss: 2.3996 - mse: 2.3381\n",
      "Epoch 13: val_loss improved from 2.39894 to 2.39869, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e013_vl2.399.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.4003 - mse: 2.3388 - val_loss: 2.3987 - val_mse: 2.3372\n",
      "Epoch 14/25\n",
      "116/125 [==========================>...] - ETA: 0s - loss: 2.3986 - mse: 2.3371\n",
      "Epoch 14: val_loss improved from 2.39869 to 2.39825, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e014_vl2.398.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.4001 - mse: 2.3387 - val_loss: 2.3982 - val_mse: 2.3369\n",
      "Epoch 15/25\n",
      "122/125 [============================>.] - ETA: 0s - loss: 2.3991 - mse: 2.3378\n",
      "Epoch 15: val_loss did not improve from 2.39825\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3996 - mse: 2.3383 - val_loss: 2.3997 - val_mse: 2.3384\n",
      "Epoch 16/25\n",
      "118/125 [===========================>..] - ETA: 0s - loss: 2.4004 - mse: 2.3391\n",
      "Epoch 16: val_loss improved from 2.39825 to 2.39806, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e016_vl2.398.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3999 - mse: 2.3387 - val_loss: 2.3981 - val_mse: 2.3369\n",
      "Epoch 17/25\n",
      "116/125 [==========================>...] - ETA: 0s - loss: 2.3978 - mse: 2.3367\n",
      "Epoch 17: val_loss improved from 2.39806 to 2.39773, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e017_vl2.398.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3993 - mse: 2.3381 - val_loss: 2.3977 - val_mse: 2.3366\n",
      "Epoch 18/25\n",
      "122/125 [============================>.] - ETA: 0s - loss: 2.3981 - mse: 2.3371\n",
      "Epoch 18: val_loss did not improve from 2.39773\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3992 - mse: 2.3381 - val_loss: 2.3979 - val_mse: 2.3369\n",
      "Epoch 19/25\n",
      "112/125 [=========================>....] - ETA: 0s - loss: 2.4009 - mse: 2.3400\n",
      "Epoch 19: val_loss improved from 2.39773 to 2.39722, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e019_vl2.397.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3988 - mse: 2.3378 - val_loss: 2.3972 - val_mse: 2.3363\n",
      "Epoch 20/25\n",
      "117/125 [===========================>..] - ETA: 0s - loss: 2.3977 - mse: 2.3368\n",
      "Epoch 20: val_loss did not improve from 2.39722\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3983 - mse: 2.3374 - val_loss: 2.3986 - val_mse: 2.3378\n",
      "Epoch 21/25\n",
      "124/125 [============================>.] - ETA: 0s - loss: 2.3983 - mse: 2.3374\n",
      "Epoch 21: val_loss improved from 2.39722 to 2.39619, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e021_vl2.396.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3982 - mse: 2.3374 - val_loss: 2.3962 - val_mse: 2.3355\n",
      "Epoch 22/25\n",
      "118/125 [===========================>..] - ETA: 0s - loss: 2.3956 - mse: 2.3349\n",
      "Epoch 22: val_loss did not improve from 2.39619\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3978 - mse: 2.3371 - val_loss: 2.3971 - val_mse: 2.3365\n",
      "Epoch 23/25\n",
      "124/125 [============================>.] - ETA: 0s - loss: 2.3975 - mse: 2.3369\n",
      "Epoch 23: val_loss improved from 2.39619 to 2.39594, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e023_vl2.396.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3975 - mse: 2.3369 - val_loss: 2.3959 - val_mse: 2.3354\n",
      "Epoch 24/25\n",
      "118/125 [===========================>..] - ETA: 0s - loss: 2.3982 - mse: 2.3376\n",
      "Epoch 24: val_loss did not improve from 2.39594\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3976 - mse: 2.3371 - val_loss: 2.3966 - val_mse: 2.3361\n",
      "Epoch 25/25\n",
      "121/125 [============================>.] - ETA: 0s - loss: 2.3979 - mse: 2.3374\n",
      "Epoch 25: val_loss did not improve from 2.39594\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3977 - mse: 2.3372 - val_loss: 2.3960 - val_mse: 2.3356\n",
      "Time elapsed to train: 19.67 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [3.919 4.673 3.148 5.006 3.891 3.228 2.746 2.448 2.045 1.384 1.368 0.004 0.004]\n",
      "<R> = [3.917 4.686 3.139 5.022 3.890 3.218 2.735 2.436 2.033 1.376 1.359 0.004 0.004]\n",
      "s_R = [1.044 1.030 1.221 1.092 1.108 1.136 1.362 1.586 2.213 4.803 5.017 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7627609 2.8352292 5.8752074 ... 2.9053524 3.9966333 4.4531717]\n",
      "mag_pred: [3.7627609 2.8352292 5.8752074 ... 2.9053524 3.9966333 4.4531717]\n",
      "Time elapsed to make plots: 20.76 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 381.22104    56.829395  153.47986  ...   18.377369   56.022224\n",
      " 2237.0984  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0087\n",
      "  1% : 0.178\n",
      "  10% : 0.607\n",
      "  50% : 4.21\n",
      "  90% : 49.8\n",
      "  99% : 387\n",
      "  100% : 7.1e+03\n",
      "<chi^2/d.o.f.> = 3.08\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 88151 stars (34.8%) based on chi^2/dof > 7.9\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 50.17109  67.20436 682.5742  ... 334.38647  71.80263  32.1332 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.047\n",
      "  1% : 0.176\n",
      "  10% : 0.602\n",
      "  50% : 4.1\n",
      "  90% : 49.3\n",
      "  99% : 368\n",
      "  100% : 5.38e+03\n",
      "<chi^2/d.o.f.> = 3.04\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 71.16 s\n",
      "learning rate = 0.00011080315744038671\n",
      "setting learning rate to 9.071795328941248e-05\n",
      "Iteration 13 of 20.\n",
      "Epoch 1/25\n",
      "109/117 [==========================>...] - ETA: 0s - loss: 2.0466 - mse: 1.9863\n",
      "Epoch 1: val_loss improved from inf to 2.04807, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e001_vl2.048.h5\n",
      "117/117 [==============================] - 1s 8ms/step - loss: 2.0474 - mse: 1.9871 - val_loss: 2.0481 - val_mse: 1.9879\n",
      "Epoch 2/25\n",
      "112/117 [===========================>..] - ETA: 0s - loss: 2.0470 - mse: 1.9869\n",
      "Epoch 2: val_loss improved from 2.04807 to 2.04796, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e002_vl2.048.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 2.0464 - mse: 1.9863 - val_loss: 2.0480 - val_mse: 1.9879\n",
      "Epoch 3/25\n",
      "110/117 [===========================>..] - ETA: 0s - loss: 2.0455 - mse: 1.9856\n",
      "Epoch 3: val_loss improved from 2.04796 to 2.04689, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e003_vl2.047.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 2.0461 - mse: 1.9861 - val_loss: 2.0469 - val_mse: 1.9870\n",
      "Epoch 4/25\n",
      "112/117 [===========================>..] - ETA: 0s - loss: 2.0468 - mse: 1.9870\n",
      "Epoch 4: val_loss did not improve from 2.04689\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 2.0461 - mse: 1.9863 - val_loss: 2.0482 - val_mse: 1.9884\n",
      "Epoch 5/25\n",
      "115/117 [============================>.] - ETA: 0s - loss: 2.0456 - mse: 1.9859\n",
      "Epoch 5: val_loss did not improve from 2.04689\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 2.0455 - mse: 1.9859 - val_loss: 2.0470 - val_mse: 1.9875\n",
      "Epoch 6/25\n",
      "110/117 [===========================>..] - ETA: 0s - loss: 2.0456 - mse: 1.9861\n",
      "Epoch 6: val_loss improved from 2.04689 to 2.04618, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e006_vl2.046.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 2.0456 - mse: 1.9860 - val_loss: 2.0462 - val_mse: 1.9867\n",
      "Epoch 7/25\n",
      "112/117 [===========================>..] - ETA: 0s - loss: 2.0474 - mse: 1.9880\n",
      "Epoch 7: val_loss improved from 2.04618 to 2.04590, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e007_vl2.046.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 2.0454 - mse: 1.9859 - val_loss: 2.0459 - val_mse: 1.9865\n",
      "Epoch 8/25\n",
      "108/117 [==========================>...] - ETA: 0s - loss: 2.0444 - mse: 1.9852\n",
      "Epoch 8: val_loss improved from 2.04590 to 2.04558, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e008_vl2.046.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 2.0452 - mse: 1.9859 - val_loss: 2.0456 - val_mse: 1.9863\n",
      "Epoch 9/25\n",
      "114/117 [============================>.] - ETA: 0s - loss: 2.0443 - mse: 1.9851\n",
      "Epoch 9: val_loss did not improve from 2.04558\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 2.0447 - mse: 1.9855 - val_loss: 2.0465 - val_mse: 1.9874\n",
      "Epoch 10/25\n",
      "108/117 [==========================>...] - ETA: 0s - loss: 2.0447 - mse: 1.9856\n",
      "Epoch 10: val_loss improved from 2.04558 to 2.04514, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e010_vl2.045.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 2.0446 - mse: 1.9856 - val_loss: 2.0451 - val_mse: 1.9861\n",
      "Epoch 11/25\n",
      "108/117 [==========================>...] - ETA: 0s - loss: 2.0452 - mse: 1.9863\n",
      "Epoch 11: val_loss did not improve from 2.04514\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 2.0446 - mse: 1.9856 - val_loss: 2.0458 - val_mse: 1.9869\n",
      "Epoch 12/25\n",
      "111/117 [===========================>..] - ETA: 0s - loss: 2.0442 - mse: 1.9854\n",
      "Epoch 12: val_loss did not improve from 2.04514\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 2.0443 - mse: 1.9855 - val_loss: 2.0452 - val_mse: 1.9864\n",
      "Epoch 13/25\n",
      "113/117 [===========================>..] - ETA: 0s - loss: 2.0444 - mse: 1.9857\n",
      "Epoch 13: val_loss improved from 2.04514 to 2.04506, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e013_vl2.045.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 2.0443 - mse: 1.9856 - val_loss: 2.0451 - val_mse: 1.9864\n",
      "Epoch 14/25\n",
      "107/117 [==========================>...] - ETA: 0s - loss: 2.0426 - mse: 1.9840\n",
      "Epoch 14: val_loss improved from 2.04506 to 2.04442, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e014_vl2.044.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 2.0439 - mse: 1.9852 - val_loss: 2.0444 - val_mse: 1.9859\n",
      "Epoch 15/25\n",
      "109/117 [==========================>...] - ETA: 0s - loss: 2.0467 - mse: 1.9882\n",
      "Epoch 15: val_loss improved from 2.04442 to 2.04413, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e015_vl2.044.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 2.0438 - mse: 1.9853 - val_loss: 2.0441 - val_mse: 1.9857\n",
      "Epoch 16/25\n",
      "109/117 [==========================>...] - ETA: 0s - loss: 2.0442 - mse: 1.9858\n",
      "Epoch 16: val_loss improved from 2.04413 to 2.04397, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e016_vl2.044.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 2.0436 - mse: 1.9852 - val_loss: 2.0440 - val_mse: 1.9856\n",
      "Epoch 17/25\n",
      "116/117 [============================>.] - ETA: 0s - loss: 2.0434 - mse: 1.9851\n",
      "Epoch 17: val_loss improved from 2.04397 to 2.04373, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e017_vl2.044.h5\n",
      "117/117 [==============================] - 1s 7ms/step - loss: 2.0432 - mse: 1.9849 - val_loss: 2.0437 - val_mse: 1.9855\n",
      "Epoch 18/25\n",
      "110/117 [===========================>..] - ETA: 0s - loss: 2.0409 - mse: 1.9827\n",
      "Epoch 18: val_loss did not improve from 2.04373\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 2.0433 - mse: 1.9851 - val_loss: 2.0439 - val_mse: 1.9857\n",
      "Epoch 19/25\n",
      "111/117 [===========================>..] - ETA: 0s - loss: 2.0430 - mse: 1.9849\n",
      "Epoch 19: val_loss did not improve from 2.04373\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 2.0434 - mse: 1.9853 - val_loss: 2.0442 - val_mse: 1.9861\n",
      "Epoch 20/25\n",
      "113/117 [===========================>..] - ETA: 0s - loss: 2.0430 - mse: 1.9850\n",
      "Epoch 20: val_loss did not improve from 2.04373\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 2.0429 - mse: 1.9848 - val_loss: 2.0443 - val_mse: 1.9863\n",
      "Epoch 21/25\n",
      "117/117 [==============================] - ETA: 0s - loss: 2.0428 - mse: 1.9849\n",
      "Epoch 21: val_loss improved from 2.04373 to 2.04348, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e021_vl2.043.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 2.0428 - mse: 1.9849 - val_loss: 2.0435 - val_mse: 1.9856\n",
      "Epoch 22/25\n",
      "111/117 [===========================>..] - ETA: 0s - loss: 2.0423 - mse: 1.9845\n",
      "Epoch 22: val_loss did not improve from 2.04348\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 2.0427 - mse: 1.9848 - val_loss: 2.0445 - val_mse: 1.9867\n",
      "Epoch 23/25\n",
      "108/117 [==========================>...] - ETA: 0s - loss: 2.0435 - mse: 1.9858\n",
      "Epoch 23: val_loss improved from 2.04348 to 2.04291, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e023_vl2.043.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 2.0424 - mse: 1.9847 - val_loss: 2.0429 - val_mse: 1.9852\n",
      "Epoch 24/25\n",
      "107/117 [==========================>...] - ETA: 0s - loss: 2.0435 - mse: 1.9859\n",
      "Epoch 24: val_loss improved from 2.04291 to 2.04231, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e024_vl2.042.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 2.0425 - mse: 1.9848 - val_loss: 2.0423 - val_mse: 1.9847\n",
      "Epoch 25/25\n",
      "114/117 [============================>.] - ETA: 0s - loss: 2.0432 - mse: 1.9857\n",
      "Epoch 25: val_loss improved from 2.04231 to 2.04223, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e025_vl2.042.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 2.0423 - mse: 1.9848 - val_loss: 2.0422 - val_mse: 1.9847\n",
      "Time elapsed to train: 18.34 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [3.972 4.733 3.196 5.073 3.944 3.276 2.789 2.492 2.088 1.434 1.418 0.003 0.003]\n",
      "<R> = [3.968 4.739 3.186 5.078 3.939 3.266 2.778 2.480 2.077 1.426 1.410 0.003 0.003]\n",
      "s_R = [0.981 0.974 1.135 1.038 1.044 1.068 1.263 1.442 1.912 3.734 3.870 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.751816  2.7911444 5.891735  ... 2.878005  3.9795296 4.445574 ]\n",
      "mag_pred: [3.751816  2.7911444 5.891735  ... 2.878005  3.9795296 4.445574 ]\n",
      "Time elapsed to make plots: 17.75 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 375.55835    54.33463   185.56981  ...   15.870407   53.91475\n",
      " 2353.7246  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00774\n",
      "  1% : 0.176\n",
      "  10% : 0.59\n",
      "  50% : 4.08\n",
      "  90% : 50.5\n",
      "  99% : 386\n",
      "  100% : 7.27e+03\n",
      "<chi^2/d.o.f.> = 3.02\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 99979 stars (39.5%) based on chi^2/dof > 6.3\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 46.42753   70.060974 720.36914  ... 355.08307   63.7968    34.216248]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0457\n",
      "  1% : 0.17\n",
      "  10% : 0.587\n",
      "  50% : 3.98\n",
      "  90% : 50.1\n",
      "  99% : 370\n",
      "  100% : 5.36e+03\n",
      "<chi^2/d.o.f.> = 2.99\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 68.83 s\n",
      "learning rate = 9.071795648196712e-05\n",
      "setting learning rate to 7.427357821433387e-05\n",
      "Iteration 14 of 20.\n",
      "Epoch 1/25\n",
      " 98/108 [==========================>...] - ETA: 0s - loss: 1.7439 - mse: 1.6865\n",
      "Epoch 1: val_loss improved from inf to 1.74370, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e001_vl1.744.h5\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 1.7418 - mse: 1.6844 - val_loss: 1.7437 - val_mse: 1.6864\n",
      "Epoch 2/25\n",
      "103/108 [===========================>..] - ETA: 0s - loss: 1.7403 - mse: 1.6831\n",
      "Epoch 2: val_loss improved from 1.74370 to 1.74301, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e002_vl1.743.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7408 - mse: 1.6835 - val_loss: 1.7430 - val_mse: 1.6858\n",
      "Epoch 3/25\n",
      "101/108 [===========================>..] - ETA: 0s - loss: 1.7387 - mse: 1.6815\n",
      "Epoch 3: val_loss improved from 1.74301 to 1.74275, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e003_vl1.743.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7405 - mse: 1.6834 - val_loss: 1.7428 - val_mse: 1.6857\n",
      "Epoch 4/25\n",
      " 97/108 [=========================>....] - ETA: 0s - loss: 1.7408 - mse: 1.6838\n",
      "Epoch 4: val_loss improved from 1.74275 to 1.74250, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e004_vl1.743.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7404 - mse: 1.6834 - val_loss: 1.7425 - val_mse: 1.6855\n",
      "Epoch 5/25\n",
      "104/108 [===========================>..] - ETA: 0s - loss: 1.7396 - mse: 1.6827\n",
      "Epoch 5: val_loss improved from 1.74250 to 1.74238, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e005_vl1.742.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7402 - mse: 1.6832 - val_loss: 1.7424 - val_mse: 1.6855\n",
      "Epoch 6/25\n",
      "102/108 [===========================>..] - ETA: 0s - loss: 1.7388 - mse: 1.6820\n",
      "Epoch 6: val_loss improved from 1.74238 to 1.74218, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e006_vl1.742.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7401 - mse: 1.6833 - val_loss: 1.7422 - val_mse: 1.6854\n",
      "Epoch 7/25\n",
      "100/108 [==========================>...] - ETA: 0s - loss: 1.7397 - mse: 1.6830\n",
      "Epoch 7: val_loss improved from 1.74218 to 1.74191, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e007_vl1.742.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7397 - mse: 1.6830 - val_loss: 1.7419 - val_mse: 1.6853\n",
      "Epoch 8/25\n",
      "102/108 [===========================>..] - ETA: 0s - loss: 1.7396 - mse: 1.6830\n",
      "Epoch 8: val_loss improved from 1.74191 to 1.74179, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e008_vl1.742.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7396 - mse: 1.6829 - val_loss: 1.7418 - val_mse: 1.6852\n",
      "Epoch 9/25\n",
      " 99/108 [==========================>...] - ETA: 0s - loss: 1.7412 - mse: 1.6847\n",
      "Epoch 9: val_loss did not improve from 1.74179\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7397 - mse: 1.6832 - val_loss: 1.7418 - val_mse: 1.6854\n",
      "Epoch 10/25\n",
      "104/108 [===========================>..] - ETA: 0s - loss: 1.7396 - mse: 1.6832\n",
      "Epoch 10: val_loss improved from 1.74179 to 1.74161, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e010_vl1.742.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7393 - mse: 1.6829 - val_loss: 1.7416 - val_mse: 1.6853\n",
      "Epoch 11/25\n",
      "106/108 [============================>.] - ETA: 0s - loss: 1.7387 - mse: 1.6824\n",
      "Epoch 11: val_loss improved from 1.74161 to 1.74150, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e011_vl1.741.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7391 - mse: 1.6828 - val_loss: 1.7415 - val_mse: 1.6853\n",
      "Epoch 12/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.7394 - mse: 1.6832\n",
      "Epoch 12: val_loss improved from 1.74150 to 1.74099, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e012_vl1.741.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7391 - mse: 1.6829 - val_loss: 1.7410 - val_mse: 1.6849\n",
      "Epoch 13/25\n",
      "101/108 [===========================>..] - ETA: 0s - loss: 1.7402 - mse: 1.6841\n",
      "Epoch 13: val_loss improved from 1.74099 to 1.74082, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e013_vl1.741.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7389 - mse: 1.6828 - val_loss: 1.7408 - val_mse: 1.6848\n",
      "Epoch 14/25\n",
      "104/108 [===========================>..] - ETA: 0s - loss: 1.7377 - mse: 1.6817\n",
      "Epoch 14: val_loss improved from 1.74082 to 1.74070, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e014_vl1.741.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7387 - mse: 1.6827 - val_loss: 1.7407 - val_mse: 1.6847\n",
      "Epoch 15/25\n",
      " 99/108 [==========================>...] - ETA: 0s - loss: 1.7386 - mse: 1.6827\n",
      "Epoch 15: val_loss improved from 1.74070 to 1.74062, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e015_vl1.741.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7387 - mse: 1.6828 - val_loss: 1.7406 - val_mse: 1.6848\n",
      "Epoch 16/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.7390 - mse: 1.6832\n",
      "Epoch 16: val_loss improved from 1.74062 to 1.74052, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e016_vl1.741.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7386 - mse: 1.6828 - val_loss: 1.7405 - val_mse: 1.6848\n",
      "Epoch 17/25\n",
      " 99/108 [==========================>...] - ETA: 0s - loss: 1.7404 - mse: 1.6847\n",
      "Epoch 17: val_loss did not improve from 1.74052\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7384 - mse: 1.6827 - val_loss: 1.7410 - val_mse: 1.6854\n",
      "Epoch 18/25\n",
      "106/108 [============================>.] - ETA: 0s - loss: 1.7373 - mse: 1.6817\n",
      "Epoch 18: val_loss improved from 1.74052 to 1.74044, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e018_vl1.740.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7382 - mse: 1.6826 - val_loss: 1.7404 - val_mse: 1.6849\n",
      "Epoch 19/25\n",
      "101/108 [===========================>..] - ETA: 0s - loss: 1.7374 - mse: 1.6820\n",
      "Epoch 19: val_loss improved from 1.74044 to 1.73983, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e019_vl1.740.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7382 - mse: 1.6827 - val_loss: 1.7398 - val_mse: 1.6844\n",
      "Epoch 20/25\n",
      "103/108 [===========================>..] - ETA: 0s - loss: 1.7392 - mse: 1.6838\n",
      "Epoch 20: val_loss improved from 1.73983 to 1.73976, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e020_vl1.740.h5\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 1.7380 - mse: 1.6826 - val_loss: 1.7398 - val_mse: 1.6844\n",
      "Epoch 21/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.7377 - mse: 1.6824\n",
      "Epoch 21: val_loss did not improve from 1.73976\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7378 - mse: 1.6825 - val_loss: 1.7401 - val_mse: 1.6848\n",
      "Epoch 22/25\n",
      "103/108 [===========================>..] - ETA: 0s - loss: 1.7375 - mse: 1.6822\n",
      "Epoch 22: val_loss did not improve from 1.73976\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7379 - mse: 1.6827 - val_loss: 1.7400 - val_mse: 1.6848\n",
      "Epoch 23/25\n",
      "100/108 [==========================>...] - ETA: 0s - loss: 1.7377 - mse: 1.6826\n",
      "Epoch 23: val_loss improved from 1.73976 to 1.73965, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e023_vl1.740.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7378 - mse: 1.6826 - val_loss: 1.7397 - val_mse: 1.6846\n",
      "Epoch 24/25\n",
      "100/108 [==========================>...] - ETA: 0s - loss: 1.7380 - mse: 1.6829\n",
      "Epoch 24: val_loss did not improve from 1.73965\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 1.7374 - mse: 1.6824 - val_loss: 1.7405 - val_mse: 1.6855\n",
      "Epoch 25/25\n",
      "103/108 [===========================>..] - ETA: 0s - loss: 1.7366 - mse: 1.6816\n",
      "Epoch 25: val_loss improved from 1.73965 to 1.73921, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e025_vl1.739.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7374 - mse: 1.6825 - val_loss: 1.7392 - val_mse: 1.6843\n",
      "Time elapsed to train: 17.07 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [4.018 4.782 3.232 5.129 3.987 3.309 2.818 2.518 2.114 1.459 1.445 0.003 0.003]\n",
      "<R> = [4.012 4.784 3.223 5.129 3.981 3.300 2.808 2.508 2.103 1.450 1.436 0.003 0.003]\n",
      "s_R = [0.916 0.911 1.051 0.980 0.978 0.998 1.159 1.302 1.671 2.962 3.066 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7402942 2.7372572 5.9100866 ... 2.8396192 3.9657502 4.440355 ]\n",
      "mag_pred: [3.7402942 2.7372572 5.9100866 ... 2.8396192 3.9657502 4.440355 ]\n",
      "Time elapsed to make plots: 21.04 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 374.9101     51.129192  209.22906  ...   14.035953   51.29326\n",
      " 2389.811   ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00869\n",
      "  1% : 0.175\n",
      "  10% : 0.577\n",
      "  50% : 3.97\n",
      "  90% : 50.5\n",
      "  99% : 384\n",
      "  100% : 7.5e+03\n",
      "<chi^2/d.o.f.> = 2.97\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 112401 stars (44.4%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 43.228065  71.53357  776.405    ... 376.9233    55.84542   37.395588]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.045\n",
      "  1% : 0.169\n",
      "  10% : 0.571\n",
      "  50% : 3.89\n",
      "  90% : 50\n",
      "  99% : 370\n",
      "  100% : 5.35e+03\n",
      "<chi^2/d.o.f.> = 2.93\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 65.79 s\n",
      "learning rate = 7.427357923006639e-05\n",
      "setting learning rate to 6.0810062625217954e-05\n",
      "Iteration 15 of 20.\n",
      "Epoch 1/25\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1.4801 - mse: 1.4253\n",
      "Epoch 1: val_loss improved from inf to 1.48104, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e001_vl1.481.h5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1.4803 - mse: 1.4255 - val_loss: 1.4810 - val_mse: 1.4263\n",
      "Epoch 2/25\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1.4797 - mse: 1.4250\n",
      "Epoch 2: val_loss improved from 1.48104 to 1.48029, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e002_vl1.480.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4796 - mse: 1.4249 - val_loss: 1.4803 - val_mse: 1.4257\n",
      "Epoch 3/25\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1.4789 - mse: 1.4243\n",
      "Epoch 3: val_loss improved from 1.48029 to 1.48013, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e003_vl1.480.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4791 - mse: 1.4246 - val_loss: 1.4801 - val_mse: 1.4256\n",
      "Epoch 4/25\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 1.4800 - mse: 1.4256\n",
      "Epoch 4: val_loss improved from 1.48013 to 1.48011, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e004_vl1.480.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4789 - mse: 1.4245 - val_loss: 1.4801 - val_mse: 1.4257\n",
      "Epoch 5/25\n",
      " 89/100 [=========================>....] - ETA: 0s - loss: 1.4773 - mse: 1.4229\n",
      "Epoch 5: val_loss improved from 1.48011 to 1.47962, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e005_vl1.480.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4787 - mse: 1.4244 - val_loss: 1.4796 - val_mse: 1.4253\n",
      "Epoch 6/25\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1.4784 - mse: 1.4241\n",
      "Epoch 6: val_loss improved from 1.47962 to 1.47921, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e006_vl1.479.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4788 - mse: 1.4246 - val_loss: 1.4792 - val_mse: 1.4250\n",
      "Epoch 7/25\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1.4787 - mse: 1.4246\n",
      "Epoch 7: val_loss did not improve from 1.47921\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4788 - mse: 1.4246 - val_loss: 1.4798 - val_mse: 1.4258\n",
      "Epoch 8/25\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1.4790 - mse: 1.4250\n",
      "Epoch 8: val_loss improved from 1.47921 to 1.47893, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e008_vl1.479.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4782 - mse: 1.4242 - val_loss: 1.4789 - val_mse: 1.4250\n",
      "Epoch 9/25\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1.4781 - mse: 1.4242\n",
      "Epoch 9: val_loss did not improve from 1.47893\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4781 - mse: 1.4242 - val_loss: 1.4792 - val_mse: 1.4253\n",
      "Epoch 10/25\n",
      " 90/100 [==========================>...] - ETA: 0s - loss: 1.4801 - mse: 1.4263\n",
      "Epoch 10: val_loss improved from 1.47893 to 1.47884, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e010_vl1.479.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4782 - mse: 1.4244 - val_loss: 1.4788 - val_mse: 1.4251\n",
      "Epoch 11/25\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1.4778 - mse: 1.4241\n",
      "Epoch 11: val_loss did not improve from 1.47884\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4781 - mse: 1.4244 - val_loss: 1.4790 - val_mse: 1.4254\n",
      "Epoch 12/25\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1.4783 - mse: 1.4247\n",
      "Epoch 12: val_loss did not improve from 1.47884\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4779 - mse: 1.4243 - val_loss: 1.4795 - val_mse: 1.4260\n",
      "Epoch 13/25\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 1.4787 - mse: 1.4252\n",
      "Epoch 13: val_loss improved from 1.47884 to 1.47843, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e013_vl1.478.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4777 - mse: 1.4242 - val_loss: 1.4784 - val_mse: 1.4250\n",
      "Epoch 14/25\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1.4781 - mse: 1.4247\n",
      "Epoch 14: val_loss improved from 1.47843 to 1.47816, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e014_vl1.478.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4777 - mse: 1.4243 - val_loss: 1.4782 - val_mse: 1.4248\n",
      "Epoch 15/25\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4785 - mse: 1.4252\n",
      "Epoch 15: val_loss did not improve from 1.47816\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4777 - mse: 1.4244 - val_loss: 1.4785 - val_mse: 1.4253\n",
      "Epoch 16/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4775 - mse: 1.4242\n",
      "Epoch 16: val_loss improved from 1.47816 to 1.47810, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e016_vl1.478.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4775 - mse: 1.4242 - val_loss: 1.4781 - val_mse: 1.4249\n",
      "Epoch 17/25\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 1.4772 - mse: 1.4241\n",
      "Epoch 17: val_loss improved from 1.47810 to 1.47781, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e017_vl1.478.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4773 - mse: 1.4242 - val_loss: 1.4778 - val_mse: 1.4247\n",
      "Epoch 18/25\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1.4771 - mse: 1.4241\n",
      "Epoch 18: val_loss improved from 1.47781 to 1.47769, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e018_vl1.478.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4773 - mse: 1.4243 - val_loss: 1.4777 - val_mse: 1.4247\n",
      "Epoch 19/25\n",
      " 89/100 [=========================>....] - ETA: 0s - loss: 1.4767 - mse: 1.4237\n",
      "Epoch 19: val_loss did not improve from 1.47769\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4771 - mse: 1.4242 - val_loss: 1.4780 - val_mse: 1.4251\n",
      "Epoch 20/25\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1.4767 - mse: 1.4239\n",
      "Epoch 20: val_loss did not improve from 1.47769\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4768 - mse: 1.4240 - val_loss: 1.4778 - val_mse: 1.4250\n",
      "Epoch 21/25\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1.4776 - mse: 1.4249\n",
      "Epoch 21: val_loss did not improve from 1.47769\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4771 - mse: 1.4244 - val_loss: 1.4777 - val_mse: 1.4251\n",
      "Epoch 22/25\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1.4772 - mse: 1.4246\n",
      "Epoch 22: val_loss improved from 1.47769 to 1.47742, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e022_vl1.477.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4769 - mse: 1.4242 - val_loss: 1.4774 - val_mse: 1.4248\n",
      "Epoch 23/25\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1.4761 - mse: 1.4236\n",
      "Epoch 23: val_loss improved from 1.47742 to 1.47713, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e023_vl1.477.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4767 - mse: 1.4242 - val_loss: 1.4771 - val_mse: 1.4246\n",
      "Epoch 24/25\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1.4768 - mse: 1.4243\n",
      "Epoch 24: val_loss did not improve from 1.47713\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4766 - mse: 1.4242 - val_loss: 1.4777 - val_mse: 1.4254\n",
      "Epoch 25/25\n",
      " 90/100 [==========================>...] - ETA: 0s - loss: 1.4751 - mse: 1.4228\n",
      "Epoch 25: val_loss improved from 1.47713 to 1.47704, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e025_vl1.477.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4764 - mse: 1.4241 - val_loss: 1.4770 - val_mse: 1.4247\n",
      "Time elapsed to train: 15.99 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [4.052 4.823 3.257 5.176 4.022 3.333 2.836 2.532 2.127 1.470 1.457 0.002 0.003]\n",
      "<R> = [4.046 4.819 3.248 5.169 4.015 3.324 2.827 2.522 2.118 1.461 1.447 0.002 0.003]\n",
      "s_R = [0.846 0.845 0.967 0.918 0.905 0.923 1.063 1.179 1.472 2.461 2.542 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7309148 2.6857927 5.929033  ... 2.802042  3.9531612 4.4369736]\n",
      "mag_pred: [3.7309148 2.6857927 5.929033  ... 2.802042  3.9531612 4.4369736]\n",
      "Time elapsed to make plots: 17.68 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 366.46094    49.892586  227.85529  ...   11.805738   50.01075\n",
      " 2321.9712  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00729\n",
      "  1% : 0.169\n",
      "  10% : 0.558\n",
      "  50% : 3.88\n",
      "  90% : 50.2\n",
      "  99% : 376\n",
      "  100% : 7.77e+03\n",
      "<chi^2/d.o.f.> = 2.92\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 111165 stars (43.9%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 38.983086  72.332245 844.0121   ... 397.70505   48.590206  40.73883 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0383\n",
      "  1% : 0.164\n",
      "  10% : 0.553\n",
      "  50% : 3.8\n",
      "  90% : 49.9\n",
      "  99% : 372\n",
      "  100% : 5.33e+03\n",
      "<chi^2/d.o.f.> = 2.88\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 66.67 s\n",
      "learning rate = 6.0810063587268814e-05\n",
      "setting learning rate to 4.9787068367863945e-05\n",
      "Iteration 16 of 20.\n",
      "Epoch 1/25\n",
      " 94/101 [==========================>...] - ETA: 0s - loss: 1.4586 - mse: 1.4064\n",
      "Epoch 1: val_loss improved from inf to 1.45838, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e001_vl1.458.h5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 1.4582 - mse: 1.4059 - val_loss: 1.4584 - val_mse: 1.4062\n",
      "Epoch 2/25\n",
      " 99/101 [============================>.] - ETA: 0s - loss: 1.4578 - mse: 1.4056\n",
      "Epoch 2: val_loss improved from 1.45838 to 1.45801, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e002_vl1.458.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4579 - mse: 1.4058 - val_loss: 1.4580 - val_mse: 1.4059\n",
      "Epoch 3/25\n",
      " 98/101 [============================>.] - ETA: 0s - loss: 1.4575 - mse: 1.4055\n",
      "Epoch 3: val_loss did not improve from 1.45801\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4579 - mse: 1.4059 - val_loss: 1.4583 - val_mse: 1.4063\n",
      "Epoch 4/25\n",
      " 95/101 [===========================>..] - ETA: 0s - loss: 1.4578 - mse: 1.4058\n",
      "Epoch 4: val_loss improved from 1.45801 to 1.45767, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e004_vl1.458.h5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 1.4577 - mse: 1.4057 - val_loss: 1.4577 - val_mse: 1.4057\n",
      "Epoch 5/25\n",
      "100/101 [============================>.] - ETA: 0s - loss: 1.4577 - mse: 1.4058\n",
      "Epoch 5: val_loss did not improve from 1.45767\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4578 - mse: 1.4059 - val_loss: 1.4580 - val_mse: 1.4062\n",
      "Epoch 6/25\n",
      " 99/101 [============================>.] - ETA: 0s - loss: 1.4568 - mse: 1.4049\n",
      "Epoch 6: val_loss did not improve from 1.45767\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4576 - mse: 1.4057 - val_loss: 1.4581 - val_mse: 1.4064\n",
      "Epoch 7/25\n",
      " 91/101 [==========================>...] - ETA: 0s - loss: 1.4585 - mse: 1.4067\n",
      "Epoch 7: val_loss improved from 1.45767 to 1.45756, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e007_vl1.458.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4576 - mse: 1.4059 - val_loss: 1.4576 - val_mse: 1.4059\n",
      "Epoch 8/25\n",
      " 95/101 [===========================>..] - ETA: 0s - loss: 1.4582 - mse: 1.4065\n",
      "Epoch 8: val_loss did not improve from 1.45756\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4573 - mse: 1.4057 - val_loss: 1.4580 - val_mse: 1.4063\n",
      "Epoch 9/25\n",
      " 92/101 [==========================>...] - ETA: 0s - loss: 1.4568 - mse: 1.4052\n",
      "Epoch 9: val_loss improved from 1.45756 to 1.45708, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e009_vl1.457.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4573 - mse: 1.4057 - val_loss: 1.4571 - val_mse: 1.4056\n",
      "Epoch 10/25\n",
      " 95/101 [===========================>..] - ETA: 0s - loss: 1.4578 - mse: 1.4063\n",
      "Epoch 10: val_loss improved from 1.45708 to 1.45701, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e010_vl1.457.h5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 1.4571 - mse: 1.4056 - val_loss: 1.4570 - val_mse: 1.4055\n",
      "Epoch 11/25\n",
      " 93/101 [==========================>...] - ETA: 0s - loss: 1.4568 - mse: 1.4054\n",
      "Epoch 11: val_loss did not improve from 1.45701\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4571 - mse: 1.4057 - val_loss: 1.4574 - val_mse: 1.4060\n",
      "Epoch 12/25\n",
      " 96/101 [===========================>..] - ETA: 0s - loss: 1.4581 - mse: 1.4068\n",
      "Epoch 12: val_loss did not improve from 1.45701\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4571 - mse: 1.4058 - val_loss: 1.4571 - val_mse: 1.4058\n",
      "Epoch 13/25\n",
      " 97/101 [===========================>..] - ETA: 0s - loss: 1.4578 - mse: 1.4065\n",
      "Epoch 13: val_loss improved from 1.45701 to 1.45698, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e013_vl1.457.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4569 - mse: 1.4057 - val_loss: 1.4570 - val_mse: 1.4057\n",
      "Epoch 14/25\n",
      "101/101 [==============================] - ETA: 0s - loss: 1.4569 - mse: 1.4057\n",
      "Epoch 14: val_loss did not improve from 1.45698\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4569 - mse: 1.4057 - val_loss: 1.4571 - val_mse: 1.4060\n",
      "Epoch 15/25\n",
      " 92/101 [==========================>...] - ETA: 0s - loss: 1.4588 - mse: 1.4077\n",
      "Epoch 15: val_loss improved from 1.45698 to 1.45695, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e015_vl1.457.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4568 - mse: 1.4057 - val_loss: 1.4569 - val_mse: 1.4059\n",
      "Epoch 16/25\n",
      " 89/101 [=========================>....] - ETA: 0s - loss: 1.4564 - mse: 1.4053\n",
      "Epoch 16: val_loss improved from 1.45695 to 1.45653, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e016_vl1.457.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4567 - mse: 1.4057 - val_loss: 1.4565 - val_mse: 1.4055\n",
      "Epoch 17/25\n",
      " 91/101 [==========================>...] - ETA: 0s - loss: 1.4553 - mse: 1.4043\n",
      "Epoch 17: val_loss improved from 1.45653 to 1.45644, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e017_vl1.456.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4566 - mse: 1.4056 - val_loss: 1.4564 - val_mse: 1.4055\n",
      "Epoch 18/25\n",
      "101/101 [==============================] - ETA: 0s - loss: 1.4566 - mse: 1.4057\n",
      "Epoch 18: val_loss did not improve from 1.45644\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4566 - mse: 1.4057 - val_loss: 1.4564 - val_mse: 1.4056\n",
      "Epoch 19/25\n",
      " 99/101 [============================>.] - ETA: 0s - loss: 1.4571 - mse: 1.4062\n",
      "Epoch 19: val_loss did not improve from 1.45644\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4565 - mse: 1.4056 - val_loss: 1.4564 - val_mse: 1.4057\n",
      "Epoch 20/25\n",
      " 95/101 [===========================>..] - ETA: 0s - loss: 1.4543 - mse: 1.4036\n",
      "Epoch 20: val_loss did not improve from 1.45644\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4563 - mse: 1.4056 - val_loss: 1.4571 - val_mse: 1.4064\n",
      "Epoch 21/25\n",
      " 94/101 [==========================>...] - ETA: 0s - loss: 1.4565 - mse: 1.4058\n",
      "Epoch 21: val_loss improved from 1.45644 to 1.45640, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e021_vl1.456.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4566 - mse: 1.4059 - val_loss: 1.4564 - val_mse: 1.4058\n",
      "Epoch 22/25\n",
      " 99/101 [============================>.] - ETA: 0s - loss: 1.4566 - mse: 1.4060\n",
      "Epoch 22: val_loss improved from 1.45640 to 1.45640, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e022_vl1.456.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4564 - mse: 1.4058 - val_loss: 1.4564 - val_mse: 1.4058\n",
      "Epoch 23/25\n",
      " 97/101 [===========================>..] - ETA: 0s - loss: 1.4556 - mse: 1.4051\n",
      "Epoch 23: val_loss improved from 1.45640 to 1.45635, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e023_vl1.456.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4562 - mse: 1.4057 - val_loss: 1.4563 - val_mse: 1.4058\n",
      "Epoch 24/25\n",
      "101/101 [==============================] - ETA: 0s - loss: 1.4561 - mse: 1.4057\n",
      "Epoch 24: val_loss improved from 1.45635 to 1.45618, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e024_vl1.456.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4561 - mse: 1.4057 - val_loss: 1.4562 - val_mse: 1.4057\n",
      "Epoch 25/25\n",
      " 93/101 [==========================>...] - ETA: 0s - loss: 1.4562 - mse: 1.4058\n",
      "Epoch 25: val_loss did not improve from 1.45618\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4560 - mse: 1.4056 - val_loss: 1.4568 - val_mse: 1.4064\n",
      "Time elapsed to train: 16.14 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [4.076 4.853 3.277 5.209 4.047 3.352 2.851 2.548 2.141 1.480 1.468 0.002 0.002]\n",
      "<R> = [4.070 4.848 3.268 5.200 4.039 3.343 2.842 2.539 2.132 1.471 1.459 0.002 0.002]\n",
      "s_R = [0.782 0.783 0.901 0.856 0.840 0.861 0.987 1.092 1.336 2.168 2.236 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7263625 2.6705441 5.937897  ... 2.8004596 3.9471476 4.434306 ]\n",
      "mag_pred: [3.7263625 2.6705441 5.937897  ... 2.8004596 3.9471476 4.434306 ]\n",
      "Time elapsed to make plots: 17.82 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 351.4166     51.216362  250.79117  ...   10.411464   50.695446\n",
      " 2350.017   ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00963\n",
      "  1% : 0.167\n",
      "  10% : 0.551\n",
      "  50% : 3.87\n",
      "  90% : 51.4\n",
      "  99% : 380\n",
      "  100% : 8.01e+03\n",
      "<chi^2/d.o.f.> = 2.9\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 111336 stars (44%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 36.48669   74.921326 919.7857   ... 409.72375   45.336025  44.89085 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0288\n",
      "  1% : 0.16\n",
      "  10% : 0.548\n",
      "  50% : 3.79\n",
      "  90% : 51.3\n",
      "  99% : 378\n",
      "  100% : 5.33e+03\n",
      "<chi^2/d.o.f.> = 2.86\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 66.49 s\n",
      "learning rate = 4.978706783731468e-05\n",
      "setting learning rate to 4.0762203978366214e-05\n",
      "Iteration 17 of 20.\n",
      "Epoch 1/25\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 1.4456 - mse: 1.3953\n",
      "Epoch 1: val_loss improved from inf to 1.44800, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e001_vl1.448.h5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1.4462 - mse: 1.3958 - val_loss: 1.4480 - val_mse: 1.3977\n",
      "Epoch 2/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.4469 - mse: 1.3967\n",
      "Epoch 2: val_loss did not improve from 1.44800\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 1.4460 - mse: 1.3958 - val_loss: 1.4481 - val_mse: 1.3979\n",
      "Epoch 3/25\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1.4458 - mse: 1.3957\n",
      "Epoch 3: val_loss improved from 1.44800 to 1.44787, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e003_vl1.448.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4460 - mse: 1.3959 - val_loss: 1.4479 - val_mse: 1.3977\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4460 - mse: 1.3959\n",
      "Epoch 4: val_loss did not improve from 1.44787\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4460 - mse: 1.3959 - val_loss: 1.4481 - val_mse: 1.3980\n",
      "Epoch 5/25\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1.4459 - mse: 1.3958\n",
      "Epoch 5: val_loss improved from 1.44787 to 1.44777, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e005_vl1.448.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4459 - mse: 1.3958 - val_loss: 1.4478 - val_mse: 1.3978\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4458 - mse: 1.3958\n",
      "Epoch 6: val_loss improved from 1.44777 to 1.44772, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e006_vl1.448.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4458 - mse: 1.3958 - val_loss: 1.4477 - val_mse: 1.3978\n",
      "Epoch 7/25\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1.4448 - mse: 1.3948\n",
      "Epoch 7: val_loss improved from 1.44772 to 1.44760, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e007_vl1.448.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4457 - mse: 1.3958 - val_loss: 1.4476 - val_mse: 1.3977\n",
      "Epoch 8/25\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1.4454 - mse: 1.3956\n",
      "Epoch 8: val_loss improved from 1.44760 to 1.44747, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e008_vl1.447.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4457 - mse: 1.3958 - val_loss: 1.4475 - val_mse: 1.3977\n",
      "Epoch 9/25\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 1.4461 - mse: 1.3963\n",
      "Epoch 9: val_loss did not improve from 1.44747\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4456 - mse: 1.3958 - val_loss: 1.4476 - val_mse: 1.3979\n",
      "Epoch 10/25\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1.4456 - mse: 1.3959\n",
      "Epoch 10: val_loss improved from 1.44747 to 1.44743, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e010_vl1.447.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4455 - mse: 1.3958 - val_loss: 1.4474 - val_mse: 1.3977\n",
      "Epoch 11/25\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1.4447 - mse: 1.3950\n",
      "Epoch 11: val_loss improved from 1.44743 to 1.44737, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e011_vl1.447.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4454 - mse: 1.3957 - val_loss: 1.4474 - val_mse: 1.3977\n",
      "Epoch 12/25\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 1.4437 - mse: 1.3941\n",
      "Epoch 12: val_loss improved from 1.44737 to 1.44714, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e012_vl1.447.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4454 - mse: 1.3958 - val_loss: 1.4471 - val_mse: 1.3976\n",
      "Epoch 13/25\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4452 - mse: 1.3956\n",
      "Epoch 13: val_loss did not improve from 1.44714\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4453 - mse: 1.3957 - val_loss: 1.4474 - val_mse: 1.3979\n",
      "Epoch 14/25\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1.4453 - mse: 1.3958\n",
      "Epoch 14: val_loss did not improve from 1.44714\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4451 - mse: 1.3957 - val_loss: 1.4472 - val_mse: 1.3978\n",
      "Epoch 15/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4452 - mse: 1.3958\n",
      "Epoch 15: val_loss did not improve from 1.44714\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4452 - mse: 1.3958 - val_loss: 1.4474 - val_mse: 1.3980\n",
      "Epoch 16/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.4451 - mse: 1.3958\n",
      "Epoch 16: val_loss did not improve from 1.44714\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4451 - mse: 1.3958 - val_loss: 1.4473 - val_mse: 1.3980\n",
      "Epoch 17/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.4451 - mse: 1.3959\n",
      "Epoch 17: val_loss improved from 1.44714 to 1.44710, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e017_vl1.447.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4451 - mse: 1.3958 - val_loss: 1.4471 - val_mse: 1.3978\n",
      "Epoch 18/25\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1.4444 - mse: 1.3952\n",
      "Epoch 18: val_loss improved from 1.44710 to 1.44690, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e018_vl1.447.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4450 - mse: 1.3957 - val_loss: 1.4469 - val_mse: 1.3977\n",
      "Epoch 19/25\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1.4449 - mse: 1.3957\n",
      "Epoch 19: val_loss improved from 1.44690 to 1.44681, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e019_vl1.447.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4450 - mse: 1.3958 - val_loss: 1.4468 - val_mse: 1.3977\n",
      "Epoch 20/25\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1.4440 - mse: 1.3948\n",
      "Epoch 20: val_loss improved from 1.44681 to 1.44671, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e020_vl1.447.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4448 - mse: 1.3956 - val_loss: 1.4467 - val_mse: 1.3976\n",
      "Epoch 21/25\n",
      " 89/100 [=========================>....] - ETA: 0s - loss: 1.4451 - mse: 1.3960\n",
      "Epoch 21: val_loss improved from 1.44671 to 1.44662, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e021_vl1.447.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4448 - mse: 1.3957 - val_loss: 1.4466 - val_mse: 1.3976\n",
      "Epoch 22/25\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1.4433 - mse: 1.3943\n",
      "Epoch 22: val_loss did not improve from 1.44662\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4447 - mse: 1.3957 - val_loss: 1.4471 - val_mse: 1.3982\n",
      "Epoch 23/25\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 1.4444 - mse: 1.3955\n",
      "Epoch 23: val_loss improved from 1.44662 to 1.44653, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e023_vl1.447.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4448 - mse: 1.3958 - val_loss: 1.4465 - val_mse: 1.3976\n",
      "Epoch 24/25\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4448 - mse: 1.3959\n",
      "Epoch 24: val_loss did not improve from 1.44653\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4447 - mse: 1.3958 - val_loss: 1.4468 - val_mse: 1.3980\n",
      "Epoch 25/25\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1.4445 - mse: 1.3957\n",
      "Epoch 25: val_loss did not improve from 1.44653\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4446 - mse: 1.3957 - val_loss: 1.4468 - val_mse: 1.3980\n",
      "Time elapsed to train: 15.80 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [4.097 4.877 3.294 5.235 4.067 3.369 2.866 2.561 2.152 1.488 1.476 0.002 0.002]\n",
      "<R> = [4.092 4.872 3.285 5.225 4.060 3.361 2.857 2.553 2.143 1.480 1.468 0.002 0.002]\n",
      "s_R = [0.730 0.727 0.847 0.801 0.788 0.810 0.928 1.021 1.234 1.941 2.005 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.727672  2.6603043 5.939875  ... 2.812155  3.9453828 4.432799 ]\n",
      "mag_pred: [3.727672  2.6603043 5.939875  ... 2.812155  3.9453828 4.432799 ]\n",
      "Time elapsed to make plots: 22.54 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 347.1007     49.53993   269.62036  ...   10.627235   49.49356\n",
      " 2434.5942  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0109\n",
      "  1% : 0.169\n",
      "  10% : 0.556\n",
      "  50% : 3.91\n",
      "  90% : 52.7\n",
      "  99% : 389\n",
      "  100% : 8.1e+03\n",
      "<chi^2/d.o.f.> = 2.91\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 111985 stars (44.3%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 36.91037   76.695595 988.19214  ... 411.04962   44.845768  46.76719 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0272\n",
      "  1% : 0.163\n",
      "  10% : 0.551\n",
      "  50% : 3.84\n",
      "  90% : 52.6\n",
      "  99% : 390\n",
      "  100% : 5.33e+03\n",
      "<chi^2/d.o.f.> = 2.86\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 63.53 s\n",
      "learning rate = 4.076220284332521e-05\n",
      "setting learning rate to 3.337326996032607e-05\n",
      "Iteration 18 of 20.\n",
      "Epoch 1/25\n",
      " 90/100 [==========================>...] - ETA: 0s - loss: 1.4436 - mse: 1.3948\n",
      "Epoch 1: val_loss improved from inf to 1.44428, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e001_vl1.444.h5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1.4431 - mse: 1.3943 - val_loss: 1.4443 - val_mse: 1.3956\n",
      "Epoch 2/25\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1.4437 - mse: 1.3950\n",
      "Epoch 2: val_loss improved from 1.44428 to 1.44421, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e002_vl1.444.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4430 - mse: 1.3943 - val_loss: 1.4442 - val_mse: 1.3955\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4429 - mse: 1.3943\n",
      "Epoch 3: val_loss improved from 1.44421 to 1.44404, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e003_vl1.444.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4429 - mse: 1.3943 - val_loss: 1.4440 - val_mse: 1.3954\n",
      "Epoch 4/25\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1.4438 - mse: 1.3952\n",
      "Epoch 4: val_loss did not improve from 1.44404\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4428 - mse: 1.3942 - val_loss: 1.4442 - val_mse: 1.3956\n",
      "Epoch 5/25\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1.4425 - mse: 1.3939\n",
      "Epoch 5: val_loss improved from 1.44404 to 1.44386, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e005_vl1.444.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4428 - mse: 1.3943 - val_loss: 1.4439 - val_mse: 1.3953\n",
      "Epoch 6/25\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4430 - mse: 1.3945\n",
      "Epoch 6: val_loss improved from 1.44386 to 1.44379, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e006_vl1.444.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4428 - mse: 1.3943 - val_loss: 1.4438 - val_mse: 1.3953\n",
      "Epoch 7/25\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 1.4435 - mse: 1.3950\n",
      "Epoch 7: val_loss did not improve from 1.44379\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4426 - mse: 1.3942 - val_loss: 1.4443 - val_mse: 1.3959\n",
      "Epoch 8/25\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4429 - mse: 1.3945\n",
      "Epoch 8: val_loss improved from 1.44379 to 1.44365, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e008_vl1.444.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4426 - mse: 1.3942 - val_loss: 1.4436 - val_mse: 1.3953\n",
      "Epoch 9/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.4430 - mse: 1.3946\n",
      "Epoch 9: val_loss did not improve from 1.44365\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4426 - mse: 1.3943 - val_loss: 1.4437 - val_mse: 1.3954\n",
      "Epoch 10/25\n",
      " 90/100 [==========================>...] - ETA: 0s - loss: 1.4424 - mse: 1.3941\n",
      "Epoch 10: val_loss did not improve from 1.44365\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4425 - mse: 1.3942 - val_loss: 1.4437 - val_mse: 1.3954\n",
      "Epoch 11/25\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1.4424 - mse: 1.3941\n",
      "Epoch 11: val_loss did not improve from 1.44365\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4426 - mse: 1.3943 - val_loss: 1.4437 - val_mse: 1.3955\n",
      "Epoch 12/25\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1.4439 - mse: 1.3957\n",
      "Epoch 12: val_loss improved from 1.44365 to 1.44338, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e012_vl1.443.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4424 - mse: 1.3941 - val_loss: 1.4434 - val_mse: 1.3952\n",
      "Epoch 13/25\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1.4418 - mse: 1.3936\n",
      "Epoch 13: val_loss did not improve from 1.44338\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4425 - mse: 1.3943 - val_loss: 1.4440 - val_mse: 1.3958\n",
      "Epoch 14/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.4424 - mse: 1.3943\n",
      "Epoch 14: val_loss did not improve from 1.44338\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4423 - mse: 1.3942 - val_loss: 1.4434 - val_mse: 1.3953\n",
      "Epoch 15/25\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4426 - mse: 1.3945\n",
      "Epoch 15: val_loss improved from 1.44338 to 1.44327, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e015_vl1.443.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4422 - mse: 1.3941 - val_loss: 1.4433 - val_mse: 1.3952\n",
      "Epoch 16/25\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1.4418 - mse: 1.3938\n",
      "Epoch 16: val_loss improved from 1.44327 to 1.44319, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e016_vl1.443.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4422 - mse: 1.3942 - val_loss: 1.4432 - val_mse: 1.3952\n",
      "Epoch 17/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4421 - mse: 1.3941\n",
      "Epoch 17: val_loss improved from 1.44319 to 1.44314, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e017_vl1.443.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4421 - mse: 1.3941 - val_loss: 1.4431 - val_mse: 1.3952\n",
      "Epoch 18/25\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1.4407 - mse: 1.3928\n",
      "Epoch 18: val_loss did not improve from 1.44314\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4422 - mse: 1.3943 - val_loss: 1.4434 - val_mse: 1.3955\n",
      "Epoch 19/25\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1.4422 - mse: 1.3943\n",
      "Epoch 19: val_loss did not improve from 1.44314\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4420 - mse: 1.3942 - val_loss: 1.4433 - val_mse: 1.3955\n",
      "Epoch 20/25\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1.4418 - mse: 1.3940\n",
      "Epoch 20: val_loss did not improve from 1.44314\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4420 - mse: 1.3942 - val_loss: 1.4432 - val_mse: 1.3953\n",
      "Epoch 21/25\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1.4441 - mse: 1.3964\n",
      "Epoch 21: val_loss did not improve from 1.44314\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4420 - mse: 1.3942 - val_loss: 1.4431 - val_mse: 1.3954\n",
      "Epoch 22/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4419 - mse: 1.3941\n",
      "Epoch 22: val_loss improved from 1.44314 to 1.44289, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e022_vl1.443.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4419 - mse: 1.3941 - val_loss: 1.4429 - val_mse: 1.3952\n",
      "Epoch 23/25\n",
      " 90/100 [==========================>...] - ETA: 0s - loss: 1.4426 - mse: 1.3949\n",
      "Epoch 23: val_loss improved from 1.44289 to 1.44285, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e023_vl1.443.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4419 - mse: 1.3943 - val_loss: 1.4429 - val_mse: 1.3952\n",
      "Epoch 24/25\n",
      " 90/100 [==========================>...] - ETA: 0s - loss: 1.4431 - mse: 1.3954\n",
      "Epoch 24: val_loss did not improve from 1.44285\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4418 - mse: 1.3942 - val_loss: 1.4429 - val_mse: 1.3953\n",
      "Epoch 25/25\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1.4412 - mse: 1.3936\n",
      "Epoch 25: val_loss improved from 1.44285 to 1.44267, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e025_vl1.443.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4417 - mse: 1.3941 - val_loss: 1.4427 - val_mse: 1.3951\n",
      "Time elapsed to train: 15.83 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [4.113 4.894 3.307 5.254 4.084 3.383 2.878 2.573 2.163 1.497 1.484 0.002 0.002]\n",
      "<R> = [4.108 4.890 3.300 5.245 4.077 3.375 2.870 2.565 2.155 1.488 1.476 0.002 0.002]\n",
      "s_R = [0.685 0.682 0.803 0.756 0.744 0.767 0.880 0.968 1.156 1.784 1.841 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7226546 2.646498  5.9358177 ... 2.8161762 3.9382508 4.427521 ]\n",
      "mag_pred: [3.7226546 2.646498  5.9358177 ... 2.8161762 3.9382508 4.427521 ]\n",
      "Time elapsed to make plots: 17.97 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 343.33023    49.99083   285.9138   ...   10.317208   50.24762\n",
      " 2493.8877  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0112\n",
      "  1% : 0.168\n",
      "  10% : 0.554\n",
      "  50% : 3.94\n",
      "  90% : 53.8\n",
      "  99% : 396\n",
      "  100% : 8.17e+03\n",
      "<chi^2/d.o.f.> = 2.9\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 112525 stars (44.5%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  36.358482   77.99619  1057.8076   ...  414.6619     44.03846\n",
      "   49.026215]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.03\n",
      "  1% : 0.162\n",
      "  10% : 0.548\n",
      "  50% : 3.87\n",
      "  90% : 53.8\n",
      "  99% : 398\n",
      "  100% : 5.33e+03\n",
      "<chi^2/d.o.f.> = 2.86\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 65.18 s\n",
      "learning rate = 3.337327143526636e-05\n",
      "setting learning rate to 2.732372244729256e-05\n",
      "Iteration 19 of 20.\n",
      "Epoch 1/25\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1.4400 - mse: 1.3925\n",
      "Epoch 1: val_loss improved from inf to 1.44229, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e001_vl1.442.h5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1.4403 - mse: 1.3928 - val_loss: 1.4423 - val_mse: 1.3947\n",
      "Epoch 2/25\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1.4405 - mse: 1.3930\n",
      "Epoch 2: val_loss improved from 1.44229 to 1.44217, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e002_vl1.442.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4403 - mse: 1.3928 - val_loss: 1.4422 - val_mse: 1.3947\n",
      "Epoch 3/25\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 1.4409 - mse: 1.3934\n",
      "Epoch 3: val_loss improved from 1.44217 to 1.44207, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e003_vl1.442.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4402 - mse: 1.3928 - val_loss: 1.4421 - val_mse: 1.3946\n",
      "Epoch 4/25\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1.4409 - mse: 1.3934\n",
      "Epoch 4: val_loss did not improve from 1.44207\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4403 - mse: 1.3929 - val_loss: 1.4422 - val_mse: 1.3948\n",
      "Epoch 5/25\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 1.4408 - mse: 1.3934\n",
      "Epoch 5: val_loss did not improve from 1.44207\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4402 - mse: 1.3928 - val_loss: 1.4422 - val_mse: 1.3948\n",
      "Epoch 6/25\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4394 - mse: 1.3921\n",
      "Epoch 6: val_loss improved from 1.44207 to 1.44194, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e006_vl1.442.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4402 - mse: 1.3929 - val_loss: 1.4419 - val_mse: 1.3946\n",
      "Epoch 7/25\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 1.4396 - mse: 1.3923\n",
      "Epoch 7: val_loss improved from 1.44194 to 1.44185, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e007_vl1.442.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4401 - mse: 1.3927 - val_loss: 1.4419 - val_mse: 1.3946\n",
      "Epoch 8/25\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 1.4394 - mse: 1.3921\n",
      "Epoch 8: val_loss did not improve from 1.44185\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4401 - mse: 1.3928 - val_loss: 1.4419 - val_mse: 1.3946\n",
      "Epoch 9/25\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1.4407 - mse: 1.3934\n",
      "Epoch 9: val_loss improved from 1.44185 to 1.44168, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e009_vl1.442.h5\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 1.4400 - mse: 1.3928 - val_loss: 1.4417 - val_mse: 1.3945\n",
      "Epoch 10/25\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 1.4392 - mse: 1.3920\n",
      "Epoch 10: val_loss improved from 1.44168 to 1.44156, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e010_vl1.442.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4399 - mse: 1.3927 - val_loss: 1.4416 - val_mse: 1.3944\n",
      "Epoch 11/25\n",
      " 90/100 [==========================>...] - ETA: 0s - loss: 1.4392 - mse: 1.3921\n",
      "Epoch 11: val_loss did not improve from 1.44156\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4399 - mse: 1.3928 - val_loss: 1.4417 - val_mse: 1.3945\n",
      "Epoch 12/25\n",
      " 90/100 [==========================>...] - ETA: 0s - loss: 1.4408 - mse: 1.3937\n",
      "Epoch 12: val_loss did not improve from 1.44156\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4398 - mse: 1.3927 - val_loss: 1.4416 - val_mse: 1.3945\n",
      "Epoch 13/25\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 1.4400 - mse: 1.3929\n",
      "Epoch 13: val_loss did not improve from 1.44156\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4398 - mse: 1.3928 - val_loss: 1.4421 - val_mse: 1.3950\n",
      "Epoch 14/25\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1.4396 - mse: 1.3926\n",
      "Epoch 14: val_loss improved from 1.44156 to 1.44148, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e014_vl1.441.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4398 - mse: 1.3928 - val_loss: 1.4415 - val_mse: 1.3945\n",
      "Epoch 15/25\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1.4396 - mse: 1.3926\n",
      "Epoch 15: val_loss improved from 1.44148 to 1.44135, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e015_vl1.441.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4398 - mse: 1.3927 - val_loss: 1.4414 - val_mse: 1.3944\n",
      "Epoch 16/25\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1.4396 - mse: 1.3927\n",
      "Epoch 16: val_loss did not improve from 1.44135\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4397 - mse: 1.3928 - val_loss: 1.4414 - val_mse: 1.3945\n",
      "Epoch 17/25\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1.4405 - mse: 1.3936\n",
      "Epoch 17: val_loss improved from 1.44135 to 1.44132, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e017_vl1.441.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4397 - mse: 1.3928 - val_loss: 1.4413 - val_mse: 1.3944\n",
      "Epoch 18/25\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 1.4406 - mse: 1.3937\n",
      "Epoch 18: val_loss improved from 1.44132 to 1.44129, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e018_vl1.441.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4396 - mse: 1.3927 - val_loss: 1.4413 - val_mse: 1.3944\n",
      "Epoch 19/25\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1.4394 - mse: 1.3926\n",
      "Epoch 19: val_loss did not improve from 1.44129\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4396 - mse: 1.3927 - val_loss: 1.4414 - val_mse: 1.3946\n",
      "Epoch 20/25\n",
      " 89/100 [=========================>....] - ETA: 0s - loss: 1.4384 - mse: 1.3916\n",
      "Epoch 20: val_loss improved from 1.44129 to 1.44122, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e020_vl1.441.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4395 - mse: 1.3927 - val_loss: 1.4412 - val_mse: 1.3944\n",
      "Epoch 21/25\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1.4400 - mse: 1.3932\n",
      "Epoch 21: val_loss improved from 1.44122 to 1.44121, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e021_vl1.441.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4395 - mse: 1.3928 - val_loss: 1.4412 - val_mse: 1.3945\n",
      "Epoch 22/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.4395 - mse: 1.3927\n",
      "Epoch 22: val_loss improved from 1.44121 to 1.44112, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e022_vl1.441.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4394 - mse: 1.3927 - val_loss: 1.4411 - val_mse: 1.3944\n",
      "Epoch 23/25\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1.4391 - mse: 1.3924\n",
      "Epoch 23: val_loss did not improve from 1.44112\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4394 - mse: 1.3927 - val_loss: 1.4414 - val_mse: 1.3948\n",
      "Epoch 24/25\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 1.4413 - mse: 1.3947\n",
      "Epoch 24: val_loss improved from 1.44112 to 1.44109, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e024_vl1.441.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4394 - mse: 1.3928 - val_loss: 1.4411 - val_mse: 1.3945\n",
      "Epoch 25/25\n",
      " 90/100 [==========================>...] - ETA: 0s - loss: 1.4395 - mse: 1.3929\n",
      "Epoch 25: val_loss did not improve from 1.44109\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 1.4393 - mse: 1.3927 - val_loss: 1.4413 - val_mse: 1.3947\n",
      "Time elapsed to train: 15.95 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [4.125 4.909 3.318 5.268 4.096 3.394 2.888 2.583 2.172 1.504 1.492 0.002 0.002]\n",
      "<R> = [4.120 4.904 3.311 5.259 4.089 3.387 2.880 2.575 2.164 1.496 1.484 0.002 0.002]\n",
      "s_R = [0.648 0.643 0.766 0.715 0.707 0.733 0.841 0.925 1.100 1.673 1.729 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7230759 2.6400166 5.938155  ... 2.8196106 3.9364374 4.427493 ]\n",
      "mag_pred: [3.7230759 2.6400166 5.938155  ... 2.8196106 3.9364374 4.427493 ]\n",
      "Time elapsed to make plots: 17.68 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 337.65372    50.841858  301.33896  ...   10.053757   50.888718\n",
      " 2539.156   ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0125\n",
      "  1% : 0.167\n",
      "  10% : 0.554\n",
      "  50% : 3.97\n",
      "  90% : 54.9\n",
      "  99% : 401\n",
      "  100% : 8.25e+03\n",
      "<chi^2/d.o.f.> = 2.9\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 113069 stars (44.7%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  35.952972   79.15348  1128.5369   ...  418.1385     43.37829\n",
      "   51.665432]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0302\n",
      "  1% : 0.162\n",
      "  10% : 0.548\n",
      "  50% : 3.89\n",
      "  90% : 54.8\n",
      "  99% : 403\n",
      "  100% : 5.33e+03\n",
      "<chi^2/d.o.f.> = 2.86\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 65.89 s\n",
      "learning rate = 2.732372195168864e-05\n",
      "setting learning rate to 2.2370771856165592e-05\n",
      "Iteration 20 of 20.\n",
      "Epoch 1/25\n",
      "95/99 [===========================>..] - ETA: 0s - loss: 1.4388 - mse: 1.3922\n",
      "Epoch 1: val_loss improved from inf to 1.43853, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e001_vl1.439.h5\n",
      "99/99 [==============================] - 1s 8ms/step - loss: 1.4386 - mse: 1.3920 - val_loss: 1.4385 - val_mse: 1.3920\n",
      "Epoch 2/25\n",
      "91/99 [==========================>...] - ETA: 0s - loss: 1.4379 - mse: 1.3914\n",
      "Epoch 2: val_loss improved from 1.43853 to 1.43835, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e002_vl1.438.h5\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 1.4386 - mse: 1.3921 - val_loss: 1.4384 - val_mse: 1.3918\n",
      "Epoch 3/25\n",
      "89/99 [=========================>....] - ETA: 0s - loss: 1.4374 - mse: 1.3909\n",
      "Epoch 3: val_loss did not improve from 1.43835\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4385 - mse: 1.3920 - val_loss: 1.4384 - val_mse: 1.3919\n",
      "Epoch 4/25\n",
      "93/99 [===========================>..] - ETA: 0s - loss: 1.4385 - mse: 1.3920\n",
      "Epoch 4: val_loss did not improve from 1.43835\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4385 - mse: 1.3920 - val_loss: 1.4384 - val_mse: 1.3920\n",
      "Epoch 5/25\n",
      "91/99 [==========================>...] - ETA: 0s - loss: 1.4371 - mse: 1.3906\n",
      "Epoch 5: val_loss did not improve from 1.43835\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4384 - mse: 1.3919 - val_loss: 1.4386 - val_mse: 1.3922\n",
      "Epoch 6/25\n",
      "96/99 [============================>.] - ETA: 0s - loss: 1.4385 - mse: 1.3921\n",
      "Epoch 6: val_loss improved from 1.43835 to 1.43829, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e006_vl1.438.h5\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 1.4385 - mse: 1.3921 - val_loss: 1.4383 - val_mse: 1.3919\n",
      "Epoch 7/25\n",
      "91/99 [==========================>...] - ETA: 0s - loss: 1.4391 - mse: 1.3927\n",
      "Epoch 7: val_loss did not improve from 1.43829\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4384 - mse: 1.3920 - val_loss: 1.4383 - val_mse: 1.3920\n",
      "Epoch 8/25\n",
      "90/99 [==========================>...] - ETA: 0s - loss: 1.4379 - mse: 1.3916\n",
      "Epoch 8: val_loss improved from 1.43829 to 1.43821, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e008_vl1.438.h5\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4384 - mse: 1.3920 - val_loss: 1.4382 - val_mse: 1.3919\n",
      "Epoch 9/25\n",
      "91/99 [==========================>...] - ETA: 0s - loss: 1.4386 - mse: 1.3923\n",
      "Epoch 9: val_loss improved from 1.43821 to 1.43818, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e009_vl1.438.h5\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4384 - mse: 1.3921 - val_loss: 1.4382 - val_mse: 1.3919\n",
      "Epoch 10/25\n",
      "94/99 [===========================>..] - ETA: 0s - loss: 1.4388 - mse: 1.3925\n",
      "Epoch 10: val_loss did not improve from 1.43818\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4382 - mse: 1.3919 - val_loss: 1.4383 - val_mse: 1.3921\n",
      "Epoch 11/25\n",
      "91/99 [==========================>...] - ETA: 0s - loss: 1.4372 - mse: 1.3910\n",
      "Epoch 11: val_loss improved from 1.43818 to 1.43809, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e011_vl1.438.h5\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4382 - mse: 1.3920 - val_loss: 1.4381 - val_mse: 1.3919\n",
      "Epoch 12/25\n",
      "89/99 [=========================>....] - ETA: 0s - loss: 1.4400 - mse: 1.3938\n",
      "Epoch 12: val_loss did not improve from 1.43809\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 1.4382 - mse: 1.3920 - val_loss: 1.4384 - val_mse: 1.3922\n",
      "Epoch 13/25\n",
      "96/99 [============================>.] - ETA: 0s - loss: 1.4383 - mse: 1.3922\n",
      "Epoch 13: val_loss improved from 1.43809 to 1.43800, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e013_vl1.438.h5\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4382 - mse: 1.3921 - val_loss: 1.4380 - val_mse: 1.3918\n",
      "Epoch 14/25\n",
      "91/99 [==========================>...] - ETA: 0s - loss: 1.4375 - mse: 1.3913\n",
      "Epoch 14: val_loss did not improve from 1.43800\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4381 - mse: 1.3920 - val_loss: 1.4380 - val_mse: 1.3919\n",
      "Epoch 15/25\n",
      "98/99 [============================>.] - ETA: 0s - loss: 1.4383 - mse: 1.3922\n",
      "Epoch 15: val_loss improved from 1.43800 to 1.43791, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e015_vl1.438.h5\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4382 - mse: 1.3920 - val_loss: 1.4379 - val_mse: 1.3918\n",
      "Epoch 16/25\n",
      "92/99 [==========================>...] - ETA: 0s - loss: 1.4382 - mse: 1.3921\n",
      "Epoch 16: val_loss did not improve from 1.43791\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4380 - mse: 1.3919 - val_loss: 1.4380 - val_mse: 1.3919\n",
      "Epoch 17/25\n",
      "93/99 [===========================>..] - ETA: 0s - loss: 1.4367 - mse: 1.3906\n",
      "Epoch 17: val_loss improved from 1.43791 to 1.43789, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e017_vl1.438.h5\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4380 - mse: 1.3920 - val_loss: 1.4379 - val_mse: 1.3919\n",
      "Epoch 18/25\n",
      "95/99 [===========================>..] - ETA: 0s - loss: 1.4381 - mse: 1.3921\n",
      "Epoch 18: val_loss improved from 1.43789 to 1.43787, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e018_vl1.438.h5\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 1.4380 - mse: 1.3920 - val_loss: 1.4379 - val_mse: 1.3919\n",
      "Epoch 19/25\n",
      "89/99 [=========================>....] - ETA: 0s - loss: 1.4370 - mse: 1.3910\n",
      "Epoch 19: val_loss improved from 1.43787 to 1.43785, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e019_vl1.438.h5\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4380 - mse: 1.3920 - val_loss: 1.4379 - val_mse: 1.3919\n",
      "Epoch 20/25\n",
      "98/99 [============================>.] - ETA: 0s - loss: 1.4378 - mse: 1.3919\n",
      "Epoch 20: val_loss improved from 1.43785 to 1.43772, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e020_vl1.438.h5\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4379 - mse: 1.3920 - val_loss: 1.4377 - val_mse: 1.3918\n",
      "Epoch 21/25\n",
      "90/99 [==========================>...] - ETA: 0s - loss: 1.4367 - mse: 1.3908\n",
      "Epoch 21: val_loss did not improve from 1.43772\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4379 - mse: 1.3920 - val_loss: 1.4380 - val_mse: 1.3921\n",
      "Epoch 22/25\n",
      "89/99 [=========================>....] - ETA: 0s - loss: 1.4390 - mse: 1.3931\n",
      "Epoch 22: val_loss did not improve from 1.43772\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4380 - mse: 1.3921 - val_loss: 1.4378 - val_mse: 1.3919\n",
      "Epoch 23/25\n",
      "99/99 [==============================] - ETA: 0s - loss: 1.4379 - mse: 1.3920\n",
      "Epoch 23: val_loss improved from 1.43772 to 1.43771, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e023_vl1.438.h5\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4379 - mse: 1.3920 - val_loss: 1.4377 - val_mse: 1.3919\n",
      "Epoch 24/25\n",
      "98/99 [============================>.] - ETA: 0s - loss: 1.4381 - mse: 1.3923\n",
      "Epoch 24: val_loss improved from 1.43771 to 1.43767, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e024_vl1.438.h5\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4379 - mse: 1.3921 - val_loss: 1.4377 - val_mse: 1.3919\n",
      "Epoch 25/25\n",
      "97/99 [============================>.] - ETA: 0s - loss: 1.4367 - mse: 1.3909\n",
      "Epoch 25: val_loss did not improve from 1.43767\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4378 - mse: 1.3920 - val_loss: 1.4377 - val_mse: 1.3920\n",
      "Time elapsed to train: 15.69 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [4.135 4.920 3.327 5.279 4.105 3.403 2.897 2.591 2.180 1.512 1.499 0.002 0.002]\n",
      "<R> = [4.130 4.915 3.320 5.271 4.098 3.395 2.889 2.583 2.172 1.504 1.491 0.002 0.002]\n",
      "s_R = [0.617 0.609 0.737 0.679 0.676 0.705 0.812 0.893 1.057 1.592 1.647 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7254145 2.6359324 5.9408054 ... 2.824131  3.9391148 4.430286 ]\n",
      "mag_pred: [3.7254145 2.6359324 5.9408054 ... 2.824131  3.9391148 4.430286 ]\n",
      "Time elapsed to make plots: 17.91 s\n"
     ]
    }
   ],
   "source": [
    "for k in range(0, n_iterations):\n",
    "    # Transform data to inputs and outputs\n",
    "    # On subsequent iterations, inflate errors using\n",
    "    # gradients dM/dtheta from trained model, and derive new\n",
    "    # estimates of the reddenings of the stars.\n",
    "    t0 = time()\n",
    "    io_train = get_inputs_outputs(\n",
    "        d_train,\n",
    "        pretrained_model=None if k == 0 else nn_model,\n",
    "        recalc_reddening=True,\n",
    "        rchisq_max=rchisq_max[k]\n",
    "    )                                                                         \n",
    "    io_test = get_inputs_outputs(                                                      #\n",
    "        d_test,                                                                        #\n",
    "        pretrained_model=None if k == 0 else nn_model,                                 #\n",
    "        recalc_reddening=True,                                                         #\n",
    "    )                                                                                  #                                                                        \n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to prepare data: {t1-t0:.2f} s')\n",
    "\n",
    "    # Set learning rate based on the iteration\n",
    "    lr = 0.001 * np.exp(-0.2*k)\n",
    "    print('learning rate = {}'.format(K.get_value(nn_model.optimizer.lr)))\n",
    "    print('setting learning rate to {}'.format(lr))\n",
    "    K.set_value(nn_model.optimizer.lr, lr)\n",
    "\n",
    "    # Train the model\n",
    "    print('Iteration {} of {}.'.format(k+1, n_iterations))\n",
    "    t0 = time()\n",
    "    train_model(\n",
    "        nn_model,\n",
    "        io_train,\n",
    "        epochs=25,\n",
    "        checkpoint_fn='{:s}_{:d}hidden_it{:d}'.format(\n",
    "            nn_name, n_hidden, k\n",
    "        ),\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to train: {t1-t0:.2f} s')\n",
    "    nn_model.save(\n",
    "        'models/{:s}_{:d}hidden_it{:d}.h5'.format(\n",
    "            nn_name, n_hidden, k\n",
    "        )\n",
    "    )\n",
    "    nn_model = keras.models.load_model(                                                #\n",
    "       'models/{:s}_{:d}hidden_it{:d}.h5'.format(nn_name, n_hidden, k)                 #\n",
    "    )                                                                                  #\n",
    "                                                                                       #\n",
    "    # Plot results on test set                                                         #\n",
    "    print('Diagnostic plots ...')                                                      #\n",
    "    t0 = time()                                                                        #\n",
    "    diagnostic_plots(                                                                  #\n",
    "       nn_model,                                                                       #\n",
    "       io_test,                                                                        #\n",
    "       d_test,                                                                         #\n",
    "       #io_train,                                                                      #\n",
    "       #d_train,                                                                       #\n",
    "       suffix='{:s}_{:d}hidden_it{:d}'.format(nn_name, n_hidden, k)                    #\n",
    "    )                                                                                  #\n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to make plots: {t1-t0:.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1d8de09-5d9d-43a1-b6ad-5aa70393a40a",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating covariances and reddening estimates of test dataset ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  36.03013    80.29135  1190.5325   ...  420.19403    43.565735\n",
      "   52.71469 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0275\n",
      "  1% : 0.161\n",
      "  10% : 0.551\n",
      "  50% : 3.92\n",
      "  90% : 55.7\n",
      "  99% : 410\n",
      "  100% : 5.33e+03\n",
      "<chi^2/d.o.f.> = 2.86\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to update covariances and reddenings: 7.69 s\n"
     ]
    }
   ],
   "source": [
    "print('Updating covariances and reddening estimates of test dataset ...')\n",
    "t0 = time()\n",
    "io_test = get_inputs_outputs(\n",
    "    d_test,\n",
    "    pretrained_model=nn_model,\n",
    "    recalc_reddening=True\n",
    ")\n",
    "t1 = time()\n",
    "print(f'Time elapsed to update covariances and reddenings: {t1-t0:.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fe20ad0-6076-42e4-b5fa-0a8b44b55833",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: [1.437394618988037, 1.3916150331497192]\n",
      "train loss: [1.4377180337905884, 1.3919380903244019]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance on (train, validation and test sets)\n",
    "loss = {}\n",
    "for n,io_eval in (('test',io_test), ('train',io_train)):\n",
    "    loss[n] = evaluate_model(\n",
    "        nn_model,\n",
    "        io_eval,\n",
    "        batch_size=batch_size,\n",
    "        rchisq_max=rchisq_max[-1]\n",
    "    )\n",
    "    print(f'{n} loss: {loss[n]}')\n",
    "fname = 'loss_{:s}_{:d}hidden_it{:d}.json'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "with open(fname, 'w') as f:\n",
    "    json.dump(loss, f, indent=2, sort_keys=True)\n",
    "\n",
    "fname = 'predictions_{:s}_{:d}hidden_it{:d}.h5'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "save_predictions(fname, nn_model, d_test, io_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ef83a49-55d7-41f4-be9e-87606f86734e",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving covariance components for small subset of test dataset ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 1000 bad. Replacing with 14.23750.\n",
      "Band 1: 0 of 1000 bad. Replacing with 14.61455.\n",
      "Band 2: 0 of 1000 bad. Replacing with 13.69537.\n",
      "Band 3: 147 of 1000 bad. Replacing with 14.96300.\n",
      "Band 4: 250 of 1000 bad. Replacing with 14.65440.\n",
      "Band 5: 310 of 1000 bad. Replacing with 14.59245.\n",
      "Band 6: 192 of 1000 bad. Replacing with 14.30900.\n",
      "Band 7: 33 of 1000 bad. Replacing with 14.03010.\n",
      "Band 8: 0 of 1000 bad. Replacing with 13.05500.\n",
      "Band 9: 1 of 1000 bad. Replacing with 15.26814.\n",
      "Band 10: 2 of 1000 bad. Replacing with 15.92215.\n",
      "Band 11: 0 of 1000 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 1000 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 1000 of 1000 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [6.94739227e+01 2.28022385e+01 1.49890909e+01 7.79216862e+00\n",
      " 1.28158140e+01 5.44104843e+01 7.66490631e+01 4.49151062e+02\n",
      " 7.23000412e+01 1.03259644e+02 6.92003021e+01 3.29930763e+01\n",
      " 2.01425491e+02 6.00104752e+01 2.00588226e+01 2.38516273e+01\n",
      " 8.43409958e+01 4.61654724e+02 2.08276443e+01 1.29666916e+02\n",
      " 2.22945518e+01 2.06976833e+01 9.67818375e+01 2.76206284e+01\n",
      " 7.93103943e+01 2.89210272e+00 2.19328629e+02 8.31221130e+02\n",
      " 3.51987381e+01 7.45477142e+01 4.32624390e+02 4.01496353e+01\n",
      " 2.70224823e+02 6.56738968e+01 9.21132660e+00 7.04827118e+00\n",
      " 2.30501347e+01 5.16892929e+01 9.29925049e+02 2.44168205e+01\n",
      " 1.90599823e+02 4.98527260e+01 9.92089558e+00 1.38353748e+01\n",
      " 8.91558456e+00 1.36372375e+02 1.82784271e+01 2.03675461e+01\n",
      " 1.23403076e+02 1.00339699e+01 7.11289883e+00 1.08016052e+01\n",
      " 9.19513524e-01 1.23785263e+02 1.58077194e+02 2.01712990e+01\n",
      " 3.01653976e+01 2.75769005e+01 2.39727264e+02 3.68109465e+00\n",
      " 7.94297333e+01 1.01038399e+01 1.36807756e+01 1.73856396e+03\n",
      " 3.54057312e+02 8.93161926e+01 2.32452049e+01 6.49045658e+00\n",
      " 2.44002350e+02 2.62583237e+01 1.42532516e+02 3.29875305e+02\n",
      " 1.99087753e+01 7.22958832e+01 3.77817039e+01 8.07378845e+01\n",
      " 6.68371948e+02 7.44899750e+00 1.23585632e+02 8.22626404e+02\n",
      " 1.21987228e+01 2.22841606e+01 8.76431942e+00 1.46424732e+01\n",
      " 3.41416550e+00 2.29396553e+01 1.81389236e+01 2.64796734e+01\n",
      " 1.14112701e+01 4.38948212e+01 6.60142670e+01 8.46019821e+01\n",
      " 6.80568695e+01 1.79275017e+01 4.40209198e+01 2.35536423e+01\n",
      " 2.00454681e+02 7.42705231e+01 3.01789932e+01 2.53716125e+01\n",
      " 4.43834686e+01 5.87403015e+02 9.61976624e+01 1.25365768e+02\n",
      " 1.18108513e+02 4.99466820e+01 1.85680957e+03 1.83353386e+01\n",
      " 3.57116608e+02 1.07800453e+02 6.44714844e+02 3.31628571e+02\n",
      " 6.65734711e+01 6.85419388e+01 5.31641312e+01 4.14756355e+01\n",
      " 1.44831192e+02 3.12992325e+01 9.85127106e+01 3.11490364e+01\n",
      " 1.82808189e+01 9.65815125e+01 2.16105151e+00 2.98462057e+00\n",
      " 3.79187584e+01 1.17501841e+01 2.28825226e+01 3.92541229e+02\n",
      " 8.85145081e+02 6.11219238e+02 8.43566799e+00 3.74713043e+02\n",
      " 3.40467644e+00 2.30743351e+01 5.42907715e+02 5.99558544e+00\n",
      " 6.79999847e+01 2.59043636e+01 2.32921753e+01 6.86754084e+00\n",
      " 5.95441055e+00 1.95550117e+01 9.67600555e+01 3.19003320e+00\n",
      " 1.96979828e+01 1.06654137e+02 2.49304031e+02 6.71240967e+02\n",
      " 2.24112759e+01 3.24553728e+00 1.45738586e+02 5.74321167e+02\n",
      " 5.46049347e+01 4.71203418e+03 6.96735954e+00 5.26425838e+00\n",
      " 2.83722639e+00 8.17997456e+00 4.77970161e+01 3.00307190e+02\n",
      " 6.52288437e+00 1.00625664e+02 5.13825150e+01 2.86918221e+01\n",
      " 2.15645428e+01 2.72369003e+01 1.75758759e+02 2.32040234e+01\n",
      " 6.78459072e+00 8.50100769e+02 5.70414307e+02 6.49707489e+01\n",
      " 1.58234100e+01 3.30153381e+02 1.00072632e+02 6.56599665e+00\n",
      " 3.07841339e+01 1.98809479e+02 2.01311989e+01 7.04002953e+00\n",
      " 2.93878815e+02 1.50973549e+01 2.10167023e+02 3.11123474e+02\n",
      " 2.15452362e+02 1.58007812e+01 1.64491623e+02 2.87691833e+02\n",
      " 5.51455383e+01 5.25354187e+02 1.15068091e+03 1.85397758e+01\n",
      " 1.04969673e+01 8.74977722e+01 1.36870584e+01 1.14844570e+01\n",
      " 3.03459106e+02 2.07288361e+02 2.44009796e+02 1.33407965e+01\n",
      " 1.75408127e+02 2.11593521e+02 3.61617775e+01 5.30702438e+01\n",
      " 3.76788330e+01 8.53469086e+01 3.97837585e+02 2.36940041e+01\n",
      " 2.19470154e+02 7.92150211e+00 3.39393616e+00 1.59555702e+01\n",
      " 8.92318344e+00 3.24284668e+01 5.49898148e+01 1.09028578e+01\n",
      " 8.57195435e+01 1.94746971e+01 4.26236725e+01 2.32588672e+03\n",
      " 1.44478340e+01 5.23787170e+02 1.03237671e+02 3.48206329e+01\n",
      " 6.45748234e+00 1.93688293e+02 1.01739868e+02 2.38246231e+01\n",
      " 1.17028931e+02 3.65960510e+02 6.93075895e+00 1.05034058e+03\n",
      " 3.93489685e+01 1.22220554e+01 1.42632113e+01 2.60304413e+01\n",
      " 8.85371246e+01 9.42204895e+01 1.34673920e+02 2.03746777e+01\n",
      " 6.84275208e+02 1.11807518e+01 1.14194412e+01 4.46338593e+02\n",
      " 6.71273327e+00 3.94676819e+01 1.55828381e+01 2.44293041e+01\n",
      " 1.04651474e+02 2.64149597e+02 2.46990242e+01 5.16017799e+01\n",
      " 2.38497467e+01 9.86322117e+00 7.46488190e+01 3.80043564e+01\n",
      " 3.95820770e+01 9.92239285e+00 4.05380096e+02 3.79159729e+02\n",
      " 1.53343445e+02 8.36520004e+00 9.13102112e+01 7.55877563e+02\n",
      " 3.36257782e+01 6.94028244e+01 2.20985279e+01 3.09631714e+02\n",
      " 3.22828712e+01 7.18616257e+01 3.40760350e+00 4.16926422e+01\n",
      " 8.78827381e+00 1.91211357e+01 4.93552361e+01 1.57614670e+01\n",
      " 7.94059830e+01 1.24403167e+00 1.28430252e+02 5.08603638e+02\n",
      " 8.37619553e+01 2.95447479e+02 5.01716661e+00 2.25311699e+01\n",
      " 4.61413918e+01 1.69091324e+02 7.52678375e+01 2.32611008e+01\n",
      " 8.92636261e+01 4.76863159e+02 3.59272644e+02 1.00851273e+02\n",
      " 1.75063133e+01 2.64052544e+01 1.24790558e+02 2.94073892e+00\n",
      " 1.38962355e+01 2.12743816e+01 7.76276550e+01 3.23309441e+01\n",
      " 5.19568558e+01 2.16692200e+02 1.00630966e+02 6.49012661e+00\n",
      " 2.18550835e+01 1.05083370e+00 5.63393066e+02 1.76402211e+00\n",
      " 5.45927979e+02 4.42949409e+01 4.38607788e+01 2.85912292e+02\n",
      " 5.94954729e+00 6.75775146e+01 5.46050692e+00 5.21325588e+00\n",
      " 3.59950943e+01 4.74910355e+01 1.98809528e+01 1.67246399e+01\n",
      " 1.65745728e+02 1.46387138e+01 6.19557190e+01 6.10952026e+02\n",
      " 3.39258432e+00 5.76861000e+01 8.53105347e+02 1.85380287e+01\n",
      " 4.19036789e+01 3.28062439e+02 2.52449295e+02 2.46804153e+02\n",
      " 4.44078016e+00 1.05892468e+03 1.78417568e+01 1.13260174e+01\n",
      " 4.53658447e+02 1.14837921e+02 8.81765652e+00 5.35290955e+02\n",
      " 2.98002869e+02 5.69034863e+00 1.16875755e+02 7.01657486e+00\n",
      " 6.87884521e+01 8.85541687e+01 3.66351898e+02 3.91265564e+02\n",
      " 1.30244446e+02 1.06204538e+01 3.86611710e+01 1.78715229e+00\n",
      " 8.71088562e+01 5.60127373e+01 6.37409729e+02 5.46149864e+01\n",
      " 4.85120316e+01 4.20194031e+02 1.62051437e+02 1.96856880e+01\n",
      " 1.20492661e+02 3.13626862e+00 1.52487427e+02 5.87969208e+01\n",
      " 2.17886856e+02 8.25223846e+01 1.78545105e+02 2.67876251e+02\n",
      " 3.17580910e+01 6.82115173e+01 1.23098770e+02 2.34468174e+01\n",
      " 9.42860107e+01 8.85399151e+00 6.73630066e+01 5.62838287e+01\n",
      " 1.95776806e+01 2.29496857e+02 4.49830933e+01 5.84489899e+01\n",
      " 9.94595642e+01 2.79119034e+01 4.34047470e+01 5.14031334e+01\n",
      " 8.63691559e+01 6.88323669e+01 4.06241913e+01 3.37668648e+01\n",
      " 2.31493855e+01 6.34517250e+01 1.26204391e+02 4.36816864e+01\n",
      " 4.76907837e+02 5.30609989e+00 2.04477997e+01 1.11475415e+03\n",
      " 5.99815655e+00 6.71268988e+00 2.84677887e+01 6.39788742e+01\n",
      " 1.72575455e+02 1.89913063e+01 6.42817459e+01 3.52889085e+00\n",
      " 5.03928406e+02 9.98040543e+01 1.44137405e+02 8.58930588e+00\n",
      " 2.64305902e+00 4.16382074e+00 1.07607812e+03 2.39819855e+02\n",
      " 5.05404625e+01 3.69506909e+03 4.53910065e+01 3.54706535e+01\n",
      " 3.90626587e+02 1.58932142e+01 4.70220184e+01 1.37649963e+02\n",
      " 1.04494352e+01 8.20531006e+01 1.72508041e+02 1.71714844e+02\n",
      " 1.64765289e+02 2.78749523e+01 1.72955292e+02 7.84962988e+00\n",
      " 8.11604118e+00 3.08237000e+02 9.12272358e+00 1.16274689e+02\n",
      " 2.60231457e+01 3.04334198e+02 2.36272614e+02 1.33577785e+01\n",
      " 1.23156567e+01 2.54483810e+02 4.08692322e+01 4.24860497e+01\n",
      " 9.42216492e+00 6.78445740e+01 6.60881758e+00 1.26099190e+02\n",
      " 2.57081223e+01 3.31418877e+01 1.13667736e+01 4.58044052e+00\n",
      " 5.31572075e+01 2.01602005e+02 2.57292999e+02 2.23838139e+01\n",
      " 1.52562048e+03 1.25881891e+01 6.10286179e+01 1.38927368e+02\n",
      " 1.15102386e+02 1.88573799e+01 1.27151337e+02 1.09650009e+02\n",
      " 2.95574512e+01 8.43059235e+01 2.70078983e+01 2.55561676e+01\n",
      " 1.34676651e+02 2.10135269e+00 1.78067551e+01 1.08856850e+01\n",
      " 2.19778900e+02 3.75962710e+00 9.00645924e+00 1.54032922e+00\n",
      " 5.49182510e+01 1.30118912e+02 3.32422998e+03 1.62620300e+02\n",
      " 7.64519653e+01 7.29833298e+01 2.12597923e+01 2.22607132e+02\n",
      " 2.43756580e+01 1.85109863e+01 4.17420959e+01 5.64965723e+03\n",
      " 4.57342834e+01 9.92956543e+01 9.04492111e+01 3.27401161e+01\n",
      " 4.34119629e+02 1.88411743e+02 1.10998901e+02 1.31048108e+03\n",
      " 8.19239044e+00 1.80307579e+01 4.52044153e+00 1.01442467e+02\n",
      " 4.73550339e+01 4.38180637e+00 2.97638512e+00 4.92088135e+02\n",
      " 1.00800757e+03 5.88852072e+00 9.10952454e+01 3.31081676e+00\n",
      " 2.69516754e+01 5.63552952e+00 2.17441772e+02 1.75410576e+01\n",
      " 3.80482635e+01 4.33208466e+02 1.37026587e+03 1.63460403e+02\n",
      " 9.93923950e+00 7.24869156e+00 2.49527302e+01 3.13855133e+02\n",
      " 1.64594406e+02 3.44579964e+01 2.39167206e+02 1.47816208e+02\n",
      " 4.71323586e+00 7.32041788e+00 2.24534607e+01 7.12689304e+00\n",
      " 6.62885427e+00 1.37920242e+02 1.28899872e+02 3.77643299e+00\n",
      " 1.14444489e+02 2.37281609e+01 9.17451286e+00 4.43428421e+01\n",
      " 3.37626270e+03 1.93197974e+03 8.28177261e+00 3.72639160e+01\n",
      " 1.14929428e+01 3.01040611e+01 2.82556934e+01 1.01142626e+01\n",
      " 1.34999666e+01 6.21504059e+01 3.50574570e+01 3.32391930e+01\n",
      " 3.42314835e+01 9.08994995e+02 7.64401703e+01 3.25424862e+00\n",
      " 1.25162001e+01 1.11725826e+01 3.70118141e+00 6.04689789e+01\n",
      " 5.09441490e+01 5.00421753e+02 5.55113506e+00 7.21570969e+01\n",
      " 2.12401794e+02 1.64790325e+01 6.49840164e+01 8.14062805e+01\n",
      " 2.36677265e+00 2.65112701e+02 1.05768509e+02 8.08381176e+00\n",
      " 5.27666260e+02 3.10085220e+01 5.17090464e+00 5.46491737e+01\n",
      " 3.05279236e+01 3.68086290e+00 6.43042908e+01 4.76330338e+01\n",
      " 1.19948502e+02 2.73236511e+02 3.61941467e+02 6.29156189e+01\n",
      " 5.40478477e+01 2.57308008e+03 5.07644272e+01 1.78934601e+02\n",
      " 1.09699574e+01 2.61695290e+01 5.03109169e+00 2.53858256e+00\n",
      " 2.30132599e+01 2.12884178e+01 5.33236885e+01 8.22089722e+02\n",
      " 1.83855438e+02 9.72520638e+00 3.04649620e+01 1.35095501e+01\n",
      " 2.40798283e+00 4.87111694e+02 8.06387329e+00 1.17866802e+01\n",
      " 1.29662123e+01 1.02584549e+02 8.26973114e+01 3.92192154e+01\n",
      " 7.78695068e+01 9.38531342e+01 1.02282104e+01 1.11685266e+01\n",
      " 2.39954834e+03 1.32886993e+02 6.25517368e+00 4.19334869e+01\n",
      " 2.01791382e+01 2.42312195e+02 3.49491930e+00 7.60168839e+01\n",
      " 1.90697540e+02 1.38630542e+03 2.61105442e+01 6.92589664e+00\n",
      " 7.61679916e+01 3.72742920e+01 2.05593491e+01 2.00210114e+01\n",
      " 2.89805031e+00 4.55974808e+01 9.57391357e+00 6.89926758e+01\n",
      " 2.23951035e+02 1.67115951e+00 2.45722008e+01 8.47541687e+02\n",
      " 3.15723705e+00 1.49059418e+02 7.31815186e+01 3.08783447e+03\n",
      " 9.91607666e+00 2.51970978e+02 6.11483669e+00 4.68829060e+00\n",
      " 1.18256092e+01 2.04435379e+02 6.20332146e+00 2.39575500e+01\n",
      " 4.36985550e+01 4.47201347e+00 6.15058994e+00 2.84519104e+02\n",
      " 8.05765503e+02 1.16208481e+02 1.08198845e+02 4.40992546e+00\n",
      " 1.85363445e+01 8.93447495e+00 2.65282745e+02 6.57295380e+01\n",
      " 3.94419632e+01 2.13090630e+01 7.18787432e+00 8.04459534e+01\n",
      " 3.68930225e+03 6.11789795e+02 5.91181299e+03 2.39021349e+00\n",
      " 3.40730972e+01 9.53890076e+01 1.30337418e+02 5.86339264e+01\n",
      " 1.12686951e+02 1.59758167e+01 8.35184574e+00 2.32918968e+01\n",
      " 2.80403404e+01 9.68075275e+00 1.27910304e+00 4.40533447e+01\n",
      " 9.84664917e+01 6.90204468e+01 1.31316431e+03 1.67108879e+01\n",
      " 6.46248531e+00 1.05689344e+01 1.15085168e+03 1.85531281e+02\n",
      " 2.77866936e+01 7.85121307e+01 3.08072395e+01 1.10530396e+01\n",
      " 6.48958618e+02 2.11679554e+01 3.43538940e+02 1.58936338e+01\n",
      " 3.12788429e+01 3.97611732e+01 1.42285843e+01 3.28300323e+01\n",
      " 3.27319031e+02 2.78488998e+01 1.37850677e+02 1.61930283e+02\n",
      " 1.84527016e+00 6.12771654e+00 4.75531387e+00 6.13034782e+01\n",
      " 1.67890015e+02 5.58960266e+01 1.20805801e+02 2.26473267e+02\n",
      " 1.76482086e+02 6.92399475e+02 7.77479458e+00 5.11231918e+01\n",
      " 2.25234570e+03 1.29798203e+01 5.71336441e+01 1.19949390e+03\n",
      " 1.32204361e+02 3.21633301e+02 1.44288193e+02 6.02912140e+01\n",
      " 7.60715771e+00 4.21646690e+00 7.23536873e+00 6.47012558e+01\n",
      " 1.22212585e+02 6.36098146e+00 1.20187622e+02 2.05940132e+01\n",
      " 6.35169106e+01 6.15513229e+01 1.16528482e+01 4.24382935e+02\n",
      " 7.15640030e+01 9.25274277e+01 2.68997345e+01 1.60650452e+02\n",
      " 7.98350647e+02 1.50622320e+01 1.54109726e+02 8.18755722e+00\n",
      " 1.60401764e+01 2.16962528e+01 6.37394190e+00 3.54494385e+03\n",
      " 7.43502502e+01 2.84430428e+01 8.96385002e+00 1.06018620e+01\n",
      " 2.93916748e+02 4.23768463e+01 1.77817932e+02 4.70466187e+02\n",
      " 3.71997223e+01 4.85298681e+00 1.90777588e+01 5.18757782e+01\n",
      " 1.65354805e+01 1.91845795e+02 4.21382294e+02 2.98662781e+02\n",
      " 2.65656605e+01 4.31854591e+01 1.94742706e+02 1.56305313e+02\n",
      " 5.14242973e+01 5.80269394e+01 8.41469002e+00 1.16348047e+01\n",
      " 3.88547134e+01 9.34479370e+02 1.74270229e+01 1.77437061e+03\n",
      " 3.59602173e+02 2.66436405e+01 1.76591110e+01 1.54897247e+02\n",
      " 5.50014381e+01 4.71381340e+01 3.07057129e+02 7.19156372e+02\n",
      " 6.27568340e+00 1.90384102e+01 1.96769357e+00 5.24330368e+01\n",
      " 9.76007233e+01 1.48688307e+01 1.73744141e+02 4.29874039e+01\n",
      " 5.88209076e+01 1.77601891e+01 8.72971916e+00 1.08005241e+02\n",
      " 3.39325142e+01 2.80844593e+01 3.71375732e+01 2.06513748e+01\n",
      " 7.90443726e+01 1.92427330e+01 1.50324387e+02 1.97703190e+01\n",
      " 9.54165039e+02 5.42392883e+01 3.85512009e+01 3.82049203e+00\n",
      " 7.95967636e+01 8.69610291e+01 7.69593201e+01 2.83784229e+03\n",
      " 9.38355827e+00 1.61778665e+00 6.32622375e+01 1.64491272e+02\n",
      " 1.81345032e+02 1.72628586e+02 4.58706665e+01 2.64027466e+02\n",
      " 1.35447113e+02 7.09703827e+00 1.56183662e+01 6.72618332e+01\n",
      " 4.33086426e+02 5.57989563e+02 1.14499878e+02 5.65524673e+00\n",
      " 1.23525757e+02 1.59469490e+01 1.95363794e+03 2.30678215e+01\n",
      " 6.05769882e+01 4.26458206e+01 5.83632751e+02 9.04678345e+00\n",
      " 3.07755241e+01 1.52147274e+01 1.57943527e+02 3.73468774e+03\n",
      " 2.68127625e+02 5.45760193e+01 1.29856537e+02 5.46741772e+00\n",
      " 8.57412231e+02 6.67556839e+01 1.33332615e+01 7.02805328e+01\n",
      " 3.20210342e+01 8.59086853e+02 2.76718497e+00 5.74561005e+01\n",
      " 2.36562347e+01 5.28440514e+01 2.09894485e+01 7.14361477e+00\n",
      " 2.62854977e+01 1.60824585e+02 2.56989899e+01 1.08347095e+03\n",
      " 1.07652397e+01 1.48537750e+02 2.80676056e+02 1.34548702e+01\n",
      " 5.54484985e+02 4.15166740e+01 1.64623444e+02 1.37680781e+00\n",
      " 1.18541765e+01 1.88680382e+01 2.01369934e+01 1.38193497e+02\n",
      " 1.67744904e+01 4.92143250e+01 4.02175674e+01 1.93084534e+02\n",
      " 2.17376366e+01 6.07253265e+01 4.21059799e+01 4.74937363e+01\n",
      " 1.52442718e+00 5.66214657e+00 1.09727307e+03 4.84430542e+02\n",
      " 6.61694031e+01 3.41291580e+01 3.10065826e+02 2.85304657e+02\n",
      " 1.50947327e+02 5.07226372e+00 1.02765789e+01 1.80021534e+01\n",
      " 8.38498718e+02 3.05556030e+01 2.53378662e+02 2.00552940e+01\n",
      " 6.43265747e+02 2.82519196e+02 5.81487579e+01 3.72432434e+02\n",
      " 3.47542114e+02 8.38396606e+01 1.44151058e+01 5.72401221e+03\n",
      " 8.84372864e+01 2.05377899e+02 1.32792557e+02 7.92287445e+01\n",
      " 1.88635206e+00 4.00992918e+00 1.00710339e+03 4.00807953e+01\n",
      " 3.42037659e+01 5.32749252e+01 4.91764282e+02 4.85795264e+03\n",
      " 6.80215454e+01 3.83207560e+00 2.48117027e+01 6.95796265e+02\n",
      " 5.76687622e+00 2.63356667e+01 1.12323523e+01 5.40204239e+00\n",
      " 6.64731750e+01 2.95982990e+01 6.58190918e+00 3.69761475e+02\n",
      " 4.04331398e+00 9.46098518e+00 3.85096497e+02 2.82702759e+02\n",
      " 6.32872070e+02 4.52506653e+02 1.94654865e+01 1.19981949e+02\n",
      " 3.28290863e+01 4.10367546e+01 3.03332877e+00 2.60998840e+02\n",
      " 3.54913635e+01 5.19284058e+01 3.03407707e+01 5.88408813e+02\n",
      " 4.84059334e+00 8.49386292e+02 5.43817596e+01 1.35288401e+01\n",
      " 4.84247627e+01 1.61866875e+01 7.88913584e+00 1.30488867e+03\n",
      " 2.19350143e+02 6.84695282e+01 2.90247620e+02 1.30053034e+01\n",
      " 5.30479797e+02 2.54699612e+01 2.63546729e+03 2.16783081e+02\n",
      " 5.55089378e+00 6.16240454e+00 8.14679565e+01 2.45930811e+03\n",
      " 1.96756134e+02 4.73143578e+00 2.26607075e+01 4.43015930e+02\n",
      " 1.09163452e+02 5.72268555e+02 2.76899796e+01 1.32070179e+01\n",
      " 2.19984932e+01 3.50609169e+01 2.05685043e+00 4.87003418e+02\n",
      " 1.14574249e+02 1.74480782e+01 3.73145247e+00 2.58219696e+02\n",
      " 1.42430687e+01 1.27879171e+01 3.28505969e+00 2.30277109e+00\n",
      " 2.16367168e+01 4.23025246e+01 5.69097281e+00 2.82647610e+00\n",
      " 5.53625679e+00 2.95412560e+01 3.19558716e+01 4.70276337e+01\n",
      " 4.06068726e+01 2.17230892e+00 3.87554291e+02 4.39785400e+02\n",
      " 9.90261688e+01 2.80346489e+01 6.91937485e+01 5.06034184e+00\n",
      " 1.53117508e+02 2.29678818e+02 5.06911507e+01 4.47840347e+01\n",
      " 3.26370277e+01 2.55198326e+01 6.28630400e+00 5.09308624e+00]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0766\n",
      "  1% : 0.154\n",
      "  10% : 0.523\n",
      "  50% : 4.22\n",
      "  90% : 52.2\n",
      "  99% : 386\n",
      "  100% : 673\n",
      "<chi^2/d.o.f.> = 2.83\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n"
     ]
    }
   ],
   "source": [
    "print('Saving covariance components for small subset of test dataset ...')\n",
    "# Fix random seed (same subset every run)\n",
    "np.random.seed(3)\n",
    "idx = np.arange(d_test.size)\n",
    "np.random.shuffle(idx)\n",
    "idx = idx[:1000]\n",
    "d_comp = d_test[idx]\n",
    "io_comp = get_inputs_outputs(\n",
    "    d_comp,\n",
    "    pretrained_model=nn_model,\n",
    "    recalc_reddening=True,\n",
    "    return_cov_components=True\n",
    ")\n",
    "fname = 'predictions_{:s}_{:d}hidden_it{:d}_comp.h5'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "save_predictions(fname, nn_model, d_comp, io_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bf3ec27-6103-4713-9c21-1222e68e39f1",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data and reddening estimates of subset of test dataset ...\n"
     ]
    }
   ],
   "source": [
    "print('Saving data and reddening estimates of subset of test dataset ...')\n",
    "np.random.seed(5)\n",
    "idx = np.arange(d_test.size)\n",
    "np.random.shuffle(idx)\n",
    "idx = idx[:10000]\n",
    "d_small = d_test[idx]\n",
    "r_fit_small = io_test['r'][idx]\n",
    "r_var_small = io_test['r_var'][idx]\n",
    "fname = 'test_data_small_{:s}_{:d}hidden.h5'.format(\n",
    "    nn_name, n_hidden\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82da0ebc-697f-4f8b-ae07-05ba4f0e7217",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving subset to test_data_small_ext_0h_l1n2_2hidden.h5 ...\n"
     ]
    }
   ],
   "source": [
    "print(f'Saving subset to {fname} ...')\n",
    "with h5py.File(fname, 'w') as f:\n",
    "    dset = f.create_dataset(\n",
    "        'data',\n",
    "        data=d_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )\n",
    "    for key in d_attrs:\n",
    "        dset.attrs[key] = d_attrs[key]\n",
    "\n",
    "    # Store updated reddening estimates\n",
    "    dset = f.create_dataset(\n",
    "        'r_fit',\n",
    "        data=r_fit_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )\n",
    "    dset = f.create_dataset(\n",
    "        'r_var',\n",
    "        data=r_var_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 2,
      "defaultCellHeight": 40,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
