{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b43db49-f88d-44af-8188-9c546a2bb2e1",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "source": [
    "Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12337364-915d-45e0-aa68-ff9ad349e998",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "# # Tell Tensorflow not to allocate all GPU memory right away.\n",
    "# # This is very important in shared environments!\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU') \n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from glob import glob\n",
    "from time import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b0b4d-d609-4535-82f4-76f5979bb893",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### The dataloder used by Green+2020 which will be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f39968a5-1090-448f-a6dc-b53829db1f41",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def load_data(fname, return_attrs=False):\n",
    "    print(f'Loading {fname} ...')\n",
    "    attrs = {}\n",
    "    with h5py.File(fname, 'r') as f:\n",
    "        dset = f['io_data']\n",
    "        for key in dset.attrs.keys():\n",
    "            attrs[key] = dset.attrs[key]\n",
    "        d = dset[:]\n",
    "    \n",
    "    if return_attrs:\n",
    "        return d, attrs\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a7c2e5-f232-46ff-b235-d6604c1b5d35",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Obtaining a correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3e0eccc-4ffd-4904-a210-7b430692c477",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def get_corr_matrix(cov):\n",
    "    rho = cov.copy()\n",
    "    sqrt_cov_diag = np.sqrt(cov[np.diag_indices(cov.shape[0])])\n",
    "    rho /= sqrt_cov_diag[:,None]\n",
    "    rho /= sqrt_cov_diag[None,:]\n",
    "    rho[np.diag_indices(cov.shape[0])] = sqrt_cov_diag\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f2ec3-9dba-4970-ab73-494dddd61534",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Cannot be explained in one markdown cell above, need to look through it more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72257ca9-2c06-4d52-9589-9b9086876356",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def get_inputs_outputs(d, pretrained_model=None,\n",
    "                          recalc_reddening=False,\n",
    "                          rchisq_max=None,\n",
    "                          return_cov_components=False):\n",
    "    n_bands = 13 # Gaia (G, BP, RP), PS1 (grizy), 2MASS (JHK), unWISE (W1,W2)\n",
    "    n_atm_params = 3 # (T_eff, logg, [M/H])\n",
    "    \n",
    "    large_err = 999.\n",
    "\n",
    "    # Stellar spectroscopic parameters\n",
    "    print('Fill in stellar atmospheric parameters ...')\n",
    "    x = np.empty((d.size,3), dtype='f4')\n",
    "    x[:] = d['atm_param'][:]\n",
    "\n",
    "    x_p = np.empty((d.size,3), dtype='f4')\n",
    "    x_p = d['atm_param_p'][:]\n",
    "\n",
    "    # Magnitudes\n",
    "    print('Fill in stellar magnitudes ...')\n",
    "    y = np.empty((d.size,n_bands), dtype='f4')\n",
    "    y[:] = d['mag'][:]\n",
    "\n",
    "    # Covariance of y\n",
    "    print('Empty covariance matrix ...')\n",
    "    cov_y = np.zeros((d.size,n_bands,n_bands), dtype='f4')\n",
    "\n",
    "    # \\delta m\n",
    "    print('Covariance: \\delta m ...')\n",
    "    for i in range(n_bands):\n",
    "        cov_y[:,i,i] = d['mag_err'][:,i]**2\n",
    "\n",
    "    # Replace NaN magnitudes with median (in each band).\n",
    "    # Also set corresponding variances to large number.\n",
    "    print('Replace NaN magnitudes ...')\n",
    "    for b in range(n_bands):\n",
    "        idx = (\n",
    "              ~np.isfinite(y[:,b])\n",
    "            | ~np.isfinite(cov_y[:,b,b])\n",
    "        )\n",
    "        n_bad = np.count_nonzero(idx)\n",
    "        n_tot = idx.size\n",
    "        y0 = np.median(y[~idx,b])\n",
    "        if np.isnan(y0):\n",
    "            y0 = 0.\n",
    "        print(f'Band {b}: {n_bad} of {n_tot} bad. Replacing with {y0:.5f}.')\n",
    "        y[idx,b] = y0\n",
    "        cov_y[idx,b,b] = large_err**2.\n",
    "\n",
    "    # Transform both y and its covariance\n",
    "    B = np.identity(n_bands, dtype='f4')\n",
    "    B[1:,0] = -1.\n",
    "    \n",
    "    print('Transform y -> B y ...')\n",
    "    y = np.einsum('ij,nj->ni', B, y) # y' = B y\n",
    "    print('Transform C -> B C B^T ...')\n",
    "    #cov_y = np.einsum('ik,nkl,jl->nij', B, cov_y, B) # C' = B C B^T\n",
    "    cov_y = np.einsum('nik,jk->nij', cov_y, B)\n",
    "    cov_y = np.einsum('ik,nkj->nij', B, cov_y)\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp = {\n",
    "            'delta_m': cov_y.copy()\n",
    "        }\n",
    "    \n",
    "    # Add in dM/dtheta and dR/dtheta terms\n",
    "    if pretrained_model is not None:\n",
    "        print('Calculate J = dM/dtheta ...')\n",
    "        J_M = calc_dmag_color_dtheta(pretrained_model, x_p)\n",
    "        cov_x = d['atm_param_cov_p']\n",
    "        print('Covariance: J C_theta J^T ...')\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_M)\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['dM/dtheta'] = np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_M)\n",
    "\n",
    "    # If pretrained model provided, could calculate reduced chi^2\n",
    "    # with maximum-likelihood (mu, E) here.\n",
    "\n",
    "    # \\delta \\mu (must be added in after transformation,\n",
    "    #             due to possibly infinite terms).\n",
    "    print('{:d} NaN parallaxes'.format(\n",
    "        np.count_nonzero(np.isnan(d['parallax']))\n",
    "    ))\n",
    "    err_over_plx = d['parallax_err'] / d['parallax']\n",
    "    print('Covariance: DM uncertainty term ...')\n",
    "    cov_y[:,0,0] += (5./np.log(10.) * err_over_plx)**2.\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp['dm'] = np.zeros_like(cov_y)\n",
    "        cov_comp['dm'][:,0,0] = (5./np.log(10.) * err_over_plx)**2.\n",
    "\n",
    "    # Subtract distance modulus from m_G\n",
    "    #dm = -5. * (np.log10(d['parallax']) - 2.)\n",
    "    #dm_corr = 0.5 * err_over_plx**2 + 0.75 * err_over_plx**4\n",
    "    #dm_corr_pct = np.percentile(dm_corr, [1., 5., 10., 50., 90., 95., 99.])\n",
    "    #print(dm_corr_pct)\n",
    "\n",
    "    print('Estimate DM ...')\n",
    "    dm = 10. - 5.*np.log10(d['parallax'])# + 5./np.log(10.)*dm_corr\n",
    "    y[:,0] -= dm\n",
    "\n",
    "    # Don't attempt to predict M_G for poor plx/err or when plx < 0\n",
    "    print('Filter out M_G for poor parallax measurements ...')\n",
    "    idx = (\n",
    "          (err_over_plx > 0.2)\n",
    "        | (d['parallax'] < 1.e-8)\n",
    "        | ~np.isfinite(d['parallax'])\n",
    "        | ~np.isfinite(d['parallax_err'])\n",
    "    )\n",
    "    n_use = idx.size - np.count_nonzero(idx)\n",
    "    print(r'Using {:d} of {:d} ({:.3f}%) of stellar parallaxes.'.format(\n",
    "        n_use, idx.size, n_use/idx.size*100.\n",
    "    ))\n",
    "    cov_y[idx,0,0] = large_err**2\n",
    "    y[idx,0] = np.nanmedian(y[:,0])\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp['dm'][idx,0,0] = large_err**2\n",
    "\n",
    "    # Reddenings\n",
    "    print('Copy reddenings ...')\n",
    "    r = np.empty((d.size,), dtype='f4')\n",
    "    r[:] = d['r'][:]\n",
    "    \n",
    "    if pretrained_model is None:\n",
    "        # If R has not yet been estimated, then\n",
    "        # cut out stars with sigma_r > 0.2 mag.\n",
    "        idx = (d['r_err'] > 0.2)\n",
    "        print(f'Cutting {np.count_nonzero(idx)} stars with large sigma_r.')\n",
    "        for k in range(cov_y.shape[1]):\n",
    "            cov_y[idx,k,k] += large_err**2\n",
    "\n",
    "    if pretrained_model is not None:\n",
    "        # Update reddenings, based on vector R and (y_obs - y_pred).\n",
    "        # Use provided reddenings as a prior.\n",
    "\n",
    "        # First, need to calculate inv_cov_y\n",
    "        print('Invert C_y matrices ...')\n",
    "        inv_cov_y = np.stack([np.linalg.inv(c) for c in cov_y])\n",
    "\n",
    "        # Predict M & R for each star based on atm. params\n",
    "        M_pred = predict_M(pretrained_model, x_p)\n",
    "        R = predict_R(pretrained_model, x_p)\n",
    "        \n",
    "        r_var = d['r_err']**2\n",
    "        \n",
    "        # Calculate posterior on reddening\n",
    "        if recalc_reddening:\n",
    "            print('Calculate posterior on reddening ...')\n",
    "            r_pred, r_var = update_reddenings(\n",
    "                M_pred, R, y,\n",
    "                inv_cov_y,\n",
    "                r, r_var\n",
    "            )\n",
    "            \n",
    "            # Clip mean and variance of reddenings\n",
    "            print('Clip reddenings and reddening variances ...')\n",
    "            r[:] = np.clip(r_pred, 0., 10.) # TODO: Update upper limit?\n",
    "        \n",
    "        # TODO: Different lower bounds on error for different sources?\n",
    "        r_var[:] = np.clip(r_var, 0.02**2 + (0.1*r)**2, 10.**2)\n",
    "        \n",
    "        # Reddening uncertainty term in covariance of y\n",
    "        print('Covariance: reddening uncertainty term ...')\n",
    "        cov_y += r_var[:,None,None] * R[:,:,None]*R[:,None,:]\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['r'] = r_var[:,None,None] * R[:,:,None]*R[:,None,:]\n",
    "        \n",
    "        # Propagate uncertainty in theta to uncertainty in R\n",
    "        print('Calculate J = dA/dtheta ...')\n",
    "        J_A = calc_dext_red_dtheta(pretrained_model, x_p, r)\n",
    "        cov_x = d['atm_param_cov_p']\n",
    "        print('Covariance: J C_theta J^T ...')\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_A)\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_A)\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_M)\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['dA/dtheta'] = np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_A)\n",
    "            cov_comp['dMA/dtheta'] = np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_A)\n",
    "            cov_comp['dAM/dtheta'] = np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_M)\n",
    "        \n",
    "        # Calculate chi^2 for each star\n",
    "        chisq = calc_chisq(M_pred+r[:,None]*R-y, inv_cov_y)\n",
    "        print('chisq =', chisq)\n",
    "\n",
    "        # Calculate d.o.f. of each star\n",
    "        print('Calculate d.o.f. of each star ...')\n",
    "        n_dof = np.zeros(d.size, dtype='i4')\n",
    "        for k in range(n_bands):\n",
    "            n_dof += (cov_y[:,k,k] < (large_err-1.)**2).astype('i4')\n",
    "        #print('n_dof =', n_dof)\n",
    "\n",
    "        # Calculate reduced chi^2 for each star\n",
    "        print('Calculate chi^2/d.o.f. for each star ...')\n",
    "        rchisq = chisq / (n_dof - 1.)\n",
    "        pct = (0., 1., 10., 50., 90., 99., 100.)\n",
    "        rchisq_pct = np.percentile(rchisq[np.isfinite(rchisq)], pct)\n",
    "        print('chi^2/dof percentiles:')\n",
    "        for p,rc in zip(pct,rchisq_pct):\n",
    "            print(rf'  {p:.0f}% : {rc:.3g}')\n",
    "        idx_rchisq = (rchisq < 10.)\n",
    "        print(f'<chi^2/d.o.f.> = {np.mean(rchisq[idx_rchisq]):.3g}')\n",
    "        \n",
    "        # Filter on reduced chi^2\n",
    "        if rchisq_max is not None:\n",
    "            print('Filter on chi^2/d.o.f. ...')\n",
    "            idx = np.isfinite(rchisq) & (rchisq > 0.) & (rchisq < rchisq_max)\n",
    "            n_filt = np.count_nonzero(~idx)\n",
    "            pct_filt = 100. * n_filt / idx.size\n",
    "            print(\n",
    "                rf'Filtering {n_filt:d} stars ({pct_filt:.3g}%) ' +\n",
    "                rf'based on chi^2/dof > {rchisq_max:.1f}'\n",
    "            )\n",
    "            x = x[idx]\n",
    "            x_p = x_p[idx]\n",
    "            r = r[idx]\n",
    "            y = y[idx]\n",
    "            cov_y = cov_y[idx]\n",
    "            r_var = r_var[idx]\n",
    "            rchisq = rchisq[idx]\n",
    "            \n",
    "            if return_cov_components:\n",
    "                for key in cov_comp:\n",
    "                    cov_comp[key] = cov_comp[key][idx]\n",
    "\n",
    "    # Cholesky transform of inverse covariance: L L^T = C^(-1).\n",
    "    print('Cholesky transform of each stellar covariance matrix ...')\n",
    "    LT = np.empty_like(cov_y)\n",
    "    inv_cov_y = np.empty_like(cov_y)\n",
    "    for k,c in enumerate(cov_y):\n",
    "        try:\n",
    "            # Inflate diagonal of cov slightly, to ensure\n",
    "            # positive-definiteness\n",
    "            c_diag = c[np.diag_indices_from(c)]\n",
    "            c[np.diag_indices_from(c)] += 1.e-4 + 1.e-3 * c_diag\n",
    "            \n",
    "            inv_cov_y[k] = np.linalg.inv(c)\n",
    "            LT[k] = np.linalg.cholesky(inv_cov_y[k]).T\n",
    "            #ic = np.linalg.inv(c)\n",
    "            #LT.append(np.linalg.cholesky(ic).T)\n",
    "            #inv_cov_y.append(ic)\n",
    "        except np.linalg.LinAlgError as e:\n",
    "            rho = get_corr_matrix(c)\n",
    "            print('Offending correlation matrix:')\n",
    "            print(np.array2string(\n",
    "                rho[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >7.4f}'.format(z)}\n",
    "            ))\n",
    "            print('Offending covariance matrix:')\n",
    "            print(np.array2string(\n",
    "                c[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >9.6f}'.format(z)}\n",
    "            ))\n",
    "            print('Covariance matrix of (normed) atmospheric parameters:')\n",
    "            print(d['atm_param_cov_p'][k])\n",
    "            if pretrained_model is not None:\n",
    "                print(f'Variance of r: {r_var[k]:.8f}')\n",
    "            \n",
    "            # Inflate errors along the diagonal and try again\n",
    "            c_diag = c[np.diag_indices_from(c)]\n",
    "            c[np.diag_indices_from(c)] += 0.02 + 0.02 * c_diag\n",
    "            rho = get_corr_matrix(c)\n",
    "            print('Inflated correlation matrix:')\n",
    "            print(np.array2string(\n",
    "                rho[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >7.4f}'.format(z)}\n",
    "            ))\n",
    "            \n",
    "            inv_cov_y[k] = np.linalg.inv(c)\n",
    "            LT[k] = np.linalg.cholesky(inv_cov_y[k]).T\n",
    "            #raise e\n",
    "\n",
    "    #print('Stack L^T matrices ...')\n",
    "    #LT = np.stack(LT)\n",
    "    #print('Stack C^(-1) matrices ...')\n",
    "    #inv_cov_y = np.stack(inv_cov_y)\n",
    "\n",
    "    # L^T y\n",
    "    print('Calculate L^T y ...')\n",
    "    LTy = np.einsum('nij,nj->ni', LT, y)\n",
    "\n",
    "    print('Gather inputs and outputs and return ...')\n",
    "    inputs_outputs = {\n",
    "        'x':x, 'x_p':x_p, 'r':r, 'y':y,\n",
    "        'LT':LT, 'LTy':LTy,\n",
    "        'cov_y':cov_y, 'inv_cov_y':inv_cov_y,\n",
    "    }\n",
    "    \n",
    "    if return_cov_components:\n",
    "        inputs_outputs['cov_comp'] = cov_comp\n",
    "    \n",
    "    if pretrained_model is not None:\n",
    "        inputs_outputs['r_var'] = r_var\n",
    "        inputs_outputs['rchisq'] = rchisq\n",
    "\n",
    "    # Check that there are no NaNs or Infs in results\n",
    "    for key in inputs_outputs:\n",
    "        if isinstance(inputs_outputs[key], dict):\n",
    "            continue\n",
    "        if key == 'rchisq': # Infs appear when d.o.f. = 1\n",
    "            continue\n",
    "        if np.any(~np.isfinite(inputs_outputs[key])):\n",
    "            raise ValueError(f'NaNs or Infs detected in {key}.')\n",
    "\n",
    "    return inputs_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caad35d-51ad-4e5f-8e27-57ac56e80468",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Predicts the absolute magnitude in the Gaia G-band and the colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb5329ec-4d17-4a14-9ec3-936b60844ca9",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def predict_M(nn_model, x_p):\n",
    "    \"\"\"\n",
    "    Predicts (absmag0,color1,color2,...) for input\n",
    "    normalized stellar parameters.\n",
    "\n",
    "    Inputs:\n",
    "        nn_model (keras.Model): Neural network model.\n",
    "        x_p (np.ndarray): Normalized stellar parameters.\n",
    "            Shape = (n_stars, 3).\n",
    "    \n",
    "    Outputs:\n",
    "        M (np.ndarray): Shape = (n_stars, n_bands).\n",
    "    \"\"\"\n",
    "    inputs = nn_model.get_layer(name='theta').input\n",
    "    outputs = nn_model.get_layer(name='BM').output\n",
    "    mag_color_model = keras.Model(inputs, outputs)\n",
    "    M = mag_color_model.predict(x_p)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14482c31-4986-4451-b4f7-295c2b3530b0",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Predicting the redenning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b36fc92-d995-4531-a1e4-994b63a9a954",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def predict_R(nn_model, x_p=None):\n",
    "    inputs = nn_model.get_layer(name='theta').input\n",
    "    outputs = nn_model.get_layer(name='R').output\n",
    "    R_model = keras.Model(inputs, outputs)\n",
    "    if x_p is None:\n",
    "        R = R_model.predict(np.array([[0.,0.,0.]]))[0]\n",
    "        R[1:] -= R[0]\n",
    "    else:\n",
    "        R = R_model.predict(x_p)\n",
    "        R[:,1:] -= R[:,0][:,None]\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2cab63-a66c-4c34-a7f1-50cb9568337b",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Saving the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52ee4e30-e866-45c2-a60f-37f5d8996b9f",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def save_predictions(fname, nn_model, d_test, io_test):\n",
    "    M_pred = predict_M(nn_model, io_test['x_p'])\n",
    "    R_pred = predict_R(nn_model, io_test['x_p'])\n",
    "    R0 = predict_R(nn_model)\n",
    "    \n",
    "    with h5py.File(fname, 'w') as f:\n",
    "        f.create_dataset('/data', data=d_test, chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/y_obs', data=io_test['y'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/cov_y', data=io_test['cov_y'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/r_fit', data=io_test['r'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/M_pred', data=M_pred, chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/R_pred', data=R_pred, chunks=True,\n",
    "                        compression='gzip', compression_opts=3)\n",
    "        f.attrs['R0'] = R0\n",
    "        \n",
    "        if 'cov_comp' in io_test:\n",
    "            for key in io_test['cov_comp']:\n",
    "                f.create_dataset(\n",
    "                    f'/cov_comp/{key.replace(r\"/\",\"_\")}',\n",
    "                    data=io_test['cov_comp'][key],\n",
    "                    chunks=True,\n",
    "                    compression='gzip',\n",
    "                    compression_opts=3\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9dbfb5-0fa8-47b6-b59e-5507d8182916",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Updates the redenning, as in the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12ce532d-8584-46ea-b538-a65837b35597",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def update_reddenings(M_pred, R, y_obs, inv_cov_y, r0, r_var0):\n",
    "    \"\"\"\n",
    "    Updates the posterior on reddening of each star, given\n",
    "    the predicted absolute magnitudes, reddening vector,\n",
    "    observed magnitudes, inverse covariance matrix, and priors on\n",
    "    reddening.\n",
    "    \n",
    "    The model is given by\n",
    "    \n",
    "        y_obs = M_pred + R r,\n",
    "    \n",
    "    with the uncertainties in y_obs described by inv_cov_y, and\n",
    "    with a prior on r described by (r0, r_var0). We solve for\n",
    "    the Gaussian posterior on r: p(r|y_obs,M_pred,R,r0,r_var0).\n",
    "    \n",
    "    Let n = # of bands, k = # of stars.\n",
    "\n",
    "    Inputs:\n",
    "        M_pred (np.ndarray): Shape-(k,n) array containing predicted\n",
    "            zero-reddening asbolute magnitude & colors for each star.\n",
    "        R (np.ndarray): Shape-(k,n) array containing reddening vector\n",
    "            for each star.\n",
    "        inv_cov_y (np.ndarray): Shape-(k,n,n) array containing\n",
    "            covariance matrix of y_obs-y_pred for each star.\n",
    "        y_obs (np.ndarray): Shape-(k,n) array containing observed\n",
    "            magnitude (minus distance modulus) & colors for each star.\n",
    "        r0 (np.ndarray): Shape-(k,) array containing mean of prior on\n",
    "            reddening for each star.\n",
    "        r_var0 (np.ndarray): Shape-(k,) array containing variance of\n",
    "            prior on reddening for each star.\n",
    "\n",
    "    Outputs:\n",
    "        r_mean (np.ndarray): Shape-(k,) array containing mean posterior\n",
    "            reddening of each star.\n",
    "        r_var (np.ndarray): Shape-(k,) array containing variance of\n",
    "            reddening posterior for each star.\n",
    "    \"\"\"\n",
    "    print('Updating reddenings:')\n",
    "    print('  * R^T C_y^(-1) ...')\n",
    "    RT_Cinv = np.einsum('ni,nij->nj', R, inv_cov_y)\n",
    "    print('  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...')\n",
    "    num = r0/r_var0 + np.einsum('ni,ni->n', RT_Cinv, y_obs - M_pred)\n",
    "    print('  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...')\n",
    "    den = np.einsum('ni,ni->n', RT_Cinv, R) + 1./r_var0\n",
    "    print('  * r_mean, r_var ...')\n",
    "    r_mean = num / den\n",
    "    r_var = 1. / den\n",
    "\n",
    "    return r_mean, r_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d6a72-37ab-4d7a-bfb3-cd329804a9ca",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### calculates the chi^2, as in docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c76cf577-6ee4-41db-a3ea-bada40e97afb",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def calc_chisq(dy, inv_cov_y):\n",
    "    \"\"\"\n",
    "    Returns the chi^2 for each observation, given\n",
    "    an array of residuals and inverse covariance matrices.\n",
    "    \n",
    "        chi^2 = dy^T C^{-1} dy.\n",
    "    \n",
    "    Inputs:\n",
    "        dy (np.ndarray): Residual values. Shape = (n_obs, n_dim),\n",
    "            where n_obs is the number of observations, and n_dim is\n",
    "            the dimensionality of the vector space.\n",
    "        inv_cov_y (np.ndarray): Inverse covariance matrices.\n",
    "            Shape = (n_obs, n_dim, n_dim).\n",
    "    \n",
    "    Returns:\n",
    "        chisq (np.ndarray): Chi^2 for each observation. Shape=(n_obs,).\n",
    "    \"\"\"\n",
    "    C_inv_dy = np.einsum('nij,nj->ni', inv_cov_y, dy)\n",
    "    chisq = np.einsum('ni,ni->n', dy, C_inv_dy)\n",
    "    return chisq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50c262-4e28-419e-83d5-8b75ec32470b",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Creates the architecture of the NN as described in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45204db0-8dfb-448f-879b-11102036d543",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def get_nn_model(n_hidden_layers=1, hidden_size=32, l1=1.e0, l2=1.e-4, n_bands=13):\n",
    "    # Stellar model: B M(theta)\n",
    "    atm = keras.Input(shape=(3,), name='theta')\n",
    "    x = atm\n",
    "    for i in range(n_hidden_layers):\n",
    "        x = keras.layers.Dense(\n",
    "            hidden_size,\n",
    "            activation='sigmoid',\n",
    "            kernel_regularizer=keras.regularizers.l2(l=l2),\n",
    "            name=f'stellar_model_hidden_{i+1}'\n",
    "        )(x)\n",
    "    mag_color = keras.layers.Dense(n_bands, name='BM')(x)\n",
    "\n",
    "    # Reddening measurement E\n",
    "    red = keras.Input(shape=(1,), name='E')\n",
    "    \n",
    "    # Extinction vector: R(theta)\n",
    "    r = atm\n",
    "    #for i in range(n_hidden_layers):\n",
    "    #    r = keras.layers.Dense(\n",
    "    #        6,\n",
    "    #        use_bias=True,\n",
    "    #        activation='sigmoid',\n",
    "    #        kernel_regularizer=keras.regularizers.l2(l=l2),\n",
    "    #        name=f'extinction_model_hidden_{i+1}'\n",
    "    #    )(r)\n",
    "    ext_vec = keras.layers.Dense(\n",
    "        n_bands,\n",
    "        use_bias=True,\n",
    "        activation='exponential',\n",
    "        #kernel_regularizer=keras.regularizers.l1_l2(l1=1.e0, l2=1.e0),\n",
    "        kernel_regularizer=keras.regularizers.l1(l=l1),\n",
    "        name='R'\n",
    "    )(r)\n",
    "    \n",
    "    # Extinction A = ER\n",
    "    ext = keras.layers.Multiply(name='A')([red, ext_vec])\n",
    "    \n",
    "    # Transform extinction to extinction,reddening using B: BA\n",
    "    B = np.identity(n_bands, dtype='f4')\n",
    "    B[1:,0] = -1.\n",
    "    ext_red = keras.layers.Dense(\n",
    "        n_bands,\n",
    "        use_bias=False,\n",
    "        trainable=False,\n",
    "        weights=[B.T],\n",
    "        name='BA'\n",
    "    )(ext)\n",
    "\n",
    "    # Predicted mag,color, B(M+A)\n",
    "    y = keras.layers.Add(name='B_M_plus_A')([mag_color, ext_red])\n",
    "\n",
    "    # Cholesky decomposition of inverse covariance matrix, L L^T = C^(-1)\n",
    "    LT = keras.Input(shape=(n_bands,n_bands), name='LT')\n",
    "\n",
    "    # Multiply y_pred by L^T, since loss is given by |L^T (y_pred - y_obs)|^2,\n",
    "    # where y_pred = B(M+A), and y_obs = B(m-mu).\n",
    "    LTy = keras.layers.Dot((2,1), name='LT_B_M_plus_A')([LT, y])\n",
    "\n",
    "    # Compile model\n",
    "    model = keras.Model(\n",
    "        inputs=[atm,red,LT],\n",
    "        outputs=LTy,\n",
    "        name='stellar_photometry_model'\n",
    "    )\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer='Adam',\n",
    "        metrics=['mse']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c98052-09ff-4591-830a-446eedd1c701",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### splits the dataset according to a fraction selected by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f096cf60-242d-4eef-8d91-59430a2672dc",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def split_dataset(frac, *args):\n",
    "    assert len(args) != 0\n",
    "\n",
    "    n_tot = args[0].shape[0]\n",
    "    idx = np.arange(n_tot)\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    n = int(frac * n_tot)\n",
    "    idx_left = idx[:n]\n",
    "    idx_right = idx[n:]\n",
    "\n",
    "    left, right = [], []\n",
    "\n",
    "    for x in args:\n",
    "        left.append(x[idx_left])\n",
    "        right.append(x[idx_right])\n",
    "    \n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a650c5-2ed5-4cfd-bd99-92ff0587e213",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d4f6eac-a9dd-4e9d-9d27-f9995997b7a2",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def train_model(nn_model, io_train, epochs=100,\n",
    "                checkpoint_fn='checkpoint', batch_size=32):\n",
    "    checkpoint_fn = (\n",
    "          'checkpoints/'\n",
    "        + checkpoint_fn\n",
    "        + '.e{epoch:03d}_vl{val_loss:.3f}.h5'\n",
    "    )\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_fn,\n",
    "            save_best_only=True,\n",
    "            monitor='val_loss',\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    inputs = [io_train['x_p'], io_train['r'], io_train['LT']]\n",
    "    outputs = io_train['LTy']\n",
    "    nn_model.fit(\n",
    "        inputs, outputs,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.25/0.9,\n",
    "        callbacks=callbacks,\n",
    "        batch_size=batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d76b11-59a7-41ca-a531-13411c1a6ce9",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### tests and makes sure the loss is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7eb14a0f-a62d-4d46-ab6d-4b33476566da",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(nn_model, io_eval, batch_size=32, rchisq_max=None):\n",
    "    \"\"\"\n",
    "    Runs the model on the given inputs and outputs, and returns the\n",
    "    MSE and loss.\n",
    "    \n",
    "    Inputs:\n",
    "        nn_model (keras.Model): The neural network model.\n",
    "        io_eval (dict): A dictionary containing, among other things,\n",
    "            x_p, r, LT and LTy. If rchisq_max is provided, then the\n",
    "            dictionary must also contain rchisq.\n",
    "        batch_size (int): Defaults to 32.\n",
    "        rchisq_max (float): Stars with greater than this reduced chi^2\n",
    "            will not be included in the calculation. Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "        A list containing the MSE and loss.\n",
    "    \"\"\"\n",
    "    inputs = [io_eval['x_p'], io_eval['r'], io_eval['LT']]\n",
    "    outputs = io_eval['LTy']\n",
    "    \n",
    "    if rchisq_max is not None:\n",
    "        idx = (io_eval['rchisq'] < rchisq_max)\n",
    "        inputs = [x[idx] for x in inputs]\n",
    "        outputs = outputs[idx]\n",
    "    \n",
    "    loss = nn_model.evaluate(\n",
    "        inputs,\n",
    "        outputs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    loss = [float(x) for x in loss] # Make JSON serializable\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd030e3e-55e6-419d-9a07-ce0a6baeb62c",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### plots? follow up here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d65e396c-7677-41d8-b229-8c3b2377a7b6",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def diagnostic_plots(nn_model, io_test, d_test, suffix=None):\n",
    "    if suffix is None:\n",
    "        suff = ''\n",
    "    else:\n",
    "        suff = '_' + suffix\n",
    "    \n",
    "    inputs = [\n",
    "        nn_model.get_layer(name='theta').input,\n",
    "        nn_model.get_layer(name='E').input\n",
    "    ]\n",
    "    outputs = nn_model.get_layer(name='B_M_plus_A').output\n",
    "    absmag_model = keras.Model(inputs, outputs)\n",
    "\n",
    "    # Predict y for the test dataset\n",
    "    test_pred = {\n",
    "        'y': absmag_model.predict([\n",
    "            io_test['x_p'],\n",
    "            io_test['r']\n",
    "        ]),\n",
    "        'y_dered': absmag_model.predict([\n",
    "            io_test['x_p'],\n",
    "            np.zeros_like(io_test['r'])\n",
    "        ])\n",
    "    }\n",
    "    test_pred['y_resid'] = io_test['y'] - test_pred['y']\n",
    "\n",
    "    # Get the extinction vector\n",
    "    R = predict_R(nn_model)\n",
    "    R[1:] += R[0]\n",
    "    print(\n",
    "          'R(<theta>) = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,R)))\n",
    "        + ']'\n",
    "    )\n",
    "    R_all = predict_R(nn_model, io_test['x_p'])\n",
    "    R_all[:,1:] += R_all[:,0][:,None]\n",
    "    print(\n",
    "          '<R> = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,np.median(R_all,axis=0))))\n",
    "        + ']'\n",
    "    )\n",
    "    print(\n",
    "          's_R = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,np.std(R_all,axis=0))))\n",
    "        + ']'\n",
    "    )\n",
    "\n",
    "    # Read out colors, magnitudes\n",
    "    g = io_test['y'][:,3] + io_test['y'][:,0]\n",
    "    ri = io_test['y'][:,4] - io_test['y'][:,5]\n",
    "    gr = io_test['y'][:,3] - io_test['y'][:,4]\n",
    "    g_pred = test_pred['y'][:,3] + test_pred['y'][:,0]\n",
    "    ri_pred = test_pred['y'][:,4] - test_pred['y'][:,5]\n",
    "    gr_pred = test_pred['y'][:,3] - test_pred['y'][:,4]\n",
    "    g_pred_dered = test_pred['y_dered'][:,3] + test_pred['y_dered'][:,0]\n",
    "    ri_pred_dered = test_pred['y_dered'][:,4] - test_pred['y_dered'][:,5]\n",
    "    gr_pred_dered = test_pred['y_dered'][:,3] - test_pred['y_dered'][:,4]\n",
    "    A_g = 0.25 * R[3]\n",
    "    E_ri = 0.25 * (R[4] - R[5])\n",
    "    E_gr = 0.25 * (R[3] - R[4])\n",
    "\n",
    "    gaia_g = io_test['y'][:,0]\n",
    "    bp_rp = io_test['y'][:,1] - io_test['y'][:,2]\n",
    "    gaia_g_pred = test_pred['y'][:,0]\n",
    "    bp_rp_pred = test_pred['y'][:,1] - test_pred['y'][:,2]\n",
    "    gaia_g_pred_dered = test_pred['y_dered'][:,0]\n",
    "    gaia_bp_rp_pred_dered = test_pred['y_dered'][:,1] - test_pred['y_dered'][:,2]\n",
    "    A_gaia_g = 0.25 * R[0]\n",
    "    E_bp_rp = 0.25 * (R[1] - R[2])\n",
    "\n",
    "    print('g =', g)\n",
    "    print('ri =', ri)\n",
    "    print('gr =', gr)\n",
    "    print('gaia_g =', gaia_g)\n",
    "    print('bp_rp =', bp_rp)\n",
    "\n",
    "    # Plot HRD\n",
    "    params = {\n",
    "        'density': (None, r'$N$', (None, None)),\n",
    "        'teff': (d_test['atm_param'][:,0], r'$T_{\\mathrm{eff}}$', (4000., 8000.)),\n",
    "        'logg': (d_test['atm_param'][:,1], r'$\\log \\left( g \\right)$', (0., 5.)),\n",
    "        'mh': (d_test['atm_param'][:,2], r'$\\left[ \\mathrm{M} / \\mathrm{H} \\right]$', (-2.5, 0.5))\n",
    "    }\n",
    "\n",
    "    plot_spec = [\n",
    "        {\n",
    "            'colors': [(1,2), (4,5)],\n",
    "            'mag': 0\n",
    "        },\n",
    "        {\n",
    "            'colors': [(3,4), (4,5)],\n",
    "            'mag': 0\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    idx_goodobs = np.isfinite(d_test['mag_err'])\n",
    "    idx_goodobs &= (np.abs(io_test['cov_y'][:,0,0]) < 90.)[:,None]\n",
    "    idx_goodobs = idx_goodobs.T\n",
    "\n",
    "    def scatter_or_hexbin(ax, x, y, c, vmin, vmax, extent):\n",
    "        if p == 'density':\n",
    "            im = ax.hexbin(\n",
    "                x, y,\n",
    "                extent=extent,\n",
    "                bins='log',\n",
    "                rasterized=True\n",
    "            )\n",
    "        else:\n",
    "            im = ax.scatter(\n",
    "                x,\n",
    "                y,\n",
    "                c=c,\n",
    "                edgecolors='none',\n",
    "                alpha=0.1,\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "                rasterized=True\n",
    "            )\n",
    "        return im\n",
    "\n",
    "    def get_lim(*args, **kwargs):\n",
    "        expand = kwargs.get('expand', 0.4)\n",
    "        expand_low = kwargs.get('expand_low', expand)\n",
    "        expand_high = kwargs.get('expand_high', expand)\n",
    "        pct = kwargs.get('pct', 1.)\n",
    "        lim = [np.inf, -np.inf]\n",
    "        for a in args:\n",
    "            a0,a1 = np.nanpercentile(a, [pct, 100.-pct])\n",
    "            lim[0] = min(a0, lim[0])\n",
    "            lim[1] = max(a1, lim[1])\n",
    "        w = lim[1] - lim[0]\n",
    "        lim[0] -= expand_low * w\n",
    "        lim[1] += expand_high * w\n",
    "        return lim\n",
    "\n",
    "    labels = ['G', 'BP', 'RP', 'g', 'r', 'i', 'z', 'y']\n",
    "\n",
    "    for ps in plot_spec:\n",
    "        mag_label = r'$M_{{ {} }}$'.format(labels[ps['mag']])\n",
    "        mag_obs = io_test['y'][:,ps['mag']]\n",
    "        mag_pred = test_pred['y'][:,ps['mag']]\n",
    "        mag_pred_dered = test_pred['y_dered'][:,ps['mag']]\n",
    "        A_vec = 0.25 * R[ps['mag']]\n",
    "        print('mag_pred:',mag_pred)\n",
    "\n",
    "        if ps['mag'] != 0:\n",
    "            mag_obs += io_test['y'][:,0]\n",
    "            mag_pred += io_test['y'][:,0]\n",
    "            mag_pred_dered += io_test['y'][:,0]\n",
    "            A_vec += 0.25 * R[0]\n",
    "\n",
    "        color_labels = []\n",
    "        colors_obs = []\n",
    "        colors_pred = []\n",
    "        colors_pred_dered = []\n",
    "        idx_colors_obs = []\n",
    "        E_vec = []\n",
    "        for i1,i2 in ps['colors']:\n",
    "            color_labels.append(r'${} - {}$'.format(labels[i1], labels[i2]))\n",
    "            colors_obs.append(io_test['y'][:,i1] - io_test['y'][:,i2])\n",
    "            colors_pred.append(test_pred['y'][:,i1] - test_pred['y'][:,i2])\n",
    "            colors_pred_dered.append(\n",
    "                test_pred['y_dered'][:,i1] - test_pred['y_dered'][:,i2]\n",
    "            )\n",
    "            idx_colors_obs.append(idx_goodobs[i1] & idx_goodobs[i2])\n",
    "            E_vec.append(0.25 * (R[i1] - R[i2]))\n",
    "\n",
    "        mag_lim = get_lim(\n",
    "            mag_obs[idx_goodobs[ps['mag']]],\n",
    "            pct=2.\n",
    "        )[::-1]\n",
    "        color_lim = [\n",
    "            get_lim(c[idx_colors_obs[k]], expand_low=0.5, expand_high=0.4)\n",
    "            for k,c in enumerate(colors_obs)\n",
    "        ]\n",
    "        \n",
    "        for p in params.keys():\n",
    "            c, label, (vmin,vmax) = params[p]\n",
    "            \n",
    "            fig = plt.figure(figsize=(14,4.5), dpi=150)\n",
    "            fig.patch.set_alpha(0.)\n",
    "            gs = GridSpec(\n",
    "                1,4,\n",
    "                width_ratios=[1,1,1,0.1],\n",
    "                left=0.07, right=0.93,\n",
    "                bottom=0.10, top=0.92\n",
    "            )\n",
    "            ax_obs = fig.add_subplot(gs[0,0], facecolor='gray')\n",
    "            ax_pred = fig.add_subplot(gs[0,1], facecolor='gray')\n",
    "            ax_dered = fig.add_subplot(gs[0,2], facecolor='gray')\n",
    "            cax = fig.add_subplot(gs[0,3], facecolor='w')\n",
    "\n",
    "            extent = color_lim[0] + mag_lim\n",
    "\n",
    "            idx = (\n",
    "                  idx_goodobs[ps['mag']]\n",
    "                & idx_goodobs[ps['colors'][0][0]]\n",
    "                & idx_goodobs[ps['colors'][0][1]]\n",
    "            )\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_obs,\n",
    "                colors_obs[0][idx],\n",
    "                mag_obs[idx],\n",
    "                c if c is None else c[idx],\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "                #(-0.3,1.0,11.5,-2.0)\n",
    "            )\n",
    "\n",
    "            ax_obs.set_xlim(color_lim[0])\n",
    "            ax_obs.set_ylim(mag_lim)\n",
    "            ax_obs.set_xlabel(color_labels[0])\n",
    "            ax_obs.set_ylabel(mag_label)\n",
    "            ax_obs.grid('on', alpha=0.3)\n",
    "            ax_obs.set_title(r'$\\mathrm{Observed}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_pred,\n",
    "                colors_pred[0],\n",
    "                mag_pred,\n",
    "                c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "\n",
    "            ax_pred.set_xlim(color_lim[0])\n",
    "            ax_pred.set_ylim(mag_lim)\n",
    "            ax_pred.set_xlabel(color_labels[0])\n",
    "            ax_pred.grid('on', alpha=0.3)\n",
    "            ax_pred.set_title(r'$\\mathrm{Predicted}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_dered,\n",
    "                colors_pred_dered[0],\n",
    "                mag_pred_dered,\n",
    "                c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "\n",
    "            ax_dered.set_xlim(color_lim[0])\n",
    "            ax_dered.set_ylim(mag_lim)\n",
    "            ax_dered.set_xlabel(color_labels[0])\n",
    "            ax_dered.grid('on', alpha=0.3)\n",
    "            ax_dered.set_title(r'$\\mathrm{Predicted+Dereddened}$')\n",
    "\n",
    "            ax_dered.annotate(\n",
    "                '',\n",
    "                xy=(0.35+E_vec[0], 1.+A_vec),\n",
    "                xytext=(0.35, 1.),\n",
    "                arrowprops=dict(color='r', width=1., headwidth=5., headlength=5.)\n",
    "            )\n",
    "\n",
    "            cb = fig.colorbar(im, cax=cax)\n",
    "            cb.set_label(label)\n",
    "            cb.set_alpha(1.)\n",
    "            cb.draw_all()\n",
    "\n",
    "            cm_desc = '{}_vs_{}{}'.format(\n",
    "                labels[ps['mag']],\n",
    "                labels[ps['colors'][0][0]],\n",
    "                labels[ps['colors'][0][1]]\n",
    "            )\n",
    "            fig.savefig(\n",
    "                'plots/nn_predictions_'+cm_desc+'_'+p+suff+'.svg',\n",
    "                dpi=150,\n",
    "                facecolor=fig.get_facecolor(),\n",
    "                edgecolor='none'\n",
    "            )\n",
    "            plt.close(fig)\n",
    "\n",
    "            # Color-color diagrams\n",
    "            fig = plt.figure(figsize=(14,4.5), dpi=150)\n",
    "            fig.patch.set_alpha(0.)\n",
    "            gs = GridSpec(\n",
    "                1,4,\n",
    "                width_ratios=[1,1,1,0.1],\n",
    "                left=0.07, right=0.93,\n",
    "                bottom=0.10, top=0.92\n",
    "            )\n",
    "            ax_obs = fig.add_subplot(gs[0,0], facecolor='gray')\n",
    "            ax_pred = fig.add_subplot(gs[0,1], facecolor='gray')\n",
    "            ax_dered = fig.add_subplot(gs[0,2], facecolor='gray')\n",
    "            cax = fig.add_subplot(gs[0,3], facecolor='w')\n",
    "\n",
    "            extent = color_lim[0] + color_lim[1]\n",
    "\n",
    "            idx = (\n",
    "                  idx_goodobs[ps['colors'][0][0]]\n",
    "                & idx_goodobs[ps['colors'][0][1]]\n",
    "                & idx_goodobs[ps['colors'][1][0]]\n",
    "                & idx_goodobs[ps['colors'][1][1]]\n",
    "            )\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_obs,\n",
    "                colors_obs[0][idx],\n",
    "                colors_obs[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "                #(-0.2,1.5,-0.15,0.8)\n",
    "            )\n",
    "            ax_obs.set_xlim(color_lim[0])\n",
    "            ax_obs.set_ylim(color_lim[1])\n",
    "            ax_obs.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_obs.set_ylabel(color_labels[1], fontsize=14)\n",
    "            ax_obs.grid('on', alpha=0.3)\n",
    "            ax_obs.set_title(r'$\\mathrm{Observed}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_pred,\n",
    "                colors_pred[0][idx],\n",
    "                colors_pred[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                #c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "            ax_pred.set_xlim(color_lim[0])\n",
    "            ax_pred.set_ylim(color_lim[1])\n",
    "            ax_pred.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_pred.grid('on', alpha=0.3)\n",
    "            ax_pred.set_title(r'$\\mathrm{Predicted}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_dered,\n",
    "                colors_pred_dered[0][idx],\n",
    "                colors_pred_dered[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                #c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "            ax_dered.set_xlim(color_lim[0])\n",
    "            ax_dered.set_ylim(color_lim[1])\n",
    "            ax_dered.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_dered.grid('on', alpha=0.3)\n",
    "            ax_dered.set_title(r'$\\mathrm{Predicted+Dereddened}$')\n",
    "\n",
    "            ax_dered.annotate(\n",
    "                '',\n",
    "                xy=(0.4+E_vec[0], 0.3+E_vec[1]),\n",
    "                xytext=(0.4, 0.3),\n",
    "                arrowprops=dict(color='r', width=1., headwidth=5., headlength=5.)\n",
    "            )\n",
    "\n",
    "            cb = fig.colorbar(im, cax=cax)\n",
    "            cb.set_label(label, fontsize=14)\n",
    "            cb.set_alpha(1.)\n",
    "            cb.draw_all()\n",
    "\n",
    "            cc_desc = '{}{}_vs_{}{}'.format(\n",
    "                labels[ps['colors'][0][0]],\n",
    "                labels[ps['colors'][0][1]],\n",
    "                labels[ps['colors'][1][0]],\n",
    "                labels[ps['colors'][1][1]]\n",
    "            )\n",
    "            fig.savefig(\n",
    "                'plots/test_'+cc_desc+'_'+p+suff+'.svg',\n",
    "                dpi=150,\n",
    "                facecolor=fig.get_facecolor(),\n",
    "                edgecolor='none'\n",
    "            )\n",
    "            plt.close(fig)\n",
    "\n",
    "    # Plot histogram of reddening residuals\n",
    "    dr = io_test['r'] - d_test['r']\n",
    "    fig = plt.figure(figsize=(8,5), dpi=150)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.hist(dr, range=(-0.15, 0.15), bins=50)\n",
    "    dr_mean = np.nanmean(dr)\n",
    "    dr_std = np.std(dr)\n",
    "    dr_skew = scipy.stats.moment(dr, moment=3, nan_policy='omit')\n",
    "    dr_txt = r'$\\Delta E = {:+.3f} \\pm {:.3f}$'.format(dr_mean, dr_std)\n",
    "    dr_skew /= (dr_std**1.5 + 1.e-5)\n",
    "    dr_txt += '\\n' + r'$\\tilde{{\\mu}}_3 = {:+.3f}$'.format(dr_skew)\n",
    "    ax.text(0.05, 0.95, dr_txt, ha='left', va='top', transform=ax.transAxes)\n",
    "    ax.set_xlabel(\n",
    "        r'$\\Delta E \\ \\left( \\mathrm{estimated} - \\mathrm{Bayestar19} \\right)$',\n",
    "        fontsize=14\n",
    "    )\n",
    "    fig.savefig('plots/test_dE'+suff+'.svg', dpi=150)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc50d23-d49f-4732-87e4-a7e1ec8fc816",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Calculates the derivative of the stellar model portion for gradient descent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8c296da-d523-4953-87b3-738be2e038fe",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def calc_dmag_color_dtheta(nn_model, x_p):\n",
    "    m = keras.Model(\n",
    "        inputs=nn_model.get_layer(name='theta').input,\n",
    "        outputs=nn_model.get_layer(name='BM').output\n",
    "    )\n",
    "    with tf.GradientTape() as g:\n",
    "        x_p = tf.constant(x_p)\n",
    "        g.watch(x_p)\n",
    "        mag_color = m(x_p)\n",
    "    J = g.batch_jacobian(mag_color, x_p).numpy()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb05c4c2-5d82-4311-b6f2-b46532797a41",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Calculates the derivative of the extinction model portion for gradient descent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2af63500-d06a-4ba6-bcc1-5fd5c3df6247",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def calc_dext_red_dtheta(nn_model, x_p, r):\n",
    "    A_model = keras.Model(\n",
    "        inputs=[\n",
    "            nn_model.get_layer(name='theta').input,\n",
    "            nn_model.get_layer(name='E').input\n",
    "        ],\n",
    "        outputs=nn_model.get_layer(name='BA').output\n",
    "    )\n",
    "    r = tf.constant(np.reshape(r, (r.size,1)))\n",
    "    #r = tf.reshape(r, (tf.size(r), 1))\n",
    "    with tf.GradientTape() as g:\n",
    "        x_p = tf.constant(x_p)\n",
    "        g.watch(x_p)\n",
    "        A = A_model([x_p, r])\n",
    "    J = g.batch_jacobian(A, x_p).numpy()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fb7f2c-5df5-4b99-aae0-39035aa43797",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Saves the normalizations, which seen in the tutorial is useful for scaling and shifting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86cef280-6cca-48f4-93ce-a8f4b7336300",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def save_theta_norm(d_attrs, fname):\n",
    "    d = {\n",
    "        'theta_med': d_attrs['atm_param_med'].tolist(),\n",
    "        'theta_std': d_attrs['atm_param_std'].tolist()\n",
    "    }\n",
    "    with open(fname, 'w') as f:\n",
    "        json.dump(d, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab8ecb-d1c9-438d-8794-1ff0b7eceef3",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### start of main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b834ddb7-6836-4e26-b7d7-81ce6cf146fd",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"green2020_stellar_photometry_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " theta (InputLayer)             [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " stellar_model_hidden_1 (Dense)  (None, 32)          128         ['theta[0][0]']                  \n",
      "                                                                                                  \n",
      " E (InputLayer)                 [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " R (Dense)                      (None, 13)           52          ['theta[0][0]']                  \n",
      "                                                                                                  \n",
      " stellar_model_hidden_2 (Dense)  (None, 32)          1056        ['stellar_model_hidden_1[0][0]'] \n",
      "                                                                                                  \n",
      " A (Multiply)                   (None, 13)           0           ['E[0][0]',                      \n",
      "                                                                  'R[0][0]']                      \n",
      "                                                                                                  \n",
      " BM (Dense)                     (None, 13)           429         ['stellar_model_hidden_2[0][0]'] \n",
      "                                                                                                  \n",
      " BA (Dense)                     (None, 13)           169         ['A[0][0]']                      \n",
      "                                                                                                  \n",
      " LT (InputLayer)                [(None, 13, 13)]     0           []                               \n",
      "                                                                                                  \n",
      " B_M_plus_A (Add)               (None, 13)           0           ['BM[0][0]',                     \n",
      "                                                                  'BA[0][0]']                     \n",
      "                                                                                                  \n",
      " LT_B_M_plus_A (Dot)            (None, 13)           0           ['LT[0][0]',                     \n",
      "                                                                  'B_M_plus_A[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,834\n",
      "Trainable params: 1,665\n",
      "Non-trainable params: 169\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load/create neural network\n",
    "nn_name = 'ext_0h_l1n2'\n",
    "n_hidden = 2\n",
    "nn_model = get_nn_model(n_hidden_layers=n_hidden, l2=1.e-4, l1=1.e-2)\n",
    "#nn_model = keras.models.load_model(\n",
    "#    'models/{:s}_{:d}hidden_it14.h5'.format(nn_name, n_hidden)\n",
    "#)\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07e4514b-44a8-4a5c-8512-e7feaa15e94e",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Loading /arc/home/aydanmckay/ml/network/data.h5 ...\n"
     ]
    }
   ],
   "source": [
    "# Load stellar data\n",
    "print('Loading data ...')\n",
    "fname = '/arc/home/aydanmckay/ml/network/data.h5'\n",
    "d, d_attrs = load_data(fname, return_attrs=True)\n",
    "#d = d[::25]\n",
    "save_theta_norm(d_attrs, 'theta_normalization.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d54baa9f-60d9-4fc0-acb7-e4c49cd83a66",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    253053 training/validation stars.\n",
      "     28118 test stars.\n"
     ]
    }
   ],
   "source": [
    "# (training+validation) / test split\n",
    "# Fix random seed (same split every run)\n",
    "np.random.seed(7)\n",
    "(d_train,), (d_test,) = split_dataset(0.9, d)\n",
    "np.random.shuffle(d_train) # Want d_train to be in random order\n",
    "print(f'{d_train.size: >10d} training/validation stars.')\n",
    "print(f'{d_test.size: >10d} test stars.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa8b04a6-3b93-4b72-9d3f-8855c3111e8c",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi^2/dof = [None, 100.00000000000004, 79.41833348134496, 63.07271692954115, 50.09130066684769, 39.78167620874025, 31.593944275926187, 25.091384024965357, 19.927159040031896, 15.825817619770502, 12.56860061341878, 9.981773149103292, 7.927357886906197, 6.295775522882865, 4.999999999999999, 5.0, 5.0, 5.0, 5.0, 5.0]\n"
     ]
    }
   ],
   "source": [
    "# Iteratively update dM/dtheta contribution to uncertainties,\n",
    "# reddening estimates and reduced chi^2 cut, and retrain.\n",
    "n_iterations = 20\n",
    "\n",
    "# On GPU, use large batch sizes for memory transfer efficiency\n",
    "batch_size = 1024\n",
    "\n",
    "rchisq_max_init = 100.\n",
    "rchisq_max_final = 5.\n",
    "rchisq_max = np.exp(np.linspace(\n",
    "    np.log(rchisq_max_init),\n",
    "    np.log(rchisq_max_final),\n",
    "    n_iterations-6\n",
    "))\n",
    "rchisq_max = [None] + rchisq_max.tolist() + 5*[rchisq_max_final]\n",
    "print('chi^2/dof = {}'.format(rchisq_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b3ee798-6cee-458d-b5e3-e6f014c0c873",
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Cutting 0 stars with large sigma_r.\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Cutting 0 stars with large sigma_r.\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 35.96 s\n",
      "learning rate = 0.0010000000474974513\n",
      "setting learning rate to 0.001\n",
      "Iteration 1 of 20.\n",
      "Epoch 1/25\n",
      "168/179 [===========================>..] - ETA: 0s - loss: 26294.2910 - mse: 26294.1582\n",
      "Epoch 00001: val_loss improved from inf to 8585.71973, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e001_vl8585.720.h5\n",
      "179/179 [==============================] - 2s 7ms/step - loss: 25288.1777 - mse: 25288.0449 - val_loss: 8585.7197 - val_mse: 8585.5928\n",
      "Epoch 2/25\n",
      " 34/179 [====>.........................] - ETA: 0s - loss: 7548.9072 - mse: 7548.7817"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/179 [===========================>..] - ETA: 0s - loss: 6442.1938 - mse: 6442.0679\n",
      "Epoch 00002: val_loss improved from 8585.71973 to 3267.05884, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e002_vl3267.059.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 6345.4097 - mse: 6345.2842 - val_loss: 3267.0588 - val_mse: 3266.9351\n",
      "Epoch 3/25\n",
      "176/179 [============================>.] - ETA: 0s - loss: 3144.3435 - mse: 3144.2209\n",
      "Epoch 00003: val_loss improved from 3267.05884 to 1630.35022, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e003_vl1630.350.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 3123.2571 - mse: 3123.1345 - val_loss: 1630.3502 - val_mse: 1630.2294\n",
      "Epoch 4/25\n",
      "176/179 [============================>.] - ETA: 0s - loss: 1749.5946 - mse: 1749.4745\n",
      "Epoch 00004: val_loss improved from 1630.35022 to 872.90637, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e004_vl872.906.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 1739.8268 - mse: 1739.7065 - val_loss: 872.9064 - val_mse: 872.7875\n",
      "Epoch 5/25\n",
      "176/179 [============================>.] - ETA: 0s - loss: 1122.4581 - mse: 1122.3409\n",
      "Epoch 00005: val_loss improved from 872.90637 to 582.88898, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e005_vl582.889.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 1114.7299 - mse: 1114.6127 - val_loss: 582.8890 - val_mse: 582.7723\n",
      "Epoch 6/25\n",
      "173/179 [===========================>..] - ETA: 0s - loss: 850.2058 - mse: 850.0895\n",
      "Epoch 00006: val_loss improved from 582.88898 to 474.74139, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e006_vl474.741.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 838.9460 - mse: 838.8297 - val_loss: 474.7414 - val_mse: 474.6260\n",
      "Epoch 7/25\n",
      "174/179 [============================>.] - ETA: 0s - loss: 715.6351 - mse: 715.5203\n",
      "Epoch 00007: val_loss improved from 474.74139 to 440.59177, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e007_vl440.592.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 708.5255 - mse: 708.4107 - val_loss: 440.5918 - val_mse: 440.4771\n",
      "Epoch 8/25\n",
      "172/179 [===========================>..] - ETA: 0s - loss: 646.6525 - mse: 646.5379\n",
      "Epoch 00008: val_loss improved from 440.59177 to 428.05548, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e008_vl428.055.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 638.9300 - mse: 638.8154 - val_loss: 428.0555 - val_mse: 427.9416\n",
      "Epoch 9/25\n",
      "173/179 [===========================>..] - ETA: 0s - loss: 597.9605 - mse: 597.8469\n",
      "Epoch 00009: val_loss improved from 428.05548 to 419.74719, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e009_vl419.747.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 592.2527 - mse: 592.1390 - val_loss: 419.7472 - val_mse: 419.6334\n",
      "Epoch 10/25\n",
      "174/179 [============================>.] - ETA: 0s - loss: 559.9120 - mse: 559.7979\n",
      "Epoch 00010: val_loss improved from 419.74719 to 412.03986, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e010_vl412.040.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 556.2709 - mse: 556.1568 - val_loss: 412.0399 - val_mse: 411.9266\n",
      "Epoch 11/25\n",
      "174/179 [============================>.] - ETA: 0s - loss: 530.8272 - mse: 530.7144\n",
      "Epoch 00011: val_loss improved from 412.03986 to 404.00061, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e011_vl404.001.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 528.0029 - mse: 527.8901 - val_loss: 404.0006 - val_mse: 403.8883\n",
      "Epoch 12/25\n",
      "171/179 [===========================>..] - ETA: 0s - loss: 507.5364 - mse: 507.4244\n",
      "Epoch 00012: val_loss improved from 404.00061 to 395.20108, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e012_vl395.201.h5\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 502.5641 - mse: 502.4520 - val_loss: 395.2011 - val_mse: 395.0894\n",
      "Epoch 13/25\n",
      "178/179 [============================>.] - ETA: 0s - loss: 478.9835 - mse: 478.8719\n",
      "Epoch 00013: val_loss improved from 395.20108 to 384.33987, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e013_vl384.340.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 478.5775 - mse: 478.4660 - val_loss: 384.3399 - val_mse: 384.2290\n",
      "Epoch 14/25\n",
      "176/179 [============================>.] - ETA: 0s - loss: 455.7427 - mse: 455.6324\n",
      "Epoch 00014: val_loss improved from 384.33987 to 371.19772, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e014_vl371.198.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 454.6355 - mse: 454.5252 - val_loss: 371.1977 - val_mse: 371.0876\n",
      "Epoch 15/25\n",
      "177/179 [============================>.] - ETA: 0s - loss: 431.2596 - mse: 431.1497\n",
      "Epoch 00015: val_loss improved from 371.19772 to 356.63211, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e015_vl356.632.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 430.6979 - mse: 430.5880 - val_loss: 356.6321 - val_mse: 356.5223\n",
      "Epoch 16/25\n",
      "179/179 [==============================] - ETA: 0s - loss: 408.8973 - mse: 408.7880\n",
      "Epoch 00016: val_loss improved from 356.63211 to 343.71057, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e016_vl343.711.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 408.8973 - mse: 408.7880 - val_loss: 343.7106 - val_mse: 343.6015\n",
      "Epoch 17/25\n",
      "175/179 [============================>.] - ETA: 0s - loss: 391.8052 - mse: 391.6963\n",
      "Epoch 00017: val_loss improved from 343.71057 to 334.21014, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e017_vl334.210.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 390.6698 - mse: 390.5609 - val_loss: 334.2101 - val_mse: 334.1020\n",
      "Epoch 18/25\n",
      "174/179 [============================>.] - ETA: 0s - loss: 331.1252 - mse: 331.0170\n",
      "Epoch 00018: val_loss improved from 334.21014 to 327.69269, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e018_vl327.693.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 377.2210 - mse: 377.1128 - val_loss: 327.6927 - val_mse: 327.5851\n",
      "Epoch 19/25\n",
      "170/179 [===========================>..] - ETA: 0s - loss: 368.4893 - mse: 368.3820\n",
      "Epoch 00019: val_loss improved from 327.69269 to 322.38538, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e019_vl322.385.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 366.2910 - mse: 366.1837 - val_loss: 322.3854 - val_mse: 322.2785\n",
      "Epoch 20/25\n",
      "173/179 [===========================>..] - ETA: 0s - loss: 358.3327 - mse: 358.2261\n",
      "Epoch 00020: val_loss improved from 322.38538 to 317.91019, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e020_vl317.910.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 357.2191 - mse: 357.1125 - val_loss: 317.9102 - val_mse: 317.8040\n",
      "Epoch 21/25\n",
      "178/179 [============================>.] - ETA: 0s - loss: 349.3150 - mse: 349.2091\n",
      "Epoch 00021: val_loss improved from 317.91019 to 314.05649, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e021_vl314.056.h5\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 349.2501 - mse: 349.1442 - val_loss: 314.0565 - val_mse: 313.9510\n",
      "Epoch 22/25\n",
      "175/179 [============================>.] - ETA: 0s - loss: 342.8581 - mse: 342.7530\n",
      "Epoch 00022: val_loss improved from 314.05649 to 310.61243, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e022_vl310.612.h5\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 342.1582 - mse: 342.0531 - val_loss: 310.6124 - val_mse: 310.5080\n",
      "Epoch 23/25\n",
      "179/179 [==============================] - ETA: 0s - loss: 335.9597 - mse: 335.8559\n",
      "Epoch 00023: val_loss improved from 310.61243 to 307.57343, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e023_vl307.573.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 335.9597 - mse: 335.8559 - val_loss: 307.5734 - val_mse: 307.4700\n",
      "Epoch 24/25\n",
      "175/179 [============================>.] - ETA: 0s - loss: 331.2125 - mse: 331.1097\n",
      "Epoch 00024: val_loss improved from 307.57343 to 304.98068, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e024_vl304.981.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 330.3721 - mse: 330.2693 - val_loss: 304.9807 - val_mse: 304.8785\n",
      "Epoch 25/25\n",
      "176/179 [============================>.] - ETA: 0s - loss: 325.6121 - mse: 325.5106\n",
      "Epoch 00025: val_loss improved from 304.98068 to 302.27756, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e025_vl302.278.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 325.2471 - mse: 325.1456 - val_loss: 302.2776 - val_mse: 302.1765\n",
      "Time elapsed to train: 27.40 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 271.97913    79.02346   361.95245  ...   95.045395   71.15366\n",
      " 4468.907   ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.941\n",
      "  1% : 2.56\n",
      "  10% : 5.81\n",
      "  50% : 17.3\n",
      "  90% : 82\n",
      "  99% : 416\n",
      "  100% : 7.66e+03\n",
      "<chi^2/d.o.f.> = 6.44\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 20010 stars (7.91%) based on chi^2/dof > 100.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [213.37555 100.72161 637.96265 ... 251.30145 286.69894 161.19028]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 1.13\n",
      "  1% : 2.51\n",
      "  10% : 5.74\n",
      "  50% : 17.3\n",
      "  90% : 82.3\n",
      "  99% : 427\n",
      "  100% : 4.96e+03\n",
      "<chi^2/d.o.f.> = 6.42\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 74.05 s\n",
      "learning rate = 0.0010000000474974513\n",
      "setting learning rate to 0.0008187307530779819\n",
      "Iteration 2 of 20.\n",
      "Epoch 1/25\n",
      "165/165 [==============================] - ETA: 0s - loss: 15.5900 - mse: 15.4891\n",
      "Epoch 00001: val_loss improved from inf to 15.25311, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e001_vl15.253.h5\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 15.5900 - mse: 15.4891 - val_loss: 15.2531 - val_mse: 15.1523\n",
      "Epoch 2/25\n",
      "165/165 [==============================] - ETA: 0s - loss: 15.1623 - mse: 15.0615\n",
      "Epoch 00002: val_loss improved from 15.25311 to 14.94419, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e002_vl14.944.h5\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 15.1623 - mse: 15.0615 - val_loss: 14.9442 - val_mse: 14.8433\n",
      "Epoch 3/25\n",
      "160/165 [============================>.] - ETA: 0s - loss: 14.8944 - mse: 14.7934\n",
      "Epoch 00003: val_loss improved from 14.94419 to 14.70084, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e003_vl14.701.h5\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 14.8889 - mse: 14.7879 - val_loss: 14.7008 - val_mse: 14.5997\n",
      "Epoch 4/25\n",
      "162/165 [============================>.] - ETA: 0s - loss: 14.6642 - mse: 14.5630\n",
      "Epoch 00004: val_loss improved from 14.70084 to 14.50219, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e004_vl14.502.h5\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 14.6676 - mse: 14.5663 - val_loss: 14.5022 - val_mse: 14.4008\n",
      "Epoch 5/25\n",
      "161/165 [============================>.] - ETA: 0s - loss: 14.4914 - mse: 14.3899\n",
      "Epoch 00005: val_loss improved from 14.50219 to 14.33887, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e005_vl14.339.h5\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 14.4845 - mse: 14.3830 - val_loss: 14.3389 - val_mse: 14.2373\n",
      "Epoch 6/25\n",
      "157/165 [===========================>..] - ETA: 0s - loss: 14.3404 - mse: 14.2387\n",
      "Epoch 00006: val_loss improved from 14.33887 to 14.19921, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e006_vl14.199.h5\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 14.3315 - mse: 14.2298 - val_loss: 14.1992 - val_mse: 14.0974\n",
      "Epoch 7/25\n",
      "161/165 [============================>.] - ETA: 0s - loss: 14.2110 - mse: 14.1092\n",
      "Epoch 00007: val_loss improved from 14.19921 to 14.09216, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e007_vl14.092.h5\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 14.2041 - mse: 14.1023 - val_loss: 14.0922 - val_mse: 13.9903\n",
      "Epoch 8/25\n",
      "160/165 [============================>.] - ETA: 0s - loss: 14.1070 - mse: 14.0051\n",
      "Epoch 00008: val_loss improved from 14.09216 to 13.98974, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e008_vl13.990.h5\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 14.0994 - mse: 13.9975 - val_loss: 13.9897 - val_mse: 13.8878\n",
      "Epoch 9/25\n",
      "163/165 [============================>.] - ETA: 0s - loss: 14.0118 - mse: 13.9098\n",
      "Epoch 00009: val_loss improved from 13.98974 to 13.90960, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e009_vl13.910.h5\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 14.0096 - mse: 13.9076 - val_loss: 13.9096 - val_mse: 13.8076\n",
      "Epoch 10/25\n",
      "158/165 [===========================>..] - ETA: 0s - loss: 13.9441 - mse: 13.8420\n",
      "Epoch 00010: val_loss improved from 13.90960 to 13.83951, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e010_vl13.840.h5\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 13.9332 - mse: 13.8312 - val_loss: 13.8395 - val_mse: 13.7375\n",
      "Epoch 11/25\n",
      "165/165 [==============================] - ETA: 0s - loss: 13.8708 - mse: 13.7687\n",
      "Epoch 00011: val_loss improved from 13.83951 to 13.78562, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e011_vl13.786.h5\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 13.8708 - mse: 13.7687 - val_loss: 13.7856 - val_mse: 13.6836\n",
      "Epoch 12/25\n",
      "161/165 [============================>.] - ETA: 0s - loss: 13.8131 - mse: 13.7111\n",
      "Epoch 00012: val_loss improved from 13.78562 to 13.73283, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e012_vl13.733.h5\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 13.8182 - mse: 13.7162 - val_loss: 13.7328 - val_mse: 13.6308\n",
      "Epoch 13/25\n",
      "159/165 [===========================>..] - ETA: 0s - loss: 13.7646 - mse: 13.6626\n",
      "Epoch 00013: val_loss improved from 13.73283 to 13.69548, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e013_vl13.695.h5\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 13.7677 - mse: 13.6657 - val_loss: 13.6955 - val_mse: 13.5935\n",
      "Epoch 14/25\n",
      "163/165 [============================>.] - ETA: 0s - loss: 13.7242 - mse: 13.6222\n",
      "Epoch 00014: val_loss improved from 13.69548 to 13.64911, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e014_vl13.649.h5\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 13.7260 - mse: 13.6241 - val_loss: 13.6491 - val_mse: 13.5472\n",
      "Epoch 15/25\n",
      "163/165 [============================>.] - ETA: 0s - loss: 13.6884 - mse: 13.5865\n",
      "Epoch 00015: val_loss improved from 13.64911 to 13.61394, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e015_vl13.614.h5\n",
      "165/165 [==============================] - 1s 8ms/step - loss: 13.6887 - mse: 13.5868 - val_loss: 13.6139 - val_mse: 13.5121\n",
      "Epoch 16/25\n",
      "157/165 [===========================>..] - ETA: 0s - loss: 13.6529 - mse: 13.5511\n",
      "Epoch 00016: val_loss improved from 13.61394 to 13.58851, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e016_vl13.589.h5\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 13.6541 - mse: 13.5523 - val_loss: 13.5885 - val_mse: 13.4868\n",
      "Epoch 17/25\n",
      "160/165 [============================>.] - ETA: 0s - loss: 13.6278 - mse: 13.5261\n",
      "Epoch 00017: val_loss improved from 13.58851 to 13.55279, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e017_vl13.553.h5\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 13.6236 - mse: 13.5218 - val_loss: 13.5528 - val_mse: 13.4511\n",
      "Epoch 18/25\n",
      "165/165 [==============================] - ETA: 0s - loss: 13.5927 - mse: 13.4911\n",
      "Epoch 00018: val_loss improved from 13.55279 to 13.53002, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e018_vl13.530.h5\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 13.5927 - mse: 13.4911 - val_loss: 13.5300 - val_mse: 13.4284\n",
      "Epoch 19/25\n",
      "154/165 [===========================>..] - ETA: 0s - loss: 13.5662 - mse: 13.4646\n",
      "Epoch 00019: val_loss improved from 13.53002 to 13.50715, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e019_vl13.507.h5\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 13.5652 - mse: 13.4636 - val_loss: 13.5071 - val_mse: 13.4057\n",
      "Epoch 20/25\n",
      "155/165 [===========================>..] - ETA: 0s - loss: 13.5255 - mse: 13.4240\n",
      "Epoch 00020: val_loss improved from 13.50715 to 13.47335, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e020_vl13.473.h5\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 13.5372 - mse: 13.4357 - val_loss: 13.4734 - val_mse: 13.3719\n",
      "Epoch 21/25\n",
      "163/165 [============================>.] - ETA: 0s - loss: 13.5107 - mse: 13.4093\n",
      "Epoch 00021: val_loss improved from 13.47335 to 13.44687, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e021_vl13.447.h5\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 13.5106 - mse: 13.4092 - val_loss: 13.4469 - val_mse: 13.3455\n",
      "Epoch 22/25\n",
      "156/165 [===========================>..] - ETA: 0s - loss: 13.4857 - mse: 13.3845\n",
      "Epoch 00022: val_loss improved from 13.44687 to 13.42082, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e022_vl13.421.h5\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 13.4847 - mse: 13.3834 - val_loss: 13.4208 - val_mse: 13.3196\n",
      "Epoch 23/25\n",
      "163/165 [============================>.] - ETA: 0s - loss: 13.4546 - mse: 13.3535\n",
      "Epoch 00023: val_loss improved from 13.42082 to 13.40265, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e023_vl13.403.h5\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 13.4581 - mse: 13.3570 - val_loss: 13.4027 - val_mse: 13.3016\n",
      "Epoch 24/25\n",
      "161/165 [============================>.] - ETA: 0s - loss: 13.4308 - mse: 13.3297\n",
      "Epoch 00024: val_loss improved from 13.40265 to 13.37474, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e024_vl13.375.h5\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 13.4314 - mse: 13.3303 - val_loss: 13.3747 - val_mse: 13.2737\n",
      "Epoch 25/25\n",
      "161/165 [============================>.] - ETA: 0s - loss: 13.4023 - mse: 13.3013\n",
      "Epoch 00025: val_loss improved from 13.37474 to 13.35194, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e025_vl13.352.h5\n",
      "165/165 [==============================] - 1s 7ms/step - loss: 13.4049 - mse: 13.3040 - val_loss: 13.3519 - val_mse: 13.2511\n",
      "Time elapsed to train: 27.35 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7f82fc5d59d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7f82fc5db670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 231.08655    30.022081  227.29436  ...   50.852535   29.643057\n",
      " 2078.3003  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.145\n",
      "  1% : 0.781\n",
      "  10% : 1.84\n",
      "  50% : 7.11\n",
      "  90% : 36.9\n",
      "  99% : 271\n",
      "  100% : 7.16e+03\n",
      "<chi^2/d.o.f.> = 4.58\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 11117 stars (4.39%) based on chi^2/dof > 79.4\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [115.43419   53.436417 185.21889  ... 142.3593   108.281784  36.888977]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.198\n",
      "  1% : 0.764\n",
      "  10% : 1.83\n",
      "  50% : 7.05\n",
      "  90% : 36.9\n",
      "  99% : 285\n",
      "  100% : 5.14e+03\n",
      "<chi^2/d.o.f.> = 4.58\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 79.21 s\n",
      "learning rate = 0.0008187307394109666\n",
      "setting learning rate to 0.0006703200460356394\n",
      "Iteration 3 of 20.\n",
      "Epoch 1/25\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 8.0415 - mse: 7.9407\n",
      "Epoch 00001: val_loss improved from inf to 8.00154, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e001_vl8.002.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 8.0436 - mse: 7.9428 - val_loss: 8.0015 - val_mse: 7.9008\n",
      "Epoch 2/25\n",
      "170/171 [============================>.] - ETA: 0s - loss: 7.9798 - mse: 7.8792\n",
      "Epoch 00002: val_loss improved from 8.00154 to 7.96251, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e002_vl7.963.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 7.9798 - mse: 7.8792 - val_loss: 7.9625 - val_mse: 7.8620\n",
      "Epoch 3/25\n",
      "170/171 [============================>.] - ETA: 0s - loss: 7.9468 - mse: 7.8465\n",
      "Epoch 00003: val_loss improved from 7.96251 to 7.93118, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e003_vl7.931.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 7.9441 - mse: 7.8438 - val_loss: 7.9312 - val_mse: 7.8310\n",
      "Epoch 4/25\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 7.9164 - mse: 7.8164\n",
      "Epoch 00004: val_loss improved from 7.93118 to 7.89633, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e004_vl7.896.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 7.9148 - mse: 7.8148 - val_loss: 7.8963 - val_mse: 7.7965\n",
      "Epoch 5/25\n",
      "163/171 [===========================>..] - ETA: 0s - loss: 7.8831 - mse: 7.7834\n",
      "Epoch 00005: val_loss improved from 7.89633 to 7.87120, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e005_vl7.871.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 7.8853 - mse: 7.7857 - val_loss: 7.8712 - val_mse: 7.7718\n",
      "Epoch 6/25\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 7.8623 - mse: 7.7631\n",
      "Epoch 00006: val_loss improved from 7.87120 to 7.84750, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e006_vl7.847.h5\n",
      "171/171 [==============================] - 1s 7ms/step - loss: 7.8585 - mse: 7.7593 - val_loss: 7.8475 - val_mse: 7.7485\n",
      "Epoch 7/25\n",
      "170/171 [============================>.] - ETA: 0s - loss: 7.8323 - mse: 7.7336\n",
      "Epoch 00007: val_loss improved from 7.84750 to 7.81825, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e007_vl7.818.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 7.8332 - mse: 7.7345 - val_loss: 7.8182 - val_mse: 7.7198\n",
      "Epoch 8/25\n",
      "163/171 [===========================>..] - ETA: 0s - loss: 7.8029 - mse: 7.7047\n",
      "Epoch 00008: val_loss improved from 7.81825 to 7.79458, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e008_vl7.795.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 7.8086 - mse: 7.7104 - val_loss: 7.7946 - val_mse: 7.6966\n",
      "Epoch 9/25\n",
      "168/171 [============================>.] - ETA: 0s - loss: 7.7841 - mse: 7.6864\n",
      "Epoch 00009: val_loss improved from 7.79458 to 7.77264, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e009_vl7.773.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 7.7826 - mse: 7.6849 - val_loss: 7.7726 - val_mse: 7.6752\n",
      "Epoch 10/25\n",
      "164/171 [===========================>..] - ETA: 0s - loss: 7.7647 - mse: 7.6675\n",
      "Epoch 00010: val_loss improved from 7.77264 to 7.74380, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e010_vl7.744.h5\n",
      "171/171 [==============================] - 1s 7ms/step - loss: 7.7583 - mse: 7.6611 - val_loss: 7.7438 - val_mse: 7.6469\n",
      "Epoch 11/25\n",
      "163/171 [===========================>..] - ETA: 0s - loss: 7.7315 - mse: 7.6349\n",
      "Epoch 00011: val_loss improved from 7.74380 to 7.71773, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e011_vl7.718.h5\n",
      "171/171 [==============================] - 1s 7ms/step - loss: 7.7329 - mse: 7.6363 - val_loss: 7.7177 - val_mse: 7.6214\n",
      "Epoch 12/25\n",
      "166/171 [============================>.] - ETA: 0s - loss: 7.7109 - mse: 7.6148\n",
      "Epoch 00012: val_loss improved from 7.71773 to 7.69553, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e012_vl7.696.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 7.7076 - mse: 7.6116 - val_loss: 7.6955 - val_mse: 7.5998\n",
      "Epoch 13/25\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 7.6847 - mse: 7.5893\n",
      "Epoch 00013: val_loss improved from 7.69553 to 7.67070, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e013_vl7.671.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 7.6834 - mse: 7.5880 - val_loss: 7.6707 - val_mse: 7.5756\n",
      "Epoch 14/25\n",
      "171/171 [==============================] - ETA: 0s - loss: 7.6571 - mse: 7.5624\n",
      "Epoch 00014: val_loss improved from 7.67070 to 7.65010, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e014_vl7.650.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 7.6571 - mse: 7.5624 - val_loss: 7.6501 - val_mse: 7.5558\n",
      "Epoch 15/25\n",
      "168/171 [============================>.] - ETA: 0s - loss: 7.6427 - mse: 7.5487\n",
      "Epoch 00015: val_loss improved from 7.65010 to 7.61852, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e015_vl7.619.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 7.6341 - mse: 7.5401 - val_loss: 7.6185 - val_mse: 7.5249\n",
      "Epoch 16/25\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 7.6088 - mse: 7.5156\n",
      "Epoch 00016: val_loss improved from 7.61852 to 7.59599, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e016_vl7.596.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 7.6084 - mse: 7.5152 - val_loss: 7.5960 - val_mse: 7.5032\n",
      "Epoch 17/25\n",
      "166/171 [============================>.] - ETA: 0s - loss: 7.5820 - mse: 7.4897\n",
      "Epoch 00017: val_loss improved from 7.59599 to 7.57070, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e017_vl7.571.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 7.5849 - mse: 7.4925 - val_loss: 7.5707 - val_mse: 7.4788\n",
      "Epoch 18/25\n",
      "162/171 [===========================>..] - ETA: 0s - loss: 7.5643 - mse: 7.4728\n",
      "Epoch 00018: val_loss improved from 7.57070 to 7.55939, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e018_vl7.559.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 7.5633 - mse: 7.4719 - val_loss: 7.5594 - val_mse: 7.4684\n",
      "Epoch 19/25\n",
      "169/171 [============================>.] - ETA: 0s - loss: 7.5383 - mse: 7.4477\n",
      "Epoch 00019: val_loss improved from 7.55939 to 7.52710, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e019_vl7.527.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 7.5399 - mse: 7.4494 - val_loss: 7.5271 - val_mse: 7.4371\n",
      "Epoch 20/25\n",
      "162/171 [===========================>..] - ETA: 0s - loss: 7.5231 - mse: 7.4336\n",
      "Epoch 00020: val_loss improved from 7.52710 to 7.50420, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e020_vl7.504.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 7.5174 - mse: 7.4279 - val_loss: 7.5042 - val_mse: 7.4152\n",
      "Epoch 21/25\n",
      "171/171 [==============================] - ETA: 0s - loss: 7.4982 - mse: 7.4098\n",
      "Epoch 00021: val_loss improved from 7.50420 to 7.48569, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e021_vl7.486.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 7.4982 - mse: 7.4098 - val_loss: 7.4857 - val_mse: 7.3978\n",
      "Epoch 22/25\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 7.4827 - mse: 7.3953\n",
      "Epoch 00022: val_loss improved from 7.48569 to 7.46787, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e022_vl7.468.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 7.4775 - mse: 7.3902 - val_loss: 7.4679 - val_mse: 7.3811\n",
      "Epoch 23/25\n",
      "169/171 [============================>.] - ETA: 0s - loss: 7.4569 - mse: 7.3707\n",
      "Epoch 00023: val_loss improved from 7.46787 to 7.44896, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e023_vl7.449.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 7.4589 - mse: 7.3727 - val_loss: 7.4490 - val_mse: 7.3634\n",
      "Epoch 24/25\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 7.4388 - mse: 7.3538\n",
      "Epoch 00024: val_loss improved from 7.44896 to 7.43773, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e024_vl7.438.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 7.4386 - mse: 7.3535 - val_loss: 7.4377 - val_mse: 7.3533\n",
      "Epoch 25/25\n",
      "164/171 [===========================>..] - ETA: 0s - loss: 7.4262 - mse: 7.3423\n",
      "Epoch 00025: val_loss improved from 7.43773 to 7.42380, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e025_vl7.424.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 7.4224 - mse: 7.3385 - val_loss: 7.4238 - val_mse: 7.3404\n",
      "Time elapsed to train: 25.63 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 356.92694    30.0798    105.38758  ...   42.96451    27.274755\n",
      " 1219.273   ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0569\n",
      "  1% : 0.319\n",
      "  10% : 0.945\n",
      "  50% : 5.48\n",
      "  90% : 25.8\n",
      "  99% : 191\n",
      "  100% : 6.95e+03\n",
      "<chi^2/d.o.f.> = 3.94\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 9700 stars (3.83%) based on chi^2/dof > 63.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 81.901855  44.580765 147.48349  ... 134.75542   89.26003   18.379013]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0706\n",
      "  1% : 0.319\n",
      "  10% : 0.942\n",
      "  50% : 5.44\n",
      "  90% : 25.8\n",
      "  99% : 195\n",
      "  100% : 5.12e+03\n",
      "<chi^2/d.o.f.> = 3.92\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 74.74 s\n",
      "learning rate = 0.0006703200633637607\n",
      "setting learning rate to 0.0005488116360940264\n",
      "Iteration 4 of 20.\n",
      "Epoch 1/25\n",
      "172/172 [==============================] - ETA: 0s - loss: 5.8394 - mse: 5.7565\n",
      "Epoch 00001: val_loss improved from inf to 5.82932, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e001_vl5.829.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 5.8394 - mse: 5.7565 - val_loss: 5.8293 - val_mse: 5.7470\n",
      "Epoch 2/25\n",
      "171/172 [============================>.] - ETA: 0s - loss: 5.8096 - mse: 5.7277\n",
      "Epoch 00002: val_loss improved from 5.82932 to 5.80864, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e002_vl5.809.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 5.8097 - mse: 5.7278 - val_loss: 5.8086 - val_mse: 5.7273\n",
      "Epoch 3/25\n",
      "167/172 [============================>.] - ETA: 0s - loss: 5.7852 - mse: 5.7043\n",
      "Epoch 00003: val_loss improved from 5.80864 to 5.78905, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e003_vl5.789.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 5.7891 - mse: 5.7082 - val_loss: 5.7891 - val_mse: 5.7087\n",
      "Epoch 4/25\n",
      "162/172 [===========================>..] - ETA: 0s - loss: 5.7718 - mse: 5.6919\n",
      "Epoch 00004: val_loss improved from 5.78905 to 5.77155, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e004_vl5.772.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 5.7709 - mse: 5.6911 - val_loss: 5.7716 - val_mse: 5.6923\n",
      "Epoch 5/25\n",
      "172/172 [==============================] - ETA: 0s - loss: 5.7554 - mse: 5.6767\n",
      "Epoch 00005: val_loss improved from 5.77155 to 5.75366, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e005_vl5.754.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 5.7554 - mse: 5.6767 - val_loss: 5.7537 - val_mse: 5.6754\n",
      "Epoch 6/25\n",
      "171/172 [============================>.] - ETA: 0s - loss: 5.7396 - mse: 5.6619\n",
      "Epoch 00006: val_loss improved from 5.75366 to 5.74250, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e006_vl5.742.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 5.7396 - mse: 5.6619 - val_loss: 5.7425 - val_mse: 5.6654\n",
      "Epoch 7/25\n",
      "170/172 [============================>.] - ETA: 0s - loss: 5.7243 - mse: 5.6477\n",
      "Epoch 00007: val_loss improved from 5.74250 to 5.72797, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e007_vl5.728.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 5.7244 - mse: 5.6478 - val_loss: 5.7280 - val_mse: 5.6520\n",
      "Epoch 8/25\n",
      "168/172 [============================>.] - ETA: 0s - loss: 5.7113 - mse: 5.6359\n",
      "Epoch 00008: val_loss improved from 5.72797 to 5.71188, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e008_vl5.712.h5\n",
      "172/172 [==============================] - 1s 7ms/step - loss: 5.7130 - mse: 5.6377 - val_loss: 5.7119 - val_mse: 5.6372\n",
      "Epoch 9/25\n",
      "165/172 [===========================>..] - ETA: 0s - loss: 5.6975 - mse: 5.6233\n",
      "Epoch 00009: val_loss improved from 5.71188 to 5.69975, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e009_vl5.700.h5\n",
      "172/172 [==============================] - 1s 7ms/step - loss: 5.6990 - mse: 5.6248 - val_loss: 5.6997 - val_mse: 5.6262\n",
      "Epoch 10/25\n",
      "162/172 [===========================>..] - ETA: 0s - loss: 5.6843 - mse: 5.6113\n",
      "Epoch 00010: val_loss improved from 5.69975 to 5.68729, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e010_vl5.687.h5\n",
      "172/172 [==============================] - 1s 7ms/step - loss: 5.6867 - mse: 5.6137 - val_loss: 5.6873 - val_mse: 5.6147\n",
      "Epoch 11/25\n",
      "171/172 [============================>.] - ETA: 0s - loss: 5.6753 - mse: 5.6032\n",
      "Epoch 00011: val_loss improved from 5.68729 to 5.67788, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e011_vl5.678.h5\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 5.6758 - mse: 5.6038 - val_loss: 5.6779 - val_mse: 5.6065\n",
      "Epoch 12/25\n",
      "166/172 [===========================>..] - ETA: 0s - loss: 5.6663 - mse: 5.5955\n",
      "Epoch 00012: val_loss improved from 5.67788 to 5.67131, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e012_vl5.671.h5\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 5.6634 - mse: 5.5926 - val_loss: 5.6713 - val_mse: 5.6011\n",
      "Epoch 13/25\n",
      "167/172 [============================>.] - ETA: 0s - loss: 5.6503 - mse: 5.5807\n",
      "Epoch 00013: val_loss improved from 5.67131 to 5.65648, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e013_vl5.656.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 5.6525 - mse: 5.5829 - val_loss: 5.6565 - val_mse: 5.5875\n",
      "Epoch 14/25\n",
      "172/172 [==============================] - ETA: 0s - loss: 5.6426 - mse: 5.5742\n",
      "Epoch 00014: val_loss improved from 5.65648 to 5.64943, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e014_vl5.649.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 5.6426 - mse: 5.5742 - val_loss: 5.6494 - val_mse: 5.5816\n",
      "Epoch 15/25\n",
      "172/172 [==============================] - ETA: 0s - loss: 5.6313 - mse: 5.5642\n",
      "Epoch 00015: val_loss improved from 5.64943 to 5.63550, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e015_vl5.635.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 5.6313 - mse: 5.5642 - val_loss: 5.6355 - val_mse: 5.5691\n",
      "Epoch 16/25\n",
      "164/172 [===========================>..] - ETA: 0s - loss: 5.6199 - mse: 5.5541\n",
      "Epoch 00016: val_loss improved from 5.63550 to 5.62599, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e016_vl5.626.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 5.6212 - mse: 5.5554 - val_loss: 5.6260 - val_mse: 5.5609\n",
      "Epoch 17/25\n",
      "164/172 [===========================>..] - ETA: 0s - loss: 5.6067 - mse: 5.5423\n",
      "Epoch 00017: val_loss improved from 5.62599 to 5.61469, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e017_vl5.615.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 5.6117 - mse: 5.5474 - val_loss: 5.6147 - val_mse: 5.5510\n",
      "Epoch 18/25\n",
      "165/172 [===========================>..] - ETA: 0s - loss: 5.6024 - mse: 5.5394\n",
      "Epoch 00018: val_loss improved from 5.61469 to 5.60672, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e018_vl5.607.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 5.6016 - mse: 5.5386 - val_loss: 5.6067 - val_mse: 5.5444\n",
      "Epoch 19/25\n",
      "164/172 [===========================>..] - ETA: 0s - loss: 5.5989 - mse: 5.5373\n",
      "Epoch 00019: val_loss improved from 5.60672 to 5.59823, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e019_vl5.598.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 5.5938 - mse: 5.5322 - val_loss: 5.5982 - val_mse: 5.5373\n",
      "Epoch 20/25\n",
      "167/172 [============================>.] - ETA: 0s - loss: 5.5878 - mse: 5.5275\n",
      "Epoch 00020: val_loss improved from 5.59823 to 5.58858, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e020_vl5.589.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 5.5854 - mse: 5.5251 - val_loss: 5.5886 - val_mse: 5.5291\n",
      "Epoch 21/25\n",
      "171/172 [============================>.] - ETA: 0s - loss: 5.5749 - mse: 5.5161\n",
      "Epoch 00021: val_loss improved from 5.58858 to 5.58211, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e021_vl5.582.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 5.5755 - mse: 5.5167 - val_loss: 5.5821 - val_mse: 5.5240\n",
      "Epoch 22/25\n",
      "167/172 [============================>.] - ETA: 0s - loss: 5.5691 - mse: 5.5117\n",
      "Epoch 00022: val_loss improved from 5.58211 to 5.57886, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e022_vl5.579.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 5.5663 - mse: 5.5089 - val_loss: 5.5789 - val_mse: 5.5222\n",
      "Epoch 23/25\n",
      "169/172 [============================>.] - ETA: 0s - loss: 5.5625 - mse: 5.5066\n",
      "Epoch 00023: val_loss improved from 5.57886 to 5.56886, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e023_vl5.569.h5\n",
      "172/172 [==============================] - 1s 5ms/step - loss: 5.5595 - mse: 5.5036 - val_loss: 5.5689 - val_mse: 5.5138\n",
      "Epoch 24/25\n",
      "162/172 [===========================>..] - ETA: 0s - loss: 5.5504 - mse: 5.4961\n",
      "Epoch 00024: val_loss improved from 5.56886 to 5.56224, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e024_vl5.562.h5\n",
      "172/172 [==============================] - 1s 6ms/step - loss: 5.5505 - mse: 5.4962 - val_loss: 5.5622 - val_mse: 5.5087\n",
      "Epoch 25/25\n",
      "167/172 [============================>.] - ETA: 0s - loss: 5.5446 - mse: 5.4919\n",
      "Epoch 00025: val_loss improved from 5.56224 to 5.55436, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e025_vl5.554.h5\n",
      "172/172 [==============================] - 1s 7ms/step - loss: 5.5439 - mse: 5.4912 - val_loss: 5.5544 - val_mse: 5.5024\n",
      "Time elapsed to train: 25.71 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [526.0863    29.466808  48.61852  ...  38.42602   37.62784  908.7254  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.017\n",
      "  1% : 0.229\n",
      "  10% : 0.745\n",
      "  50% : 5.06\n",
      "  90% : 28.3\n",
      "  99% : 202\n",
      "  100% : 6.99e+03\n",
      "<chi^2/d.o.f.> = 3.59\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 13861 stars (5.48%) based on chi^2/dof > 50.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 73.85243   30.007694 462.8413   ...  83.89732   96.822815  18.089806]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0403\n",
      "  1% : 0.228\n",
      "  10% : 0.742\n",
      "  50% : 5\n",
      "  90% : 28.2\n",
      "  99% : 206\n",
      "  100% : 5.12e+03\n",
      "<chi^2/d.o.f.> = 3.58\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 74.30 s\n",
      "learning rate = 0.0005488116294145584\n",
      "setting learning rate to 0.0004493289641172216\n",
      "Iteration 5 of 20.\n",
      "Epoch 1/25\n",
      "165/169 [============================>.] - ETA: 0s - loss: 5.7599 - mse: 5.7083\n",
      "Epoch 00001: val_loss improved from inf to 5.74425, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e001_vl5.744.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 5.7605 - mse: 5.7090 - val_loss: 5.7442 - val_mse: 5.6931\n",
      "Epoch 2/25\n",
      "159/169 [===========================>..] - ETA: 0s - loss: 5.7289 - mse: 5.6781\n",
      "Epoch 00002: val_loss improved from 5.74425 to 5.72956, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e002_vl5.730.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 5.7345 - mse: 5.6837 - val_loss: 5.7296 - val_mse: 5.6792\n",
      "Epoch 3/25\n",
      "163/169 [===========================>..] - ETA: 0s - loss: 5.7237 - mse: 5.6739\n",
      "Epoch 00003: val_loss improved from 5.72956 to 5.71884, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e003_vl5.719.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 5.7220 - mse: 5.6722 - val_loss: 5.7188 - val_mse: 5.6695\n",
      "Epoch 4/25\n",
      "158/169 [===========================>..] - ETA: 0s - loss: 5.7155 - mse: 5.6666\n",
      "Epoch 00004: val_loss improved from 5.71884 to 5.71405, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e004_vl5.714.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 5.7130 - mse: 5.6641 - val_loss: 5.7141 - val_mse: 5.6657\n",
      "Epoch 5/25\n",
      "162/169 [===========================>..] - ETA: 0s - loss: 5.7050 - mse: 5.6571\n",
      "Epoch 00005: val_loss improved from 5.71405 to 5.70190, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e005_vl5.702.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 5.7053 - mse: 5.6574 - val_loss: 5.7019 - val_mse: 5.6545\n",
      "Epoch 6/25\n",
      "160/169 [===========================>..] - ETA: 0s - loss: 5.6979 - mse: 5.6509\n",
      "Epoch 00006: val_loss improved from 5.70190 to 5.69657, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e006_vl5.697.h5\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 5.6982 - mse: 5.6512 - val_loss: 5.6966 - val_mse: 5.6500\n",
      "Epoch 7/25\n",
      "164/169 [============================>.] - ETA: 0s - loss: 5.6901 - mse: 5.6439\n",
      "Epoch 00007: val_loss improved from 5.69657 to 5.69152, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e007_vl5.692.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 5.6901 - mse: 5.6440 - val_loss: 5.6915 - val_mse: 5.6458\n",
      "Epoch 8/25\n",
      "168/169 [============================>.] - ETA: 0s - loss: 5.6856 - mse: 5.6404\n",
      "Epoch 00008: val_loss improved from 5.69152 to 5.68635, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e008_vl5.686.h5\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 5.6859 - mse: 5.6406 - val_loss: 5.6863 - val_mse: 5.6415\n",
      "Epoch 9/25\n",
      "162/169 [===========================>..] - ETA: 0s - loss: 5.6809 - mse: 5.6366\n",
      "Epoch 00009: val_loss improved from 5.68635 to 5.68169, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e009_vl5.682.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 5.6790 - mse: 5.6346 - val_loss: 5.6817 - val_mse: 5.6379\n",
      "Epoch 10/25\n",
      "162/169 [===========================>..] - ETA: 0s - loss: 5.6813 - mse: 5.6380\n",
      "Epoch 00010: val_loss improved from 5.68169 to 5.67787, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e010_vl5.678.h5\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 5.6742 - mse: 5.6309 - val_loss: 5.6779 - val_mse: 5.6350\n",
      "Epoch 11/25\n",
      "167/169 [============================>.] - ETA: 0s - loss: 5.6673 - mse: 5.6248\n",
      "Epoch 00011: val_loss improved from 5.67787 to 5.67287, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e011_vl5.673.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 5.6680 - mse: 5.6255 - val_loss: 5.6729 - val_mse: 5.6309\n",
      "Epoch 12/25\n",
      "163/169 [===========================>..] - ETA: 0s - loss: 5.6643 - mse: 5.6227\n",
      "Epoch 00012: val_loss improved from 5.67287 to 5.66440, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e012_vl5.664.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 5.6633 - mse: 5.6217 - val_loss: 5.6644 - val_mse: 5.6233\n",
      "Epoch 13/25\n",
      "164/169 [============================>.] - ETA: 0s - loss: 5.6576 - mse: 5.6169\n",
      "Epoch 00013: val_loss improved from 5.66440 to 5.66419, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e013_vl5.664.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 5.6597 - mse: 5.6190 - val_loss: 5.6642 - val_mse: 5.6240\n",
      "Epoch 14/25\n",
      "163/169 [===========================>..] - ETA: 0s - loss: 5.6537 - mse: 5.6140\n",
      "Epoch 00014: val_loss improved from 5.66419 to 5.65563, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e014_vl5.656.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 5.6552 - mse: 5.6155 - val_loss: 5.6556 - val_mse: 5.6164\n",
      "Epoch 15/25\n",
      "161/169 [===========================>..] - ETA: 0s - loss: 5.6462 - mse: 5.6074\n",
      "Epoch 00015: val_loss improved from 5.65563 to 5.65367, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e015_vl5.654.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 5.6502 - mse: 5.6115 - val_loss: 5.6537 - val_mse: 5.6154\n",
      "Epoch 16/25\n",
      "166/169 [============================>.] - ETA: 0s - loss: 5.6477 - mse: 5.6100\n",
      "Epoch 00016: val_loss did not improve from 5.65367\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 5.6472 - mse: 5.6095 - val_loss: 5.6599 - val_mse: 5.6228\n",
      "Epoch 17/25\n",
      "169/169 [==============================] - ETA: 0s - loss: 5.6432 - mse: 5.6065\n",
      "Epoch 00017: val_loss improved from 5.65367 to 5.64317, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e017_vl5.643.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 5.6432 - mse: 5.6065 - val_loss: 5.6432 - val_mse: 5.6069\n",
      "Epoch 18/25\n",
      "158/169 [===========================>..] - ETA: 0s - loss: 5.6457 - mse: 5.6097\n",
      "Epoch 00018: val_loss improved from 5.64317 to 5.64143, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e018_vl5.641.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 5.6409 - mse: 5.6049 - val_loss: 5.6414 - val_mse: 5.6058\n",
      "Epoch 19/25\n",
      "163/169 [===========================>..] - ETA: 0s - loss: 5.6364 - mse: 5.6011\n",
      "Epoch 00019: val_loss improved from 5.64143 to 5.64141, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e019_vl5.641.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 5.6377 - mse: 5.6024 - val_loss: 5.6414 - val_mse: 5.6063\n",
      "Epoch 20/25\n",
      "166/169 [============================>.] - ETA: 0s - loss: 5.6335 - mse: 5.5987\n",
      "Epoch 00020: val_loss improved from 5.64141 to 5.63653, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e020_vl5.637.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 5.6349 - mse: 5.6001 - val_loss: 5.6365 - val_mse: 5.6020\n",
      "Epoch 21/25\n",
      "162/169 [===========================>..] - ETA: 0s - loss: 5.6307 - mse: 5.5965\n",
      "Epoch 00021: val_loss improved from 5.63653 to 5.63192, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e021_vl5.632.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 5.6305 - mse: 5.5963 - val_loss: 5.6319 - val_mse: 5.5979\n",
      "Epoch 22/25\n",
      "166/169 [============================>.] - ETA: 0s - loss: 5.6307 - mse: 5.5969\n",
      "Epoch 00022: val_loss did not improve from 5.63192\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 5.6296 - mse: 5.5958 - val_loss: 5.6338 - val_mse: 5.6004\n",
      "Epoch 23/25\n",
      "161/169 [===========================>..] - ETA: 0s - loss: 5.6238 - mse: 5.5905\n",
      "Epoch 00023: val_loss improved from 5.63192 to 5.62955, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e023_vl5.630.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 5.6264 - mse: 5.5930 - val_loss: 5.6296 - val_mse: 5.5963\n",
      "Epoch 24/25\n",
      "167/169 [============================>.] - ETA: 0s - loss: 5.6240 - mse: 5.5910\n",
      "Epoch 00024: val_loss did not improve from 5.62955\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 5.6230 - mse: 5.5899 - val_loss: 5.6320 - val_mse: 5.5990\n",
      "Epoch 25/25\n",
      "168/169 [============================>.] - ETA: 0s - loss: 5.6226 - mse: 5.5897\n",
      "Epoch 00025: val_loss improved from 5.62955 to 5.62334, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e025_vl5.623.h5\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 5.6217 - mse: 5.5889 - val_loss: 5.6233 - val_mse: 5.5907\n",
      "Time elapsed to train: 25.06 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 367.49518    47.43712    49.882156 ...   38.225925   43.13336\n",
      " 1101.5007  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0268\n",
      "  1% : 0.227\n",
      "  10% : 0.784\n",
      "  50% : 5.71\n",
      "  90% : 46.5\n",
      "  99% : 365\n",
      "  100% : 1.04e+04\n",
      "<chi^2/d.o.f.> = 3.49\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 29237 stars (11.6%) based on chi^2/dof > 39.8\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  80.15496    27.18346  3359.4404   ...   64.652855  108.903946\n",
      "   23.764008]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0529\n",
      "  1% : 0.234\n",
      "  10% : 0.774\n",
      "  50% : 5.64\n",
      "  90% : 46.6\n",
      "  99% : 379\n",
      "  100% : 5.14e+03\n",
      "<chi^2/d.o.f.> = 3.49\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 75.81 s\n",
      "learning rate = 0.0004493289743550122\n",
      "setting learning rate to 0.00036787944117144236\n",
      "Iteration 6 of 20.\n",
      "Epoch 1/25\n",
      "156/158 [============================>.] - ETA: 0s - loss: 5.8582 - mse: 5.8254\n",
      "Epoch 00001: val_loss improved from inf to 5.84271, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e001_vl5.843.h5\n",
      "158/158 [==============================] - 1s 8ms/step - loss: 5.8587 - mse: 5.8260 - val_loss: 5.8427 - val_mse: 5.8100\n",
      "Epoch 2/25\n",
      "147/158 [==========================>...] - ETA: 0s - loss: 5.8470 - mse: 5.8144\n",
      "Epoch 00002: val_loss improved from 5.84271 to 5.83687, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e002_vl5.837.h5\n",
      "158/158 [==============================] - 1s 7ms/step - loss: 5.8495 - mse: 5.8168 - val_loss: 5.8369 - val_mse: 5.8042\n",
      "Epoch 3/25\n",
      "158/158 [==============================] - ETA: 0s - loss: 5.8433 - mse: 5.8107\n",
      "Epoch 00003: val_loss improved from 5.83687 to 5.83128, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e003_vl5.831.h5\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 5.8433 - mse: 5.8107 - val_loss: 5.8313 - val_mse: 5.7988\n",
      "Epoch 4/25\n",
      "157/158 [============================>.] - ETA: 0s - loss: 5.8403 - mse: 5.8079\n",
      "Epoch 00004: val_loss improved from 5.83128 to 5.82728, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e004_vl5.827.h5\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 5.8400 - mse: 5.8075 - val_loss: 5.8273 - val_mse: 5.7948\n",
      "Epoch 5/25\n",
      "149/158 [===========================>..] - ETA: 0s - loss: 5.8369 - mse: 5.8046\n",
      "Epoch 00005: val_loss improved from 5.82728 to 5.82728, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e005_vl5.827.h5\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 5.8358 - mse: 5.8034 - val_loss: 5.8273 - val_mse: 5.7950\n",
      "Epoch 6/25\n",
      "158/158 [==============================] - ETA: 0s - loss: 5.8336 - mse: 5.8014\n",
      "Epoch 00006: val_loss did not improve from 5.82728\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 5.8336 - mse: 5.8014 - val_loss: 5.8279 - val_mse: 5.7957\n",
      "Epoch 7/25\n",
      "148/158 [===========================>..] - ETA: 0s - loss: 5.8318 - mse: 5.7997\n",
      "Epoch 00007: val_loss improved from 5.82728 to 5.81658, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e007_vl5.817.h5\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 5.8297 - mse: 5.7976 - val_loss: 5.8166 - val_mse: 5.7846\n",
      "Epoch 8/25\n",
      "155/158 [============================>.] - ETA: 0s - loss: 5.8272 - mse: 5.7953\n",
      "Epoch 00008: val_loss did not improve from 5.81658\n",
      "158/158 [==============================] - 1s 5ms/step - loss: 5.8259 - mse: 5.7941 - val_loss: 5.8218 - val_mse: 5.7900\n",
      "Epoch 9/25\n",
      "149/158 [===========================>..] - ETA: 0s - loss: 5.8294 - mse: 5.7976\n",
      "Epoch 00009: val_loss did not improve from 5.81658\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 5.8261 - mse: 5.7943 - val_loss: 5.8373 - val_mse: 5.8056\n",
      "Epoch 10/25\n",
      "149/158 [===========================>..] - ETA: 0s - loss: 5.8156 - mse: 5.7839\n",
      "Epoch 00010: val_loss did not improve from 5.81658\n",
      "158/158 [==============================] - 1s 5ms/step - loss: 5.8232 - mse: 5.7915 - val_loss: 5.8215 - val_mse: 5.7898\n",
      "Epoch 11/25\n",
      "149/158 [===========================>..] - ETA: 0s - loss: 5.8221 - mse: 5.7906\n",
      "Epoch 00011: val_loss improved from 5.81658 to 5.81068, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e011_vl5.811.h5\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 5.8206 - mse: 5.7890 - val_loss: 5.8107 - val_mse: 5.7792\n",
      "Epoch 12/25\n",
      "151/158 [===========================>..] - ETA: 0s - loss: 5.8095 - mse: 5.7781\n",
      "Epoch 00012: val_loss did not improve from 5.81068\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 5.8165 - mse: 5.7851 - val_loss: 5.8150 - val_mse: 5.7837\n",
      "Epoch 13/25\n",
      "151/158 [===========================>..] - ETA: 0s - loss: 5.8126 - mse: 5.7813\n",
      "Epoch 00013: val_loss improved from 5.81068 to 5.80695, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e013_vl5.807.h5\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 5.8146 - mse: 5.7834 - val_loss: 5.8069 - val_mse: 5.7759\n",
      "Epoch 14/25\n",
      "151/158 [===========================>..] - ETA: 0s - loss: 5.8177 - mse: 5.7867\n",
      "Epoch 00014: val_loss improved from 5.80695 to 5.80277, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e014_vl5.803.h5\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 5.8158 - mse: 5.7848 - val_loss: 5.8028 - val_mse: 5.7719\n",
      "Epoch 15/25\n",
      "153/158 [============================>.] - ETA: 0s - loss: 5.8111 - mse: 5.7804\n",
      "Epoch 00015: val_loss improved from 5.80277 to 5.80076, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e015_vl5.801.h5\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 5.8096 - mse: 5.7789 - val_loss: 5.8008 - val_mse: 5.7702\n",
      "Epoch 16/25\n",
      "152/158 [===========================>..] - ETA: 0s - loss: 5.8085 - mse: 5.7780\n",
      "Epoch 00016: val_loss improved from 5.80076 to 5.79617, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e016_vl5.796.h5\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 5.8074 - mse: 5.7769 - val_loss: 5.7962 - val_mse: 5.7658\n",
      "Epoch 17/25\n",
      "150/158 [===========================>..] - ETA: 0s - loss: 5.8020 - mse: 5.7718\n",
      "Epoch 00017: val_loss improved from 5.79617 to 5.79134, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e017_vl5.791.h5\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 5.8042 - mse: 5.7740 - val_loss: 5.7913 - val_mse: 5.7613\n",
      "Epoch 18/25\n",
      "154/158 [============================>.] - ETA: 0s - loss: 5.8019 - mse: 5.7720\n",
      "Epoch 00018: val_loss did not improve from 5.79134\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 5.8018 - mse: 5.7719 - val_loss: 5.7955 - val_mse: 5.7658\n",
      "Epoch 19/25\n",
      "149/158 [===========================>..] - ETA: 0s - loss: 5.8051 - mse: 5.7756\n",
      "Epoch 00019: val_loss did not improve from 5.79134\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 5.8008 - mse: 5.7713 - val_loss: 5.7923 - val_mse: 5.7629\n",
      "Epoch 20/25\n",
      "148/158 [===========================>..] - ETA: 0s - loss: 5.7982 - mse: 5.7690\n",
      "Epoch 00020: val_loss improved from 5.79134 to 5.78573, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e020_vl5.786.h5\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 5.7991 - mse: 5.7699 - val_loss: 5.7857 - val_mse: 5.7568\n",
      "Epoch 21/25\n",
      "149/158 [===========================>..] - ETA: 0s - loss: 5.7988 - mse: 5.7701\n",
      "Epoch 00021: val_loss improved from 5.78573 to 5.78524, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e021_vl5.785.h5\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 5.7957 - mse: 5.7669 - val_loss: 5.7852 - val_mse: 5.7567\n",
      "Epoch 22/25\n",
      "157/158 [============================>.] - ETA: 0s - loss: 5.7926 - mse: 5.7644\n",
      "Epoch 00022: val_loss improved from 5.78524 to 5.78489, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e022_vl5.785.h5\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 5.7930 - mse: 5.7647 - val_loss: 5.7849 - val_mse: 5.7568\n",
      "Epoch 23/25\n",
      "155/158 [============================>.] - ETA: 0s - loss: 5.7941 - mse: 5.7663\n",
      "Epoch 00023: val_loss improved from 5.78489 to 5.77696, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e023_vl5.777.h5\n",
      "158/158 [==============================] - 1s 5ms/step - loss: 5.7900 - mse: 5.7622 - val_loss: 5.7770 - val_mse: 5.7494\n",
      "Epoch 24/25\n",
      "152/158 [===========================>..] - ETA: 0s - loss: 5.7859 - mse: 5.7584\n",
      "Epoch 00024: val_loss did not improve from 5.77696\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 5.7872 - mse: 5.7597 - val_loss: 5.7782 - val_mse: 5.7507\n",
      "Epoch 25/25\n",
      "156/158 [============================>.] - ETA: 0s - loss: 5.7831 - mse: 5.7557\n",
      "Epoch 00025: val_loss improved from 5.77696 to 5.77256, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e025_vl5.773.h5\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 5.7861 - mse: 5.7588 - val_loss: 5.7726 - val_mse: 5.7451\n",
      "Time elapsed to train: 23.79 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 282.8015     94.07704    64.55487  ...   39.758213   48.839478\n",
      " 1505.7703  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0296\n",
      "  1% : 0.232\n",
      "  10% : 0.811\n",
      "  50% : 5.83\n",
      "  90% : 48.8\n",
      "  99% : 412\n",
      "  100% : 9.9e+03\n",
      "<chi^2/d.o.f.> = 3.51\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 37165 stars (14.7%) based on chi^2/dof > 31.6\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  90.74613    30.376776 2029.4614   ...  101.35784   109.38733\n",
      "   34.138588]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0387\n",
      "  1% : 0.239\n",
      "  10% : 0.784\n",
      "  50% : 5.79\n",
      "  90% : 49.1\n",
      "  99% : 428\n",
      "  100% : 5.15e+03\n",
      "<chi^2/d.o.f.> = 3.51\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 72.72 s\n",
      "learning rate = 0.0003678794309962541\n",
      "setting learning rate to 0.00030119421191220205\n",
      "Iteration 7 of 20.\n",
      "Epoch 1/25\n",
      "141/153 [==========================>...] - ETA: 0s - loss: 5.1879 - mse: 5.1605\n",
      "Epoch 00001: val_loss improved from inf to 5.18338, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e001_vl5.183.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.1867 - mse: 5.1593 - val_loss: 5.1834 - val_mse: 5.1560\n",
      "Epoch 2/25\n",
      "142/153 [==========================>...] - ETA: 0s - loss: 5.1796 - mse: 5.1522\n",
      "Epoch 00002: val_loss did not improve from 5.18338\n",
      "153/153 [==============================] - 1s 5ms/step - loss: 5.1813 - mse: 5.1540 - val_loss: 5.1846 - val_mse: 5.1573\n",
      "Epoch 3/25\n",
      "148/153 [============================>.] - ETA: 0s - loss: 5.1790 - mse: 5.1517\n",
      "Epoch 00003: val_loss improved from 5.18338 to 5.17782, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e003_vl5.178.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.1769 - mse: 5.1497 - val_loss: 5.1778 - val_mse: 5.1506\n",
      "Epoch 4/25\n",
      "146/153 [===========================>..] - ETA: 0s - loss: 5.1758 - mse: 5.1486\n",
      "Epoch 00004: val_loss improved from 5.17782 to 5.17121, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e004_vl5.171.h5\n",
      "153/153 [==============================] - 1s 5ms/step - loss: 5.1747 - mse: 5.1475 - val_loss: 5.1712 - val_mse: 5.1441\n",
      "Epoch 5/25\n",
      "150/153 [============================>.] - ETA: 0s - loss: 5.1675 - mse: 5.1404\n",
      "Epoch 00005: val_loss improved from 5.17121 to 5.16955, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e005_vl5.170.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.1710 - mse: 5.1439 - val_loss: 5.1695 - val_mse: 5.1425\n",
      "Epoch 6/25\n",
      "149/153 [============================>.] - ETA: 0s - loss: 5.1697 - mse: 5.1427\n",
      "Epoch 00006: val_loss improved from 5.16955 to 5.16674, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e006_vl5.167.h5\n",
      "153/153 [==============================] - 1s 7ms/step - loss: 5.1690 - mse: 5.1420 - val_loss: 5.1667 - val_mse: 5.1398\n",
      "Epoch 7/25\n",
      "148/153 [============================>.] - ETA: 0s - loss: 5.1652 - mse: 5.1383\n",
      "Epoch 00007: val_loss improved from 5.16674 to 5.16459, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e007_vl5.165.h5\n",
      "153/153 [==============================] - 1s 5ms/step - loss: 5.1656 - mse: 5.1388 - val_loss: 5.1646 - val_mse: 5.1377\n",
      "Epoch 8/25\n",
      "143/153 [===========================>..] - ETA: 0s - loss: 5.1628 - mse: 5.1360\n",
      "Epoch 00008: val_loss improved from 5.16459 to 5.16098, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e008_vl5.161.h5\n",
      "153/153 [==============================] - 1s 5ms/step - loss: 5.1625 - mse: 5.1357 - val_loss: 5.1610 - val_mse: 5.1343\n",
      "Epoch 9/25\n",
      "144/153 [===========================>..] - ETA: 0s - loss: 5.1600 - mse: 5.1334\n",
      "Epoch 00009: val_loss improved from 5.16098 to 5.15293, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e009_vl5.153.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.1589 - mse: 5.1323 - val_loss: 5.1529 - val_mse: 5.1264\n",
      "Epoch 10/25\n",
      "143/153 [===========================>..] - ETA: 0s - loss: 5.1502 - mse: 5.1238\n",
      "Epoch 00010: val_loss improved from 5.15293 to 5.15076, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e010_vl5.151.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.1549 - mse: 5.1284 - val_loss: 5.1508 - val_mse: 5.1243\n",
      "Epoch 11/25\n",
      "144/153 [===========================>..] - ETA: 0s - loss: 5.1579 - mse: 5.1317\n",
      "Epoch 00011: val_loss did not improve from 5.15076\n",
      "153/153 [==============================] - 1s 5ms/step - loss: 5.1527 - mse: 5.1264 - val_loss: 5.1532 - val_mse: 5.1270\n",
      "Epoch 12/25\n",
      "147/153 [===========================>..] - ETA: 0s - loss: 5.1521 - mse: 5.1260\n",
      "Epoch 00012: val_loss improved from 5.15076 to 5.14625, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e012_vl5.146.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.1496 - mse: 5.1235 - val_loss: 5.1462 - val_mse: 5.1203\n",
      "Epoch 13/25\n",
      "146/153 [===========================>..] - ETA: 0s - loss: 5.1452 - mse: 5.1194\n",
      "Epoch 00013: val_loss improved from 5.14625 to 5.14266, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e013_vl5.143.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.1455 - mse: 5.1197 - val_loss: 5.1427 - val_mse: 5.1170\n",
      "Epoch 14/25\n",
      "151/153 [============================>.] - ETA: 0s - loss: 5.1409 - mse: 5.1153\n",
      "Epoch 00014: val_loss improved from 5.14266 to 5.13930, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e014_vl5.139.h5\n",
      "153/153 [==============================] - 1s 5ms/step - loss: 5.1408 - mse: 5.1152 - val_loss: 5.1393 - val_mse: 5.1138\n",
      "Epoch 15/25\n",
      "150/153 [============================>.] - ETA: 0s - loss: 5.1380 - mse: 5.1126\n",
      "Epoch 00015: val_loss improved from 5.13930 to 5.13214, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e015_vl5.132.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.1362 - mse: 5.1109 - val_loss: 5.1321 - val_mse: 5.1070\n",
      "Epoch 16/25\n",
      "144/153 [===========================>..] - ETA: 0s - loss: 5.1299 - mse: 5.1049\n",
      "Epoch 00016: val_loss improved from 5.13214 to 5.12919, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e016_vl5.129.h5\n",
      "153/153 [==============================] - 1s 5ms/step - loss: 5.1340 - mse: 5.1090 - val_loss: 5.1292 - val_mse: 5.1044\n",
      "Epoch 17/25\n",
      "143/153 [===========================>..] - ETA: 0s - loss: 5.1264 - mse: 5.1017\n",
      "Epoch 00017: val_loss improved from 5.12919 to 5.12231, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e017_vl5.122.h5\n",
      "153/153 [==============================] - 1s 5ms/step - loss: 5.1286 - mse: 5.1039 - val_loss: 5.1223 - val_mse: 5.0978\n",
      "Epoch 18/25\n",
      "146/153 [===========================>..] - ETA: 0s - loss: 5.1209 - mse: 5.0965\n",
      "Epoch 00018: val_loss improved from 5.12231 to 5.12134, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e018_vl5.121.h5\n",
      "153/153 [==============================] - 1s 5ms/step - loss: 5.1231 - mse: 5.0987 - val_loss: 5.1213 - val_mse: 5.0972\n",
      "Epoch 19/25\n",
      "148/153 [============================>.] - ETA: 0s - loss: 5.1191 - mse: 5.0951\n",
      "Epoch 00019: val_loss improved from 5.12134 to 5.11588, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e019_vl5.116.h5\n",
      "153/153 [==============================] - 1s 5ms/step - loss: 5.1187 - mse: 5.0947 - val_loss: 5.1159 - val_mse: 5.0921\n",
      "Epoch 20/25\n",
      "143/153 [===========================>..] - ETA: 0s - loss: 5.1145 - mse: 5.0909\n",
      "Epoch 00020: val_loss improved from 5.11588 to 5.11422, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e020_vl5.114.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.1139 - mse: 5.0903 - val_loss: 5.1142 - val_mse: 5.0909\n",
      "Epoch 21/25\n",
      "152/153 [============================>.] - ETA: 0s - loss: 5.1095 - mse: 5.0863\n",
      "Epoch 00021: val_loss improved from 5.11422 to 5.10572, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e021_vl5.106.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.1093 - mse: 5.0861 - val_loss: 5.1057 - val_mse: 5.0827\n",
      "Epoch 22/25\n",
      "150/153 [============================>.] - ETA: 0s - loss: 5.1060 - mse: 5.0831\n",
      "Epoch 00022: val_loss improved from 5.10572 to 5.10027, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e022_vl5.100.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.1051 - mse: 5.0822 - val_loss: 5.1003 - val_mse: 5.0775\n",
      "Epoch 23/25\n",
      "148/153 [============================>.] - ETA: 0s - loss: 5.0993 - mse: 5.0767\n",
      "Epoch 00023: val_loss improved from 5.10027 to 5.09504, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e023_vl5.095.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.0982 - mse: 5.0757 - val_loss: 5.0950 - val_mse: 5.0727\n",
      "Epoch 24/25\n",
      "149/153 [============================>.] - ETA: 0s - loss: 5.0961 - mse: 5.0739\n",
      "Epoch 00024: val_loss improved from 5.09504 to 5.09388, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e024_vl5.094.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.0946 - mse: 5.0724 - val_loss: 5.0939 - val_mse: 5.0719\n",
      "Epoch 25/25\n",
      "148/153 [============================>.] - ETA: 0s - loss: 5.0902 - mse: 5.0683\n",
      "Epoch 00025: val_loss improved from 5.09388 to 5.08558, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e025_vl5.086.h5\n",
      "153/153 [==============================] - 1s 6ms/step - loss: 5.0883 - mse: 5.0664 - val_loss: 5.0856 - val_mse: 5.0639\n",
      "Time elapsed to train: 21.85 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 234.3378    116.22413    58.093636 ...   38.251244   55.009407\n",
      " 1937.5991  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0193\n",
      "  1% : 0.223\n",
      "  10% : 0.768\n",
      "  50% : 5.56\n",
      "  90% : 47.8\n",
      "  99% : 440\n",
      "  100% : 1.07e+04\n",
      "<chi^2/d.o.f.> = 3.47\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 43793 stars (17.3%) based on chi^2/dof > 25.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  92.69681    33.456448 1580.6132   ...  158.02364   103.971214\n",
      "   34.0677  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0242\n",
      "  1% : 0.219\n",
      "  10% : 0.756\n",
      "  50% : 5.49\n",
      "  90% : 47.2\n",
      "  99% : 453\n",
      "  100% : 5.13e+03\n",
      "<chi^2/d.o.f.> = 3.46\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 71.49 s\n",
      "learning rate = 0.0003011942026205361\n",
      "setting learning rate to 0.00024659696394160646\n",
      "Iteration 8 of 20.\n",
      "Epoch 1/25\n",
      "147/148 [============================>.] - ETA: 0s - loss: 4.3609 - mse: 4.3392\n",
      "Epoch 00001: val_loss improved from inf to 4.35887, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e001_vl4.359.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3607 - mse: 4.3389 - val_loss: 4.3589 - val_mse: 4.3372\n",
      "Epoch 2/25\n",
      "144/148 [============================>.] - ETA: 0s - loss: 4.3534 - mse: 4.3318\n",
      "Epoch 00002: val_loss did not improve from 4.35887\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3515 - mse: 4.3300 - val_loss: 4.3604 - val_mse: 4.3389\n",
      "Epoch 3/25\n",
      "145/148 [============================>.] - ETA: 0s - loss: 4.3461 - mse: 4.3246\n",
      "Epoch 00003: val_loss improved from 4.35887 to 4.35116, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e003_vl4.351.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3482 - mse: 4.3268 - val_loss: 4.3512 - val_mse: 4.3298\n",
      "Epoch 4/25\n",
      "148/148 [==============================] - ETA: 0s - loss: 4.3466 - mse: 4.3253\n",
      "Epoch 00004: val_loss did not improve from 4.35116\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3466 - mse: 4.3253 - val_loss: 4.3563 - val_mse: 4.3351\n",
      "Epoch 5/25\n",
      "143/148 [===========================>..] - ETA: 0s - loss: 4.3421 - mse: 4.3210\n",
      "Epoch 00005: val_loss improved from 4.35116 to 4.34581, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e005_vl4.346.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3435 - mse: 4.3224 - val_loss: 4.3458 - val_mse: 4.3247\n",
      "Epoch 6/25\n",
      "139/148 [===========================>..] - ETA: 0s - loss: 4.3405 - mse: 4.3194\n",
      "Epoch 00006: val_loss improved from 4.34581 to 4.34487, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e006_vl4.345.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3408 - mse: 4.3197 - val_loss: 4.3449 - val_mse: 4.3238\n",
      "Epoch 7/25\n",
      "142/148 [===========================>..] - ETA: 0s - loss: 4.3399 - mse: 4.3189\n",
      "Epoch 00007: val_loss did not improve from 4.34487\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3391 - mse: 4.3181 - val_loss: 4.3460 - val_mse: 4.3249\n",
      "Epoch 8/25\n",
      "145/148 [============================>.] - ETA: 0s - loss: 4.3355 - mse: 4.3144\n",
      "Epoch 00008: val_loss improved from 4.34487 to 4.34179, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e008_vl4.342.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3373 - mse: 4.3162 - val_loss: 4.3418 - val_mse: 4.3207\n",
      "Epoch 9/25\n",
      "146/148 [============================>.] - ETA: 0s - loss: 4.3344 - mse: 4.3131\n",
      "Epoch 00009: val_loss improved from 4.34179 to 4.33912, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e009_vl4.339.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3350 - mse: 4.3138 - val_loss: 4.3391 - val_mse: 4.3178\n",
      "Epoch 10/25\n",
      "145/148 [============================>.] - ETA: 0s - loss: 4.3348 - mse: 4.3134\n",
      "Epoch 00010: val_loss did not improve from 4.33912\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 4.3351 - mse: 4.3138 - val_loss: 4.3426 - val_mse: 4.3211\n",
      "Epoch 11/25\n",
      "146/148 [============================>.] - ETA: 0s - loss: 4.3333 - mse: 4.3118\n",
      "Epoch 00011: val_loss did not improve from 4.33912\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 4.3333 - mse: 4.3117 - val_loss: 4.3392 - val_mse: 4.3176\n",
      "Epoch 12/25\n",
      "145/148 [============================>.] - ETA: 0s - loss: 4.3354 - mse: 4.3137\n",
      "Epoch 00012: val_loss did not improve from 4.33912\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 4.3325 - mse: 4.3108 - val_loss: 4.3407 - val_mse: 4.3189\n",
      "Epoch 13/25\n",
      "136/148 [==========================>...] - ETA: 0s - loss: 4.3333 - mse: 4.3115\n",
      "Epoch 00013: val_loss did not improve from 4.33912\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 4.3308 - mse: 4.3090 - val_loss: 4.3392 - val_mse: 4.3172\n",
      "Epoch 14/25\n",
      "144/148 [============================>.] - ETA: 0s - loss: 4.3267 - mse: 4.3047\n",
      "Epoch 00014: val_loss did not improve from 4.33912\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3301 - mse: 4.3081 - val_loss: 4.3408 - val_mse: 4.3187\n",
      "Epoch 15/25\n",
      "144/148 [============================>.] - ETA: 0s - loss: 4.3276 - mse: 4.3054\n",
      "Epoch 00015: val_loss improved from 4.33912 to 4.33348, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e015_vl4.333.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3288 - mse: 4.3066 - val_loss: 4.3335 - val_mse: 4.3112\n",
      "Epoch 16/25\n",
      "146/148 [============================>.] - ETA: 0s - loss: 4.3277 - mse: 4.3054\n",
      "Epoch 00016: val_loss did not improve from 4.33348\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3283 - mse: 4.3059 - val_loss: 4.3361 - val_mse: 4.3136\n",
      "Epoch 17/25\n",
      "141/148 [===========================>..] - ETA: 0s - loss: 4.3278 - mse: 4.3053\n",
      "Epoch 00017: val_loss improved from 4.33348 to 4.33192, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e017_vl4.332.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3278 - mse: 4.3052 - val_loss: 4.3319 - val_mse: 4.3093\n",
      "Epoch 18/25\n",
      "146/148 [============================>.] - ETA: 0s - loss: 4.3244 - mse: 4.3016\n",
      "Epoch 00018: val_loss did not improve from 4.33192\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3261 - mse: 4.3033 - val_loss: 4.3342 - val_mse: 4.3114\n",
      "Epoch 19/25\n",
      "137/148 [==========================>...] - ETA: 0s - loss: 4.3270 - mse: 4.3042\n",
      "Epoch 00019: val_loss did not improve from 4.33192\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 4.3260 - mse: 4.3031 - val_loss: 4.3391 - val_mse: 4.3161\n",
      "Epoch 20/25\n",
      "139/148 [===========================>..] - ETA: 0s - loss: 4.3252 - mse: 4.3022\n",
      "Epoch 00020: val_loss improved from 4.33192 to 4.33175, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e020_vl4.332.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3258 - mse: 4.3028 - val_loss: 4.3317 - val_mse: 4.3086\n",
      "Epoch 21/25\n",
      "148/148 [==============================] - ETA: 0s - loss: 4.3239 - mse: 4.3007\n",
      "Epoch 00021: val_loss improved from 4.33175 to 4.32892, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e021_vl4.329.h5\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 4.3239 - mse: 4.3007 - val_loss: 4.3289 - val_mse: 4.3056\n",
      "Epoch 22/25\n",
      "140/148 [===========================>..] - ETA: 0s - loss: 4.3242 - mse: 4.3008\n",
      "Epoch 00022: val_loss did not improve from 4.32892\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3236 - mse: 4.3002 - val_loss: 4.3290 - val_mse: 4.3055\n",
      "Epoch 23/25\n",
      "144/148 [============================>.] - ETA: 0s - loss: 4.3208 - mse: 4.2973\n",
      "Epoch 00023: val_loss improved from 4.32892 to 4.32698, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e023_vl4.327.h5\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3225 - mse: 4.2990 - val_loss: 4.3270 - val_mse: 4.3034\n",
      "Epoch 24/25\n",
      "141/148 [===========================>..] - ETA: 0s - loss: 4.3201 - mse: 4.2965\n",
      "Epoch 00024: val_loss did not improve from 4.32698\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3222 - mse: 4.2985 - val_loss: 4.3286 - val_mse: 4.3049\n",
      "Epoch 25/25\n",
      "143/148 [===========================>..] - ETA: 0s - loss: 4.3227 - mse: 4.2989\n",
      "Epoch 00025: val_loss did not improve from 4.32698\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4.3212 - mse: 4.2974 - val_loss: 4.3271 - val_mse: 4.3032\n",
      "Time elapsed to train: 21.56 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 204.93011   115.607544   57.394302 ...   34.14776    56.145683\n",
      " 2230.755   ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0266\n",
      "  1% : 0.217\n",
      "  10% : 0.729\n",
      "  50% : 5.16\n",
      "  90% : 47.2\n",
      "  99% : 449\n",
      "  100% : 1.26e+04\n",
      "<chi^2/d.o.f.> = 3.39\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 50595 stars (20%) based on chi^2/dof > 19.9\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  89.265015   39.888123 1317.9949   ...  204.89151    90.70734\n",
      "   34.94874 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0209\n",
      "  1% : 0.211\n",
      "  10% : 0.716\n",
      "  50% : 5.1\n",
      "  90% : 46.7\n",
      "  99% : 465\n",
      "  100% : 5.16e+03\n",
      "<chi^2/d.o.f.> = 3.36\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 73.90 s\n",
      "learning rate = 0.00024659695918671787\n",
      "setting learning rate to 0.00020189651799465538\n",
      "Iteration 9 of 20.\n",
      "Epoch 1/25\n",
      "138/143 [===========================>..] - ETA: 0s - loss: 3.7011 - mse: 3.6773\n",
      "Epoch 00001: val_loss improved from inf to 3.70373, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e001_vl3.704.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.7004 - mse: 3.6766 - val_loss: 3.7037 - val_mse: 3.6800\n",
      "Epoch 2/25\n",
      "132/143 [==========================>...] - ETA: 0s - loss: 3.6956 - mse: 3.6719\n",
      "Epoch 00002: val_loss improved from 3.70373 to 3.70352, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e002_vl3.704.h5\n",
      "143/143 [==============================] - 1s 7ms/step - loss: 3.6973 - mse: 3.6737 - val_loss: 3.7035 - val_mse: 3.6800\n",
      "Epoch 3/25\n",
      "138/143 [===========================>..] - ETA: 0s - loss: 3.6979 - mse: 3.6744\n",
      "Epoch 00003: val_loss did not improve from 3.70352\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.6968 - mse: 3.6733 - val_loss: 3.7037 - val_mse: 3.6803\n",
      "Epoch 4/25\n",
      "140/143 [============================>.] - ETA: 0s - loss: 3.6966 - mse: 3.6733\n",
      "Epoch 00004: val_loss did not improve from 3.70352\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.6962 - mse: 3.6728 - val_loss: 3.7097 - val_mse: 3.6864\n",
      "Epoch 5/25\n",
      "140/143 [============================>.] - ETA: 0s - loss: 3.6957 - mse: 3.6724\n",
      "Epoch 00005: val_loss improved from 3.70352 to 3.70314, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e005_vl3.703.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.6967 - mse: 3.6734 - val_loss: 3.7031 - val_mse: 3.6799\n",
      "Epoch 6/25\n",
      "138/143 [===========================>..] - ETA: 0s - loss: 3.6968 - mse: 3.6737\n",
      "Epoch 00006: val_loss improved from 3.70314 to 3.70142, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e006_vl3.701.h5\n",
      "143/143 [==============================] - 1s 5ms/step - loss: 3.6952 - mse: 3.6720 - val_loss: 3.7014 - val_mse: 3.6784\n",
      "Epoch 7/25\n",
      "140/143 [============================>.] - ETA: 0s - loss: 3.6956 - mse: 3.6726\n",
      "Epoch 00007: val_loss improved from 3.70142 to 3.70097, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e007_vl3.701.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.6952 - mse: 3.6721 - val_loss: 3.7010 - val_mse: 3.6780\n",
      "Epoch 8/25\n",
      "138/143 [===========================>..] - ETA: 0s - loss: 3.6955 - mse: 3.6726\n",
      "Epoch 00008: val_loss did not improve from 3.70097\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.6947 - mse: 3.6718 - val_loss: 3.7018 - val_mse: 3.6789\n",
      "Epoch 9/25\n",
      "138/143 [===========================>..] - ETA: 0s - loss: 3.6978 - mse: 3.6749\n",
      "Epoch 00009: val_loss did not improve from 3.70097\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.6952 - mse: 3.6724 - val_loss: 3.7073 - val_mse: 3.6846\n",
      "Epoch 10/25\n",
      "134/143 [===========================>..] - ETA: 0s - loss: 3.6944 - mse: 3.6717\n",
      "Epoch 00010: val_loss did not improve from 3.70097\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.6941 - mse: 3.6714 - val_loss: 3.7015 - val_mse: 3.6788\n",
      "Epoch 11/25\n",
      "140/143 [============================>.] - ETA: 0s - loss: 3.6962 - mse: 3.6735\n",
      "Epoch 00011: val_loss improved from 3.70097 to 3.69960, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e011_vl3.700.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.6937 - mse: 3.6710 - val_loss: 3.6996 - val_mse: 3.6770\n",
      "Epoch 12/25\n",
      "135/143 [===========================>..] - ETA: 0s - loss: 3.6970 - mse: 3.6745\n",
      "Epoch 00012: val_loss did not improve from 3.69960\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.6931 - mse: 3.6705 - val_loss: 3.7002 - val_mse: 3.6777\n",
      "Epoch 13/25\n",
      "141/143 [============================>.] - ETA: 0s - loss: 3.6890 - mse: 3.6666\n",
      "Epoch 00013: val_loss improved from 3.69960 to 3.69751, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e013_vl3.698.h5\n",
      "143/143 [==============================] - 1s 8ms/step - loss: 3.6925 - mse: 3.6701 - val_loss: 3.6975 - val_mse: 3.6751\n",
      "Epoch 14/25\n",
      "142/143 [============================>.] - ETA: 0s - loss: 3.6909 - mse: 3.6685\n",
      "Epoch 00014: val_loss did not improve from 3.69751\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.6924 - mse: 3.6700 - val_loss: 3.6995 - val_mse: 3.6772\n",
      "Epoch 15/25\n",
      "139/143 [============================>.] - ETA: 0s - loss: 3.6942 - mse: 3.6719\n",
      "Epoch 00015: val_loss did not improve from 3.69751\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.6923 - mse: 3.6700 - val_loss: 3.6980 - val_mse: 3.6758\n",
      "Epoch 16/25\n",
      "138/143 [===========================>..] - ETA: 0s - loss: 3.6904 - mse: 3.6682\n",
      "Epoch 00016: val_loss did not improve from 3.69751\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.6916 - mse: 3.6694 - val_loss: 3.6993 - val_mse: 3.6771\n",
      "Epoch 17/25\n",
      "139/143 [============================>.] - ETA: 0s - loss: 3.6900 - mse: 3.6679\n",
      "Epoch 00017: val_loss did not improve from 3.69751\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.6916 - mse: 3.6695 - val_loss: 3.6983 - val_mse: 3.6762\n",
      "Epoch 18/25\n",
      "139/143 [============================>.] - ETA: 0s - loss: 3.6906 - mse: 3.6685\n",
      "Epoch 00018: val_loss did not improve from 3.69751\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.6909 - mse: 3.6689 - val_loss: 3.6986 - val_mse: 3.6766\n",
      "Epoch 19/25\n",
      "136/143 [===========================>..] - ETA: 0s - loss: 3.6874 - mse: 3.6654\n",
      "Epoch 00019: val_loss did not improve from 3.69751\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.6905 - mse: 3.6686 - val_loss: 3.7011 - val_mse: 3.6791\n",
      "Epoch 20/25\n",
      "137/143 [===========================>..] - ETA: 0s - loss: 3.6901 - mse: 3.6682\n",
      "Epoch 00020: val_loss improved from 3.69751 to 3.69646, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e020_vl3.696.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.6904 - mse: 3.6685 - val_loss: 3.6965 - val_mse: 3.6746\n",
      "Epoch 21/25\n",
      "134/143 [===========================>..] - ETA: 0s - loss: 3.6890 - mse: 3.6671\n",
      "Epoch 00021: val_loss improved from 3.69646 to 3.69569, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e021_vl3.696.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.6901 - mse: 3.6683 - val_loss: 3.6957 - val_mse: 3.6738\n",
      "Epoch 22/25\n",
      "141/143 [============================>.] - ETA: 0s - loss: 3.6891 - mse: 3.6672\n",
      "Epoch 00022: val_loss did not improve from 3.69569\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.6903 - mse: 3.6685 - val_loss: 3.6988 - val_mse: 3.6770\n",
      "Epoch 23/25\n",
      "135/143 [===========================>..] - ETA: 0s - loss: 3.6874 - mse: 3.6656\n",
      "Epoch 00023: val_loss did not improve from 3.69569\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.6895 - mse: 3.6678 - val_loss: 3.6962 - val_mse: 3.6744\n",
      "Epoch 24/25\n",
      "138/143 [===========================>..] - ETA: 0s - loss: 3.6902 - mse: 3.6684\n",
      "Epoch 00024: val_loss did not improve from 3.69569\n",
      "143/143 [==============================] - 1s 5ms/step - loss: 3.6892 - mse: 3.6674 - val_loss: 3.6968 - val_mse: 3.6750\n",
      "Epoch 25/25\n",
      "139/143 [============================>.] - ETA: 0s - loss: 3.6875 - mse: 3.6658\n",
      "Epoch 00025: val_loss did not improve from 3.69569\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.6900 - mse: 3.6683 - val_loss: 3.6962 - val_mse: 3.6745\n",
      "Time elapsed to train: 21.47 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 206.8526     97.51039    66.11941  ...   28.394947   57.750195\n",
      " 2372.6582  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0143\n",
      "  1% : 0.202\n",
      "  10% : 0.694\n",
      "  50% : 4.82\n",
      "  90% : 46.6\n",
      "  99% : 463\n",
      "  100% : 1.33e+04\n",
      "<chi^2/d.o.f.> = 3.31\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 58102 stars (23%) based on chi^2/dof > 15.8\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  77.968925   47.296417 1184.1156   ...  264.22144    74.14502\n",
      "   37.110126]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0413\n",
      "  1% : 0.2\n",
      "  10% : 0.681\n",
      "  50% : 4.75\n",
      "  90% : 45.9\n",
      "  99% : 475\n",
      "  100% : 5.2e+03\n",
      "<chi^2/d.o.f.> = 3.29\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 69.78 s\n",
      "learning rate = 0.00020189651695545763\n",
      "setting learning rate to 0.00016529888822158653\n",
      "Iteration 10 of 20.\n",
      "Epoch 1/25\n",
      "137/138 [============================>.] - ETA: 0s - loss: 3.1590 - mse: 3.1374\n",
      "Epoch 00001: val_loss improved from inf to 3.16251, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e001_vl3.163.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.1596 - mse: 3.1380 - val_loss: 3.1625 - val_mse: 3.1410\n",
      "Epoch 2/25\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 3.1589 - mse: 3.1376\n",
      "Epoch 00002: val_loss improved from 3.16251 to 3.16173, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e002_vl3.162.h5\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 3.1589 - mse: 3.1375 - val_loss: 3.1617 - val_mse: 3.1404\n",
      "Epoch 3/25\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 3.1584 - mse: 3.1372\n",
      "Epoch 00003: val_loss did not improve from 3.16173\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.1586 - mse: 3.1374 - val_loss: 3.1633 - val_mse: 3.1421\n",
      "Epoch 4/25\n",
      "129/138 [===========================>..] - ETA: 0s - loss: 3.1565 - mse: 3.1354\n",
      "Epoch 00004: val_loss improved from 3.16173 to 3.16147, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e004_vl3.161.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.1581 - mse: 3.1370 - val_loss: 3.1615 - val_mse: 3.1404\n",
      "Epoch 5/25\n",
      "135/138 [============================>.] - ETA: 0s - loss: 3.1577 - mse: 3.1366\n",
      "Epoch 00005: val_loss improved from 3.16147 to 3.16062, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e005_vl3.161.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.1584 - mse: 3.1373 - val_loss: 3.1606 - val_mse: 3.1396\n",
      "Epoch 6/25\n",
      "128/138 [==========================>...] - ETA: 0s - loss: 3.1583 - mse: 3.1373\n",
      "Epoch 00006: val_loss did not improve from 3.16062\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.1576 - mse: 3.1365 - val_loss: 3.1609 - val_mse: 3.1400\n",
      "Epoch 7/25\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 3.1578 - mse: 3.1368\n",
      "Epoch 00007: val_loss improved from 3.16062 to 3.16033, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e007_vl3.160.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.1575 - mse: 3.1365 - val_loss: 3.1603 - val_mse: 3.1394\n",
      "Epoch 8/25\n",
      "133/138 [===========================>..] - ETA: 0s - loss: 3.1546 - mse: 3.1337\n",
      "Epoch 00008: val_loss improved from 3.16033 to 3.15909, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e008_vl3.159.h5\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 3.1571 - mse: 3.1362 - val_loss: 3.1591 - val_mse: 3.1382\n",
      "Epoch 9/25\n",
      "136/138 [============================>.] - ETA: 0s - loss: 3.1568 - mse: 3.1359\n",
      "Epoch 00009: val_loss did not improve from 3.15909\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.1570 - mse: 3.1361 - val_loss: 3.1595 - val_mse: 3.1387\n",
      "Epoch 10/25\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 3.1616 - mse: 3.1408\n",
      "Epoch 00010: val_loss did not improve from 3.15909\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.1577 - mse: 3.1368 - val_loss: 3.1592 - val_mse: 3.1383\n",
      "Epoch 11/25\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 3.1589 - mse: 3.1381\n",
      "Epoch 00011: val_loss did not improve from 3.15909\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.1565 - mse: 3.1357 - val_loss: 3.1597 - val_mse: 3.1389\n",
      "Epoch 12/25\n",
      "127/138 [==========================>...] - ETA: 0s - loss: 3.1549 - mse: 3.1342\n",
      "Epoch 00012: val_loss improved from 3.15909 to 3.15908, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e012_vl3.159.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.1562 - mse: 3.1355 - val_loss: 3.1591 - val_mse: 3.1383\n",
      "Epoch 13/25\n",
      "129/138 [===========================>..] - ETA: 0s - loss: 3.1572 - mse: 3.1364\n",
      "Epoch 00013: val_loss did not improve from 3.15908\n",
      "138/138 [==============================] - 1s 5ms/step - loss: 3.1571 - mse: 3.1364 - val_loss: 3.1596 - val_mse: 3.1388\n",
      "Epoch 14/25\n",
      "125/138 [==========================>...] - ETA: 0s - loss: 3.1554 - mse: 3.1347\n",
      "Epoch 00014: val_loss improved from 3.15908 to 3.15892, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e014_vl3.159.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.1567 - mse: 3.1360 - val_loss: 3.1589 - val_mse: 3.1382\n",
      "Epoch 15/25\n",
      "136/138 [============================>.] - ETA: 0s - loss: 3.1557 - mse: 3.1351\n",
      "Epoch 00015: val_loss did not improve from 3.15892\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.1563 - mse: 3.1356 - val_loss: 3.1595 - val_mse: 3.1388\n",
      "Epoch 16/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.1556 - mse: 3.1349\n",
      "Epoch 00016: val_loss improved from 3.15892 to 3.15825, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e016_vl3.158.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.1556 - mse: 3.1349 - val_loss: 3.1582 - val_mse: 3.1376\n",
      "Epoch 17/25\n",
      "128/138 [==========================>...] - ETA: 0s - loss: 3.1577 - mse: 3.1371\n",
      "Epoch 00017: val_loss did not improve from 3.15825\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.1557 - mse: 3.1351 - val_loss: 3.1583 - val_mse: 3.1377\n",
      "Epoch 18/25\n",
      "131/138 [===========================>..] - ETA: 0s - loss: 3.1534 - mse: 3.1328\n",
      "Epoch 00018: val_loss improved from 3.15825 to 3.15818, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e018_vl3.158.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.1554 - mse: 3.1348 - val_loss: 3.1582 - val_mse: 3.1376\n",
      "Epoch 19/25\n",
      "130/138 [===========================>..] - ETA: 0s - loss: 3.1546 - mse: 3.1340\n",
      "Epoch 00019: val_loss did not improve from 3.15818\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.1553 - mse: 3.1347 - val_loss: 3.1584 - val_mse: 3.1378\n",
      "Epoch 20/25\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 3.1540 - mse: 3.1335\n",
      "Epoch 00020: val_loss did not improve from 3.15818\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.1552 - mse: 3.1346 - val_loss: 3.1583 - val_mse: 3.1377\n",
      "Epoch 21/25\n",
      "129/138 [===========================>..] - ETA: 0s - loss: 3.1596 - mse: 3.1390\n",
      "Epoch 00021: val_loss improved from 3.15818 to 3.15791, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e021_vl3.158.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.1552 - mse: 3.1346 - val_loss: 3.1579 - val_mse: 3.1374\n",
      "Epoch 22/25\n",
      "128/138 [==========================>...] - ETA: 0s - loss: 3.1530 - mse: 3.1325\n",
      "Epoch 00022: val_loss did not improve from 3.15791\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.1555 - mse: 3.1350 - val_loss: 3.1580 - val_mse: 3.1374\n",
      "Epoch 23/25\n",
      "132/138 [===========================>..] - ETA: 0s - loss: 3.1570 - mse: 3.1364\n",
      "Epoch 00023: val_loss improved from 3.15791 to 3.15739, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e023_vl3.157.h5\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.1553 - mse: 3.1348 - val_loss: 3.1574 - val_mse: 3.1368\n",
      "Epoch 24/25\n",
      "137/138 [============================>.] - ETA: 0s - loss: 3.1553 - mse: 3.1347\n",
      "Epoch 00024: val_loss did not improve from 3.15739\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.1551 - mse: 3.1345 - val_loss: 3.1583 - val_mse: 3.1378\n",
      "Epoch 25/25\n",
      "136/138 [============================>.] - ETA: 0s - loss: 3.1537 - mse: 3.1332\n",
      "Epoch 00025: val_loss did not improve from 3.15739\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 3.1545 - mse: 3.1340 - val_loss: 3.1582 - val_mse: 3.1377\n",
      "Time elapsed to train: 20.34 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 204.96756    85.65157    78.156364 ...   24.507763   55.904896\n",
      " 2474.4468  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0198\n",
      "  1% : 0.194\n",
      "  10% : 0.66\n",
      "  50% : 4.59\n",
      "  90% : 46.6\n",
      "  99% : 470\n",
      "  100% : 1.34e+04\n",
      "<chi^2/d.o.f.> = 3.23\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 67145 stars (26.5%) based on chi^2/dof > 12.6\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  69.25917   53.34155 1106.9832  ...  317.17096   64.85361   39.52304]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0418\n",
      "  1% : 0.193\n",
      "  10% : 0.653\n",
      "  50% : 4.5\n",
      "  90% : 45.3\n",
      "  99% : 482\n",
      "  100% : 5.23e+03\n",
      "<chi^2/d.o.f.> = 3.22\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 69.54 s\n",
      "learning rate = 0.00016529888671357185\n",
      "setting learning rate to 0.0001353352832366127\n",
      "Iteration 11 of 20.\n",
      "Epoch 1/25\n",
      "124/132 [===========================>..] - ETA: 0s - loss: 2.7173 - mse: 2.6968\n",
      "Epoch 00001: val_loss improved from inf to 2.71101, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e001_vl2.711.h5\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 2.7138 - mse: 2.6933 - val_loss: 2.7110 - val_mse: 2.6906\n",
      "Epoch 2/25\n",
      "126/132 [===========================>..] - ETA: 0s - loss: 2.7128 - mse: 2.6924\n",
      "Epoch 00002: val_loss did not improve from 2.71101\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.7125 - mse: 2.6922 - val_loss: 2.7119 - val_mse: 2.6915\n",
      "Epoch 3/25\n",
      "123/132 [==========================>...] - ETA: 0s - loss: 2.7115 - mse: 2.6912\n",
      "Epoch 00003: val_loss did not improve from 2.71101\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.7126 - mse: 2.6922 - val_loss: 2.7112 - val_mse: 2.6909\n",
      "Epoch 4/25\n",
      "129/132 [============================>.] - ETA: 0s - loss: 2.7108 - mse: 2.6905\n",
      "Epoch 00004: val_loss improved from 2.71101 to 2.71064, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e004_vl2.711.h5\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 2.7123 - mse: 2.6920 - val_loss: 2.7106 - val_mse: 2.6904\n",
      "Epoch 5/25\n",
      "124/132 [===========================>..] - ETA: 0s - loss: 2.7129 - mse: 2.6926\n",
      "Epoch 00005: val_loss did not improve from 2.71064\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.7128 - mse: 2.6926 - val_loss: 2.7111 - val_mse: 2.6908\n",
      "Epoch 6/25\n",
      "123/132 [==========================>...] - ETA: 0s - loss: 2.7120 - mse: 2.6918\n",
      "Epoch 00006: val_loss improved from 2.71064 to 2.70996, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e006_vl2.710.h5\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.7121 - mse: 2.6918 - val_loss: 2.7100 - val_mse: 2.6898\n",
      "Epoch 7/25\n",
      "130/132 [============================>.] - ETA: 0s - loss: 2.7119 - mse: 2.6916\n",
      "Epoch 00007: val_loss did not improve from 2.70996\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.7119 - mse: 2.6917 - val_loss: 2.7115 - val_mse: 2.6914\n",
      "Epoch 8/25\n",
      "123/132 [==========================>...] - ETA: 0s - loss: 2.7122 - mse: 2.6920\n",
      "Epoch 00008: val_loss did not improve from 2.70996\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.7123 - mse: 2.6921 - val_loss: 2.7100 - val_mse: 2.6898\n",
      "Epoch 9/25\n",
      "132/132 [==============================] - ETA: 0s - loss: 2.7120 - mse: 2.6918\n",
      "Epoch 00009: val_loss improved from 2.70996 to 2.70962, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e009_vl2.710.h5\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.7120 - mse: 2.6918 - val_loss: 2.7096 - val_mse: 2.6895\n",
      "Epoch 10/25\n",
      "132/132 [==============================] - ETA: 0s - loss: 2.7117 - mse: 2.6916\n",
      "Epoch 00010: val_loss did not improve from 2.70962\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.7117 - mse: 2.6916 - val_loss: 2.7097 - val_mse: 2.6896\n",
      "Epoch 11/25\n",
      "125/132 [===========================>..] - ETA: 0s - loss: 2.7121 - mse: 2.6919\n",
      "Epoch 00011: val_loss improved from 2.70962 to 2.70918, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e011_vl2.709.h5\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.7116 - mse: 2.6914 - val_loss: 2.7092 - val_mse: 2.6891\n",
      "Epoch 12/25\n",
      "123/132 [==========================>...] - ETA: 0s - loss: 2.7150 - mse: 2.6949\n",
      "Epoch 00012: val_loss did not improve from 2.70918\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.7118 - mse: 2.6917 - val_loss: 2.7094 - val_mse: 2.6893\n",
      "Epoch 13/25\n",
      "128/132 [============================>.] - ETA: 0s - loss: 2.7091 - mse: 2.6890\n",
      "Epoch 00013: val_loss did not improve from 2.70918\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 2.7113 - mse: 2.6912 - val_loss: 2.7093 - val_mse: 2.6892\n",
      "Epoch 14/25\n",
      "123/132 [==========================>...] - ETA: 0s - loss: 2.7139 - mse: 2.6938\n",
      "Epoch 00014: val_loss did not improve from 2.70918\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 2.7110 - mse: 2.6909 - val_loss: 2.7102 - val_mse: 2.6901\n",
      "Epoch 15/25\n",
      "121/132 [==========================>...] - ETA: 0s - loss: 2.7107 - mse: 2.6906\n",
      "Epoch 00015: val_loss improved from 2.70918 to 2.70885, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e015_vl2.709.h5\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 2.7114 - mse: 2.6913 - val_loss: 2.7089 - val_mse: 2.6888\n",
      "Epoch 16/25\n",
      "132/132 [==============================] - ETA: 0s - loss: 2.7114 - mse: 2.6914\n",
      "Epoch 00016: val_loss did not improve from 2.70885\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 2.7114 - mse: 2.6914 - val_loss: 2.7093 - val_mse: 2.6892\n",
      "Epoch 17/25\n",
      "128/132 [============================>.] - ETA: 0s - loss: 2.7117 - mse: 2.6917\n",
      "Epoch 00017: val_loss did not improve from 2.70885\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.7109 - mse: 2.6908 - val_loss: 2.7092 - val_mse: 2.6892\n",
      "Epoch 18/25\n",
      "124/132 [===========================>..] - ETA: 0s - loss: 2.7103 - mse: 2.6902\n",
      "Epoch 00018: val_loss did not improve from 2.70885\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.7114 - mse: 2.6914 - val_loss: 2.7102 - val_mse: 2.6901\n",
      "Epoch 19/25\n",
      "129/132 [============================>.] - ETA: 0s - loss: 2.7130 - mse: 2.6929\n",
      "Epoch 00019: val_loss did not improve from 2.70885\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.7112 - mse: 2.6911 - val_loss: 2.7089 - val_mse: 2.6888\n",
      "Epoch 20/25\n",
      "131/132 [============================>.] - ETA: 0s - loss: 2.7112 - mse: 2.6911\n",
      "Epoch 00020: val_loss did not improve from 2.70885\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.7111 - mse: 2.6910 - val_loss: 2.7098 - val_mse: 2.6898\n",
      "Epoch 21/25\n",
      "130/132 [============================>.] - ETA: 0s - loss: 2.7101 - mse: 2.6900\n",
      "Epoch 00021: val_loss improved from 2.70885 to 2.70841, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e021_vl2.708.h5\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.7107 - mse: 2.6906 - val_loss: 2.7084 - val_mse: 2.6884\n",
      "Epoch 22/25\n",
      "125/132 [===========================>..] - ETA: 0s - loss: 2.7085 - mse: 2.6884\n",
      "Epoch 00022: val_loss did not improve from 2.70841\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.7106 - mse: 2.6906 - val_loss: 2.7112 - val_mse: 2.6911\n",
      "Epoch 23/25\n",
      "128/132 [============================>.] - ETA: 0s - loss: 2.7106 - mse: 2.6906\n",
      "Epoch 00023: val_loss did not improve from 2.70841\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.7108 - mse: 2.6908 - val_loss: 2.7090 - val_mse: 2.6889\n",
      "Epoch 24/25\n",
      "121/132 [==========================>...] - ETA: 0s - loss: 2.7108 - mse: 2.6907\n",
      "Epoch 00024: val_loss improved from 2.70841 to 2.70800, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e024_vl2.708.h5\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.7107 - mse: 2.6906 - val_loss: 2.7080 - val_mse: 2.6880\n",
      "Epoch 25/25\n",
      "130/132 [============================>.] - ETA: 0s - loss: 2.7098 - mse: 2.6897\n",
      "Epoch 00025: val_loss did not improve from 2.70800\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.7101 - mse: 2.6901 - val_loss: 2.7091 - val_mse: 2.6891\n",
      "Time elapsed to train: 20.35 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 205.51076    79.20822    88.900375 ...   20.82264    55.099976\n",
      " 2526.3467  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.017\n",
      "  1% : 0.19\n",
      "  10% : 0.637\n",
      "  50% : 4.39\n",
      "  90% : 46.7\n",
      "  99% : 468\n",
      "  100% : 1.31e+04\n",
      "<chi^2/d.o.f.> = 3.16\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 77227 stars (30.5%) based on chi^2/dof > 10.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  60.05211    59.66012  1054.8715   ...  373.1081     56.793175\n",
      "   43.53537 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0376\n",
      "  1% : 0.19\n",
      "  10% : 0.631\n",
      "  50% : 4.32\n",
      "  90% : 45.3\n",
      "  99% : 477\n",
      "  100% : 5.25e+03\n",
      "<chi^2/d.o.f.> = 3.15\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 70.19 s\n",
      "learning rate = 0.00013533528544940054\n",
      "setting learning rate to 0.00011080315836233387\n",
      "Iteration 12 of 20.\n",
      "Epoch 1/25\n",
      "118/125 [===========================>..] - ETA: 0s - loss: 2.3160 - mse: 2.2960\n",
      "Epoch 00001: val_loss improved from inf to 2.33154, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e001_vl2.332.h5\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 2.3163 - mse: 2.2963 - val_loss: 2.3315 - val_mse: 2.3116\n",
      "Epoch 2/25\n",
      "123/125 [============================>.] - ETA: 0s - loss: 2.3167 - mse: 2.2968\n",
      "Epoch 00002: val_loss improved from 2.33154 to 2.32659, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e002_vl2.327.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3166 - mse: 2.2967 - val_loss: 2.3266 - val_mse: 2.3067\n",
      "Epoch 3/25\n",
      "117/125 [===========================>..] - ETA: 0s - loss: 2.3135 - mse: 2.2936\n",
      "Epoch 00003: val_loss did not improve from 2.32659\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3156 - mse: 2.2956 - val_loss: 2.3271 - val_mse: 2.3071\n",
      "Epoch 4/25\n",
      "116/125 [==========================>...] - ETA: 0s - loss: 2.3163 - mse: 2.2964\n",
      "Epoch 00004: val_loss did not improve from 2.32659\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3156 - mse: 2.2957 - val_loss: 2.3292 - val_mse: 2.3093\n",
      "Epoch 5/25\n",
      "122/125 [============================>.] - ETA: 0s - loss: 2.3157 - mse: 2.2958\n",
      "Epoch 00005: val_loss did not improve from 2.32659\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3153 - mse: 2.2955 - val_loss: 2.3270 - val_mse: 2.3071\n",
      "Epoch 6/25\n",
      "124/125 [============================>.] - ETA: 0s - loss: 2.3153 - mse: 2.2955\n",
      "Epoch 00006: val_loss improved from 2.32659 to 2.32620, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e006_vl2.326.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3153 - mse: 2.2954 - val_loss: 2.3262 - val_mse: 2.3063\n",
      "Epoch 7/25\n",
      "120/125 [===========================>..] - ETA: 0s - loss: 2.3164 - mse: 2.2965\n",
      "Epoch 00007: val_loss improved from 2.32620 to 2.32393, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e007_vl2.324.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3155 - mse: 2.2957 - val_loss: 2.3239 - val_mse: 2.3041\n",
      "Epoch 8/25\n",
      "125/125 [==============================] - ETA: 0s - loss: 2.3148 - mse: 2.2949\n",
      "Epoch 00008: val_loss did not improve from 2.32393\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3148 - mse: 2.2949 - val_loss: 2.3266 - val_mse: 2.3068\n",
      "Epoch 9/25\n",
      "115/125 [==========================>...] - ETA: 0s - loss: 2.3168 - mse: 2.2970\n",
      "Epoch 00009: val_loss did not improve from 2.32393\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3149 - mse: 2.2951 - val_loss: 2.3277 - val_mse: 2.3078\n",
      "Epoch 10/25\n",
      "124/125 [============================>.] - ETA: 0s - loss: 2.3151 - mse: 2.2952\n",
      "Epoch 00010: val_loss did not improve from 2.32393\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3151 - mse: 2.2953 - val_loss: 2.3282 - val_mse: 2.3083\n",
      "Epoch 11/25\n",
      "123/125 [============================>.] - ETA: 0s - loss: 2.3145 - mse: 2.2947\n",
      "Epoch 00011: val_loss did not improve from 2.32393\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3149 - mse: 2.2951 - val_loss: 2.3270 - val_mse: 2.3071\n",
      "Epoch 12/25\n",
      "114/125 [==========================>...] - ETA: 0s - loss: 2.3169 - mse: 2.2971\n",
      "Epoch 00012: val_loss did not improve from 2.32393\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3148 - mse: 2.2950 - val_loss: 2.3295 - val_mse: 2.3096\n",
      "Epoch 13/25\n",
      "117/125 [===========================>..] - ETA: 0s - loss: 2.3146 - mse: 2.2948\n",
      "Epoch 00013: val_loss did not improve from 2.32393\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3154 - mse: 2.2955 - val_loss: 2.3260 - val_mse: 2.3062\n",
      "Epoch 14/25\n",
      "115/125 [==========================>...] - ETA: 0s - loss: 2.3152 - mse: 2.2954\n",
      "Epoch 00014: val_loss did not improve from 2.32393\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3145 - mse: 2.2947 - val_loss: 2.3242 - val_mse: 2.3044\n",
      "Epoch 15/25\n",
      "124/125 [============================>.] - ETA: 0s - loss: 2.3149 - mse: 2.2951\n",
      "Epoch 00015: val_loss did not improve from 2.32393\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3149 - mse: 2.2950 - val_loss: 2.3245 - val_mse: 2.3046\n",
      "Epoch 16/25\n",
      "119/125 [===========================>..] - ETA: 0s - loss: 2.3139 - mse: 2.2941\n",
      "Epoch 00016: val_loss improved from 2.32393 to 2.32388, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e016_vl2.324.h5\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 2.3144 - mse: 2.2946 - val_loss: 2.3239 - val_mse: 2.3041\n",
      "Epoch 17/25\n",
      "125/125 [==============================] - ETA: 0s - loss: 2.3142 - mse: 2.2943\n",
      "Epoch 00017: val_loss did not improve from 2.32388\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3142 - mse: 2.2943 - val_loss: 2.3239 - val_mse: 2.3041\n",
      "Epoch 18/25\n",
      "121/125 [============================>.] - ETA: 0s - loss: 2.3151 - mse: 2.2953\n",
      "Epoch 00018: val_loss did not improve from 2.32388\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3139 - mse: 2.2941 - val_loss: 2.3247 - val_mse: 2.3049\n",
      "Epoch 19/25\n",
      "123/125 [============================>.] - ETA: 0s - loss: 2.3143 - mse: 2.2945\n",
      "Epoch 00019: val_loss did not improve from 2.32388\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3142 - mse: 2.2944 - val_loss: 2.3260 - val_mse: 2.3061\n",
      "Epoch 20/25\n",
      "115/125 [==========================>...] - ETA: 0s - loss: 2.3117 - mse: 2.2919\n",
      "Epoch 00020: val_loss did not improve from 2.32388\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3145 - mse: 2.2947 - val_loss: 2.3256 - val_mse: 2.3058\n",
      "Epoch 21/25\n",
      "123/125 [============================>.] - ETA: 0s - loss: 2.3149 - mse: 2.2951\n",
      "Epoch 00021: val_loss did not improve from 2.32388\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3145 - mse: 2.2947 - val_loss: 2.3248 - val_mse: 2.3050\n",
      "Epoch 22/25\n",
      "118/125 [===========================>..] - ETA: 0s - loss: 2.3128 - mse: 2.2930\n",
      "Epoch 00022: val_loss improved from 2.32388 to 2.32309, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e022_vl2.323.h5\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3140 - mse: 2.2942 - val_loss: 2.3231 - val_mse: 2.3033\n",
      "Epoch 23/25\n",
      "120/125 [===========================>..] - ETA: 0s - loss: 2.3115 - mse: 2.2917\n",
      "Epoch 00023: val_loss did not improve from 2.32309\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 2.3141 - mse: 2.2943 - val_loss: 2.3250 - val_mse: 2.3052\n",
      "Epoch 24/25\n",
      "115/125 [==========================>...] - ETA: 0s - loss: 2.3139 - mse: 2.2941\n",
      "Epoch 00024: val_loss did not improve from 2.32309\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 2.3146 - mse: 2.2947 - val_loss: 2.3273 - val_mse: 2.3074\n",
      "Epoch 25/25\n",
      "117/125 [===========================>..] - ETA: 0s - loss: 2.3141 - mse: 2.2942\n",
      "Epoch 00025: val_loss did not improve from 2.32309\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 2.3143 - mse: 2.2944 - val_loss: 2.3259 - val_mse: 2.3061\n",
      "Time elapsed to train: 18.66 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 212.49521    73.959885   98.31412  ...   17.886164   55.80721\n",
      " 2518.9502  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0154\n",
      "  1% : 0.187\n",
      "  10% : 0.618\n",
      "  50% : 4.2\n",
      "  90% : 46.4\n",
      "  99% : 463\n",
      "  100% : 1.28e+04\n",
      "<chi^2/d.o.f.> = 3.09\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 87913 stars (34.7%) based on chi^2/dof > 7.9\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  52.888226   65.04204  1017.2617   ...  436.70532    50.945496\n",
      "   47.686718]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0427\n",
      "  1% : 0.184\n",
      "  10% : 0.609\n",
      "  50% : 4.14\n",
      "  90% : 44.8\n",
      "  99% : 466\n",
      "  100% : 5.26e+03\n",
      "<chi^2/d.o.f.> = 3.08\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 67.97 s\n",
      "learning rate = 0.00011080315744038671\n",
      "setting learning rate to 9.071795328941248e-05\n",
      "Iteration 13 of 20.\n",
      "Epoch 1/25\n",
      "115/117 [============================>.] - ETA: 0s - loss: 1.9742 - mse: 1.9544\n",
      "Epoch 00001: val_loss improved from inf to 1.98213, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e001_vl1.982.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.9747 - mse: 1.9549 - val_loss: 1.9821 - val_mse: 1.9623\n",
      "Epoch 2/25\n",
      "109/117 [==========================>...] - ETA: 0s - loss: 1.9712 - mse: 1.9515\n",
      "Epoch 00002: val_loss did not improve from 1.98213\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.9723 - mse: 1.9525 - val_loss: 1.9827 - val_mse: 1.9630\n",
      "Epoch 3/25\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.9719 - mse: 1.9522\n",
      "Epoch 00003: val_loss improved from 1.98213 to 1.98198, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e003_vl1.982.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.9719 - mse: 1.9522 - val_loss: 1.9820 - val_mse: 1.9622\n",
      "Epoch 4/25\n",
      "114/117 [============================>.] - ETA: 0s - loss: 1.9724 - mse: 1.9527\n",
      "Epoch 00004: val_loss improved from 1.98198 to 1.98186, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e004_vl1.982.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.9719 - mse: 1.9522 - val_loss: 1.9819 - val_mse: 1.9621\n",
      "Epoch 5/25\n",
      "110/117 [===========================>..] - ETA: 0s - loss: 1.9702 - mse: 1.9505\n",
      "Epoch 00005: val_loss improved from 1.98186 to 1.98181, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e005_vl1.982.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.9718 - mse: 1.9521 - val_loss: 1.9818 - val_mse: 1.9621\n",
      "Epoch 6/25\n",
      "112/117 [===========================>..] - ETA: 0s - loss: 1.9734 - mse: 1.9537\n",
      "Epoch 00006: val_loss improved from 1.98181 to 1.98178, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e006_vl1.982.h5\n",
      "117/117 [==============================] - 1s 7ms/step - loss: 1.9718 - mse: 1.9520 - val_loss: 1.9818 - val_mse: 1.9621\n",
      "Epoch 7/25\n",
      "109/117 [==========================>...] - ETA: 0s - loss: 1.9708 - mse: 1.9511\n",
      "Epoch 00007: val_loss improved from 1.98178 to 1.98146, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e007_vl1.981.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.9716 - mse: 1.9519 - val_loss: 1.9815 - val_mse: 1.9618\n",
      "Epoch 8/25\n",
      "109/117 [==========================>...] - ETA: 0s - loss: 1.9720 - mse: 1.9523\n",
      "Epoch 00008: val_loss improved from 1.98146 to 1.98121, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e008_vl1.981.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.9717 - mse: 1.9520 - val_loss: 1.9812 - val_mse: 1.9615\n",
      "Epoch 9/25\n",
      "115/117 [============================>.] - ETA: 0s - loss: 1.9713 - mse: 1.9516\n",
      "Epoch 00009: val_loss did not improve from 1.98121\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.9717 - mse: 1.9520 - val_loss: 1.9813 - val_mse: 1.9616\n",
      "Epoch 10/25\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.9717 - mse: 1.9520\n",
      "Epoch 00010: val_loss did not improve from 1.98121\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.9717 - mse: 1.9520 - val_loss: 1.9822 - val_mse: 1.9626\n",
      "Epoch 11/25\n",
      "108/117 [==========================>...] - ETA: 0s - loss: 1.9740 - mse: 1.9543\n",
      "Epoch 00011: val_loss improved from 1.98121 to 1.98110, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e011_vl1.981.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.9716 - mse: 1.9519 - val_loss: 1.9811 - val_mse: 1.9614\n",
      "Epoch 12/25\n",
      "107/117 [==========================>...] - ETA: 0s - loss: 1.9725 - mse: 1.9529\n",
      "Epoch 00012: val_loss did not improve from 1.98110\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.9713 - mse: 1.9516 - val_loss: 1.9815 - val_mse: 1.9618\n",
      "Epoch 13/25\n",
      "108/117 [==========================>...] - ETA: 0s - loss: 1.9713 - mse: 1.9516\n",
      "Epoch 00013: val_loss improved from 1.98110 to 1.98088, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e013_vl1.981.h5\n",
      "117/117 [==============================] - 1s 7ms/step - loss: 1.9713 - mse: 1.9516 - val_loss: 1.9809 - val_mse: 1.9612\n",
      "Epoch 14/25\n",
      "114/117 [============================>.] - ETA: 0s - loss: 1.9710 - mse: 1.9513\n",
      "Epoch 00014: val_loss did not improve from 1.98088\n",
      "117/117 [==============================] - 1s 7ms/step - loss: 1.9714 - mse: 1.9517 - val_loss: 1.9813 - val_mse: 1.9616\n",
      "Epoch 15/25\n",
      "111/117 [===========================>..] - ETA: 0s - loss: 1.9710 - mse: 1.9514\n",
      "Epoch 00015: val_loss did not improve from 1.98088\n",
      "117/117 [==============================] - 1s 7ms/step - loss: 1.9712 - mse: 1.9515 - val_loss: 1.9811 - val_mse: 1.9614\n",
      "Epoch 16/25\n",
      "111/117 [===========================>..] - ETA: 0s - loss: 1.9701 - mse: 1.9504\n",
      "Epoch 00016: val_loss did not improve from 1.98088\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.9712 - mse: 1.9515 - val_loss: 1.9809 - val_mse: 1.9612\n",
      "Epoch 17/25\n",
      "107/117 [==========================>...] - ETA: 0s - loss: 1.9737 - mse: 1.9540\n",
      "Epoch 00017: val_loss improved from 1.98088 to 1.98080, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e017_vl1.981.h5\n",
      "117/117 [==============================] - 1s 7ms/step - loss: 1.9711 - mse: 1.9514 - val_loss: 1.9808 - val_mse: 1.9611\n",
      "Epoch 18/25\n",
      "115/117 [============================>.] - ETA: 0s - loss: 1.9715 - mse: 1.9518\n",
      "Epoch 00018: val_loss improved from 1.98080 to 1.98047, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e018_vl1.980.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.9711 - mse: 1.9515 - val_loss: 1.9805 - val_mse: 1.9608\n",
      "Epoch 19/25\n",
      "109/117 [==========================>...] - ETA: 0s - loss: 1.9700 - mse: 1.9503\n",
      "Epoch 00019: val_loss did not improve from 1.98047\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.9709 - mse: 1.9512 - val_loss: 1.9806 - val_mse: 1.9609\n",
      "Epoch 20/25\n",
      "114/117 [============================>.] - ETA: 0s - loss: 1.9703 - mse: 1.9507\n",
      "Epoch 00020: val_loss did not improve from 1.98047\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.9708 - mse: 1.9511 - val_loss: 1.9808 - val_mse: 1.9611\n",
      "Epoch 21/25\n",
      "106/117 [==========================>...] - ETA: 0s - loss: 1.9718 - mse: 1.9521\n",
      "Epoch 00021: val_loss did not improve from 1.98047\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.9709 - mse: 1.9512 - val_loss: 1.9806 - val_mse: 1.9610\n",
      "Epoch 22/25\n",
      "110/117 [===========================>..] - ETA: 0s - loss: 1.9711 - mse: 1.9514\n",
      "Epoch 00022: val_loss improved from 1.98047 to 1.98043, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e022_vl1.980.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.9712 - mse: 1.9515 - val_loss: 1.9804 - val_mse: 1.9608\n",
      "Epoch 23/25\n",
      "113/117 [===========================>..] - ETA: 0s - loss: 1.9710 - mse: 1.9513\n",
      "Epoch 00023: val_loss improved from 1.98043 to 1.98025, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e023_vl1.980.h5\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.9708 - mse: 1.9511 - val_loss: 1.9803 - val_mse: 1.9606\n",
      "Epoch 24/25\n",
      "116/117 [============================>.] - ETA: 0s - loss: 1.9708 - mse: 1.9511\n",
      "Epoch 00024: val_loss did not improve from 1.98025\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.9709 - mse: 1.9512 - val_loss: 1.9803 - val_mse: 1.9606\n",
      "Epoch 25/25\n",
      "111/117 [===========================>..] - ETA: 0s - loss: 1.9723 - mse: 1.9526\n",
      "Epoch 00025: val_loss did not improve from 1.98025\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.9709 - mse: 1.9512 - val_loss: 1.9808 - val_mse: 1.9611\n",
      "Time elapsed to train: 18.24 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 215.12819    68.2987    107.79361  ...   14.961477   54.19718\n",
      " 2484.1797  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0143\n",
      "  1% : 0.176\n",
      "  10% : 0.584\n",
      "  50% : 4.01\n",
      "  90% : 45.7\n",
      "  99% : 443\n",
      "  100% : 1.24e+04\n",
      "<chi^2/d.o.f.> = 3.01\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 98845 stars (39.1%) based on chi^2/dof > 6.3\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 45.78927   69.944855 979.30054  ... 505.50522   44.871338  51.328568]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0503\n",
      "  1% : 0.171\n",
      "  10% : 0.579\n",
      "  50% : 3.97\n",
      "  90% : 44.4\n",
      "  99% : 452\n",
      "  100% : 5.26e+03\n",
      "<chi^2/d.o.f.> = 3\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 66.48 s\n",
      "learning rate = 9.071795648196712e-05\n",
      "setting learning rate to 7.427357821433387e-05\n",
      "Iteration 14 of 20.\n",
      "Epoch 1/25\n",
      "106/109 [============================>.] - ETA: 0s - loss: 1.6780 - mse: 1.6584\n",
      "Epoch 00001: val_loss improved from inf to 1.68586, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e001_vl1.686.h5\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.6784 - mse: 1.6587 - val_loss: 1.6859 - val_mse: 1.6662\n",
      "Epoch 2/25\n",
      "102/109 [===========================>..] - ETA: 0s - loss: 1.6765 - mse: 1.6568\n",
      "Epoch 00002: val_loss improved from 1.68586 to 1.68549, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e002_vl1.685.h5\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.6777 - mse: 1.6581 - val_loss: 1.6855 - val_mse: 1.6659\n",
      "Epoch 3/25\n",
      "101/109 [==========================>...] - ETA: 0s - loss: 1.6783 - mse: 1.6587\n",
      "Epoch 00003: val_loss improved from 1.68549 to 1.68522, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e003_vl1.685.h5\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.6773 - mse: 1.6576 - val_loss: 1.6852 - val_mse: 1.6656\n",
      "Epoch 4/25\n",
      " 99/109 [==========================>...] - ETA: 0s - loss: 1.6761 - mse: 1.6565\n",
      "Epoch 00004: val_loss improved from 1.68522 to 1.68488, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e004_vl1.685.h5\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.6774 - mse: 1.6578 - val_loss: 1.6849 - val_mse: 1.6653\n",
      "Epoch 5/25\n",
      "108/109 [============================>.] - ETA: 0s - loss: 1.6775 - mse: 1.6579\n",
      "Epoch 00005: val_loss improved from 1.68488 to 1.68483, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e005_vl1.685.h5\n",
      "109/109 [==============================] - 1s 7ms/step - loss: 1.6771 - mse: 1.6575 - val_loss: 1.6848 - val_mse: 1.6653\n",
      "Epoch 6/25\n",
      "108/109 [============================>.] - ETA: 0s - loss: 1.6775 - mse: 1.6579\n",
      "Epoch 00006: val_loss did not improve from 1.68483\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.6770 - mse: 1.6574 - val_loss: 1.6849 - val_mse: 1.6653\n",
      "Epoch 7/25\n",
      "106/109 [============================>.] - ETA: 0s - loss: 1.6768 - mse: 1.6572\n",
      "Epoch 00007: val_loss improved from 1.68483 to 1.68457, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e007_vl1.685.h5\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.6769 - mse: 1.6573 - val_loss: 1.6846 - val_mse: 1.6650\n",
      "Epoch 8/25\n",
      "104/109 [===========================>..] - ETA: 0s - loss: 1.6764 - mse: 1.6568\n",
      "Epoch 00008: val_loss did not improve from 1.68457\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.6770 - mse: 1.6575 - val_loss: 1.6852 - val_mse: 1.6657\n",
      "Epoch 9/25\n",
      "108/109 [============================>.] - ETA: 0s - loss: 1.6768 - mse: 1.6572\n",
      "Epoch 00009: val_loss did not improve from 1.68457\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.6767 - mse: 1.6572 - val_loss: 1.6856 - val_mse: 1.6660\n",
      "Epoch 10/25\n",
      "107/109 [============================>.] - ETA: 0s - loss: 1.6763 - mse: 1.6568\n",
      "Epoch 00010: val_loss did not improve from 1.68457\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.6769 - mse: 1.6573 - val_loss: 1.6849 - val_mse: 1.6654\n",
      "Epoch 11/25\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.6768 - mse: 1.6572\n",
      "Epoch 00011: val_loss improved from 1.68457 to 1.68438, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e011_vl1.684.h5\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.6768 - mse: 1.6572 - val_loss: 1.6844 - val_mse: 1.6648\n",
      "Epoch 12/25\n",
      "105/109 [===========================>..] - ETA: 0s - loss: 1.6766 - mse: 1.6571\n",
      "Epoch 00012: val_loss did not improve from 1.68438\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.6766 - mse: 1.6570 - val_loss: 1.6844 - val_mse: 1.6649\n",
      "Epoch 13/25\n",
      "107/109 [============================>.] - ETA: 0s - loss: 1.6773 - mse: 1.6577\n",
      "Epoch 00013: val_loss improved from 1.68438 to 1.68416, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e013_vl1.684.h5\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.6766 - mse: 1.6571 - val_loss: 1.6842 - val_mse: 1.6646\n",
      "Epoch 14/25\n",
      "104/109 [===========================>..] - ETA: 0s - loss: 1.6739 - mse: 1.6544\n",
      "Epoch 00014: val_loss improved from 1.68416 to 1.68406, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e014_vl1.684.h5\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.6765 - mse: 1.6570 - val_loss: 1.6841 - val_mse: 1.6645\n",
      "Epoch 15/25\n",
      "107/109 [============================>.] - ETA: 0s - loss: 1.6761 - mse: 1.6566\n",
      "Epoch 00015: val_loss improved from 1.68406 to 1.68398, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e015_vl1.684.h5\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.6765 - mse: 1.6569 - val_loss: 1.6840 - val_mse: 1.6644\n",
      "Epoch 16/25\n",
      "101/109 [==========================>...] - ETA: 0s - loss: 1.6754 - mse: 1.6558\n",
      "Epoch 00016: val_loss did not improve from 1.68398\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.6764 - mse: 1.6569 - val_loss: 1.6845 - val_mse: 1.6649\n",
      "Epoch 17/25\n",
      "105/109 [===========================>..] - ETA: 0s - loss: 1.6763 - mse: 1.6568\n",
      "Epoch 00017: val_loss did not improve from 1.68398\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.6765 - mse: 1.6569 - val_loss: 1.6844 - val_mse: 1.6649\n",
      "Epoch 18/25\n",
      "104/109 [===========================>..] - ETA: 0s - loss: 1.6755 - mse: 1.6559\n",
      "Epoch 00018: val_loss did not improve from 1.68398\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.6762 - mse: 1.6567 - val_loss: 1.6845 - val_mse: 1.6650\n",
      "Epoch 19/25\n",
      "107/109 [============================>.] - ETA: 0s - loss: 1.6767 - mse: 1.6572\n",
      "Epoch 00019: val_loss improved from 1.68398 to 1.68386, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e019_vl1.684.h5\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.6765 - mse: 1.6569 - val_loss: 1.6839 - val_mse: 1.6643\n",
      "Epoch 20/25\n",
      "107/109 [============================>.] - ETA: 0s - loss: 1.6768 - mse: 1.6573\n",
      "Epoch 00020: val_loss did not improve from 1.68386\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.6765 - mse: 1.6569 - val_loss: 1.6845 - val_mse: 1.6650\n",
      "Epoch 21/25\n",
      "100/109 [==========================>...] - ETA: 0s - loss: 1.6745 - mse: 1.6549\n",
      "Epoch 00021: val_loss did not improve from 1.68386\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.6764 - mse: 1.6568 - val_loss: 1.6839 - val_mse: 1.6644\n",
      "Epoch 22/25\n",
      " 98/109 [=========================>....] - ETA: 0s - loss: 1.6771 - mse: 1.6576\n",
      "Epoch 00022: val_loss did not improve from 1.68386\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.6761 - mse: 1.6566 - val_loss: 1.6840 - val_mse: 1.6645\n",
      "Epoch 23/25\n",
      "107/109 [============================>.] - ETA: 0s - loss: 1.6760 - mse: 1.6565\n",
      "Epoch 00023: val_loss improved from 1.68386 to 1.68365, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e023_vl1.684.h5\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.6760 - mse: 1.6565 - val_loss: 1.6836 - val_mse: 1.6641\n",
      "Epoch 24/25\n",
      "101/109 [==========================>...] - ETA: 0s - loss: 1.6777 - mse: 1.6582\n",
      "Epoch 00024: val_loss did not improve from 1.68365\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.6761 - mse: 1.6565 - val_loss: 1.6843 - val_mse: 1.6648\n",
      "Epoch 25/25\n",
      "104/109 [===========================>..] - ETA: 0s - loss: 1.6750 - mse: 1.6555\n",
      "Epoch 00025: val_loss did not improve from 1.68365\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.6760 - mse: 1.6565 - val_loss: 1.6838 - val_mse: 1.6643\n",
      "Time elapsed to train: 16.28 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 222.47693    62.66018   115.43823  ...   13.133763   52.73188\n",
      " 2433.0588  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0106\n",
      "  1% : 0.172\n",
      "  10% : 0.564\n",
      "  50% : 3.88\n",
      "  90% : 45.1\n",
      "  99% : 425\n",
      "  100% : 1.2e+04\n",
      "<chi^2/d.o.f.> = 2.96\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 110833 stars (43.8%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 40.984947  71.94308  988.69214  ... 562.50684   39.92634   56.302128]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0452\n",
      "  1% : 0.17\n",
      "  10% : 0.557\n",
      "  50% : 3.84\n",
      "  90% : 44\n",
      "  99% : 437\n",
      "  100% : 5.26e+03\n",
      "<chi^2/d.o.f.> = 2.94\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 63.85 s\n",
      "learning rate = 7.427357923006639e-05\n",
      "setting learning rate to 6.0810062625217954e-05\n",
      "Iteration 15 of 20.\n",
      "Epoch 1/25\n",
      " 98/101 [============================>.] - ETA: 0s - loss: 1.4238 - mse: 1.4043\n",
      "Epoch 00001: val_loss improved from inf to 1.42687, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e001_vl1.427.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4229 - mse: 1.4034 - val_loss: 1.4269 - val_mse: 1.4074\n",
      "Epoch 2/25\n",
      " 89/101 [=========================>....] - ETA: 0s - loss: 1.4212 - mse: 1.4017\n",
      "Epoch 00002: val_loss improved from 1.42687 to 1.42595, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e002_vl1.426.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4223 - mse: 1.4028 - val_loss: 1.4259 - val_mse: 1.4065\n",
      "Epoch 3/25\n",
      " 91/101 [==========================>...] - ETA: 0s - loss: 1.4217 - mse: 1.4022\n",
      "Epoch 00003: val_loss improved from 1.42595 to 1.42594, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e003_vl1.426.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4221 - mse: 1.4026 - val_loss: 1.4259 - val_mse: 1.4065\n",
      "Epoch 4/25\n",
      " 95/101 [===========================>..] - ETA: 0s - loss: 1.4212 - mse: 1.4017\n",
      "Epoch 00004: val_loss improved from 1.42594 to 1.42578, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e004_vl1.426.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4221 - mse: 1.4026 - val_loss: 1.4258 - val_mse: 1.4063\n",
      "Epoch 5/25\n",
      " 93/101 [==========================>...] - ETA: 0s - loss: 1.4206 - mse: 1.4011\n",
      "Epoch 00005: val_loss did not improve from 1.42578\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4218 - mse: 1.4023 - val_loss: 1.4262 - val_mse: 1.4067\n",
      "Epoch 6/25\n",
      " 97/101 [===========================>..] - ETA: 0s - loss: 1.4227 - mse: 1.4032\n",
      "Epoch 00006: val_loss did not improve from 1.42578\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 1.4218 - mse: 1.4023 - val_loss: 1.4259 - val_mse: 1.4064\n",
      "Epoch 7/25\n",
      " 91/101 [==========================>...] - ETA: 0s - loss: 1.4218 - mse: 1.4024\n",
      "Epoch 00007: val_loss improved from 1.42578 to 1.42541, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e007_vl1.425.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4218 - mse: 1.4024 - val_loss: 1.4254 - val_mse: 1.4060\n",
      "Epoch 8/25\n",
      " 90/101 [=========================>....] - ETA: 0s - loss: 1.4207 - mse: 1.4013\n",
      "Epoch 00008: val_loss improved from 1.42541 to 1.42531, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e008_vl1.425.h5\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 1.4216 - mse: 1.4021 - val_loss: 1.4253 - val_mse: 1.4059\n",
      "Epoch 9/25\n",
      " 97/101 [===========================>..] - ETA: 0s - loss: 1.4221 - mse: 1.4026\n",
      "Epoch 00009: val_loss did not improve from 1.42531\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 1.4215 - mse: 1.4021 - val_loss: 1.4260 - val_mse: 1.4066\n",
      "Epoch 10/25\n",
      " 91/101 [==========================>...] - ETA: 0s - loss: 1.4225 - mse: 1.4031\n",
      "Epoch 00010: val_loss did not improve from 1.42531\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 1.4217 - mse: 1.4023 - val_loss: 1.4258 - val_mse: 1.4064\n",
      "Epoch 11/25\n",
      " 98/101 [============================>.] - ETA: 0s - loss: 1.4214 - mse: 1.4020\n",
      "Epoch 00011: val_loss did not improve from 1.42531\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4216 - mse: 1.4022 - val_loss: 1.4254 - val_mse: 1.4060\n",
      "Epoch 12/25\n",
      " 91/101 [==========================>...] - ETA: 0s - loss: 1.4238 - mse: 1.4044\n",
      "Epoch 00012: val_loss improved from 1.42531 to 1.42525, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e012_vl1.425.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4215 - mse: 1.4021 - val_loss: 1.4253 - val_mse: 1.4058\n",
      "Epoch 13/25\n",
      " 97/101 [===========================>..] - ETA: 0s - loss: 1.4229 - mse: 1.4035\n",
      "Epoch 00013: val_loss improved from 1.42525 to 1.42515, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e013_vl1.425.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4214 - mse: 1.4020 - val_loss: 1.4251 - val_mse: 1.4057\n",
      "Epoch 14/25\n",
      " 93/101 [==========================>...] - ETA: 0s - loss: 1.4217 - mse: 1.4023\n",
      "Epoch 00014: val_loss improved from 1.42515 to 1.42498, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e014_vl1.425.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4213 - mse: 1.4019 - val_loss: 1.4250 - val_mse: 1.4056\n",
      "Epoch 15/25\n",
      "101/101 [==============================] - ETA: 0s - loss: 1.4213 - mse: 1.4018\n",
      "Epoch 00015: val_loss did not improve from 1.42498\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4213 - mse: 1.4018 - val_loss: 1.4258 - val_mse: 1.4064\n",
      "Epoch 16/25\n",
      " 94/101 [==========================>...] - ETA: 0s - loss: 1.4212 - mse: 1.4018\n",
      "Epoch 00016: val_loss improved from 1.42498 to 1.42493, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e016_vl1.425.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4213 - mse: 1.4019 - val_loss: 1.4249 - val_mse: 1.4055\n",
      "Epoch 17/25\n",
      " 99/101 [============================>.] - ETA: 0s - loss: 1.4212 - mse: 1.4017\n",
      "Epoch 00017: val_loss improved from 1.42493 to 1.42489, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e017_vl1.425.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4214 - mse: 1.4020 - val_loss: 1.4249 - val_mse: 1.4055\n",
      "Epoch 18/25\n",
      " 91/101 [==========================>...] - ETA: 0s - loss: 1.4206 - mse: 1.4012\n",
      "Epoch 00018: val_loss improved from 1.42489 to 1.42472, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e018_vl1.425.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4211 - mse: 1.4017 - val_loss: 1.4247 - val_mse: 1.4053\n",
      "Epoch 19/25\n",
      " 93/101 [==========================>...] - ETA: 0s - loss: 1.4192 - mse: 1.3998\n",
      "Epoch 00019: val_loss did not improve from 1.42472\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 1.4211 - mse: 1.4016 - val_loss: 1.4248 - val_mse: 1.4054\n",
      "Epoch 20/25\n",
      " 90/101 [=========================>....] - ETA: 0s - loss: 1.4201 - mse: 1.4007\n",
      "Epoch 00020: val_loss did not improve from 1.42472\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 1.4211 - mse: 1.4017 - val_loss: 1.4253 - val_mse: 1.4059\n",
      "Epoch 21/25\n",
      "100/101 [============================>.] - ETA: 0s - loss: 1.4212 - mse: 1.4018\n",
      "Epoch 00021: val_loss improved from 1.42472 to 1.42462, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e021_vl1.425.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4211 - mse: 1.4017 - val_loss: 1.4246 - val_mse: 1.4052\n",
      "Epoch 22/25\n",
      " 93/101 [==========================>...] - ETA: 0s - loss: 1.4204 - mse: 1.4010\n",
      "Epoch 00022: val_loss did not improve from 1.42462\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4210 - mse: 1.4016 - val_loss: 1.4247 - val_mse: 1.4053\n",
      "Epoch 23/25\n",
      " 94/101 [==========================>...] - ETA: 0s - loss: 1.4213 - mse: 1.4019\n",
      "Epoch 00023: val_loss did not improve from 1.42462\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4209 - mse: 1.4015 - val_loss: 1.4248 - val_mse: 1.4054\n",
      "Epoch 24/25\n",
      " 99/101 [============================>.] - ETA: 0s - loss: 1.4212 - mse: 1.4018\n",
      "Epoch 00024: val_loss did not improve from 1.42462\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4210 - mse: 1.4016 - val_loss: 1.4248 - val_mse: 1.4054\n",
      "Epoch 25/25\n",
      "100/101 [============================>.] - ETA: 0s - loss: 1.4211 - mse: 1.4017\n",
      "Epoch 00025: val_loss improved from 1.42462 to 1.42458, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e025_vl1.425.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4210 - mse: 1.4016 - val_loss: 1.4246 - val_mse: 1.4052\n",
      "Time elapsed to train: 14.60 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 223.99951    60.77469   122.51575  ...   11.185669   51.952713\n",
      " 2363.3057  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00871\n",
      "  1% : 0.168\n",
      "  10% : 0.547\n",
      "  50% : 3.77\n",
      "  90% : 45\n",
      "  99% : 419\n",
      "  100% : 1.16e+04\n",
      "<chi^2/d.o.f.> = 2.91\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 109419 stars (43.2%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  36.189827   73.93839  1006.9958   ...  629.91016    35.890015\n",
      "   62.18854 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0382\n",
      "  1% : 0.165\n",
      "  10% : 0.544\n",
      "  50% : 3.72\n",
      "  90% : 44\n",
      "  99% : 424\n",
      "  100% : 5.25e+03\n",
      "<chi^2/d.o.f.> = 2.9\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 63.55 s\n",
      "learning rate = 6.0810063587268814e-05\n",
      "setting learning rate to 4.9787068367863945e-05\n",
      "Iteration 16 of 20.\n",
      "Epoch 1/25\n",
      " 97/102 [===========================>..] - ETA: 0s - loss: 1.4060 - mse: 1.3867\n",
      "Epoch 00001: val_loss improved from inf to 1.40933, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e001_vl1.409.h5\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.4059 - mse: 1.3866 - val_loss: 1.4093 - val_mse: 1.3899\n",
      "Epoch 2/25\n",
      "100/102 [============================>.] - ETA: 0s - loss: 1.4063 - mse: 1.3869\n",
      "Epoch 00002: val_loss improved from 1.40933 to 1.40916, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e002_vl1.409.h5\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.4059 - mse: 1.3865 - val_loss: 1.4092 - val_mse: 1.3898\n",
      "Epoch 3/25\n",
      " 95/102 [==========================>...] - ETA: 0s - loss: 1.4068 - mse: 1.3875\n",
      "Epoch 00003: val_loss did not improve from 1.40916\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.4059 - mse: 1.3865 - val_loss: 1.4092 - val_mse: 1.3898\n",
      "Epoch 4/25\n",
      "100/102 [============================>.] - ETA: 0s - loss: 1.4055 - mse: 1.3861\n",
      "Epoch 00004: val_loss did not improve from 1.40916\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.4057 - mse: 1.3863 - val_loss: 1.4096 - val_mse: 1.3902\n",
      "Epoch 5/25\n",
      " 92/102 [==========================>...] - ETA: 0s - loss: 1.4058 - mse: 1.3865\n",
      "Epoch 00005: val_loss did not improve from 1.40916\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.4057 - mse: 1.3864 - val_loss: 1.4092 - val_mse: 1.3899\n",
      "Epoch 6/25\n",
      "101/102 [============================>.] - ETA: 0s - loss: 1.4055 - mse: 1.3861\n",
      "Epoch 00006: val_loss improved from 1.40916 to 1.40910, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e006_vl1.409.h5\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.4056 - mse: 1.3862 - val_loss: 1.4091 - val_mse: 1.3897\n",
      "Epoch 7/25\n",
      " 94/102 [==========================>...] - ETA: 0s - loss: 1.4063 - mse: 1.3869\n",
      "Epoch 00007: val_loss did not improve from 1.40910\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.4055 - mse: 1.3861 - val_loss: 1.4093 - val_mse: 1.3900\n",
      "Epoch 8/25\n",
      " 98/102 [===========================>..] - ETA: 0s - loss: 1.4071 - mse: 1.3877\n",
      "Epoch 00008: val_loss improved from 1.40910 to 1.40903, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e008_vl1.409.h5\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.4056 - mse: 1.3862 - val_loss: 1.4090 - val_mse: 1.3897\n",
      "Epoch 9/25\n",
      " 97/102 [===========================>..] - ETA: 0s - loss: 1.4072 - mse: 1.3878\n",
      "Epoch 00009: val_loss did not improve from 1.40903\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.4056 - mse: 1.3862 - val_loss: 1.4093 - val_mse: 1.3899\n",
      "Epoch 10/25\n",
      "100/102 [============================>.] - ETA: 0s - loss: 1.4053 - mse: 1.3859\n",
      "Epoch 00010: val_loss improved from 1.40903 to 1.40886, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e010_vl1.409.h5\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.4054 - mse: 1.3861 - val_loss: 1.4089 - val_mse: 1.3895\n",
      "Epoch 11/25\n",
      " 91/102 [=========================>....] - ETA: 0s - loss: 1.4039 - mse: 1.3846\n",
      "Epoch 00011: val_loss did not improve from 1.40886\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.4054 - mse: 1.3860 - val_loss: 1.4093 - val_mse: 1.3900\n",
      "Epoch 12/25\n",
      " 91/102 [=========================>....] - ETA: 0s - loss: 1.4078 - mse: 1.3884\n",
      "Epoch 00012: val_loss did not improve from 1.40886\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.4054 - mse: 1.3861 - val_loss: 1.4093 - val_mse: 1.3899\n",
      "Epoch 13/25\n",
      " 94/102 [==========================>...] - ETA: 0s - loss: 1.4046 - mse: 1.3853\n",
      "Epoch 00013: val_loss improved from 1.40886 to 1.40886, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e013_vl1.409.h5\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 1.4054 - mse: 1.3860 - val_loss: 1.4089 - val_mse: 1.3895\n",
      "Epoch 14/25\n",
      " 96/102 [===========================>..] - ETA: 0s - loss: 1.4045 - mse: 1.3851\n",
      "Epoch 00014: val_loss did not improve from 1.40886\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.4053 - mse: 1.3860 - val_loss: 1.4093 - val_mse: 1.3899\n",
      "Epoch 15/25\n",
      " 97/102 [===========================>..] - ETA: 0s - loss: 1.4054 - mse: 1.3860\n",
      "Epoch 00015: val_loss did not improve from 1.40886\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.4054 - mse: 1.3860 - val_loss: 1.4091 - val_mse: 1.3897\n",
      "Epoch 16/25\n",
      "100/102 [============================>.] - ETA: 0s - loss: 1.4051 - mse: 1.3857\n",
      "Epoch 00016: val_loss improved from 1.40886 to 1.40867, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e016_vl1.409.h5\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.4053 - mse: 1.3860 - val_loss: 1.4087 - val_mse: 1.3893\n",
      "Epoch 17/25\n",
      " 94/102 [==========================>...] - ETA: 0s - loss: 1.4052 - mse: 1.3858\n",
      "Epoch 00017: val_loss improved from 1.40867 to 1.40863, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e017_vl1.409.h5\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.4052 - mse: 1.3859 - val_loss: 1.4086 - val_mse: 1.3893\n",
      "Epoch 18/25\n",
      " 93/102 [==========================>...] - ETA: 0s - loss: 1.4060 - mse: 1.3866\n",
      "Epoch 00018: val_loss improved from 1.40863 to 1.40857, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e018_vl1.409.h5\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 1.4053 - mse: 1.3859 - val_loss: 1.4086 - val_mse: 1.3892\n",
      "Epoch 19/25\n",
      "100/102 [============================>.] - ETA: 0s - loss: 1.4054 - mse: 1.3860\n",
      "Epoch 00019: val_loss did not improve from 1.40857\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.4052 - mse: 1.3858 - val_loss: 1.4086 - val_mse: 1.3893\n",
      "Epoch 20/25\n",
      "102/102 [==============================] - ETA: 0s - loss: 1.4053 - mse: 1.3860\n",
      "Epoch 00020: val_loss did not improve from 1.40857\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.4053 - mse: 1.3860 - val_loss: 1.4086 - val_mse: 1.3893\n",
      "Epoch 21/25\n",
      "102/102 [==============================] - ETA: 0s - loss: 1.4052 - mse: 1.3858\n",
      "Epoch 00021: val_loss did not improve from 1.40857\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.4052 - mse: 1.3858 - val_loss: 1.4086 - val_mse: 1.3893\n",
      "Epoch 22/25\n",
      " 96/102 [===========================>..] - ETA: 0s - loss: 1.4036 - mse: 1.3843\n",
      "Epoch 00022: val_loss did not improve from 1.40857\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.4051 - mse: 1.3857 - val_loss: 1.4087 - val_mse: 1.3894\n",
      "Epoch 23/25\n",
      "101/102 [============================>.] - ETA: 0s - loss: 1.4050 - mse: 1.3857\n",
      "Epoch 00023: val_loss did not improve from 1.40857\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.4050 - mse: 1.3857 - val_loss: 1.4089 - val_mse: 1.3896\n",
      "Epoch 24/25\n",
      " 90/102 [=========================>....] - ETA: 0s - loss: 1.4061 - mse: 1.3868\n",
      "Epoch 00024: val_loss did not improve from 1.40857\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.4050 - mse: 1.3857 - val_loss: 1.4090 - val_mse: 1.3896\n",
      "Epoch 25/25\n",
      "101/102 [============================>.] - ETA: 0s - loss: 1.4057 - mse: 1.3864\n",
      "Epoch 00025: val_loss improved from 1.40857 to 1.40837, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e025_vl1.408.h5\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.4052 - mse: 1.3858 - val_loss: 1.4084 - val_mse: 1.3890\n",
      "Time elapsed to train: 15.35 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 224.8165     59.115944  133.97032  ...   10.445589   51.278496\n",
      " 2415.9473  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00955\n",
      "  1% : 0.168\n",
      "  10% : 0.544\n",
      "  50% : 3.75\n",
      "  90% : 45.9\n",
      "  99% : 423\n",
      "  100% : 1.15e+04\n",
      "<chi^2/d.o.f.> = 2.89\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 109451 stars (43.3%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  34.1457     76.14397  1043.7365   ...  669.7727     33.887505\n",
      "   69.62698 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0352\n",
      "  1% : 0.167\n",
      "  10% : 0.541\n",
      "  50% : 3.7\n",
      "  90% : 45\n",
      "  99% : 425\n",
      "  100% : 5.25e+03\n",
      "<chi^2/d.o.f.> = 2.87\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 66.38 s\n",
      "learning rate = 4.978706783731468e-05\n",
      "setting learning rate to 4.0762203978366214e-05\n",
      "Iteration 17 of 20.\n",
      "Epoch 1/25\n",
      " 99/102 [============================>.] - ETA: 0s - loss: 1.3986 - mse: 1.3793\n",
      "Epoch 00001: val_loss improved from inf to 1.40339, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e001_vl1.403.h5\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3984 - mse: 1.3791 - val_loss: 1.4034 - val_mse: 1.3841\n",
      "Epoch 2/25\n",
      " 95/102 [==========================>...] - ETA: 0s - loss: 1.3985 - mse: 1.3792\n",
      "Epoch 00002: val_loss improved from 1.40339 to 1.40311, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e002_vl1.403.h5\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3985 - mse: 1.3792 - val_loss: 1.4031 - val_mse: 1.3838\n",
      "Epoch 3/25\n",
      " 98/102 [===========================>..] - ETA: 0s - loss: 1.3978 - mse: 1.3785\n",
      "Epoch 00003: val_loss did not improve from 1.40311\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.3983 - mse: 1.3789 - val_loss: 1.4032 - val_mse: 1.3839\n",
      "Epoch 4/25\n",
      " 93/102 [==========================>...] - ETA: 0s - loss: 1.3983 - mse: 1.3790\n",
      "Epoch 00004: val_loss did not improve from 1.40311\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3983 - mse: 1.3790 - val_loss: 1.4033 - val_mse: 1.3840\n",
      "Epoch 5/25\n",
      " 98/102 [===========================>..] - ETA: 0s - loss: 1.3985 - mse: 1.3792\n",
      "Epoch 00005: val_loss improved from 1.40311 to 1.40305, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e005_vl1.403.h5\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3983 - mse: 1.3790 - val_loss: 1.4030 - val_mse: 1.3837\n",
      "Epoch 6/25\n",
      " 91/102 [=========================>....] - ETA: 0s - loss: 1.3992 - mse: 1.3799\n",
      "Epoch 00006: val_loss did not improve from 1.40305\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3983 - mse: 1.3790 - val_loss: 1.4032 - val_mse: 1.3838\n",
      "Epoch 7/25\n",
      " 96/102 [===========================>..] - ETA: 0s - loss: 1.3994 - mse: 1.3801\n",
      "Epoch 00007: val_loss improved from 1.40305 to 1.40298, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e007_vl1.403.h5\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3983 - mse: 1.3790 - val_loss: 1.4030 - val_mse: 1.3837\n",
      "Epoch 8/25\n",
      " 91/102 [=========================>....] - ETA: 0s - loss: 1.3986 - mse: 1.3792\n",
      "Epoch 00008: val_loss did not improve from 1.40298\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3981 - mse: 1.3788 - val_loss: 1.4036 - val_mse: 1.3843\n",
      "Epoch 9/25\n",
      " 97/102 [===========================>..] - ETA: 0s - loss: 1.3989 - mse: 1.3796\n",
      "Epoch 00009: val_loss did not improve from 1.40298\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.3982 - mse: 1.3789 - val_loss: 1.4030 - val_mse: 1.3837\n",
      "Epoch 10/25\n",
      " 99/102 [============================>.] - ETA: 0s - loss: 1.3986 - mse: 1.3793\n",
      "Epoch 00010: val_loss did not improve from 1.40298\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.3981 - mse: 1.3788 - val_loss: 1.4032 - val_mse: 1.3839\n",
      "Epoch 11/25\n",
      "100/102 [============================>.] - ETA: 0s - loss: 1.3980 - mse: 1.3787\n",
      "Epoch 00011: val_loss did not improve from 1.40298\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.3982 - mse: 1.3789 - val_loss: 1.4030 - val_mse: 1.3837\n",
      "Epoch 12/25\n",
      " 97/102 [===========================>..] - ETA: 0s - loss: 1.3974 - mse: 1.3781\n",
      "Epoch 00012: val_loss improved from 1.40298 to 1.40288, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e012_vl1.403.h5\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3982 - mse: 1.3789 - val_loss: 1.4029 - val_mse: 1.3836\n",
      "Epoch 13/25\n",
      " 92/102 [==========================>...] - ETA: 0s - loss: 1.4002 - mse: 1.3809\n",
      "Epoch 00013: val_loss did not improve from 1.40288\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3980 - mse: 1.3787 - val_loss: 1.4032 - val_mse: 1.3839\n",
      "Epoch 14/25\n",
      " 99/102 [============================>.] - ETA: 0s - loss: 1.3975 - mse: 1.3782\n",
      "Epoch 00014: val_loss did not improve from 1.40288\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.3980 - mse: 1.3787 - val_loss: 1.4031 - val_mse: 1.3838\n",
      "Epoch 15/25\n",
      " 95/102 [==========================>...] - ETA: 0s - loss: 1.3987 - mse: 1.3794\n",
      "Epoch 00015: val_loss improved from 1.40288 to 1.40275, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e015_vl1.403.h5\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3980 - mse: 1.3787 - val_loss: 1.4028 - val_mse: 1.3835\n",
      "Epoch 16/25\n",
      "100/102 [============================>.] - ETA: 0s - loss: 1.3975 - mse: 1.3782\n",
      "Epoch 00016: val_loss did not improve from 1.40275\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.3979 - mse: 1.3786 - val_loss: 1.4030 - val_mse: 1.3837\n",
      "Epoch 17/25\n",
      " 99/102 [============================>.] - ETA: 0s - loss: 1.3967 - mse: 1.3774\n",
      "Epoch 00017: val_loss did not improve from 1.40275\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.3979 - mse: 1.3786 - val_loss: 1.4028 - val_mse: 1.3836\n",
      "Epoch 18/25\n",
      " 98/102 [===========================>..] - ETA: 0s - loss: 1.3977 - mse: 1.3784\n",
      "Epoch 00018: val_loss did not improve from 1.40275\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.3978 - mse: 1.3786 - val_loss: 1.4030 - val_mse: 1.3838\n",
      "Epoch 19/25\n",
      "101/102 [============================>.] - ETA: 0s - loss: 1.3979 - mse: 1.3786\n",
      "Epoch 00019: val_loss improved from 1.40275 to 1.40258, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e019_vl1.403.h5\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3979 - mse: 1.3786 - val_loss: 1.4026 - val_mse: 1.3833\n",
      "Epoch 20/25\n",
      " 91/102 [=========================>....] - ETA: 0s - loss: 1.3992 - mse: 1.3799\n",
      "Epoch 00020: val_loss did not improve from 1.40258\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3978 - mse: 1.3785 - val_loss: 1.4028 - val_mse: 1.3835\n",
      "Epoch 21/25\n",
      " 94/102 [==========================>...] - ETA: 0s - loss: 1.3972 - mse: 1.3780\n",
      "Epoch 00021: val_loss did not improve from 1.40258\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3978 - mse: 1.3786 - val_loss: 1.4026 - val_mse: 1.3833\n",
      "Epoch 22/25\n",
      " 94/102 [==========================>...] - ETA: 0s - loss: 1.3966 - mse: 1.3773\n",
      "Epoch 00022: val_loss did not improve from 1.40258\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3978 - mse: 1.3785 - val_loss: 1.4032 - val_mse: 1.3839\n",
      "Epoch 23/25\n",
      "100/102 [============================>.] - ETA: 0s - loss: 1.3980 - mse: 1.3787\n",
      "Epoch 00023: val_loss improved from 1.40258 to 1.40253, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e023_vl1.403.h5\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3977 - mse: 1.3784 - val_loss: 1.4025 - val_mse: 1.3833\n",
      "Epoch 24/25\n",
      " 97/102 [===========================>..] - ETA: 0s - loss: 1.3973 - mse: 1.3780\n",
      "Epoch 00024: val_loss did not improve from 1.40253\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3978 - mse: 1.3785 - val_loss: 1.4025 - val_mse: 1.3833\n",
      "Epoch 25/25\n",
      " 98/102 [===========================>..] - ETA: 0s - loss: 1.3982 - mse: 1.3790\n",
      "Epoch 00025: val_loss did not improve from 1.40253\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3977 - mse: 1.3784 - val_loss: 1.4025 - val_mse: 1.3833\n",
      "Time elapsed to train: 14.70 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 228.04312     57.99933    144.1171    ...   10.2563305   51.501755\n",
      " 2503.4543   ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00845\n",
      "  1% : 0.167\n",
      "  10% : 0.543\n",
      "  50% : 3.77\n",
      "  90% : 46.9\n",
      "  99% : 432\n",
      "  100% : 1.12e+04\n",
      "<chi^2/d.o.f.> = 2.89\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 109807 stars (43.4%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  33.44894    77.801605 1074.1077   ...  682.09595    32.680195\n",
      "   76.8698  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0382\n",
      "  1% : 0.165\n",
      "  10% : 0.54\n",
      "  50% : 3.72\n",
      "  90% : 45.8\n",
      "  99% : 433\n",
      "  100% : 5.25e+03\n",
      "<chi^2/d.o.f.> = 2.86\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 61.56 s\n",
      "learning rate = 4.076220284332521e-05\n",
      "setting learning rate to 3.337326996032607e-05\n",
      "Iteration 18 of 20.\n",
      "Epoch 1/25\n",
      "101/102 [============================>.] - ETA: 0s - loss: 1.3959 - mse: 1.3766\n",
      "Epoch 00001: val_loss improved from inf to 1.40152, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e001_vl1.402.h5\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 1.3959 - mse: 1.3767 - val_loss: 1.4015 - val_mse: 1.3823\n",
      "Epoch 2/25\n",
      " 91/102 [=========================>....] - ETA: 0s - loss: 1.3939 - mse: 1.3746\n",
      "Epoch 00002: val_loss did not improve from 1.40152\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3957 - mse: 1.3765 - val_loss: 1.4016 - val_mse: 1.3823\n",
      "Epoch 3/25\n",
      " 95/102 [==========================>...] - ETA: 0s - loss: 1.3955 - mse: 1.3762\n",
      "Epoch 00003: val_loss did not improve from 1.40152\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3960 - mse: 1.3767 - val_loss: 1.4019 - val_mse: 1.3827\n",
      "Epoch 4/25\n",
      "100/102 [============================>.] - ETA: 0s - loss: 1.3952 - mse: 1.3760\n",
      "Epoch 00004: val_loss improved from 1.40152 to 1.40146, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e004_vl1.401.h5\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3958 - mse: 1.3766 - val_loss: 1.4015 - val_mse: 1.3822\n",
      "Epoch 5/25\n",
      " 96/102 [===========================>..] - ETA: 0s - loss: 1.3951 - mse: 1.3758\n",
      "Epoch 00005: val_loss did not improve from 1.40146\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3958 - mse: 1.3765 - val_loss: 1.4015 - val_mse: 1.3822\n",
      "Epoch 6/25\n",
      "101/102 [============================>.] - ETA: 0s - loss: 1.3957 - mse: 1.3764\n",
      "Epoch 00006: val_loss did not improve from 1.40146\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3957 - mse: 1.3765 - val_loss: 1.4018 - val_mse: 1.3825\n",
      "Epoch 7/25\n",
      " 98/102 [===========================>..] - ETA: 0s - loss: 1.3955 - mse: 1.3763\n",
      "Epoch 00007: val_loss did not improve from 1.40146\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3958 - mse: 1.3765 - val_loss: 1.4015 - val_mse: 1.3823\n",
      "Epoch 8/25\n",
      " 93/102 [==========================>...] - ETA: 0s - loss: 1.3943 - mse: 1.3750\n",
      "Epoch 00008: val_loss improved from 1.40146 to 1.40119, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e008_vl1.401.h5\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3957 - mse: 1.3765 - val_loss: 1.4012 - val_mse: 1.3819\n",
      "Epoch 9/25\n",
      " 97/102 [===========================>..] - ETA: 0s - loss: 1.3962 - mse: 1.3770\n",
      "Epoch 00009: val_loss did not improve from 1.40119\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3956 - mse: 1.3763 - val_loss: 1.4017 - val_mse: 1.3825\n",
      "Epoch 10/25\n",
      " 91/102 [=========================>....] - ETA: 0s - loss: 1.3955 - mse: 1.3763\n",
      "Epoch 00010: val_loss improved from 1.40119 to 1.40115, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e010_vl1.401.h5\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3958 - mse: 1.3765 - val_loss: 1.4011 - val_mse: 1.3819\n",
      "Epoch 11/25\n",
      " 92/102 [==========================>...] - ETA: 0s - loss: 1.3948 - mse: 1.3756\n",
      "Epoch 00011: val_loss did not improve from 1.40115\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3956 - mse: 1.3763 - val_loss: 1.4012 - val_mse: 1.3819\n",
      "Epoch 12/25\n",
      "100/102 [============================>.] - ETA: 0s - loss: 1.3959 - mse: 1.3767\n",
      "Epoch 00012: val_loss did not improve from 1.40115\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.3956 - mse: 1.3763 - val_loss: 1.4015 - val_mse: 1.3823\n",
      "Epoch 13/25\n",
      " 91/102 [=========================>....] - ETA: 0s - loss: 1.3953 - mse: 1.3761\n",
      "Epoch 00013: val_loss did not improve from 1.40115\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3955 - mse: 1.3763 - val_loss: 1.4014 - val_mse: 1.3822\n",
      "Epoch 14/25\n",
      " 95/102 [==========================>...] - ETA: 0s - loss: 1.3948 - mse: 1.3756\n",
      "Epoch 00014: val_loss did not improve from 1.40115\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.3956 - mse: 1.3764 - val_loss: 1.4017 - val_mse: 1.3825\n",
      "Epoch 15/25\n",
      "102/102 [==============================] - ETA: 0s - loss: 1.3956 - mse: 1.3763\n",
      "Epoch 00015: val_loss did not improve from 1.40115\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.3956 - mse: 1.3763 - val_loss: 1.4013 - val_mse: 1.3820\n",
      "Epoch 16/25\n",
      "102/102 [==============================] - ETA: 0s - loss: 1.3954 - mse: 1.3762\n",
      "Epoch 00016: val_loss did not improve from 1.40115\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3954 - mse: 1.3762 - val_loss: 1.4014 - val_mse: 1.3822\n",
      "Epoch 17/25\n",
      " 99/102 [============================>.] - ETA: 0s - loss: 1.3957 - mse: 1.3765\n",
      "Epoch 00017: val_loss improved from 1.40115 to 1.40112, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e017_vl1.401.h5\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3955 - mse: 1.3763 - val_loss: 1.4011 - val_mse: 1.3819\n",
      "Epoch 18/25\n",
      "100/102 [============================>.] - ETA: 0s - loss: 1.3961 - mse: 1.3769\n",
      "Epoch 00018: val_loss did not improve from 1.40112\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.3955 - mse: 1.3763 - val_loss: 1.4021 - val_mse: 1.3829\n",
      "Epoch 19/25\n",
      " 92/102 [==========================>...] - ETA: 0s - loss: 1.3948 - mse: 1.3756\n",
      "Epoch 00019: val_loss did not improve from 1.40112\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3956 - mse: 1.3764 - val_loss: 1.4012 - val_mse: 1.3820\n",
      "Epoch 20/25\n",
      "101/102 [============================>.] - ETA: 0s - loss: 1.3955 - mse: 1.3763\n",
      "Epoch 00020: val_loss did not improve from 1.40112\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3955 - mse: 1.3762 - val_loss: 1.4013 - val_mse: 1.3820\n",
      "Epoch 21/25\n",
      "100/102 [============================>.] - ETA: 0s - loss: 1.3954 - mse: 1.3761\n",
      "Epoch 00021: val_loss did not improve from 1.40112\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3954 - mse: 1.3762 - val_loss: 1.4015 - val_mse: 1.3822\n",
      "Epoch 22/25\n",
      " 95/102 [==========================>...] - ETA: 0s - loss: 1.3950 - mse: 1.3758\n",
      "Epoch 00022: val_loss did not improve from 1.40112\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3955 - mse: 1.3763 - val_loss: 1.4013 - val_mse: 1.3820\n",
      "Epoch 23/25\n",
      "100/102 [============================>.] - ETA: 0s - loss: 1.3956 - mse: 1.3764\n",
      "Epoch 00023: val_loss improved from 1.40112 to 1.40105, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e023_vl1.401.h5\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3956 - mse: 1.3763 - val_loss: 1.4011 - val_mse: 1.3818\n",
      "Epoch 24/25\n",
      " 98/102 [===========================>..] - ETA: 0s - loss: 1.3953 - mse: 1.3761\n",
      "Epoch 00024: val_loss did not improve from 1.40105\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.3953 - mse: 1.3761 - val_loss: 1.4011 - val_mse: 1.3818\n",
      "Epoch 25/25\n",
      " 92/102 [==========================>...] - ETA: 0s - loss: 1.3946 - mse: 1.3753\n",
      "Epoch 00025: val_loss did not improve from 1.40105\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.3953 - mse: 1.3761 - val_loss: 1.4012 - val_mse: 1.3820\n",
      "Time elapsed to train: 15.12 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 229.42935    56.61992   153.31741  ...   10.317036   50.60215\n",
      " 2578.5547  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00941\n",
      "  1% : 0.169\n",
      "  10% : 0.544\n",
      "  50% : 3.79\n",
      "  90% : 47.8\n",
      "  99% : 439\n",
      "  100% : 1.11e+04\n",
      "<chi^2/d.o.f.> = 2.89\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 110250 stars (43.6%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  33.400948   79.16486  1104.8188   ...  689.0736     31.841719\n",
      "   82.965996]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0431\n",
      "  1% : 0.165\n",
      "  10% : 0.543\n",
      "  50% : 3.74\n",
      "  90% : 46.6\n",
      "  99% : 442\n",
      "  100% : 5.26e+03\n",
      "<chi^2/d.o.f.> = 2.85\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 65.01 s\n",
      "learning rate = 3.337327143526636e-05\n",
      "setting learning rate to 2.732372244729256e-05\n",
      "Iteration 19 of 20.\n",
      "Epoch 1/25\n",
      "101/101 [==============================] - ETA: 0s - loss: 1.3943 - mse: 1.3750\n",
      "Epoch 00001: val_loss improved from inf to 1.39995, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e001_vl1.400.h5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 1.3943 - mse: 1.3750 - val_loss: 1.4000 - val_mse: 1.3807\n",
      "Epoch 2/25\n",
      " 90/101 [=========================>....] - ETA: 0s - loss: 1.3934 - mse: 1.3742\n",
      "Epoch 00002: val_loss did not improve from 1.39995\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3942 - mse: 1.3750 - val_loss: 1.4000 - val_mse: 1.3808\n",
      "Epoch 3/25\n",
      "100/101 [============================>.] - ETA: 0s - loss: 1.3949 - mse: 1.3756\n",
      "Epoch 00003: val_loss improved from 1.39995 to 1.39983, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e003_vl1.400.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3943 - mse: 1.3751 - val_loss: 1.3998 - val_mse: 1.3806\n",
      "Epoch 4/25\n",
      "100/101 [============================>.] - ETA: 0s - loss: 1.3945 - mse: 1.3753\n",
      "Epoch 00004: val_loss improved from 1.39983 to 1.39973, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e004_vl1.400.h5\n",
      "101/101 [==============================] - 1s 8ms/step - loss: 1.3942 - mse: 1.3749 - val_loss: 1.3997 - val_mse: 1.3805\n",
      "Epoch 5/25\n",
      "101/101 [==============================] - ETA: 0s - loss: 1.3941 - mse: 1.3749\n",
      "Epoch 00005: val_loss improved from 1.39973 to 1.39968, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e005_vl1.400.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3941 - mse: 1.3749 - val_loss: 1.3997 - val_mse: 1.3805\n",
      "Epoch 6/25\n",
      " 92/101 [==========================>...] - ETA: 0s - loss: 1.3940 - mse: 1.3748\n",
      "Epoch 00006: val_loss did not improve from 1.39968\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3941 - mse: 1.3749 - val_loss: 1.3999 - val_mse: 1.3807\n",
      "Epoch 7/25\n",
      " 91/101 [==========================>...] - ETA: 0s - loss: 1.3940 - mse: 1.3748\n",
      "Epoch 00007: val_loss did not improve from 1.39968\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3941 - mse: 1.3749 - val_loss: 1.3997 - val_mse: 1.3805\n",
      "Epoch 8/25\n",
      "101/101 [==============================] - ETA: 0s - loss: 1.3941 - mse: 1.3749\n",
      "Epoch 00008: val_loss improved from 1.39968 to 1.39958, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e008_vl1.400.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3941 - mse: 1.3749 - val_loss: 1.3996 - val_mse: 1.3804\n",
      "Epoch 9/25\n",
      " 91/101 [==========================>...] - ETA: 0s - loss: 1.3934 - mse: 1.3742\n",
      "Epoch 00009: val_loss did not improve from 1.39958\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3940 - mse: 1.3748 - val_loss: 1.3996 - val_mse: 1.3804\n",
      "Epoch 10/25\n",
      "100/101 [============================>.] - ETA: 0s - loss: 1.3938 - mse: 1.3746\n",
      "Epoch 00010: val_loss improved from 1.39958 to 1.39953, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e010_vl1.400.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3940 - mse: 1.3748 - val_loss: 1.3995 - val_mse: 1.3803\n",
      "Epoch 11/25\n",
      "101/101 [==============================] - ETA: 0s - loss: 1.3940 - mse: 1.3748\n",
      "Epoch 00011: val_loss improved from 1.39953 to 1.39953, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e011_vl1.400.h5\n",
      "101/101 [==============================] - 1s 8ms/step - loss: 1.3940 - mse: 1.3748 - val_loss: 1.3995 - val_mse: 1.3803\n",
      "Epoch 12/25\n",
      " 94/101 [==========================>...] - ETA: 0s - loss: 1.3944 - mse: 1.3752\n",
      "Epoch 00012: val_loss did not improve from 1.39953\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3940 - mse: 1.3748 - val_loss: 1.3995 - val_mse: 1.3803\n",
      "Epoch 13/25\n",
      " 96/101 [===========================>..] - ETA: 0s - loss: 1.3939 - mse: 1.3747\n",
      "Epoch 00013: val_loss did not improve from 1.39953\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3940 - mse: 1.3748 - val_loss: 1.3996 - val_mse: 1.3804\n",
      "Epoch 14/25\n",
      " 93/101 [==========================>...] - ETA: 0s - loss: 1.3934 - mse: 1.3742\n",
      "Epoch 00014: val_loss improved from 1.39953 to 1.39945, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e014_vl1.399.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3940 - mse: 1.3748 - val_loss: 1.3994 - val_mse: 1.3802\n",
      "Epoch 15/25\n",
      " 92/101 [==========================>...] - ETA: 0s - loss: 1.3937 - mse: 1.3745\n",
      "Epoch 00015: val_loss did not improve from 1.39945\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3941 - mse: 1.3749 - val_loss: 1.3996 - val_mse: 1.3804\n",
      "Epoch 16/25\n",
      " 99/101 [============================>.] - ETA: 0s - loss: 1.3945 - mse: 1.3753\n",
      "Epoch 00016: val_loss did not improve from 1.39945\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3940 - mse: 1.3748 - val_loss: 1.3995 - val_mse: 1.3803\n",
      "Epoch 17/25\n",
      " 94/101 [==========================>...] - ETA: 0s - loss: 1.3947 - mse: 1.3755\n",
      "Epoch 00017: val_loss did not improve from 1.39945\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3939 - mse: 1.3747 - val_loss: 1.3995 - val_mse: 1.3803\n",
      "Epoch 18/25\n",
      " 98/101 [============================>.] - ETA: 0s - loss: 1.3942 - mse: 1.3750\n",
      "Epoch 00018: val_loss did not improve from 1.39945\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3939 - mse: 1.3747 - val_loss: 1.3995 - val_mse: 1.3803\n",
      "Epoch 19/25\n",
      " 94/101 [==========================>...] - ETA: 0s - loss: 1.3941 - mse: 1.3749\n",
      "Epoch 00019: val_loss did not improve from 1.39945\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3939 - mse: 1.3747 - val_loss: 1.3997 - val_mse: 1.3805\n",
      "Epoch 20/25\n",
      " 99/101 [============================>.] - ETA: 0s - loss: 1.3943 - mse: 1.3751\n",
      "Epoch 00020: val_loss did not improve from 1.39945\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3940 - mse: 1.3748 - val_loss: 1.3995 - val_mse: 1.3803\n",
      "Epoch 21/25\n",
      " 92/101 [==========================>...] - ETA: 0s - loss: 1.3960 - mse: 1.3768\n",
      "Epoch 00021: val_loss did not improve from 1.39945\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3939 - mse: 1.3747 - val_loss: 1.3998 - val_mse: 1.3806\n",
      "Epoch 22/25\n",
      " 93/101 [==========================>...] - ETA: 0s - loss: 1.3939 - mse: 1.3747\n",
      "Epoch 00022: val_loss did not improve from 1.39945\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3939 - mse: 1.3747 - val_loss: 1.3994 - val_mse: 1.3803\n",
      "Epoch 23/25\n",
      " 91/101 [==========================>...] - ETA: 0s - loss: 1.3938 - mse: 1.3746\n",
      "Epoch 00023: val_loss did not improve from 1.39945\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3938 - mse: 1.3746 - val_loss: 1.3996 - val_mse: 1.3804\n",
      "Epoch 24/25\n",
      "101/101 [==============================] - ETA: 0s - loss: 1.3939 - mse: 1.3747\n",
      "Epoch 00024: val_loss improved from 1.39945 to 1.39944, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e024_vl1.399.h5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 1.3939 - mse: 1.3747 - val_loss: 1.3994 - val_mse: 1.3803\n",
      "Epoch 25/25\n",
      " 90/101 [=========================>....] - ETA: 0s - loss: 1.3939 - mse: 1.3747\n",
      "Epoch 00025: val_loss improved from 1.39944 to 1.39940, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e025_vl1.399.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3939 - mse: 1.3747 - val_loss: 1.3994 - val_mse: 1.3802\n",
      "Time elapsed to train: 15.89 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 231.38676    56.70578   162.52539  ...   10.260039   51.0518\n",
      " 2669.6948  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0083\n",
      "  1% : 0.167\n",
      "  10% : 0.545\n",
      "  50% : 3.82\n",
      "  90% : 49\n",
      "  99% : 446\n",
      "  100% : 1.1e+04\n",
      "<chi^2/d.o.f.> = 2.89\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 110799 stars (43.8%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  33.2252     80.50551  1142.1526   ...  694.42236    31.146387\n",
      "   90.18651 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0416\n",
      "  1% : 0.163\n",
      "  10% : 0.543\n",
      "  50% : 3.78\n",
      "  90% : 47.9\n",
      "  99% : 451\n",
      "  100% : 5.26e+03\n",
      "<chi^2/d.o.f.> = 2.86\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 64.61 s\n",
      "learning rate = 2.732372195168864e-05\n",
      "setting learning rate to 2.2370771856165592e-05\n",
      "Iteration 20 of 20.\n",
      "Epoch 1/25\n",
      " 98/101 [============================>.] - ETA: 0s - loss: 1.3954 - mse: 1.3763\n",
      "Epoch 00001: val_loss improved from inf to 1.40106, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e001_vl1.401.h5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 1.3951 - mse: 1.3759 - val_loss: 1.4011 - val_mse: 1.3819\n",
      "Epoch 2/25\n",
      " 92/101 [==========================>...] - ETA: 0s - loss: 1.3949 - mse: 1.3757\n",
      "Epoch 00002: val_loss improved from 1.40106 to 1.40097, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e002_vl1.401.h5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 1.3950 - mse: 1.3759 - val_loss: 1.4010 - val_mse: 1.3818\n",
      "Epoch 3/25\n",
      " 91/101 [==========================>...] - ETA: 0s - loss: 1.3968 - mse: 1.3776\n",
      "Epoch 00003: val_loss did not improve from 1.40097\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3950 - mse: 1.3759 - val_loss: 1.4011 - val_mse: 1.3819\n",
      "Epoch 4/25\n",
      " 92/101 [==========================>...] - ETA: 0s - loss: 1.3958 - mse: 1.3766\n",
      "Epoch 00004: val_loss did not improve from 1.40097\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3950 - mse: 1.3758 - val_loss: 1.4013 - val_mse: 1.3821\n",
      "Epoch 5/25\n",
      " 98/101 [============================>.] - ETA: 0s - loss: 1.3952 - mse: 1.3760\n",
      "Epoch 00005: val_loss improved from 1.40097 to 1.40095, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e005_vl1.401.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3951 - mse: 1.3759 - val_loss: 1.4010 - val_mse: 1.3818\n",
      "Epoch 6/25\n",
      " 92/101 [==========================>...] - ETA: 0s - loss: 1.3947 - mse: 1.3755\n",
      "Epoch 00006: val_loss improved from 1.40095 to 1.40092, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e006_vl1.401.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3950 - mse: 1.3758 - val_loss: 1.4009 - val_mse: 1.3817\n",
      "Epoch 7/25\n",
      "101/101 [==============================] - ETA: 0s - loss: 1.3950 - mse: 1.3758\n",
      "Epoch 00007: val_loss did not improve from 1.40092\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 1.3950 - mse: 1.3758 - val_loss: 1.4011 - val_mse: 1.3819\n",
      "Epoch 8/25\n",
      " 95/101 [===========================>..] - ETA: 0s - loss: 1.3946 - mse: 1.3754\n",
      "Epoch 00008: val_loss improved from 1.40092 to 1.40089, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e008_vl1.401.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3949 - mse: 1.3758 - val_loss: 1.4009 - val_mse: 1.3817\n",
      "Epoch 9/25\n",
      " 97/101 [===========================>..] - ETA: 0s - loss: 1.3943 - mse: 1.3751\n",
      "Epoch 00009: val_loss did not improve from 1.40089\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3949 - mse: 1.3758 - val_loss: 1.4009 - val_mse: 1.3818\n",
      "Epoch 10/25\n",
      " 93/101 [==========================>...] - ETA: 0s - loss: 1.3952 - mse: 1.3760\n",
      "Epoch 00010: val_loss improved from 1.40089 to 1.40081, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e010_vl1.401.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3949 - mse: 1.3758 - val_loss: 1.4008 - val_mse: 1.3816\n",
      "Epoch 11/25\n",
      " 95/101 [===========================>..] - ETA: 0s - loss: 1.3942 - mse: 1.3750\n",
      "Epoch 00011: val_loss did not improve from 1.40081\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3950 - mse: 1.3758 - val_loss: 1.4008 - val_mse: 1.3817\n",
      "Epoch 12/25\n",
      " 97/101 [===========================>..] - ETA: 0s - loss: 1.3951 - mse: 1.3759\n",
      "Epoch 00012: val_loss did not improve from 1.40081\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3948 - mse: 1.3757 - val_loss: 1.4009 - val_mse: 1.3817\n",
      "Epoch 13/25\n",
      " 96/101 [===========================>..] - ETA: 0s - loss: 1.3949 - mse: 1.3758\n",
      "Epoch 00013: val_loss did not improve from 1.40081\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3949 - mse: 1.3757 - val_loss: 1.4009 - val_mse: 1.3818\n",
      "Epoch 14/25\n",
      " 99/101 [============================>.] - ETA: 0s - loss: 1.3946 - mse: 1.3755\n",
      "Epoch 00014: val_loss did not improve from 1.40081\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3949 - mse: 1.3757 - val_loss: 1.4008 - val_mse: 1.3817\n",
      "Epoch 15/25\n",
      "100/101 [============================>.] - ETA: 0s - loss: 1.3947 - mse: 1.3756\n",
      "Epoch 00015: val_loss did not improve from 1.40081\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3949 - mse: 1.3758 - val_loss: 1.4009 - val_mse: 1.3817\n",
      "Epoch 16/25\n",
      "100/101 [============================>.] - ETA: 0s - loss: 1.3946 - mse: 1.3754\n",
      "Epoch 00016: val_loss did not improve from 1.40081\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3949 - mse: 1.3757 - val_loss: 1.4008 - val_mse: 1.3817\n",
      "Epoch 17/25\n",
      " 97/101 [===========================>..] - ETA: 0s - loss: 1.3961 - mse: 1.3770\n",
      "Epoch 00017: val_loss did not improve from 1.40081\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3949 - mse: 1.3757 - val_loss: 1.4010 - val_mse: 1.3819\n",
      "Epoch 18/25\n",
      " 92/101 [==========================>...] - ETA: 0s - loss: 1.3938 - mse: 1.3746\n",
      "Epoch 00018: val_loss improved from 1.40081 to 1.40078, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e018_vl1.401.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3948 - mse: 1.3757 - val_loss: 1.4008 - val_mse: 1.3816\n",
      "Epoch 19/25\n",
      " 99/101 [============================>.] - ETA: 0s - loss: 1.3947 - mse: 1.3755\n",
      "Epoch 00019: val_loss did not improve from 1.40078\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 1.3948 - mse: 1.3756 - val_loss: 1.4008 - val_mse: 1.3817\n",
      "Epoch 20/25\n",
      "100/101 [============================>.] - ETA: 0s - loss: 1.3949 - mse: 1.3758\n",
      "Epoch 00020: val_loss improved from 1.40078 to 1.40069, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e020_vl1.401.h5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 1.3947 - mse: 1.3756 - val_loss: 1.4007 - val_mse: 1.3815\n",
      "Epoch 21/25\n",
      " 97/101 [===========================>..] - ETA: 0s - loss: 1.3953 - mse: 1.3761\n",
      "Epoch 00021: val_loss improved from 1.40069 to 1.40067, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e021_vl1.401.h5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 1.3947 - mse: 1.3756 - val_loss: 1.4007 - val_mse: 1.3815\n",
      "Epoch 22/25\n",
      " 96/101 [===========================>..] - ETA: 0s - loss: 1.3948 - mse: 1.3756\n",
      "Epoch 00022: val_loss did not improve from 1.40067\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3947 - mse: 1.3756 - val_loss: 1.4007 - val_mse: 1.3816\n",
      "Epoch 23/25\n",
      " 90/101 [=========================>....] - ETA: 0s - loss: 1.3942 - mse: 1.3750\n",
      "Epoch 00023: val_loss did not improve from 1.40067\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3947 - mse: 1.3756 - val_loss: 1.4008 - val_mse: 1.3817\n",
      "Epoch 24/25\n",
      " 95/101 [===========================>..] - ETA: 0s - loss: 1.3953 - mse: 1.3762\n",
      "Epoch 00024: val_loss did not improve from 1.40067\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.3948 - mse: 1.3756 - val_loss: 1.4008 - val_mse: 1.3816\n",
      "Epoch 25/25\n",
      "101/101 [==============================] - ETA: 0s - loss: 1.3948 - mse: 1.3756\n",
      "Epoch 00025: val_loss did not improve from 1.40067\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 1.3948 - mse: 1.3756 - val_loss: 1.4009 - val_mse: 1.3818\n",
      "Time elapsed to train: 15.63 s\n"
     ]
    }
   ],
   "source": [
    "for k in range(0, n_iterations):\n",
    "    # Transform data to inputs and outputs\n",
    "    # On subsequent iterations, inflate errors using\n",
    "    # gradients dM/dtheta from trained model, and derive new\n",
    "    # estimates of the reddenings of the stars.\n",
    "    t0 = time()\n",
    "    io_train = get_inputs_outputs(\n",
    "        d_train,\n",
    "        pretrained_model=None if k == 0 else nn_model,\n",
    "        recalc_reddening=True,\n",
    "        rchisq_max=rchisq_max[k]\n",
    "    )\n",
    "    io_test = get_inputs_outputs(\n",
    "        d_test,\n",
    "        pretrained_model=None if k == 0 else nn_model,\n",
    "        recalc_reddening=True,\n",
    "    )\n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to prepare data: {t1-t0:.2f} s')\n",
    "\n",
    "    # Set learning rate based on the iteration\n",
    "    lr = 0.001 * np.exp(-0.2*k)\n",
    "    print('learning rate = {}'.format(K.get_value(nn_model.optimizer.lr)))\n",
    "    print('setting learning rate to {}'.format(lr))\n",
    "    K.set_value(nn_model.optimizer.lr, lr)\n",
    "\n",
    "    # Train the model\n",
    "    print('Iteration {} of {}.'.format(k+1, n_iterations))\n",
    "    t0 = time()\n",
    "    train_model(\n",
    "        nn_model,\n",
    "        io_train,\n",
    "        epochs=25,\n",
    "        checkpoint_fn='{:s}_{:d}hidden_it{:d}'.format(\n",
    "            nn_name, n_hidden, k\n",
    "        ),\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to train: {t1-t0:.2f} s')\n",
    "    nn_model.save(\n",
    "        'models/{:s}_{:d}hidden_it{:d}.h5'.format(\n",
    "            nn_name, n_hidden, k\n",
    "        )\n",
    "    )\n",
    "    #nn_model = keras.models.load_model(\n",
    "    #    'models/{:s}_{:d}hidden_it{:d}.h5'.format(nn_name, n_hidden, k)\n",
    "    #)\n",
    "\n",
    "    # Plot results on test set\n",
    "    #print('Diagnostic plots ...')\n",
    "    #t0 = time()\n",
    "    #diagnostic_plots(\n",
    "    #    nn_model,\n",
    "    #    io_test,\n",
    "    #    d_test,\n",
    "    #    #io_train,\n",
    "    #    #d_train,\n",
    "    #    suffix='{:s}_{:d}hidden_it{:d}'.format(nn_name, n_hidden, k)\n",
    "    #)\n",
    "    #t1 = time()\n",
    "    #print(f'Time elapsed to make plots: {t1-t0:.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f1d8de09-5d9d-43a1-b6ad-5aa70393a40a",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating covariances and reddening estimates of test dataset ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  33.179718   80.97002  1176.9143   ...  696.01025    30.862041\n",
      "   95.74382 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0385\n",
      "  1% : 0.163\n",
      "  10% : 0.541\n",
      "  50% : 3.81\n",
      "  90% : 48.7\n",
      "  99% : 460\n",
      "  100% : 5.26e+03\n",
      "<chi^2/d.o.f.> = 2.86\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to update covariances and reddenings: 7.33 s\n"
     ]
    }
   ],
   "source": [
    "print('Updating covariances and reddening estimates of test dataset ...')\n",
    "t0 = time()\n",
    "io_test = get_inputs_outputs(\n",
    "    d_test,\n",
    "    pretrained_model=nn_model,\n",
    "    recalc_reddening=True\n",
    ")\n",
    "t1 = time()\n",
    "print(f'Time elapsed to update covariances and reddenings: {t1-t0:.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0fe20ad0-6076-42e4-b5fa-0a8b44b55833",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: [1.3983372449874878, 1.3791974782943726]\n",
      "train loss: [1.396499752998352, 1.377360224723816]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance on (train, validation and test sets)\n",
    "loss = {}\n",
    "for n,io_eval in (('test',io_test), ('train',io_train)):\n",
    "    loss[n] = evaluate_model(\n",
    "        nn_model,\n",
    "        io_eval,\n",
    "        batch_size=batch_size,\n",
    "        rchisq_max=rchisq_max[-1]\n",
    "    )\n",
    "    print(f'{n} loss: {loss[n]}')\n",
    "fname = 'loss_{:s}_{:d}hidden_it{:d}.json'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "with open(fname, 'w') as f:\n",
    "    json.dump(loss, f, indent=2, sort_keys=True)\n",
    "\n",
    "fname = 'predictions_{:s}_{:d}hidden_it{:d}.h5'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "save_predictions(fname, nn_model, d_test, io_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ef83a49-55d7-41f4-be9e-87606f86734e",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving covariance components for small subset of test dataset ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 1000 bad. Replacing with 14.23750.\n",
      "Band 1: 0 of 1000 bad. Replacing with 14.61455.\n",
      "Band 2: 0 of 1000 bad. Replacing with 13.69537.\n",
      "Band 3: 147 of 1000 bad. Replacing with 14.96300.\n",
      "Band 4: 250 of 1000 bad. Replacing with 14.65440.\n",
      "Band 5: 310 of 1000 bad. Replacing with 14.59245.\n",
      "Band 6: 192 of 1000 bad. Replacing with 14.30900.\n",
      "Band 7: 33 of 1000 bad. Replacing with 14.03010.\n",
      "Band 8: 0 of 1000 bad. Replacing with 13.05500.\n",
      "Band 9: 1 of 1000 bad. Replacing with 15.26814.\n",
      "Band 10: 2 of 1000 bad. Replacing with 15.92215.\n",
      "Band 11: 0 of 1000 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 1000 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 1000 of 1000 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [9.13716888e+01 6.42618103e+01 1.18706102e+01 1.03794928e+01\n",
      " 2.05639362e+01 9.55473557e+01 5.75193825e+01 4.95333740e+02\n",
      " 7.02831726e+01 5.26420746e+01 6.58328247e+01 2.53678856e+01\n",
      " 1.53258575e+02 5.86977234e+01 9.43917179e+00 2.50164070e+01\n",
      " 7.79578094e+01 1.39645264e+02 2.69131927e+01 1.47729156e+02\n",
      " 2.08496552e+01 2.72572842e+01 6.86864471e+01 1.58592529e+01\n",
      " 6.49880524e+01 3.18881893e+00 5.11948364e+02 2.95638885e+02\n",
      " 2.31814079e+01 2.22297943e+02 2.77143799e+02 4.55575142e+01\n",
      " 2.92285889e+02 6.45398407e+01 6.59691763e+00 5.57684231e+00\n",
      " 2.89718475e+01 6.87730694e+00 1.22294678e+02 7.62380505e+00\n",
      " 7.04335175e+01 7.65192719e+01 3.15058250e+01 7.82743502e+00\n",
      " 1.46472225e+01 1.02021065e+02 1.78475819e+01 1.09171391e+01\n",
      " 9.98188171e+01 9.47307587e+00 6.90891838e+00 2.76970935e+00\n",
      " 1.46408939e+00 8.59034424e+01 1.72822128e+02 7.54311705e+00\n",
      " 1.17916672e+02 1.97564659e+01 2.66267151e+02 2.80606794e+00\n",
      " 8.98271255e+01 7.37679338e+00 8.13719368e+00 1.49987964e+03\n",
      " 2.85738403e+02 2.44660172e+02 1.32518501e+01 5.03256845e+00\n",
      " 8.96242493e+02 2.70586720e+01 1.01252037e+02 2.22060730e+02\n",
      " 1.84407120e+01 1.00023987e+02 2.50236320e+01 1.14073181e+02\n",
      " 8.21529602e+02 1.51448956e+01 7.83029099e+01 7.96219604e+02\n",
      " 7.43274736e+00 2.76499443e+01 1.23974104e+01 1.04351473e+01\n",
      " 2.02271004e+01 1.07185974e+02 1.69816399e+01 3.11426830e+01\n",
      " 1.16258850e+01 4.21851349e+01 9.87643433e+01 6.24334030e+01\n",
      " 2.34878807e+01 1.45187578e+01 1.01845825e+02 1.81796074e+01\n",
      " 3.96401611e+02 1.06665520e+02 3.20957794e+01 1.65296822e+01\n",
      " 4.34752007e+01 3.11240051e+02 4.67015648e+01 1.10764122e+01\n",
      " 1.32672272e+02 2.50971184e+01 1.63455017e+03 1.48108635e+01\n",
      " 4.02806580e+02 1.19686119e+02 2.73437195e+02 5.54549904e+01\n",
      " 3.40620728e+01 1.00680847e+02 9.50726776e+01 4.73485260e+01\n",
      " 2.43690338e+02 2.78548641e+01 1.07659760e+02 2.82372932e+01\n",
      " 1.95722713e+01 1.28110123e+02 4.27582979e+00 3.22256374e+00\n",
      " 5.64228973e+01 1.02404118e+01 2.29509029e+01 2.90356262e+02\n",
      " 1.31509241e+03 6.34004150e+02 6.45854139e+00 4.08450653e+02\n",
      " 5.63671684e+00 2.36417656e+01 5.80688416e+02 1.20652838e+01\n",
      " 7.72374344e+01 2.29331245e+01 4.91149216e+01 7.45073032e+00\n",
      " 5.15846348e+00 2.61683922e+01 1.00920288e+02 7.81735516e+00\n",
      " 2.19649582e+01 1.32330780e+02 1.08802277e+02 9.77502075e+02\n",
      " 4.26388702e+01 1.69796717e+00 2.34695251e+02 7.06020630e+02\n",
      " 5.11127319e+01 2.14904150e+03 9.99406052e+00 8.43907547e+00\n",
      " 2.66237068e+00 7.52977848e+00 9.95510941e+01 2.33960358e+02\n",
      " 5.50898457e+00 1.11153656e+02 4.56574402e+01 1.40952988e+02\n",
      " 2.15492020e+01 2.48675003e+01 1.46696045e+02 2.92430344e+01\n",
      " 1.17156143e+01 6.13415344e+02 5.20731735e+01 3.49988174e+01\n",
      " 1.10912075e+01 4.31506500e+02 1.03233536e+02 6.79901361e+00\n",
      " 1.61723671e+01 1.41104584e+02 2.07698803e+01 7.51222897e+00\n",
      " 1.50130585e+02 1.79339275e+01 1.58441528e+02 3.35102356e+02\n",
      " 3.45176270e+02 6.31776047e+00 2.04307098e+02 2.72726685e+02\n",
      " 3.89737129e+01 3.08157471e+02 5.63446411e+02 2.03894196e+01\n",
      " 6.22066574e+01 9.40286102e+01 6.86660957e+00 1.46920261e+01\n",
      " 1.92841980e+02 4.88818420e+02 2.78295898e+02 5.95086002e+00\n",
      " 4.29650879e+02 3.25366028e+02 4.89852905e+00 1.94470459e+02\n",
      " 3.28305817e+01 7.33729248e+01 7.29071045e+02 2.33145580e+01\n",
      " 1.48373062e+02 4.67857456e+00 3.60905552e+00 5.30014896e+00\n",
      " 1.24673281e+01 3.15396996e+01 4.23635559e+01 8.67588615e+00\n",
      " 8.12931747e+01 1.95087776e+01 3.87272186e+01 4.72019592e+02\n",
      " 1.56552782e+01 3.20048706e+02 1.32292664e+02 1.77378273e+01\n",
      " 9.97484207e+00 2.03543579e+02 4.81447067e+01 2.36797600e+01\n",
      " 1.27006462e+02 3.94823669e+02 8.06847000e+00 8.20544739e+02\n",
      " 1.74913177e+01 1.63588486e+01 1.02110128e+01 2.10234528e+01\n",
      " 5.54807816e+01 9.17256927e+01 1.66034210e+02 2.03704834e+01\n",
      " 6.67431396e+02 9.89154434e+00 6.16048145e+00 7.59012634e+02\n",
      " 1.00298233e+01 8.10427094e+01 5.81231403e+00 2.27827644e+01\n",
      " 1.21856339e+02 2.14578369e+02 5.74805307e+00 6.15819321e+01\n",
      " 2.43120232e+01 7.57609749e+00 1.44917694e+02 2.06322212e+01\n",
      " 2.60099583e+01 7.37304640e+00 2.63871704e+02 3.64368805e+02\n",
      " 1.48775848e+02 3.90968933e+01 8.97391052e+01 5.10603516e+02\n",
      " 2.40224209e+01 8.38642120e+01 3.25398636e+01 2.06234528e+02\n",
      " 3.82282867e+01 4.02958603e+01 4.38798237e+00 3.74054451e+01\n",
      " 4.94350147e+00 7.38654041e+00 6.18467789e+01 1.58442001e+01\n",
      " 7.42649384e+01 1.10327411e+00 1.61953262e+02 3.21982910e+02\n",
      " 6.02414818e+01 3.50857819e+02 8.97718525e+00 3.01031780e+01\n",
      " 5.33899612e+01 1.18328217e+02 6.06894836e+01 3.35952225e+01\n",
      " 1.00183395e+02 2.24508698e+02 8.53166138e+02 3.49639549e+01\n",
      " 2.58828106e+01 3.38978653e+01 6.52707672e+01 2.05795813e+00\n",
      " 1.58333263e+01 1.77274361e+01 7.39492569e+01 1.42446499e+01\n",
      " 5.87755318e+01 2.01840820e+02 8.76804962e+01 1.24480696e+01\n",
      " 3.88774757e+01 1.05033541e+00 4.56162781e+02 2.14875889e+00\n",
      " 3.12202118e+02 4.19445763e+01 4.36442261e+01 3.16057129e+02\n",
      " 7.98386669e+00 9.52391129e+01 5.55698586e+00 2.05498409e+01\n",
      " 1.01606588e+01 3.86192398e+01 2.31530170e+01 2.49263210e+01\n",
      " 3.43215866e+01 1.88859062e+01 8.72176056e+01 5.73386780e+02\n",
      " 2.85977554e+00 4.50313797e+01 5.93411743e+02 2.07660980e+01\n",
      " 1.74873314e+01 3.57884888e+02 2.61695343e+02 1.68669250e+02\n",
      " 5.75289392e+00 7.45225647e+02 5.25243568e+00 8.48658562e+00\n",
      " 3.46721863e+02 8.43599625e+01 8.54120350e+00 6.84600647e+02\n",
      " 2.13458252e+02 5.16769695e+00 1.12644882e+02 9.09706688e+00\n",
      " 5.40972824e+01 6.02321281e+01 4.10317566e+02 3.23484497e+02\n",
      " 1.95816223e+02 1.16119995e+01 3.30981216e+01 3.84713020e+01\n",
      " 1.01043121e+02 1.80878693e+02 6.26979248e+02 4.22604752e+01\n",
      " 4.07201653e+01 6.96010254e+02 1.28879288e+02 2.00574760e+01\n",
      " 1.33884674e+02 4.69153214e+00 1.65565735e+02 1.37747059e+01\n",
      " 1.88790009e+02 9.10835342e+01 1.39188736e+02 1.27639418e+01\n",
      " 1.76320343e+01 5.81016731e+01 8.51621628e+01 2.25158615e+01\n",
      " 8.89920731e+01 6.76030254e+00 6.45327072e+01 6.28305893e+01\n",
      " 2.28283806e+01 2.62140564e+02 3.80217972e+01 3.55669403e+01\n",
      " 9.34215012e+01 2.47137756e+01 1.34569366e+02 4.68520203e+01\n",
      " 7.46421051e+01 1.02857208e+02 2.78473740e+01 1.74899445e+01\n",
      " 2.81285858e+01 5.11420059e+01 9.69687576e+01 3.29040260e+01\n",
      " 6.65653809e+02 4.33649921e+00 3.37088699e+01 1.29215442e+03\n",
      " 1.06785812e+01 6.35903072e+00 3.43526382e+01 9.19337692e+01\n",
      " 1.00244362e+02 2.05095844e+01 6.41181107e+01 2.06253185e+01\n",
      " 4.36072601e+02 9.16703033e+01 2.28823196e+02 7.56352854e+00\n",
      " 2.63768506e+00 2.90434575e+00 1.33330505e+02 4.13033630e+02\n",
      " 5.21534042e+01 6.26597754e+03 3.52709885e+01 2.30088005e+01\n",
      " 3.88340332e+02 2.19032249e+01 5.82485046e+01 1.39424103e+02\n",
      " 1.34091759e+01 9.91658325e+01 7.37621826e+02 1.47878265e+02\n",
      " 2.01004791e+02 2.82079716e+01 1.45422363e+02 2.34590969e+01\n",
      " 1.10589352e+01 3.54563751e+02 1.21344757e+01 1.32679565e+02\n",
      " 3.23167534e+01 3.61993225e+02 3.01309937e+02 1.19434605e+01\n",
      " 1.28939857e+01 1.63419830e+02 7.83564606e+01 5.08494186e+01\n",
      " 5.89978552e+00 8.53156128e+01 1.04916658e+01 1.40879196e+02\n",
      " 2.41024151e+01 3.41716766e+01 1.16247721e+01 2.56143832e+00\n",
      " 5.59672394e+01 4.45124969e+02 1.24738617e+02 1.98644905e+01\n",
      " 1.35145288e+03 1.48249216e+01 7.81929169e+01 8.93175049e+01\n",
      " 1.42526627e+02 2.36436081e+01 9.49602356e+01 1.66376068e+02\n",
      " 3.57350044e+01 1.02474419e+02 2.27483902e+01 3.13172722e+01\n",
      " 9.62151794e+01 2.56882930e+00 1.80650921e+01 1.20656805e+01\n",
      " 1.80552582e+02 4.45636320e+00 1.19322205e+01 1.86933661e+00\n",
      " 5.84078331e+01 1.01374641e+02 2.87714795e+03 1.99273682e+02\n",
      " 7.54794540e+01 1.24193497e+02 2.27279053e+01 1.72870026e+02\n",
      " 2.04884491e+01 1.64552860e+01 4.24312325e+01 5.90285840e+03\n",
      " 4.07084465e+01 2.36317673e+01 9.43200989e+01 2.62552528e+01\n",
      " 3.07742493e+02 1.39695190e+02 1.23427429e+02 7.04808716e+02\n",
      " 1.09262486e+01 1.72812653e+01 3.13472843e+00 3.62821106e+02\n",
      " 1.67255192e+01 7.06059408e+00 2.80575991e+00 1.67849524e+03\n",
      " 8.00940735e+02 5.55750370e+00 1.33363556e+02 3.72185087e+00\n",
      " 1.95970192e+01 9.97757339e+00 1.88400482e+02 1.34667244e+01\n",
      " 4.01823502e+01 3.47908478e+02 1.61601953e+03 1.55492218e+02\n",
      " 1.19259310e+01 7.54427147e+00 2.04023399e+01 3.92334015e+02\n",
      " 3.32458649e+02 4.56404648e+01 2.01720886e+02 9.78448944e+01\n",
      " 5.20025206e+00 9.45022774e+00 2.24462204e+01 1.52573563e+02\n",
      " 3.88196516e+00 5.92224884e+01 6.41602783e+02 3.86705756e+00\n",
      " 1.38890152e+02 4.32950974e+01 6.83646679e+00 3.65907860e+01\n",
      " 6.82042090e+03 3.18753369e+03 9.88458633e+00 3.97184525e+01\n",
      " 3.98206210e+00 2.50967865e+01 2.07894669e+01 8.35096550e+00\n",
      " 1.18388996e+01 9.97903137e+01 3.45003853e+01 3.32344208e+01\n",
      " 5.30364876e+01 2.06501343e+03 3.65312996e+01 2.21560335e+00\n",
      " 1.01469593e+01 5.07802820e+00 9.06375790e+00 6.04981384e+01\n",
      " 8.08815994e+01 4.58171448e+02 4.08602381e+00 5.25655365e+01\n",
      " 1.62013763e+02 9.56468296e+00 7.28338013e+01 9.58449554e+01\n",
      " 2.74905777e+00 1.25967201e+02 6.48652191e+01 7.78493595e+00\n",
      " 2.05390967e+03 2.96921806e+01 8.30747032e+00 2.60296059e+01\n",
      " 3.15618286e+01 2.89214110e+00 4.26254387e+01 2.98692989e+01\n",
      " 8.12697220e+01 2.80047882e+02 1.87107986e+02 8.64523544e+01\n",
      " 5.72750511e+01 3.02830127e+03 5.39124527e+01 1.93988419e+02\n",
      " 3.29167099e+01 2.65600014e+01 5.64699316e+00 2.46967745e+00\n",
      " 1.32543573e+01 2.63277016e+01 5.24842606e+01 1.39821411e+02\n",
      " 1.82880310e+02 8.59234047e+00 3.72191238e+01 8.56478786e+00\n",
      " 1.88379097e+00 5.83839111e+02 1.10105724e+01 1.06116962e+01\n",
      " 1.25016165e+01 8.15424728e+01 8.27950821e+01 3.13607292e+01\n",
      " 7.41641846e+01 8.29835281e+01 5.55904293e+00 8.23206329e+00\n",
      " 4.61683838e+03 5.96240311e+01 5.62375450e+00 3.80302505e+01\n",
      " 1.54363613e+01 2.17862488e+02 3.71862721e+00 7.26619415e+01\n",
      " 2.52358734e+02 5.97621948e+02 3.45468292e+01 1.08460674e+01\n",
      " 1.13833649e+02 3.49187775e+01 1.79564590e+01 2.49456024e+01\n",
      " 1.35376143e+00 8.40587769e+01 1.03660259e+01 6.34226379e+01\n",
      " 3.49806885e+02 2.17893505e+00 2.28576012e+01 2.55579150e+03\n",
      " 4.94136429e+00 1.34521912e+02 1.16032639e+02 7.05759082e+03\n",
      " 1.11636324e+01 4.18865265e+02 7.68972015e+00 4.72051334e+00\n",
      " 2.43158092e+01 2.27305176e+02 5.62132549e+00 2.89845657e+01\n",
      " 5.31332779e+01 6.21027803e+00 6.68811798e+00 1.28874878e+02\n",
      " 6.87512329e+02 7.73586960e+01 8.37640381e+01 2.69845057e+00\n",
      " 1.32673750e+01 5.92640257e+00 2.46994919e+02 7.57678146e+01\n",
      " 2.76672745e+01 1.70905933e+01 1.07065144e+01 1.18579018e+02\n",
      " 2.65681494e+03 3.46425049e+02 5.90843750e+03 2.23747277e+00\n",
      " 3.59529724e+01 7.95215607e+01 1.21626991e+02 8.20676575e+01\n",
      " 1.39936554e+02 4.57357445e+01 1.00296059e+01 2.39022274e+01\n",
      " 3.03716125e+01 1.06886559e+01 1.88281751e+00 3.13703766e+01\n",
      " 8.57434235e+01 8.98979492e+01 1.51967822e+03 1.45704651e+01\n",
      " 7.68383121e+00 1.32469778e+01 1.97433081e+03 1.02179024e+02\n",
      " 1.88063889e+01 8.06605988e+01 2.92660465e+01 1.48700151e+01\n",
      " 1.15994702e+03 2.44628277e+01 3.23016907e+02 1.50150986e+01\n",
      " 3.34404984e+01 3.22939110e+01 8.40271568e+00 4.90938797e+01\n",
      " 3.10215698e+02 3.25208616e+00 1.33800049e+02 9.27350159e+01\n",
      " 3.80564499e+00 4.39848328e+00 4.83407640e+00 9.54768524e+01\n",
      " 1.61495071e+02 5.52025146e+01 9.62951050e+01 4.36484375e+02\n",
      " 1.29527466e+02 7.64682922e+02 5.69162369e+00 9.43222809e+00\n",
      " 2.13148096e+03 2.07140961e+01 5.29087906e+01 5.98710938e+02\n",
      " 1.12877609e+02 1.46570938e+02 1.30580963e+02 7.07871857e+01\n",
      " 3.01104403e+00 3.44393229e+00 7.04830360e+00 4.56725807e+01\n",
      " 1.05518250e+02 5.51247883e+00 7.89007187e+01 7.50673218e+01\n",
      " 6.66378250e+01 1.40693146e+02 1.25107775e+01 4.73596313e+02\n",
      " 8.83963928e+01 7.81028748e+01 2.67883358e+01 1.76532806e+02\n",
      " 1.00651050e+03 1.67336090e+02 1.90718903e+02 5.93618488e+00\n",
      " 2.23037834e+01 3.16078091e+01 7.26902103e+00 3.48775732e+03\n",
      " 1.05173264e+02 9.50742912e+00 1.04737062e+01 8.02313805e+00\n",
      " 4.36015747e+02 5.39864044e+01 1.34943253e+02 2.00247223e+02\n",
      " 3.01366901e+01 3.13202667e+00 1.44814224e+01 5.83802299e+01\n",
      " 1.34329853e+01 3.08942810e+02 6.47432617e+02 2.43634857e+02\n",
      " 1.88458233e+01 3.62271309e+01 3.26798615e+02 1.13572632e+02\n",
      " 5.86860886e+01 7.28693619e+01 7.66648197e+00 6.41781092e+00\n",
      " 3.13575935e+01 2.68344727e+03 1.37562046e+01 1.22569934e+03\n",
      " 4.18168640e+02 6.03059769e+01 2.18097115e+01 1.22834229e+02\n",
      " 8.47104416e+01 4.11687164e+01 3.15223328e+02 1.17563782e+03\n",
      " 7.80075359e+00 1.52897091e+01 9.35492277e-01 7.16815948e+01\n",
      " 9.21723938e+01 2.34156952e+01 1.77614777e+02 2.16361275e+01\n",
      " 8.57530212e+01 4.08313980e+01 1.00424919e+01 8.14054565e+01\n",
      " 4.10042763e+01 2.24194622e+01 5.15150909e+01 1.86755829e+01\n",
      " 4.56568298e+01 1.92352562e+01 1.20780624e+02 1.56465750e+01\n",
      " 1.27010522e+03 8.61660309e+01 1.85350990e+01 4.15335369e+00\n",
      " 6.01941223e+01 1.08152679e+02 8.25101089e+01 2.00505139e+03\n",
      " 8.71368408e+00 1.21726954e+00 4.46342926e+01 6.52014618e+01\n",
      " 2.57625427e+02 3.38060791e+02 9.23266983e+01 1.33617752e+02\n",
      " 2.42663727e+02 1.21889019e+01 1.43289061e+01 1.23124634e+02\n",
      " 5.93024902e+02 3.86250305e+02 1.25623085e+02 7.63487911e+00\n",
      " 6.73097305e+01 1.89916611e+01 7.08951294e+02 2.49928265e+01\n",
      " 3.78895187e+01 3.52883835e+01 5.53313293e+02 7.49993467e+00\n",
      " 3.07001839e+01 2.24489861e+01 7.26745758e+01 3.15024219e+03\n",
      " 1.22005798e+02 9.25400391e+01 1.41190735e+02 7.98780155e+00\n",
      " 9.75923462e+02 7.38434753e+01 6.82959127e+00 7.41853943e+01\n",
      " 3.67624207e+01 1.45794409e+03 3.20189190e+00 5.42256660e+01\n",
      " 2.69586372e+01 1.08608124e+02 1.71376038e+01 8.51679420e+00\n",
      " 6.30277977e+01 1.56588806e+02 2.87627602e+01 7.02564453e+02\n",
      " 8.95494843e+00 1.52410568e+02 2.69172607e+02 1.58923407e+01\n",
      " 3.48145813e+02 8.48787308e+00 1.95927521e+02 1.01085770e+00\n",
      " 1.40452557e+01 2.23564396e+01 4.34253311e+01 1.84661774e+02\n",
      " 1.60148468e+01 6.05716133e+01 3.65827637e+01 2.28050690e+02\n",
      " 2.69645309e+01 6.15273819e+01 4.62264709e+01 1.48029816e+02\n",
      " 2.10911345e+00 7.99239683e+00 1.12414514e+03 6.11391479e+02\n",
      " 6.17723465e+01 3.03847084e+01 2.01079315e+02 1.05375842e+03\n",
      " 2.17004272e+02 8.14218998e+00 1.41309385e+01 1.92123184e+01\n",
      " 2.85966553e+02 2.51137733e+01 2.42231750e+02 1.60033417e+01\n",
      " 4.54498566e+02 4.12219360e+02 2.07680397e+01 6.02927124e+02\n",
      " 4.10664337e+02 8.40623016e+01 1.05306225e+01 5.52706055e+03\n",
      " 1.45092010e+02 1.82014893e+02 2.15573975e+02 7.17649078e+01\n",
      " 2.14128089e+00 3.87147069e+00 2.18797803e+03 1.14126406e+01\n",
      " 3.48883591e+01 4.69606438e+01 4.12498840e+02 4.31800195e+03\n",
      " 5.54939690e+01 6.24225044e+00 2.56448250e+01 6.42170166e+02\n",
      " 7.90770245e+00 2.31142502e+01 1.37922125e+01 4.60435104e+00\n",
      " 8.83685303e+01 2.00745583e+01 8.03517723e+00 3.34931213e+02\n",
      " 5.33397770e+00 1.33008251e+01 7.54078674e+01 2.55878571e+02\n",
      " 3.54214020e+02 4.05257324e+02 2.47091732e+01 1.16855453e+02\n",
      " 3.85108490e+01 4.20812683e+01 2.73312616e+00 3.87147797e+02\n",
      " 3.23870964e+01 4.63764114e+01 3.54199562e+01 5.01348480e+02\n",
      " 4.16689825e+00 6.27515625e+02 4.40619011e+01 2.13759155e+01\n",
      " 6.58465424e+01 1.42657051e+01 7.55020046e+00 1.49759192e+03\n",
      " 2.71289795e+02 8.42443848e+01 7.11003967e+02 6.72398758e+00\n",
      " 5.17545044e+02 2.58874283e+01 2.61070337e+03 3.89191681e+02\n",
      " 4.40236378e+00 6.97696304e+00 7.77275009e+01 3.70713623e+03\n",
      " 2.54191849e+02 8.15380096e+01 2.57488785e+01 2.51309204e+02\n",
      " 6.15015793e+01 5.36083740e+02 2.22381744e+01 1.35885057e+01\n",
      " 2.21876106e+01 3.78056679e+01 1.67627025e+00 1.08294153e+03\n",
      " 1.10911415e+02 1.23887100e+01 3.73841906e+00 4.55398560e+02\n",
      " 1.50134792e+01 3.30067215e+01 3.98333883e+00 2.29995608e+00\n",
      " 2.00907745e+01 4.35446053e+01 3.91757703e+00 3.67265368e+00\n",
      " 4.74657869e+00 2.94788551e+01 4.11456833e+01 3.72722015e+01\n",
      " 1.31815002e+02 2.70361757e+00 3.95993408e+02 4.04529968e+02\n",
      " 8.75195160e+01 2.46189957e+01 5.73155594e+01 3.17204380e+00\n",
      " 6.07716255e+01 2.95978119e+02 5.67279510e+01 4.17558594e+01\n",
      " 3.68013496e+01 2.84962769e+01 7.98579502e+00 5.12365627e+00]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.078\n",
      "  1% : 0.157\n",
      "  10% : 0.516\n",
      "  50% : 4.26\n",
      "  90% : 48.3\n",
      "  99% : 380\n",
      "  100% : 882\n",
      "<chi^2/d.o.f.> = 2.86\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n"
     ]
    }
   ],
   "source": [
    "print('Saving covariance components for small subset of test dataset ...')\n",
    "# Fix random seed (same subset every run)\n",
    "np.random.seed(3)\n",
    "idx = np.arange(d_test.size)\n",
    "np.random.shuffle(idx)\n",
    "idx = idx[:1000]\n",
    "d_comp = d_test[idx]\n",
    "io_comp = get_inputs_outputs(\n",
    "    d_comp,\n",
    "    pretrained_model=nn_model,\n",
    "    recalc_reddening=True,\n",
    "    return_cov_components=True\n",
    ")\n",
    "fname = 'predictions_{:s}_{:d}hidden_it{:d}_comp.h5'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "save_predictions(fname, nn_model, d_comp, io_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6bf3ec27-6103-4713-9c21-1222e68e39f1",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data and reddening estimates of subset of test dataset ...\n"
     ]
    }
   ],
   "source": [
    "print('Saving data and reddening estimates of subset of test dataset ...')\n",
    "np.random.seed(5)\n",
    "idx = np.arange(d_test.size)\n",
    "np.random.shuffle(idx)\n",
    "idx = idx[:10000]\n",
    "d_small = d_test[idx]\n",
    "r_fit_small = io_test['r'][idx]\n",
    "r_var_small = io_test['r_var'][idx]\n",
    "fname = 'test_data_small_{:s}_{:d}hidden.h5'.format(\n",
    "    nn_name, n_hidden\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82da0ebc-697f-4f8b-ae07-05ba4f0e7217",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving subset to test_data_small_ext_0h_l1n2_2hidden.h5 ...\n"
     ]
    }
   ],
   "source": [
    "print(f'Saving subset to {fname} ...')\n",
    "with h5py.File(fname, 'w') as f:\n",
    "    dset = f.create_dataset(\n",
    "        'data',\n",
    "        data=d_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )\n",
    "    for key in d_attrs:\n",
    "        dset.attrs[key] = d_attrs[key]\n",
    "\n",
    "    # Store updated reddening estimates\n",
    "    dset = f.create_dataset(\n",
    "        'r_fit',\n",
    "        data=r_fit_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )\n",
    "    dset = f.create_dataset(\n",
    "        'r_var',\n",
    "        data=r_var_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1e2d35-b8b6-4cd8-aac9-c5615f55aec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 2,
      "defaultCellHeight": 40,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
