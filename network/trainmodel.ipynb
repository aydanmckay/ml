{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b43db49-f88d-44af-8188-9c546a2bb2e1",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "source": [
    "Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12337364-915d-45e0-aa68-ff9ad349e998",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "# # Tell Tensorflow not to allocate all GPU memory right away.\n",
    "# # This is very important in shared environments!\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU') \n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from glob import glob\n",
    "from time import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b0b4d-d609-4535-82f4-76f5979bb893",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### The dataloder used by Green+2020 which will be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f39968a5-1090-448f-a6dc-b53829db1f41",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def load_data(fname, return_attrs=False):\n",
    "    print(f'Loading {fname} ...')\n",
    "    attrs = {}\n",
    "    with h5py.File(fname, 'r') as f:\n",
    "        dset = f['io_data']\n",
    "        for key in dset.attrs.keys():\n",
    "            attrs[key] = dset.attrs[key]\n",
    "        d = dset[:]\n",
    "    \n",
    "    if return_attrs:\n",
    "        return d, attrs\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a7c2e5-f232-46ff-b235-d6604c1b5d35",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Obtaining a correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e0eccc-4ffd-4904-a210-7b430692c477",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def get_corr_matrix(cov):\n",
    "    rho = cov.copy()\n",
    "    sqrt_cov_diag = np.sqrt(cov[np.diag_indices(cov.shape[0])])\n",
    "    rho /= sqrt_cov_diag[:,None]\n",
    "    rho /= sqrt_cov_diag[None,:]\n",
    "    rho[np.diag_indices(cov.shape[0])] = sqrt_cov_diag\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f2ec3-9dba-4970-ab73-494dddd61534",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Cannot be explained in one markdown cell above, need to look through it more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72257ca9-2c06-4d52-9589-9b9086876356",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def get_inputs_outputs(d, pretrained_model=None,\n",
    "                          recalc_reddening=False,\n",
    "                          rchisq_max=None,\n",
    "                          return_cov_components=False):\n",
    "    n_bands = 13 # Gaia (G, BP, RP), PS1 (grizy), 2MASS (JHK), unWISE (W1,W2)\n",
    "    n_atm_params = 3 # (T_eff, logg, [M/H])\n",
    "    \n",
    "    large_err = 999.\n",
    "\n",
    "    # Stellar spectroscopic parameters\n",
    "    print('Fill in stellar atmospheric parameters ...')\n",
    "    x = np.empty((d.size,3), dtype='f4')\n",
    "    x[:] = d['atm_param'][:]\n",
    "\n",
    "    x_p = np.empty((d.size,3), dtype='f4')\n",
    "    x_p = d['atm_param_p'][:]\n",
    "\n",
    "    # Magnitudes\n",
    "    print('Fill in stellar magnitudes ...')\n",
    "    y = np.empty((d.size,n_bands), dtype='f4')\n",
    "    y[:] = d['mag'][:]\n",
    "\n",
    "    # Covariance of y\n",
    "    print('Empty covariance matrix ...')\n",
    "    cov_y = np.zeros((d.size,n_bands,n_bands), dtype='f4')\n",
    "\n",
    "    # \\delta m\n",
    "    print('Covariance: \\delta m ...')\n",
    "    for i in range(n_bands):\n",
    "        cov_y[:,i,i] = d['mag_err'][:,i]**2\n",
    "\n",
    "    # Replace NaN magnitudes with median (in each band).\n",
    "    # Also set corresponding variances to large number.\n",
    "    print('Replace NaN magnitudes ...')\n",
    "    for b in range(n_bands):\n",
    "        idx = (\n",
    "              ~np.isfinite(y[:,b])\n",
    "            | ~np.isfinite(cov_y[:,b,b])\n",
    "        )\n",
    "        n_bad = np.count_nonzero(idx)\n",
    "        n_tot = idx.size\n",
    "        y0 = np.median(y[~idx,b])\n",
    "        if np.isnan(y0):\n",
    "            y0 = 0.\n",
    "        print(f'Band {b}: {n_bad} of {n_tot} bad. Replacing with {y0:.5f}.')\n",
    "        y[idx,b] = y0\n",
    "        cov_y[idx,b,b] = large_err**2.\n",
    "\n",
    "    # Transform both y and its covariance\n",
    "    B = np.identity(n_bands, dtype='f4')\n",
    "    B[1:,0] = -1.\n",
    "    \n",
    "    print('Transform y -> B y ...')\n",
    "    y = np.einsum('ij,nj->ni', B, y) # y' = B y\n",
    "    print('Transform C -> B C B^T ...')\n",
    "    #cov_y = np.einsum('ik,nkl,jl->nij', B, cov_y, B) # C' = B C B^T\n",
    "    cov_y = np.einsum('nik,jk->nij', cov_y, B)\n",
    "    cov_y = np.einsum('ik,nkj->nij', B, cov_y)\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp = {\n",
    "            'delta_m': cov_y.copy()\n",
    "        }\n",
    "    \n",
    "    # Add in dM/dtheta and dR/dtheta terms\n",
    "    if pretrained_model is not None:\n",
    "        print('Calculate J = dM/dtheta ...')\n",
    "        J_M = calc_dmag_color_dtheta(pretrained_model, x_p)\n",
    "        cov_x = d['atm_param_cov_p']\n",
    "        print('Covariance: J C_theta J^T ...')\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_M)\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['dM/dtheta'] = np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_M)\n",
    "\n",
    "    # If pretrained model provided, could calculate reduced chi^2\n",
    "    # with maximum-likelihood (mu, E) here.\n",
    "\n",
    "    # \\delta \\mu (must be added in after transformation,\n",
    "    #             due to possibly infinite terms).\n",
    "    print('{:d} NaN parallaxes'.format(\n",
    "        np.count_nonzero(np.isnan(d['parallax']))\n",
    "    ))\n",
    "    err_over_plx = d['parallax_err'] / d['parallax']\n",
    "    print('Covariance: DM uncertainty term ...')\n",
    "    cov_y[:,0,0] += (5./np.log(10.) * err_over_plx)**2.\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp['dm'] = np.zeros_like(cov_y)\n",
    "        cov_comp['dm'][:,0,0] = (5./np.log(10.) * err_over_plx)**2.\n",
    "\n",
    "    # Subtract distance modulus from m_G\n",
    "    #dm = -5. * (np.log10(d['parallax']) - 2.)\n",
    "    #dm_corr = 0.5 * err_over_plx**2 + 0.75 * err_over_plx**4\n",
    "    #dm_corr_pct = np.percentile(dm_corr, [1., 5., 10., 50., 90., 95., 99.])\n",
    "    #print(dm_corr_pct)\n",
    "\n",
    "    print('Estimate DM ...')\n",
    "    dm = 10. - 5.*np.log10(d['parallax'])# + 5./np.log(10.)*dm_corr\n",
    "    y[:,0] -= dm\n",
    "\n",
    "    # Don't attempt to predict M_G for poor plx/err or when plx < 0\n",
    "    print('Filter out M_G for poor parallax measurements ...')\n",
    "    idx = (\n",
    "          (err_over_plx > 0.2)\n",
    "        | (d['parallax'] < 1.e-8)\n",
    "        | ~np.isfinite(d['parallax'])\n",
    "        | ~np.isfinite(d['parallax_err'])\n",
    "    )\n",
    "    n_use = idx.size - np.count_nonzero(idx)\n",
    "    print(r'Using {:d} of {:d} ({:.3f}%) of stellar parallaxes.'.format(\n",
    "        n_use, idx.size, n_use/idx.size*100.\n",
    "    ))\n",
    "    cov_y[idx,0,0] = large_err**2\n",
    "    y[idx,0] = np.nanmedian(y[:,0])\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp['dm'][idx,0,0] = large_err**2\n",
    "\n",
    "    # Reddenings\n",
    "    print('Copy reddenings ...')\n",
    "    r = np.empty((d.size,), dtype='f4')\n",
    "    r[:] = d['r'][:]\n",
    "    \n",
    "    if pretrained_model is None:\n",
    "        # If R has not yet been estimated, then\n",
    "        # cut out stars with sigma_r > 0.2 mag.\n",
    "        idx = (d['r_err'] > 0.2)\n",
    "        print(f'Cutting {np.count_nonzero(idx)} stars with large sigma_r.')\n",
    "        for k in range(cov_y.shape[1]):\n",
    "            cov_y[idx,k,k] += large_err**2\n",
    "\n",
    "    if pretrained_model is not None:\n",
    "        # Update reddenings, based on vector R and (y_obs - y_pred).\n",
    "        # Use provided reddenings as a prior.\n",
    "\n",
    "        # First, need to calculate inv_cov_y\n",
    "        print('Invert C_y matrices ...')\n",
    "        inv_cov_y = np.stack([np.linalg.inv(c) for c in cov_y])\n",
    "\n",
    "        # Predict M & R for each star based on atm. params\n",
    "        M_pred = predict_M(pretrained_model, x_p)\n",
    "        R = predict_R(pretrained_model, x_p)\n",
    "        \n",
    "        r_var = d['r_err']**2\n",
    "        \n",
    "        # Calculate posterior on reddening\n",
    "        if recalc_reddening:\n",
    "            print('Calculate posterior on reddening ...')\n",
    "            r_pred, r_var = update_reddenings(\n",
    "                M_pred, R, y,\n",
    "                inv_cov_y,\n",
    "                r, r_var\n",
    "            )\n",
    "            \n",
    "            # Clip mean and variance of reddenings\n",
    "            print('Clip reddenings and reddening variances ...')\n",
    "            r[:] = np.clip(r_pred, 0., 10.) # TODO: Update upper limit?\n",
    "        \n",
    "        # TODO: Different lower bounds on error for different sources?\n",
    "        r_var[:] = np.clip(r_var, 0.02**2 + (0.1*r)**2, 10.**2)\n",
    "        \n",
    "        # Reddening uncertainty term in covariance of y\n",
    "        print('Covariance: reddening uncertainty term ...')\n",
    "        cov_y += r_var[:,None,None] * R[:,:,None]*R[:,None,:]\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['r'] = r_var[:,None,None] * R[:,:,None]*R[:,None,:]\n",
    "        \n",
    "        # Propagate uncertainty in theta to uncertainty in R\n",
    "        print('Calculate J = dA/dtheta ...')\n",
    "        J_A = calc_dext_red_dtheta(pretrained_model, x_p, r)\n",
    "        cov_x = d['atm_param_cov_p']\n",
    "        print('Covariance: J C_theta J^T ...')\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_A)\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_A)\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_M)\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['dA/dtheta'] = np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_A)\n",
    "            cov_comp['dMA/dtheta'] = np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_A)\n",
    "            cov_comp['dAM/dtheta'] = np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_M)\n",
    "        \n",
    "        # Calculate chi^2 for each star\n",
    "        chisq = calc_chisq(M_pred+r[:,None]*R-y, inv_cov_y)\n",
    "        print('chisq =', chisq)\n",
    "\n",
    "        # Calculate d.o.f. of each star\n",
    "        print('Calculate d.o.f. of each star ...')\n",
    "        n_dof = np.zeros(d.size, dtype='i4')\n",
    "        for k in range(n_bands):\n",
    "            n_dof += (cov_y[:,k,k] < (large_err-1.)**2).astype('i4')\n",
    "        #print('n_dof =', n_dof)\n",
    "\n",
    "        # Calculate reduced chi^2 for each star\n",
    "        print('Calculate chi^2/d.o.f. for each star ...')\n",
    "        rchisq = chisq / (n_dof - 1.)\n",
    "        pct = (0., 1., 10., 50., 90., 99., 100.)\n",
    "        rchisq_pct = np.percentile(rchisq[np.isfinite(rchisq)], pct)\n",
    "        print('chi^2/dof percentiles:')\n",
    "        for p,rc in zip(pct,rchisq_pct):\n",
    "            print(rf'  {p:.0f}% : {rc:.3g}')\n",
    "        idx_rchisq = (rchisq < 10.)\n",
    "        print(f'<chi^2/d.o.f.> = {np.mean(rchisq[idx_rchisq]):.3g}')\n",
    "        \n",
    "        # Filter on reduced chi^2\n",
    "        if rchisq_max is not None:\n",
    "            print('Filter on chi^2/d.o.f. ...')\n",
    "            idx = np.isfinite(rchisq) & (rchisq > 0.) & (rchisq < rchisq_max)\n",
    "            n_filt = np.count_nonzero(~idx)\n",
    "            pct_filt = 100. * n_filt / idx.size\n",
    "            print(\n",
    "                rf'Filtering {n_filt:d} stars ({pct_filt:.3g}%) ' +\n",
    "                rf'based on chi^2/dof > {rchisq_max:.1f}'\n",
    "            )\n",
    "            x = x[idx]\n",
    "            x_p = x_p[idx]\n",
    "            r = r[idx]\n",
    "            y = y[idx]\n",
    "            cov_y = cov_y[idx]\n",
    "            r_var = r_var[idx]\n",
    "            rchisq = rchisq[idx]\n",
    "            \n",
    "            if return_cov_components:\n",
    "                for key in cov_comp:\n",
    "                    cov_comp[key] = cov_comp[key][idx]\n",
    "\n",
    "    # Cholesky transform of inverse covariance: L L^T = C^(-1).\n",
    "    print('Cholesky transform of each stellar covariance matrix ...')\n",
    "    LT = np.empty_like(cov_y)\n",
    "    inv_cov_y = np.empty_like(cov_y)\n",
    "    for k,c in enumerate(cov_y):\n",
    "        try:\n",
    "            # Inflate diagonal of cov slightly, to ensure\n",
    "            # positive-definiteness\n",
    "            c_diag = c[np.diag_indices_from(c)]\n",
    "            c[np.diag_indices_from(c)] += 1.e-4 + 1.e-3 * c_diag\n",
    "            \n",
    "            inv_cov_y[k] = np.linalg.inv(c)\n",
    "            LT[k] = np.linalg.cholesky(inv_cov_y[k]).T\n",
    "            #ic = np.linalg.inv(c)\n",
    "            #LT.append(np.linalg.cholesky(ic).T)\n",
    "            #inv_cov_y.append(ic)\n",
    "        except np.linalg.LinAlgError as e:\n",
    "            rho = get_corr_matrix(c)\n",
    "            print('Offending correlation matrix:')\n",
    "            print(np.array2string(\n",
    "                rho[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >7.4f}'.format(z)}\n",
    "            ))\n",
    "            print('Offending covariance matrix:')\n",
    "            print(np.array2string(\n",
    "                c[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >9.6f}'.format(z)}\n",
    "            ))\n",
    "            print('Covariance matrix of (normed) atmospheric parameters:')\n",
    "            print(d['atm_param_cov_p'][k])\n",
    "            if pretrained_model is not None:\n",
    "                print(f'Variance of r: {r_var[k]:.8f}')\n",
    "            \n",
    "            # Inflate errors along the diagonal and try again\n",
    "            c_diag = c[np.diag_indices_from(c)]\n",
    "            c[np.diag_indices_from(c)] += 0.02 + 0.02 * c_diag\n",
    "            rho = get_corr_matrix(c)\n",
    "            print('Inflated correlation matrix:')\n",
    "            print(np.array2string(\n",
    "                rho[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >7.4f}'.format(z)}\n",
    "            ))\n",
    "            \n",
    "            inv_cov_y[k] = np.linalg.inv(c)\n",
    "            LT[k] = np.linalg.cholesky(inv_cov_y[k]).T\n",
    "            #raise e\n",
    "\n",
    "    #print('Stack L^T matrices ...')\n",
    "    #LT = np.stack(LT)\n",
    "    #print('Stack C^(-1) matrices ...')\n",
    "    #inv_cov_y = np.stack(inv_cov_y)\n",
    "\n",
    "    # L^T y\n",
    "    print('Calculate L^T y ...')\n",
    "    LTy = np.einsum('nij,nj->ni', LT, y)\n",
    "\n",
    "    print('Gather inputs and outputs and return ...')\n",
    "    inputs_outputs = {\n",
    "        'x':x, 'x_p':x_p, 'r':r, 'y':y,\n",
    "        'LT':LT, 'LTy':LTy,\n",
    "        'cov_y':cov_y, 'inv_cov_y':inv_cov_y,\n",
    "    }\n",
    "    \n",
    "    if return_cov_components:\n",
    "        inputs_outputs['cov_comp'] = cov_comp\n",
    "    \n",
    "    if pretrained_model is not None:\n",
    "        inputs_outputs['r_var'] = r_var\n",
    "        inputs_outputs['rchisq'] = rchisq\n",
    "\n",
    "    # Check that there are no NaNs or Infs in results\n",
    "    for key in inputs_outputs:\n",
    "        if isinstance(inputs_outputs[key], dict):\n",
    "            continue\n",
    "        if key == 'rchisq': # Infs appear when d.o.f. = 1\n",
    "            continue\n",
    "        if np.any(~np.isfinite(inputs_outputs[key])):\n",
    "            raise ValueError(f'NaNs or Infs detected in {key}.')\n",
    "\n",
    "    return inputs_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caad35d-51ad-4e5f-8e27-57ac56e80468",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Predicts the absolute magnitude in the Gaia G-band and the colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb5329ec-4d17-4a14-9ec3-936b60844ca9",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def predict_M(nn_model, x_p):\n",
    "    \"\"\"\n",
    "    Predicts (absmag0,color1,color2,...) for input\n",
    "    normalized stellar parameters.\n",
    "\n",
    "    Inputs:\n",
    "        nn_model (keras.Model): Neural network model.\n",
    "        x_p (np.ndarray): Normalized stellar parameters.\n",
    "            Shape = (n_stars, 3).\n",
    "    \n",
    "    Outputs:\n",
    "        M (np.ndarray): Shape = (n_stars, n_bands).\n",
    "    \"\"\"\n",
    "    inputs = nn_model.get_layer(name='theta').input\n",
    "    outputs = nn_model.get_layer(name='BM').output\n",
    "    mag_color_model = keras.Model(inputs, outputs)\n",
    "    M = mag_color_model.predict(x_p)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14482c31-4986-4451-b4f7-295c2b3530b0",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Predicting the redenning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b36fc92-d995-4531-a1e4-994b63a9a954",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def predict_R(nn_model, x_p=None):\n",
    "    inputs = nn_model.get_layer(name='theta').input\n",
    "    outputs = nn_model.get_layer(name='R').output\n",
    "    R_model = keras.Model(inputs, outputs)\n",
    "    if x_p is None:\n",
    "        R = R_model.predict(np.array([[0.,0.,0.]]))[0]\n",
    "        R[1:] -= R[0]\n",
    "    else:\n",
    "        R = R_model.predict(x_p)\n",
    "        R[:,1:] -= R[:,0][:,None]\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2cab63-a66c-4c34-a7f1-50cb9568337b",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Saving the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52ee4e30-e866-45c2-a60f-37f5d8996b9f",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def save_predictions(fname, nn_model, d_test, io_test):\n",
    "    M_pred = predict_M(nn_model, io_test['x_p'])\n",
    "    R_pred = predict_R(nn_model, io_test['x_p'])\n",
    "    R0 = predict_R(nn_model)\n",
    "    \n",
    "    with h5py.File(fname, 'w') as f:\n",
    "        f.create_dataset('/data', data=d_test, chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/y_obs', data=io_test['y'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/cov_y', data=io_test['cov_y'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/r_fit', data=io_test['r'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/M_pred', data=M_pred, chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/R_pred', data=R_pred, chunks=True,\n",
    "                        compression='gzip', compression_opts=3)\n",
    "        f.attrs['R0'] = R0\n",
    "        \n",
    "        if 'cov_comp' in io_test:\n",
    "            for key in io_test['cov_comp']:\n",
    "                f.create_dataset(\n",
    "                    f'/cov_comp/{key.replace(r\"/\",\"_\")}',\n",
    "                    data=io_test['cov_comp'][key],\n",
    "                    chunks=True,\n",
    "                    compression='gzip',\n",
    "                    compression_opts=3\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9dbfb5-0fa8-47b6-b59e-5507d8182916",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Updates the redenning, as in the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12ce532d-8584-46ea-b538-a65837b35597",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def update_reddenings(M_pred, R, y_obs, inv_cov_y, r0, r_var0):\n",
    "    \"\"\"\n",
    "    Updates the posterior on reddening of each star, given\n",
    "    the predicted absolute magnitudes, reddening vector,\n",
    "    observed magnitudes, inverse covariance matrix, and priors on\n",
    "    reddening.\n",
    "    \n",
    "    The model is given by\n",
    "    \n",
    "        y_obs = M_pred + R r,\n",
    "    \n",
    "    with the uncertainties in y_obs described by inv_cov_y, and\n",
    "    with a prior on r described by (r0, r_var0). We solve for\n",
    "    the Gaussian posterior on r: p(r|y_obs,M_pred,R,r0,r_var0).\n",
    "    \n",
    "    Let n = # of bands, k = # of stars.\n",
    "\n",
    "    Inputs:\n",
    "        M_pred (np.ndarray): Shape-(k,n) array containing predicted\n",
    "            zero-reddening asbolute magnitude & colors for each star.\n",
    "        R (np.ndarray): Shape-(k,n) array containing reddening vector\n",
    "            for each star.\n",
    "        inv_cov_y (np.ndarray): Shape-(k,n,n) array containing\n",
    "            covariance matrix of y_obs-y_pred for each star.\n",
    "        y_obs (np.ndarray): Shape-(k,n) array containing observed\n",
    "            magnitude (minus distance modulus) & colors for each star.\n",
    "        r0 (np.ndarray): Shape-(k,) array containing mean of prior on\n",
    "            reddening for each star.\n",
    "        r_var0 (np.ndarray): Shape-(k,) array containing variance of\n",
    "            prior on reddening for each star.\n",
    "\n",
    "    Outputs:\n",
    "        r_mean (np.ndarray): Shape-(k,) array containing mean posterior\n",
    "            reddening of each star.\n",
    "        r_var (np.ndarray): Shape-(k,) array containing variance of\n",
    "            reddening posterior for each star.\n",
    "    \"\"\"\n",
    "    print('Updating reddenings:')\n",
    "    print('  * R^T C_y^(-1) ...')\n",
    "    RT_Cinv = np.einsum('ni,nij->nj', R, inv_cov_y)\n",
    "    print('  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...')\n",
    "    num = r0/r_var0 + np.einsum('ni,ni->n', RT_Cinv, y_obs - M_pred)\n",
    "    print('  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...')\n",
    "    den = np.einsum('ni,ni->n', RT_Cinv, R) + 1./r_var0\n",
    "    print('  * r_mean, r_var ...')\n",
    "    r_mean = num / den\n",
    "    r_var = 1. / den\n",
    "\n",
    "    return r_mean, r_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d6a72-37ab-4d7a-bfb3-cd329804a9ca",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### calculates the chi^2, as in docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c76cf577-6ee4-41db-a3ea-bada40e97afb",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def calc_chisq(dy, inv_cov_y):\n",
    "    \"\"\"\n",
    "    Returns the chi^2 for each observation, given\n",
    "    an array of residuals and inverse covariance matrices.\n",
    "    \n",
    "        chi^2 = dy^T C^{-1} dy.\n",
    "    \n",
    "    Inputs:\n",
    "        dy (np.ndarray): Residual values. Shape = (n_obs, n_dim),\n",
    "            where n_obs is the number of observations, and n_dim is\n",
    "            the dimensionality of the vector space.\n",
    "        inv_cov_y (np.ndarray): Inverse covariance matrices.\n",
    "            Shape = (n_obs, n_dim, n_dim).\n",
    "    \n",
    "    Returns:\n",
    "        chisq (np.ndarray): Chi^2 for each observation. Shape=(n_obs,).\n",
    "    \"\"\"\n",
    "    C_inv_dy = np.einsum('nij,nj->ni', inv_cov_y, dy)\n",
    "    chisq = np.einsum('ni,ni->n', dy, C_inv_dy)\n",
    "    return chisq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50c262-4e28-419e-83d5-8b75ec32470b",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Creates the architecture of the NN as described in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45204db0-8dfb-448f-879b-11102036d543",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def get_nn_model(n_hidden_layers=1, hidden_size=32, l1=1.e0, l2=1.e-4, n_bands=13):\n",
    "    # Stellar model: B M(theta)\n",
    "    atm = keras.Input(shape=(3,), name='theta')\n",
    "    x = atm\n",
    "    for i in range(n_hidden_layers):\n",
    "        x = keras.layers.Dense(\n",
    "            hidden_size,\n",
    "            activation='sigmoid',\n",
    "            kernel_regularizer=keras.regularizers.l2(l=l2),\n",
    "            name=f'stellar_model_hidden_{i+1}'\n",
    "        )(x)\n",
    "    mag_color = keras.layers.Dense(n_bands, name='BM')(x)\n",
    "\n",
    "    # Reddening measurement E\n",
    "    red = keras.Input(shape=(1,), name='E')\n",
    "    \n",
    "    # Extinction vector: R(theta)\n",
    "    r = atm\n",
    "    #for i in range(n_hidden_layers):\n",
    "    #    r = keras.layers.Dense(\n",
    "    #        6,\n",
    "    #        use_bias=True,\n",
    "    #        activation='sigmoid',\n",
    "    #        kernel_regularizer=keras.regularizers.l2(l=l2),\n",
    "    #        name=f'extinction_model_hidden_{i+1}'\n",
    "    #    )(r)\n",
    "    ext_vec = keras.layers.Dense(\n",
    "        n_bands,\n",
    "        use_bias=True,\n",
    "        activation='exponential',\n",
    "        #kernel_regularizer=keras.regularizers.l1_l2(l1=1.e0, l2=1.e0),\n",
    "        kernel_regularizer=keras.regularizers.l1(l=l1),\n",
    "        name='R'\n",
    "    )(r)\n",
    "    \n",
    "    # Extinction A = ER\n",
    "    ext = keras.layers.Multiply(name='A')([red, ext_vec])\n",
    "    \n",
    "    # Transform extinction to extinction,reddening using B: BA\n",
    "    B = np.identity(n_bands, dtype='f4')\n",
    "    B[1:,0] = -1.\n",
    "    ext_red = keras.layers.Dense(\n",
    "        n_bands,\n",
    "        use_bias=False,\n",
    "        trainable=False,\n",
    "        weights=[B.T],\n",
    "        name='BA'\n",
    "    )(ext)\n",
    "\n",
    "    # Predicted mag,color, B(M+A)\n",
    "    y = keras.layers.Add(name='B_M_plus_A')([mag_color, ext_red])\n",
    "\n",
    "    # Cholesky decomposition of inverse covariance matrix, L L^T = C^(-1)\n",
    "    LT = keras.Input(shape=(n_bands,n_bands), name='LT')\n",
    "\n",
    "    # Multiply y_pred by L^T, since loss is given by |L^T (y_pred - y_obs)|^2,\n",
    "    # where y_pred = B(M+A), and y_obs = B(m-mu).\n",
    "    LTy = keras.layers.Dot((2,1), name='LT_B_M_plus_A')([LT, y])\n",
    "\n",
    "    # Compile model\n",
    "    model = keras.Model(\n",
    "        inputs=[atm,red,LT],\n",
    "        outputs=LTy,\n",
    "        name='stellar_photometry_model'\n",
    "    )\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer='Adam',\n",
    "        metrics=['mse']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c98052-09ff-4591-830a-446eedd1c701",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### splits the dataset according to a fraction selected by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f096cf60-242d-4eef-8d91-59430a2672dc",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def split_dataset(frac, *args):\n",
    "    assert len(args) != 0\n",
    "\n",
    "    n_tot = args[0].shape[0]\n",
    "    idx = np.arange(n_tot)\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    n = int(frac * n_tot)\n",
    "    idx_left = idx[:n]\n",
    "    idx_right = idx[n:]\n",
    "\n",
    "    left, right = [], []\n",
    "\n",
    "    for x in args:\n",
    "        left.append(x[idx_left])\n",
    "        right.append(x[idx_right])\n",
    "    \n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a650c5-2ed5-4cfd-bd99-92ff0587e213",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d4f6eac-a9dd-4e9d-9d27-f9995997b7a2",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def train_model(nn_model, io_train, epochs=100,\n",
    "                checkpoint_fn='checkpoint', batch_size=32):\n",
    "    checkpoint_fn = (\n",
    "          'checkpoints/'\n",
    "        + checkpoint_fn\n",
    "        + '.e{epoch:03d}_vl{val_loss:.3f}.h5'\n",
    "    )\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_fn,\n",
    "            save_best_only=True,\n",
    "            monitor='val_loss',\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    inputs = [io_train['x_p'], io_train['r'], io_train['LT']]\n",
    "    outputs = io_train['LTy']\n",
    "    nn_model.fit(\n",
    "        inputs, outputs,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.25/0.9,\n",
    "        callbacks=callbacks,\n",
    "        batch_size=batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d76b11-59a7-41ca-a531-13411c1a6ce9",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### tests and makes sure the loss is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eb14a0f-a62d-4d46-ab6d-4b33476566da",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(nn_model, io_eval, batch_size=32, rchisq_max=None):\n",
    "    \"\"\"\n",
    "    Runs the model on the given inputs and outputs, and returns the\n",
    "    MSE and loss.\n",
    "    \n",
    "    Inputs:\n",
    "        nn_model (keras.Model): The neural network model.\n",
    "        io_eval (dict): A dictionary containing, among other things,\n",
    "            x_p, r, LT and LTy. If rchisq_max is provided, then the\n",
    "            dictionary must also contain rchisq.\n",
    "        batch_size (int): Defaults to 32.\n",
    "        rchisq_max (float): Stars with greater than this reduced chi^2\n",
    "            will not be included in the calculation. Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "        A list containing the MSE and loss.\n",
    "    \"\"\"\n",
    "    inputs = [io_eval['x_p'], io_eval['r'], io_eval['LT']]\n",
    "    outputs = io_eval['LTy']\n",
    "    \n",
    "    if rchisq_max is not None:\n",
    "        idx = (io_eval['rchisq'] < rchisq_max)\n",
    "        inputs = [x[idx] for x in inputs]\n",
    "        outputs = outputs[idx]\n",
    "    \n",
    "    loss = nn_model.evaluate(\n",
    "        inputs,\n",
    "        outputs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    loss = [float(x) for x in loss] # Make JSON serializable\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd030e3e-55e6-419d-9a07-ce0a6baeb62c",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### plots? follow up here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d65e396c-7677-41d8-b229-8c3b2377a7b6",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def diagnostic_plots(nn_model, io_test, d_test, suffix=None):\n",
    "    if suffix is None:\n",
    "        suff = ''\n",
    "    else:\n",
    "        suff = '_' + suffix\n",
    "    \n",
    "    inputs = [\n",
    "        nn_model.get_layer(name='theta').input,\n",
    "        nn_model.get_layer(name='E').input\n",
    "    ]\n",
    "    outputs = nn_model.get_layer(name='B_M_plus_A').output\n",
    "    absmag_model = keras.Model(inputs, outputs)\n",
    "\n",
    "    # Predict y for the test dataset\n",
    "    test_pred = {\n",
    "        'y': absmag_model.predict([\n",
    "            io_test['x_p'],\n",
    "            io_test['r']\n",
    "        ]),\n",
    "        'y_dered': absmag_model.predict([\n",
    "            io_test['x_p'],\n",
    "            np.zeros_like(io_test['r'])\n",
    "        ])\n",
    "    }\n",
    "    test_pred['y_resid'] = io_test['y'] - test_pred['y']\n",
    "\n",
    "    # Get the extinction vector\n",
    "    R = predict_R(nn_model)\n",
    "    R[1:] += R[0]\n",
    "    print(\n",
    "          'R(<theta>) = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,R)))\n",
    "        + ']'\n",
    "    )\n",
    "    R_all = predict_R(nn_model, io_test['x_p'])\n",
    "    R_all[:,1:] += R_all[:,0][:,None]\n",
    "    print(\n",
    "          '<R> = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,np.median(R_all,axis=0))))\n",
    "        + ']'\n",
    "    )\n",
    "    print(\n",
    "          's_R = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,np.std(R_all,axis=0))))\n",
    "        + ']'\n",
    "    )\n",
    "\n",
    "    # Read out colors, magnitudes\n",
    "    g = io_test['y'][:,3] + io_test['y'][:,0]\n",
    "    ri = io_test['y'][:,4] - io_test['y'][:,5]\n",
    "    gr = io_test['y'][:,3] - io_test['y'][:,4]\n",
    "    g_pred = test_pred['y'][:,3] + test_pred['y'][:,0]\n",
    "    ri_pred = test_pred['y'][:,4] - test_pred['y'][:,5]\n",
    "    gr_pred = test_pred['y'][:,3] - test_pred['y'][:,4]\n",
    "    g_pred_dered = test_pred['y_dered'][:,3] + test_pred['y_dered'][:,0]\n",
    "    ri_pred_dered = test_pred['y_dered'][:,4] - test_pred['y_dered'][:,5]\n",
    "    gr_pred_dered = test_pred['y_dered'][:,3] - test_pred['y_dered'][:,4]\n",
    "    A_g = 0.25 * R[3]\n",
    "    E_ri = 0.25 * (R[4] - R[5])\n",
    "    E_gr = 0.25 * (R[3] - R[4])\n",
    "\n",
    "    gaia_g = io_test['y'][:,0]\n",
    "    bp_rp = io_test['y'][:,1] - io_test['y'][:,2]\n",
    "    gaia_g_pred = test_pred['y'][:,0]\n",
    "    bp_rp_pred = test_pred['y'][:,1] - test_pred['y'][:,2]\n",
    "    gaia_g_pred_dered = test_pred['y_dered'][:,0]\n",
    "    gaia_bp_rp_pred_dered = test_pred['y_dered'][:,1] - test_pred['y_dered'][:,2]\n",
    "    A_gaia_g = 0.25 * R[0]\n",
    "    E_bp_rp = 0.25 * (R[1] - R[2])\n",
    "\n",
    "    print('g =', g)\n",
    "    print('ri =', ri)\n",
    "    print('gr =', gr)\n",
    "    print('gaia_g =', gaia_g)\n",
    "    print('bp_rp =', bp_rp)\n",
    "\n",
    "    # Plot HRD\n",
    "    params = {\n",
    "        'density': (None, r'$N$', (None, None)),\n",
    "        'teff': (d_test['atm_param'][:,0], r'$T_{\\mathrm{eff}}$', (4000., 8000.)),\n",
    "        'logg': (d_test['atm_param'][:,1], r'$\\log \\left( g \\right)$', (0., 5.)),\n",
    "        'mh': (d_test['atm_param'][:,2], r'$\\left[ \\mathrm{M} / \\mathrm{H} \\right]$', (-2.5, 0.5))\n",
    "    }\n",
    "\n",
    "    plot_spec = [\n",
    "        {\n",
    "            'colors': [(1,2), (4,5)],\n",
    "            'mag': 0\n",
    "        },\n",
    "        {\n",
    "            'colors': [(3,4), (4,5)],\n",
    "            'mag': 0\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    idx_goodobs = np.isfinite(d_test['mag_err'])\n",
    "    idx_goodobs &= (np.abs(io_test['cov_y'][:,0,0]) < 90.)[:,None]\n",
    "    idx_goodobs = idx_goodobs.T\n",
    "\n",
    "    def scatter_or_hexbin(ax, x, y, c, vmin, vmax, extent):\n",
    "        if p == 'density':\n",
    "            im = ax.hexbin(\n",
    "                x, y,\n",
    "                extent=extent,\n",
    "                bins='log',\n",
    "                rasterized=True\n",
    "            )\n",
    "        else:\n",
    "            im = ax.scatter(\n",
    "                x,\n",
    "                y,\n",
    "                c=c,\n",
    "                edgecolors='none',\n",
    "                alpha=0.1,\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "                rasterized=True\n",
    "            )\n",
    "        return im\n",
    "\n",
    "    def get_lim(*args, **kwargs):\n",
    "        expand = kwargs.get('expand', 0.4)\n",
    "        expand_low = kwargs.get('expand_low', expand)\n",
    "        expand_high = kwargs.get('expand_high', expand)\n",
    "        pct = kwargs.get('pct', 1.)\n",
    "        lim = [np.inf, -np.inf]\n",
    "        for a in args:\n",
    "            a0,a1 = np.nanpercentile(a, [pct, 100.-pct])\n",
    "            lim[0] = min(a0, lim[0])\n",
    "            lim[1] = max(a1, lim[1])\n",
    "        w = lim[1] - lim[0]\n",
    "        lim[0] -= expand_low * w\n",
    "        lim[1] += expand_high * w\n",
    "        return lim\n",
    "\n",
    "    labels = ['G', 'BP', 'RP', 'g', 'r', 'i', 'z', 'y']\n",
    "\n",
    "    for ps in plot_spec:\n",
    "        mag_label = r'$M_{{ {} }}$'.format(labels[ps['mag']])\n",
    "        mag_obs = io_test['y'][:,ps['mag']]\n",
    "        mag_pred = test_pred['y'][:,ps['mag']]\n",
    "        mag_pred_dered = test_pred['y_dered'][:,ps['mag']]\n",
    "        A_vec = 0.25 * R[ps['mag']]\n",
    "        print('mag_pred:',mag_pred)\n",
    "\n",
    "        if ps['mag'] != 0:\n",
    "            mag_obs += io_test['y'][:,0]\n",
    "            mag_pred += io_test['y'][:,0]\n",
    "            mag_pred_dered += io_test['y'][:,0]\n",
    "            A_vec += 0.25 * R[0]\n",
    "\n",
    "        color_labels = []\n",
    "        colors_obs = []\n",
    "        colors_pred = []\n",
    "        colors_pred_dered = []\n",
    "        idx_colors_obs = []\n",
    "        E_vec = []\n",
    "        for i1,i2 in ps['colors']:\n",
    "            color_labels.append(r'${} - {}$'.format(labels[i1], labels[i2]))\n",
    "            colors_obs.append(io_test['y'][:,i1] - io_test['y'][:,i2])\n",
    "            colors_pred.append(test_pred['y'][:,i1] - test_pred['y'][:,i2])\n",
    "            colors_pred_dered.append(\n",
    "                test_pred['y_dered'][:,i1] - test_pred['y_dered'][:,i2]\n",
    "            )\n",
    "            idx_colors_obs.append(idx_goodobs[i1] & idx_goodobs[i2])\n",
    "            E_vec.append(0.25 * (R[i1] - R[i2]))\n",
    "\n",
    "        mag_lim = get_lim(\n",
    "            mag_obs[idx_goodobs[ps['mag']]],\n",
    "            pct=2.\n",
    "        )[::-1]\n",
    "        color_lim = [\n",
    "            get_lim(c[idx_colors_obs[k]], expand_low=0.5, expand_high=0.4)\n",
    "            for k,c in enumerate(colors_obs)\n",
    "        ]\n",
    "        \n",
    "        for p in params.keys():\n",
    "            c, label, (vmin,vmax) = params[p]\n",
    "            \n",
    "            fig = plt.figure(figsize=(14,4.5), dpi=150)\n",
    "            fig.patch.set_alpha(0.)\n",
    "            gs = GridSpec(\n",
    "                1,4,\n",
    "                width_ratios=[1,1,1,0.1],\n",
    "                left=0.07, right=0.93,\n",
    "                bottom=0.10, top=0.92\n",
    "            )\n",
    "            ax_obs = fig.add_subplot(gs[0,0], facecolor='gray')\n",
    "            ax_pred = fig.add_subplot(gs[0,1], facecolor='gray')\n",
    "            ax_dered = fig.add_subplot(gs[0,2], facecolor='gray')\n",
    "            cax = fig.add_subplot(gs[0,3], facecolor='w')\n",
    "\n",
    "            extent = color_lim[0] + mag_lim\n",
    "\n",
    "            idx = (\n",
    "                  idx_goodobs[ps['mag']]\n",
    "                & idx_goodobs[ps['colors'][0][0]]\n",
    "                & idx_goodobs[ps['colors'][0][1]]\n",
    "            )\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_obs,\n",
    "                colors_obs[0][idx],\n",
    "                mag_obs[idx],\n",
    "                c if c is None else c[idx],\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "                #(-0.3,1.0,11.5,-2.0)\n",
    "            )\n",
    "\n",
    "            ax_obs.set_xlim(color_lim[0])\n",
    "            ax_obs.set_ylim(mag_lim)\n",
    "            ax_obs.set_xlabel(color_labels[0])\n",
    "            ax_obs.set_ylabel(mag_label)\n",
    "            ax_obs.grid('on', alpha=0.3)\n",
    "            ax_obs.set_title(r'$\\mathrm{Observed}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_pred,\n",
    "                colors_pred[0],\n",
    "                mag_pred,\n",
    "                c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "\n",
    "            ax_pred.set_xlim(color_lim[0])\n",
    "            ax_pred.set_ylim(mag_lim)\n",
    "            ax_pred.set_xlabel(color_labels[0])\n",
    "            ax_pred.grid('on', alpha=0.3)\n",
    "            ax_pred.set_title(r'$\\mathrm{Predicted}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_dered,\n",
    "                colors_pred_dered[0],\n",
    "                mag_pred_dered,\n",
    "                c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "\n",
    "            ax_dered.set_xlim(color_lim[0])\n",
    "            ax_dered.set_ylim(mag_lim)\n",
    "            ax_dered.set_xlabel(color_labels[0])\n",
    "            ax_dered.grid('on', alpha=0.3)\n",
    "            ax_dered.set_title(r'$\\mathrm{Predicted+Dereddened}$')\n",
    "\n",
    "            ax_dered.annotate(\n",
    "                '',\n",
    "                xy=(0.35+E_vec[0], 1.+A_vec),\n",
    "                xytext=(0.35, 1.),\n",
    "                arrowprops=dict(color='r', width=1., headwidth=5., headlength=5.)\n",
    "            )\n",
    "\n",
    "            cb = fig.colorbar(im, cax=cax)\n",
    "            cb.set_label(label)\n",
    "            cb.set_alpha(1.)\n",
    "            cb.draw_all()\n",
    "\n",
    "            cm_desc = '{}_vs_{}{}'.format(\n",
    "                labels[ps['mag']],\n",
    "                labels[ps['colors'][0][0]],\n",
    "                labels[ps['colors'][0][1]]\n",
    "            )\n",
    "            fig.savefig(\n",
    "                '/arc/home/aydanmckay/networkplots/nn_predictions_'+cm_desc+'_'+p+suff+'.svg',\n",
    "                dpi=150,\n",
    "                facecolor=fig.get_facecolor(),\n",
    "                edgecolor='none'\n",
    "            )\n",
    "            plt.close(fig)\n",
    "\n",
    "            # Color-color diagrams\n",
    "            fig = plt.figure(figsize=(14,4.5), dpi=150)\n",
    "            fig.patch.set_alpha(0.)\n",
    "            gs = GridSpec(\n",
    "                1,4,\n",
    "                width_ratios=[1,1,1,0.1],\n",
    "                left=0.07, right=0.93,\n",
    "                bottom=0.10, top=0.92\n",
    "            )\n",
    "            ax_obs = fig.add_subplot(gs[0,0], facecolor='gray')\n",
    "            ax_pred = fig.add_subplot(gs[0,1], facecolor='gray')\n",
    "            ax_dered = fig.add_subplot(gs[0,2], facecolor='gray')\n",
    "            cax = fig.add_subplot(gs[0,3], facecolor='w')\n",
    "\n",
    "            extent = color_lim[0] + color_lim[1]\n",
    "\n",
    "            idx = (\n",
    "                  idx_goodobs[ps['colors'][0][0]]\n",
    "                & idx_goodobs[ps['colors'][0][1]]\n",
    "                & idx_goodobs[ps['colors'][1][0]]\n",
    "                & idx_goodobs[ps['colors'][1][1]]\n",
    "            )\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_obs,\n",
    "                colors_obs[0][idx],\n",
    "                colors_obs[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "                #(-0.2,1.5,-0.15,0.8)\n",
    "            )\n",
    "            ax_obs.set_xlim(color_lim[0])\n",
    "            ax_obs.set_ylim(color_lim[1])\n",
    "            ax_obs.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_obs.set_ylabel(color_labels[1], fontsize=14)\n",
    "            ax_obs.grid('on', alpha=0.3)\n",
    "            ax_obs.set_title(r'$\\mathrm{Observed}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_pred,\n",
    "                colors_pred[0][idx],\n",
    "                colors_pred[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                #c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "            ax_pred.set_xlim(color_lim[0])\n",
    "            ax_pred.set_ylim(color_lim[1])\n",
    "            ax_pred.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_pred.grid('on', alpha=0.3)\n",
    "            ax_pred.set_title(r'$\\mathrm{Predicted}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_dered,\n",
    "                colors_pred_dered[0][idx],\n",
    "                colors_pred_dered[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                #c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "            ax_dered.set_xlim(color_lim[0])\n",
    "            ax_dered.set_ylim(color_lim[1])\n",
    "            ax_dered.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_dered.grid('on', alpha=0.3)\n",
    "            ax_dered.set_title(r'$\\mathrm{Predicted+Dereddened}$')\n",
    "\n",
    "            ax_dered.annotate(\n",
    "                '',\n",
    "                xy=(0.4+E_vec[0], 0.3+E_vec[1]),\n",
    "                xytext=(0.4, 0.3),\n",
    "                arrowprops=dict(color='r', width=1., headwidth=5., headlength=5.)\n",
    "            )\n",
    "\n",
    "            cb = fig.colorbar(im, cax=cax)\n",
    "            cb.set_label(label, fontsize=14)\n",
    "            cb.set_alpha(1.)\n",
    "            cb.draw_all()\n",
    "\n",
    "            cc_desc = '{}{}_vs_{}{}'.format(\n",
    "                labels[ps['colors'][0][0]],\n",
    "                labels[ps['colors'][0][1]],\n",
    "                labels[ps['colors'][1][0]],\n",
    "                labels[ps['colors'][1][1]]\n",
    "            )\n",
    "            fig.savefig(\n",
    "                '/arc/home/aydanmckay/networkplots/test_'+cc_desc+'_'+p+suff+'.svg',\n",
    "                dpi=150,\n",
    "                facecolor=fig.get_facecolor(),\n",
    "                edgecolor='none'\n",
    "            )\n",
    "            plt.close(fig)\n",
    "    \n",
    "    # Plot histograms of residuals\n",
    "    dr = (io_test['r'] - d_test['r'])/np.hypot(np.nanstd(d_test['r']),.01)\n",
    "    # dmag = (io_test['y'] - d_test['mag'])\n",
    "    # dm1,dm2,dm3,dm4,dm5,dm6,dm7,dm8,dm9,dm10,dm11,dm12,dm13 = dmag.T\n",
    "    names = ['G','(BP-G)','(RP-G)','(g-G)','(r-G)','(i-G)','(z-G)','(y-G)','(J-G)','(H-G)','(K_s-G)','(W_1-G)','(W_2-G)']\n",
    "    # ds = [dm1,dm2,dm3,dm4,dm5,dm6,dm7,dm8,dm9,dm10,dm11,dm12,dm13]\n",
    "    fig = plt.figure(figsize=(12,18))\n",
    "    ax = fig.add_subplot(5,3,1)\n",
    "    dr_mean = np.nanmean(dr)\n",
    "    dr_std = np.nanstd(dr)\n",
    "    ax.hist(dr, bins=50)\n",
    "    dr_skew = scipy.stats.moment(dr, moment=3, nan_policy='omit')\n",
    "    dr_txt = r'$\\Delta E = {:+.3f} \\pm {:.3f}$'.format(dr_mean, dr_std)\n",
    "    dr_skew /= (dr_std**1.5 + 1.e-5)\n",
    "    dr_txt += '\\n' + r'$\\tilde{{\\mu}}_3 = {:+.3f}$'.format(dr_skew)\n",
    "    ax.text(0.05, 0.95, dr_txt, ha='left', va='top', transform=ax.transAxes)\n",
    "    ax.set_xlabel(r'$\\Delta E \\ \\left( \\mathrm{estimated} - \\mathrm{Bayestar19} \\right)$',fontsize=10)\n",
    "    for it,(io,dm,name) in enumerate(zip(io_test['y'].T,d_test['mag'].T,names)):\n",
    "        dd = (io - dm)/np.hypot(np.nanstd(dm),.01)\n",
    "        ax = fig.add_subplot(5,3,it+2)\n",
    "        dd_mean = np.nanmean(dd)\n",
    "        dd_std = np.nanstd(dd)\n",
    "        ax.hist(dd, bins=50)\n",
    "        dd_skew = scipy.stats.moment(dd, moment=3, nan_policy='omit')\n",
    "        dd_txt = r'$\\Delta '+name+r' = {:+.3f} \\pm {:.3f}$'.format(dd_mean, dd_std)\n",
    "        dd_skew /= (dd_std**1.5 + 1.e-5)\n",
    "        dd_txt += '\\n' + r'$\\tilde{{\\mu}}_3 = {:+.3f}$'.format(dd_skew)\n",
    "        ax.text(0.05, 0.95, dd_txt, ha='left', va='top', transform=ax.transAxes)\n",
    "        ax.set_xlabel(r'$\\Delta '+name+r'\\ \\left( \\mathrm{estimated} - \\mathrm{observed} \\right)$',fontsize=10)\n",
    "    fig.savefig('/arc/home/aydanmckay/networkplots/test_z-score_dE'+suff+'.svg', dpi=150)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc50d23-d49f-4732-87e4-a7e1ec8fc816",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Calculates the derivative of the stellar model portion for gradient descent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8c296da-d523-4953-87b3-738be2e038fe",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def calc_dmag_color_dtheta(nn_model, x_p):\n",
    "    m = keras.Model(\n",
    "        inputs=nn_model.get_layer(name='theta').input,\n",
    "        outputs=nn_model.get_layer(name='BM').output\n",
    "    )\n",
    "    with tf.GradientTape() as g:\n",
    "        x_p = tf.constant(x_p)\n",
    "        g.watch(x_p)\n",
    "        mag_color = m(x_p)\n",
    "    J = g.batch_jacobian(mag_color, x_p).numpy()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb05c4c2-5d82-4311-b6f2-b46532797a41",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Calculates the derivative of the extinction model portion for gradient descent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2af63500-d06a-4ba6-bcc1-5fd5c3df6247",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def calc_dext_red_dtheta(nn_model, x_p, r):\n",
    "    A_model = keras.Model(\n",
    "        inputs=[\n",
    "            nn_model.get_layer(name='theta').input,\n",
    "            nn_model.get_layer(name='E').input\n",
    "        ],\n",
    "        outputs=nn_model.get_layer(name='BA').output\n",
    "    )\n",
    "    r = tf.constant(np.reshape(r, (r.size,1)))\n",
    "    #r = tf.reshape(r, (tf.size(r), 1))\n",
    "    with tf.GradientTape() as g:\n",
    "        x_p = tf.constant(x_p)\n",
    "        g.watch(x_p)\n",
    "        A = A_model([x_p, r])\n",
    "    J = g.batch_jacobian(A, x_p).numpy()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fb7f2c-5df5-4b99-aae0-39035aa43797",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Saves the normalizations, which seen in the tutorial is useful for scaling and shifting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86cef280-6cca-48f4-93ce-a8f4b7336300",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def save_theta_norm(d_attrs, fname):\n",
    "    d = {\n",
    "        'theta_med': d_attrs['atm_param_med'].tolist(),\n",
    "        'theta_std': d_attrs['atm_param_std'].tolist()\n",
    "    }\n",
    "    with open(fname, 'w') as f:\n",
    "        json.dump(d, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab8ecb-d1c9-438d-8794-1ff0b7eceef3",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### start of main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b834ddb7-6836-4e26-b7d7-81ce6cf146fd",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"stellar_photometry_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " theta (InputLayer)             [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " stellar_model_hidden_1 (Dense)  (None, 32)          128         ['theta[0][0]']                  \n",
      "                                                                                                  \n",
      " E (InputLayer)                 [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " R (Dense)                      (None, 13)           52          ['theta[0][0]']                  \n",
      "                                                                                                  \n",
      " stellar_model_hidden_2 (Dense)  (None, 32)          1056        ['stellar_model_hidden_1[0][0]'] \n",
      "                                                                                                  \n",
      " A (Multiply)                   (None, 13)           0           ['E[0][0]',                      \n",
      "                                                                  'R[0][0]']                      \n",
      "                                                                                                  \n",
      " BM (Dense)                     (None, 13)           429         ['stellar_model_hidden_2[0][0]'] \n",
      "                                                                                                  \n",
      " BA (Dense)                     (None, 13)           169         ['A[0][0]']                      \n",
      "                                                                                                  \n",
      " LT (InputLayer)                [(None, 13, 13)]     0           []                               \n",
      "                                                                                                  \n",
      " B_M_plus_A (Add)               (None, 13)           0           ['BM[0][0]',                     \n",
      "                                                                  'BA[0][0]']                     \n",
      "                                                                                                  \n",
      " LT_B_M_plus_A (Dot)            (None, 13)           0           ['LT[0][0]',                     \n",
      "                                                                  'B_M_plus_A[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,834\n",
      "Trainable params: 1,665\n",
      "Non-trainable params: 169\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load/create neural network\n",
    "nn_name = 'ext_0h_l1n2'\n",
    "n_hidden = 2\n",
    "nn_model = get_nn_model(n_hidden_layers=n_hidden, l2=1.e-4, l1=1.e-2)\n",
    "#nn_model = keras.models.load_model(\n",
    "#    'models/{:s}_{:d}hidden_it14.h5'.format(nn_name, n_hidden)\n",
    "#)\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07e4514b-44a8-4a5c-8512-e7feaa15e94e",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Loading /arc/home/aydanmckay/ml/network/data.h5 ...\n"
     ]
    }
   ],
   "source": [
    "# Load stellar data\n",
    "print('Loading data ...')\n",
    "fname = '/arc/home/aydanmckay/ml/network/data.h5'\n",
    "d, d_attrs = load_data(fname, return_attrs=True)\n",
    "#d = d[::25]\n",
    "save_theta_norm(d_attrs, 'theta_normalization.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d54baa9f-60d9-4fc0-acb7-e4c49cd83a66",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    253053 training/validation stars.\n",
      "     28118 test stars.\n"
     ]
    }
   ],
   "source": [
    "# (training+validation) / test split\n",
    "# Fix random seed (same split every run)\n",
    "np.random.seed(7)\n",
    "(d_train,), (d_test,) = split_dataset(0.9, d)\n",
    "np.random.shuffle(d_train) # Want d_train to be in random order\n",
    "print(f'{d_train.size: >10d} training/validation stars.')\n",
    "print(f'{d_test.size: >10d} test stars.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa8b04a6-3b93-4b72-9d3f-8855c3111e8c",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi^2/dof = [None, 100.00000000000004, 79.41833348134496, 63.07271692954115, 50.09130066684769, 39.78167620874025, 31.593944275926187, 25.091384024965357, 19.927159040031896, 15.825817619770502, 12.56860061341878, 9.981773149103292, 7.927357886906197, 6.295775522882865, 4.999999999999999, 5.0, 5.0, 5.0, 5.0, 5.0]\n"
     ]
    }
   ],
   "source": [
    "# Iteratively update dM/dtheta contribution to uncertainties,\n",
    "# reddening estimates and reduced chi^2 cut, and retrain.\n",
    "n_iterations = 20\n",
    "\n",
    "# On GPU, use large batch sizes for memory transfer efficiency\n",
    "batch_size = 1024\n",
    "\n",
    "rchisq_max_init = 100.\n",
    "rchisq_max_final = 5.\n",
    "rchisq_max = np.exp(np.linspace(\n",
    "    np.log(rchisq_max_init),\n",
    "    np.log(rchisq_max_final),\n",
    "    n_iterations-6\n",
    "))\n",
    "rchisq_max = [None] + rchisq_max.tolist() + 5*[rchisq_max_final]\n",
    "print('chi^2/dof = {}'.format(rchisq_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b3ee798-6cee-458d-b5e3-e6f014c0c873",
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Cutting 0 stars with large sigma_r.\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Cutting 0 stars with large sigma_r.\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 37.54 s\n",
      "learning rate = 0.0010000000474974513\n",
      "setting learning rate to 0.001\n",
      "Iteration 1 of 20.\n",
      "Epoch 1/25\n",
      "173/179 [===========================>..] - ETA: 0s - loss: 28485.5664 - mse: 28485.4297\n",
      "Epoch 1: val_loss improved from inf to 28282.81055, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e001_vl28282.811.h5\n",
      "179/179 [==============================] - 2s 8ms/step - loss: 27930.6816 - mse: 27930.5449 - val_loss: 28282.8105 - val_mse: 28282.6875\n",
      "Epoch 2/25\n",
      "176/179 [============================>.] - ETA: 0s - loss: 6402.1323 - mse: 6402.0127\n",
      "Epoch 2: val_loss improved from 28282.81055 to 16039.83105, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e002_vl16039.831.h5\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 6375.1338 - mse: 6375.0151 - val_loss: 16039.8311 - val_mse: 16039.7168\n",
      "Epoch 3/25\n",
      "169/179 [===========================>..] - ETA: 0s - loss: 3109.2988 - mse: 3109.1824\n",
      "Epoch 3: val_loss improved from 16039.83105 to 7568.69727, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e003_vl7568.697.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 3052.3325 - mse: 3052.2156 - val_loss: 7568.6973 - val_mse: 7568.5830\n",
      "Epoch 4/25\n",
      "169/179 [===========================>..] - ETA: 0s - loss: 1548.1233 - mse: 1548.0106\n",
      "Epoch 4: val_loss improved from 7568.69727 to 4684.83301, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e004_vl4684.833.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 1517.3483 - mse: 1517.2351 - val_loss: 4684.8330 - val_mse: 4684.7231\n",
      "Epoch 5/25\n",
      "170/179 [===========================>..] - ETA: 0s - loss: 833.9048 - mse: 833.7939\n",
      "Epoch 5: val_loss improved from 4684.83301 to 3186.14233, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e005_vl3186.142.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 824.0118 - mse: 823.9008 - val_loss: 3186.1423 - val_mse: 3186.0322\n",
      "Epoch 6/25\n",
      "173/179 [===========================>..] - ETA: 0s - loss: 582.6639 - mse: 582.5543\n",
      "Epoch 6: val_loss improved from 3186.14233 to 2378.59717, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e006_vl2378.597.h5\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 578.9999 - mse: 578.8903 - val_loss: 2378.5972 - val_mse: 2378.4885\n",
      "Epoch 7/25\n",
      "177/179 [============================>.] - ETA: 0s - loss: 486.4174 - mse: 486.3085\n",
      "Epoch 7: val_loss improved from 2378.59717 to 2004.20044, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e007_vl2004.200.h5\n",
      "179/179 [==============================] - 2s 10ms/step - loss: 495.0159 - mse: 494.9070 - val_loss: 2004.2004 - val_mse: 2004.0912\n",
      "Epoch 8/25\n",
      "172/179 [===========================>..] - ETA: 0s - loss: 459.1717 - mse: 459.0629\n",
      "Epoch 8: val_loss improved from 2004.20044 to 1582.09863, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e008_vl1582.099.h5\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 464.9391 - mse: 464.8303 - val_loss: 1582.0986 - val_mse: 1581.9899\n",
      "Epoch 9/25\n",
      "167/179 [==========================>...] - ETA: 0s - loss: 446.7652 - mse: 446.6563\n",
      "Epoch 9: val_loss improved from 1582.09863 to 1310.32043, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e009_vl1310.320.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 450.0895 - mse: 449.9807 - val_loss: 1310.3204 - val_mse: 1310.2118\n",
      "Epoch 10/25\n",
      "163/179 [==========================>...] - ETA: 0s - loss: 440.9403 - mse: 440.8321\n",
      "Epoch 10: val_loss improved from 1310.32043 to 1129.91064, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e010_vl1129.911.h5\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 439.1522 - mse: 439.0438 - val_loss: 1129.9106 - val_mse: 1129.8019\n",
      "Epoch 11/25\n",
      "169/179 [===========================>..] - ETA: 0s - loss: 429.8324 - mse: 429.7235\n",
      "Epoch 11: val_loss improved from 1129.91064 to 998.13885, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e011_vl998.139.h5\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 429.6374 - mse: 429.5285 - val_loss: 998.1389 - val_mse: 998.0303\n",
      "Epoch 12/25\n",
      "176/179 [============================>.] - ETA: 0s - loss: 420.8494 - mse: 420.7408\n",
      "Epoch 12: val_loss improved from 998.13885 to 901.25201, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e012_vl901.252.h5\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 420.6510 - mse: 420.5425 - val_loss: 901.2520 - val_mse: 901.1436\n",
      "Epoch 13/25\n",
      "175/179 [============================>.] - ETA: 0s - loss: 411.4307 - mse: 411.3225\n",
      "Epoch 13: val_loss improved from 901.25201 to 796.97632, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e013_vl796.976.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 411.0594 - mse: 410.9512 - val_loss: 796.9763 - val_mse: 796.8685\n",
      "Epoch 14/25\n",
      "174/179 [============================>.] - ETA: 0s - loss: 399.5778 - mse: 399.4700\n",
      "Epoch 14: val_loss improved from 796.97632 to 725.99316, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e014_vl725.993.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 399.4587 - mse: 399.3509 - val_loss: 725.9932 - val_mse: 725.8853\n",
      "Epoch 15/25\n",
      "167/179 [==========================>...] - ETA: 0s - loss: 386.1097 - mse: 386.0020\n",
      "Epoch 15: val_loss improved from 725.99316 to 656.88495, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e015_vl656.885.h5\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 384.9211 - mse: 384.8135 - val_loss: 656.8849 - val_mse: 656.7772\n",
      "Epoch 16/25\n",
      "177/179 [============================>.] - ETA: 0s - loss: 368.4691 - mse: 368.3616\n",
      "Epoch 16: val_loss improved from 656.88495 to 596.73853, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e016_vl596.739.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 368.3482 - mse: 368.2408 - val_loss: 596.7385 - val_mse: 596.6311\n",
      "Epoch 17/25\n",
      "175/179 [============================>.] - ETA: 0s - loss: 353.6059 - mse: 353.4985\n",
      "Epoch 17: val_loss improved from 596.73853 to 549.89734, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e017_vl549.897.h5\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 353.2824 - mse: 353.1752 - val_loss: 549.8973 - val_mse: 549.7902\n",
      "Epoch 18/25\n",
      "166/179 [==========================>...] - ETA: 0s - loss: 342.2943 - mse: 342.1874\n",
      "Epoch 18: val_loss improved from 549.89734 to 510.32080, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e018_vl510.321.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 342.0880 - mse: 341.9811 - val_loss: 510.3208 - val_mse: 510.2139\n",
      "Epoch 19/25\n",
      "166/179 [==========================>...] - ETA: 0s - loss: 335.1210 - mse: 335.0149\n",
      "Epoch 19: val_loss improved from 510.32080 to 479.28278, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e019_vl479.283.h5\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 334.2585 - mse: 334.1524 - val_loss: 479.2828 - val_mse: 479.1769\n",
      "Epoch 20/25\n",
      "175/179 [============================>.] - ETA: 0s - loss: 328.7266 - mse: 328.6208\n",
      "Epoch 20: val_loss improved from 479.28278 to 453.73996, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e020_vl453.740.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 328.6724 - mse: 328.5667 - val_loss: 453.7400 - val_mse: 453.6349\n",
      "Epoch 21/25\n",
      "169/179 [===========================>..] - ETA: 0s - loss: 324.0793 - mse: 323.9742\n",
      "Epoch 21: val_loss improved from 453.73996 to 433.49713, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e021_vl433.497.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 324.3080 - mse: 324.2030 - val_loss: 433.4971 - val_mse: 433.3923\n",
      "Epoch 22/25\n",
      "174/179 [============================>.] - ETA: 0s - loss: 320.1253 - mse: 320.0211\n",
      "Epoch 22: val_loss improved from 433.49713 to 417.71689, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e022_vl417.717.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 320.6762 - mse: 320.5720 - val_loss: 417.7169 - val_mse: 417.6131\n",
      "Epoch 23/25\n",
      "174/179 [============================>.] - ETA: 0s - loss: 317.5743 - mse: 317.4710\n",
      "Epoch 23: val_loss improved from 417.71689 to 398.90536, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e023_vl398.905.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 317.3776 - mse: 317.2743 - val_loss: 398.9054 - val_mse: 398.8023\n",
      "Epoch 24/25\n",
      "178/179 [============================>.] - ETA: 0s - loss: 314.2373 - mse: 314.1344\n",
      "Epoch 24: val_loss improved from 398.90536 to 385.02432, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e024_vl385.024.h5\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 314.2583 - mse: 314.1554 - val_loss: 385.0243 - val_mse: 384.9218\n",
      "Epoch 25/25\n",
      "170/179 [===========================>..] - ETA: 0s - loss: 310.9423 - mse: 310.8402\n",
      "Epoch 25: val_loss improved from 385.02432 to 373.70316, saving model to checkpoints/ext_0h_l1n2_2hidden_it0.e025_vl373.703.h5\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 311.2441 - mse: 311.1421 - val_loss: 373.7032 - val_mse: 373.6015\n",
      "Time elapsed to train: 27.21 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.318 0.877 0.822 1.328 0.852 0.921 0.931 0.891 0.844 0.887 1.006 0.714 0.781]\n",
      "<R> = [2.351 0.875 0.831 1.277 0.860 0.904 0.948 0.885 0.834 0.886 1.009 0.723 0.765]\n",
      "s_R = [1.232 4.963 0.682 0.885 0.763 0.690 0.518 3.459 0.858 3.517 0.583 0.790 0.593]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [4.087481  4.365071  6.539426  ... 4.2601    4.2591095 4.423851 ]\n",
      "mag_pred: [4.087481  4.365071  6.539426  ... 4.2601    4.2591095 4.423851 ]\n",
      "Time elapsed to make plots: 22.27 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 347.75455   107.750885  510.0022   ...  162.84708    64.39931\n",
      " 8372.3125  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 1.48\n",
      "  1% : 3.78\n",
      "  10% : 6.9\n",
      "  50% : 22.1\n",
      "  90% : 109\n",
      "  99% : 575\n",
      "  100% : 7.17e+03\n",
      "<chi^2/d.o.f.> = 6.81\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 27991 stars (11.1%) based on chi^2/dof > 100.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [284.74207   81.226364 875.8297   ... 456.85446  288.9798   131.39372 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 1.82\n",
      "  1% : 3.75\n",
      "  10% : 6.86\n",
      "  50% : 22.1\n",
      "  90% : 110\n",
      "  99% : 624\n",
      "  100% : 4.71e+03\n",
      "<chi^2/d.o.f.> = 6.81\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 80.89 s\n",
      "learning rate = 0.0010000000474974513\n",
      "setting learning rate to 0.0008187307530779819\n",
      "Iteration 2 of 20.\n",
      "Epoch 1/25\n",
      "159/159 [==============================] - ETA: 0s - loss: 18.4613 - mse: 18.3594\n",
      "Epoch 1: val_loss improved from inf to 17.94701, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e001_vl17.947.h5\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 18.4613 - mse: 18.3594 - val_loss: 17.9470 - val_mse: 17.8449\n",
      "Epoch 2/25\n",
      "151/159 [===========================>..] - ETA: 0s - loss: 17.8760 - mse: 17.7737\n",
      "Epoch 2: val_loss improved from 17.94701 to 17.54376, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e002_vl17.544.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 17.8700 - mse: 17.7678 - val_loss: 17.5438 - val_mse: 17.4413\n",
      "Epoch 3/25\n",
      "148/159 [==========================>...] - ETA: 0s - loss: 17.5455 - mse: 17.4429\n",
      "Epoch 3: val_loss improved from 17.54376 to 17.23755, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e003_vl17.238.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 17.5234 - mse: 17.4209 - val_loss: 17.2375 - val_mse: 17.1348\n",
      "Epoch 4/25\n",
      "154/159 [============================>.] - ETA: 0s - loss: 17.2446 - mse: 17.1417\n",
      "Epoch 4: val_loss improved from 17.23755 to 16.97621, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e004_vl16.976.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 17.2408 - mse: 17.1379 - val_loss: 16.9762 - val_mse: 16.8732\n",
      "Epoch 5/25\n",
      "157/159 [============================>.] - ETA: 0s - loss: 16.9987 - mse: 16.8956\n",
      "Epoch 5: val_loss improved from 16.97621 to 16.75680, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e005_vl16.757.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 17.0008 - mse: 16.8977 - val_loss: 16.7568 - val_mse: 16.6536\n",
      "Epoch 6/25\n",
      "158/159 [============================>.] - ETA: 0s - loss: 16.7921 - mse: 16.6888\n",
      "Epoch 6: val_loss improved from 16.75680 to 16.56587, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e006_vl16.566.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 16.7960 - mse: 16.6926 - val_loss: 16.5659 - val_mse: 16.4624\n",
      "Epoch 7/25\n",
      "157/159 [============================>.] - ETA: 0s - loss: 16.6279 - mse: 16.5243\n",
      "Epoch 7: val_loss improved from 16.56587 to 16.40931, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e007_vl16.409.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 16.6241 - mse: 16.5205 - val_loss: 16.4093 - val_mse: 16.3056\n",
      "Epoch 8/25\n",
      "156/159 [============================>.] - ETA: 0s - loss: 16.4780 - mse: 16.3742\n",
      "Epoch 8: val_loss improved from 16.40931 to 16.28518, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e008_vl16.285.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 16.4799 - mse: 16.3761 - val_loss: 16.2852 - val_mse: 16.1813\n",
      "Epoch 9/25\n",
      "150/159 [===========================>..] - ETA: 0s - loss: 16.3521 - mse: 16.2481\n",
      "Epoch 9: val_loss improved from 16.28518 to 16.16788, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e009_vl16.168.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 16.3585 - mse: 16.2545 - val_loss: 16.1679 - val_mse: 16.0637\n",
      "Epoch 10/25\n",
      "155/159 [============================>.] - ETA: 0s - loss: 16.2568 - mse: 16.1526\n",
      "Epoch 10: val_loss improved from 16.16788 to 16.06992, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e010_vl16.070.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 16.2567 - mse: 16.1525 - val_loss: 16.0699 - val_mse: 15.9656\n",
      "Epoch 11/25\n",
      "156/159 [============================>.] - ETA: 0s - loss: 16.1732 - mse: 16.0688\n",
      "Epoch 11: val_loss improved from 16.06992 to 15.98557, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e011_vl15.986.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 16.1688 - mse: 16.0644 - val_loss: 15.9856 - val_mse: 15.8810\n",
      "Epoch 12/25\n",
      "155/159 [============================>.] - ETA: 0s - loss: 16.0827 - mse: 15.9781\n",
      "Epoch 12: val_loss improved from 15.98557 to 15.91558, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e012_vl15.916.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 16.0916 - mse: 15.9870 - val_loss: 15.9156 - val_mse: 15.8109\n",
      "Epoch 13/25\n",
      "150/159 [===========================>..] - ETA: 0s - loss: 16.0301 - mse: 15.9253\n",
      "Epoch 13: val_loss improved from 15.91558 to 15.84940, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e013_vl15.849.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 16.0251 - mse: 15.9203 - val_loss: 15.8494 - val_mse: 15.7445\n",
      "Epoch 14/25\n",
      "156/159 [============================>.] - ETA: 0s - loss: 15.9675 - mse: 15.8625\n",
      "Epoch 14: val_loss improved from 15.84940 to 15.79379, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e014_vl15.794.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 15.9633 - mse: 15.8584 - val_loss: 15.7938 - val_mse: 15.6887\n",
      "Epoch 15/25\n",
      "153/159 [===========================>..] - ETA: 0s - loss: 15.9061 - mse: 15.8010\n",
      "Epoch 15: val_loss improved from 15.79379 to 15.73865, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e015_vl15.739.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 15.9090 - mse: 15.8038 - val_loss: 15.7387 - val_mse: 15.6334\n",
      "Epoch 16/25\n",
      "157/159 [============================>.] - ETA: 0s - loss: 15.8606 - mse: 15.7553\n",
      "Epoch 16: val_loss improved from 15.73865 to 15.69055, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e016_vl15.691.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 15.8599 - mse: 15.7546 - val_loss: 15.6906 - val_mse: 15.5852\n",
      "Epoch 17/25\n",
      "155/159 [============================>.] - ETA: 0s - loss: 15.8118 - mse: 15.7064\n",
      "Epoch 17: val_loss improved from 15.69055 to 15.64569, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e017_vl15.646.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 15.8120 - mse: 15.7065 - val_loss: 15.6457 - val_mse: 15.5402\n",
      "Epoch 18/25\n",
      "158/159 [============================>.] - ETA: 0s - loss: 15.7665 - mse: 15.6609\n",
      "Epoch 18: val_loss improved from 15.64569 to 15.60818, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e018_vl15.608.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 15.7677 - mse: 15.6620 - val_loss: 15.6082 - val_mse: 15.5025\n",
      "Epoch 19/25\n",
      "157/159 [============================>.] - ETA: 0s - loss: 15.7279 - mse: 15.6221\n",
      "Epoch 19: val_loss improved from 15.60818 to 15.56544, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e019_vl15.565.h5\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 15.7274 - mse: 15.6216 - val_loss: 15.5654 - val_mse: 15.4596\n",
      "Epoch 20/25\n",
      "156/159 [============================>.] - ETA: 0s - loss: 15.6913 - mse: 15.5854\n",
      "Epoch 20: val_loss improved from 15.56544 to 15.52091, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e020_vl15.521.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 15.6861 - mse: 15.5802 - val_loss: 15.5209 - val_mse: 15.4150\n",
      "Epoch 21/25\n",
      "159/159 [==============================] - ETA: 0s - loss: 15.6455 - mse: 15.5395\n",
      "Epoch 21: val_loss improved from 15.52091 to 15.48813, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e021_vl15.488.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 15.6455 - mse: 15.5395 - val_loss: 15.4881 - val_mse: 15.3821\n",
      "Epoch 22/25\n",
      "150/159 [===========================>..] - ETA: 0s - loss: 15.5938 - mse: 15.4878\n",
      "Epoch 22: val_loss improved from 15.48813 to 15.45643, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e022_vl15.456.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 15.6092 - mse: 15.5032 - val_loss: 15.4564 - val_mse: 15.3503\n",
      "Epoch 23/25\n",
      "154/159 [============================>.] - ETA: 0s - loss: 15.5777 - mse: 15.4715\n",
      "Epoch 23: val_loss improved from 15.45643 to 15.41580, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e023_vl15.416.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 15.5710 - mse: 15.4648 - val_loss: 15.4158 - val_mse: 15.3096\n",
      "Epoch 24/25\n",
      "151/159 [===========================>..] - ETA: 0s - loss: 15.5383 - mse: 15.4321\n",
      "Epoch 24: val_loss improved from 15.41580 to 15.37545, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e024_vl15.375.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 15.5356 - mse: 15.4294 - val_loss: 15.3755 - val_mse: 15.2692\n",
      "Epoch 25/25\n",
      "154/159 [============================>.] - ETA: 0s - loss: 15.5027 - mse: 15.3964\n",
      "Epoch 25: val_loss improved from 15.37545 to 15.34875, saving model to checkpoints/ext_0h_l1n2_2hidden_it1.e025_vl15.349.h5\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 15.5014 - mse: 15.3952 - val_loss: 15.3487 - val_mse: 15.2425\n",
      "Time elapsed to train: 25.37 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.282 0.875 0.833 1.504 0.919 1.367 0.815 0.871 0.921 0.878 0.975 0.639 0.699]\n",
      "<R> = [2.308 0.873 0.840 1.456 0.921 1.322 0.827 0.865 0.906 0.877 0.977 0.641 0.679]\n",
      "s_R = [1.550 4.843 0.683 2.699 0.842 1.586 0.330 3.092 0.805 3.416 0.586 0.540 0.519]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [4.028478  3.663835  6.7915998 ... 3.8704784 4.6003065 4.811438 ]\n",
      "mag_pred: [4.028478  3.663835  6.7915998 ... 3.8704784 4.6003065 4.811438 ]\n",
      "Time elapsed to make plots: 18.91 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7f13386294c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7f1338614700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 237.40913    41.535545  426.64203  ...   71.40958    64.09268\n",
      " 3719.2922  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.115\n",
      "  1% : 0.667\n",
      "  10% : 1.99\n",
      "  50% : 10.5\n",
      "  90% : 49.6\n",
      "  99% : 354\n",
      "  100% : 7.2e+03\n",
      "<chi^2/d.o.f.> = 4.61\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 15770 stars (6.23%) based on chi^2/dof > 79.4\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [164.87715   55.460922 440.59784  ... 100.84286  170.63704   34.769844]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.217\n",
      "  1% : 0.677\n",
      "  10% : 1.99\n",
      "  50% : 10.3\n",
      "  90% : 50.1\n",
      "  99% : 384\n",
      "  100% : 5.05e+03\n",
      "<chi^2/d.o.f.> = 4.6\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 81.23 s\n",
      "learning rate = 0.0008187307394109666\n",
      "setting learning rate to 0.0006703200460356394\n",
      "Iteration 3 of 20.\n",
      "Epoch 1/25\n",
      "167/168 [============================>.] - ETA: 0s - loss: 9.0458 - mse: 8.9396\n",
      "Epoch 1: val_loss improved from inf to 8.90374, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e001_vl8.904.h5\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 9.0460 - mse: 8.9398 - val_loss: 8.9037 - val_mse: 8.7977\n",
      "Epoch 2/25\n",
      "161/168 [===========================>..] - ETA: 0s - loss: 8.9187 - mse: 8.8128\n",
      "Epoch 2: val_loss improved from 8.90374 to 8.82070, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e002_vl8.821.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.9200 - mse: 8.8141 - val_loss: 8.8207 - val_mse: 8.7149\n",
      "Epoch 3/25\n",
      "167/168 [============================>.] - ETA: 0s - loss: 8.8480 - mse: 8.7423\n",
      "Epoch 3: val_loss improved from 8.82070 to 8.75955, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e003_vl8.760.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.8486 - mse: 8.7429 - val_loss: 8.7595 - val_mse: 8.6540\n",
      "Epoch 4/25\n",
      "161/168 [===========================>..] - ETA: 0s - loss: 8.7853 - mse: 8.6798\n",
      "Epoch 4: val_loss improved from 8.75955 to 8.71250, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e004_vl8.713.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.7928 - mse: 8.6873 - val_loss: 8.7125 - val_mse: 8.6072\n",
      "Epoch 5/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 8.7392 - mse: 8.6340\n",
      "Epoch 5: val_loss improved from 8.71250 to 8.66779, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e005_vl8.668.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.7445 - mse: 8.6393 - val_loss: 8.6678 - val_mse: 8.5627\n",
      "Epoch 6/25\n",
      "161/168 [===========================>..] - ETA: 0s - loss: 8.7041 - mse: 8.5991\n",
      "Epoch 6: val_loss improved from 8.66779 to 8.62630, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e006_vl8.626.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.7028 - mse: 8.5979 - val_loss: 8.6263 - val_mse: 8.5215\n",
      "Epoch 7/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 8.6606 - mse: 8.5560\n",
      "Epoch 7: val_loss improved from 8.62630 to 8.58887, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e007_vl8.589.h5\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 8.6626 - mse: 8.5580 - val_loss: 8.5889 - val_mse: 8.4844\n",
      "Epoch 8/25\n",
      "167/168 [============================>.] - ETA: 0s - loss: 8.6269 - mse: 8.5226\n",
      "Epoch 8: val_loss improved from 8.58887 to 8.55310, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e008_vl8.553.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.6278 - mse: 8.5235 - val_loss: 8.5531 - val_mse: 8.4490\n",
      "Epoch 9/25\n",
      "159/168 [===========================>..] - ETA: 0s - loss: 8.5885 - mse: 8.4847\n",
      "Epoch 9: val_loss improved from 8.55310 to 8.52346, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e009_vl8.523.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.5933 - mse: 8.4895 - val_loss: 8.5235 - val_mse: 8.4198\n",
      "Epoch 10/25\n",
      "164/168 [============================>.] - ETA: 0s - loss: 8.5629 - mse: 8.4595\n",
      "Epoch 10: val_loss improved from 8.52346 to 8.48925, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e010_vl8.489.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.5592 - mse: 8.4558 - val_loss: 8.4893 - val_mse: 8.3861\n",
      "Epoch 11/25\n",
      "164/168 [============================>.] - ETA: 0s - loss: 8.5213 - mse: 8.4184\n",
      "Epoch 11: val_loss improved from 8.48925 to 8.47057, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e011_vl8.471.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.5301 - mse: 8.4272 - val_loss: 8.4706 - val_mse: 8.3679\n",
      "Epoch 12/25\n",
      "161/168 [===========================>..] - ETA: 0s - loss: 8.4982 - mse: 8.3958\n",
      "Epoch 12: val_loss improved from 8.47057 to 8.43006, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e012_vl8.430.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.4993 - mse: 8.3969 - val_loss: 8.4301 - val_mse: 8.3279\n",
      "Epoch 13/25\n",
      "160/168 [===========================>..] - ETA: 0s - loss: 8.4750 - mse: 8.3731\n",
      "Epoch 13: val_loss improved from 8.43006 to 8.40291, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e013_vl8.403.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.4682 - mse: 8.3664 - val_loss: 8.4029 - val_mse: 8.3014\n",
      "Epoch 14/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 8.4452 - mse: 8.3440\n",
      "Epoch 14: val_loss improved from 8.40291 to 8.37767, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e014_vl8.378.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.4413 - mse: 8.3401 - val_loss: 8.3777 - val_mse: 8.2767\n",
      "Epoch 15/25\n",
      "160/168 [===========================>..] - ETA: 0s - loss: 8.4176 - mse: 8.3169\n",
      "Epoch 15: val_loss improved from 8.37767 to 8.35801, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e015_vl8.358.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.4147 - mse: 8.3140 - val_loss: 8.3580 - val_mse: 8.2576\n",
      "Epoch 16/25\n",
      "165/168 [============================>.] - ETA: 0s - loss: 8.3869 - mse: 8.2867\n",
      "Epoch 16: val_loss improved from 8.35801 to 8.32102, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e016_vl8.321.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.3864 - mse: 8.2863 - val_loss: 8.3210 - val_mse: 8.2212\n",
      "Epoch 17/25\n",
      "163/168 [============================>.] - ETA: 0s - loss: 8.3645 - mse: 8.2649\n",
      "Epoch 17: val_loss improved from 8.32102 to 8.29417, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e017_vl8.294.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.3623 - mse: 8.2627 - val_loss: 8.2942 - val_mse: 8.1949\n",
      "Epoch 18/25\n",
      "164/168 [============================>.] - ETA: 0s - loss: 8.3332 - mse: 8.2342\n",
      "Epoch 18: val_loss improved from 8.29417 to 8.27288, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e018_vl8.273.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.3348 - mse: 8.2358 - val_loss: 8.2729 - val_mse: 8.1742\n",
      "Epoch 19/25\n",
      "158/168 [===========================>..] - ETA: 0s - loss: 8.3150 - mse: 8.2166\n",
      "Epoch 19: val_loss improved from 8.27288 to 8.25592, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e019_vl8.256.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.3123 - mse: 8.2139 - val_loss: 8.2559 - val_mse: 8.1579\n",
      "Epoch 20/25\n",
      "164/168 [============================>.] - ETA: 0s - loss: 8.2867 - mse: 8.1890\n",
      "Epoch 20: val_loss improved from 8.25592 to 8.22805, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e020_vl8.228.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.2866 - mse: 8.1888 - val_loss: 8.2281 - val_mse: 8.1307\n",
      "Epoch 21/25\n",
      "168/168 [==============================] - ETA: 0s - loss: 8.2650 - mse: 8.1679\n",
      "Epoch 21: val_loss improved from 8.22805 to 8.19747, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e021_vl8.197.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.2650 - mse: 8.1679 - val_loss: 8.1975 - val_mse: 8.1008\n",
      "Epoch 22/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 8.2412 - mse: 8.1448\n",
      "Epoch 22: val_loss improved from 8.19747 to 8.18193, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e022_vl8.182.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.2423 - mse: 8.1460 - val_loss: 8.1819 - val_mse: 8.0860\n",
      "Epoch 23/25\n",
      "158/168 [===========================>..] - ETA: 0s - loss: 8.2233 - mse: 8.1277\n",
      "Epoch 23: val_loss improved from 8.18193 to 8.16745, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e023_vl8.167.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.2205 - mse: 8.1249 - val_loss: 8.1674 - val_mse: 8.0723\n",
      "Epoch 24/25\n",
      "162/168 [===========================>..] - ETA: 0s - loss: 8.2023 - mse: 8.1075\n",
      "Epoch 24: val_loss improved from 8.16745 to 8.14582, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e024_vl8.146.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.1987 - mse: 8.1039 - val_loss: 8.1458 - val_mse: 8.0514\n",
      "Epoch 25/25\n",
      "168/168 [==============================] - ETA: 0s - loss: 8.1790 - mse: 8.0850\n",
      "Epoch 25: val_loss improved from 8.14582 to 8.12258, saving model to checkpoints/ext_0h_l1n2_2hidden_it2.e025_vl8.123.h5\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.1790 - mse: 8.0850 - val_loss: 8.1226 - val_mse: 8.0291\n",
      "Time elapsed to train: 26.45 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [1.515 0.899 0.837 1.455 1.153 1.149 0.505 0.812 0.684 0.858 0.808 0.506 0.572]\n",
      "<R> = [1.526 0.897 0.842 1.458 1.148 1.111 0.508 0.807 0.677 0.858 0.811 0.502 0.554]\n",
      "s_R = [0.494 4.939 0.594 3.163 1.398 0.861 0.051 2.030 0.177 3.186 0.646 0.216 0.316]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.9001489 3.474154  6.4413457 ... 3.7877362 4.3871803 4.4968624]\n",
      "mag_pred: [3.9001489 3.474154  6.4413457 ... 3.7877362 4.3871803 4.4968624]\n",
      "Time elapsed to make plots: 19.29 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 223.95792    51.223473  167.66379  ...   38.244743   60.569878\n",
      " 1505.4252  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0561\n",
      "  1% : 0.383\n",
      "  10% : 1.06\n",
      "  50% : 5.94\n",
      "  90% : 27.8\n",
      "  99% : 216\n",
      "  100% : 6.94e+03\n",
      "<chi^2/d.o.f.> = 4\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 10641 stars (4.21%) based on chi^2/dof > 63.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 94.3026    37.384384 207.57068  ... 132.53929  110.06818   25.453472]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.11\n",
      "  1% : 0.381\n",
      "  10% : 1.06\n",
      "  50% : 5.81\n",
      "  90% : 27.9\n",
      "  99% : 227\n",
      "  100% : 5.24e+03\n",
      "<chi^2/d.o.f.> = 3.98\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 80.52 s\n",
      "learning rate = 0.0006703200633637607\n",
      "setting learning rate to 0.0005488116360940264\n",
      "Iteration 4 of 20.\n",
      "Epoch 1/25\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 5.7814 - mse: 5.6887\n",
      "Epoch 1: val_loss improved from inf to 5.74617, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e001_vl5.746.h5\n",
      "171/171 [==============================] - 2s 8ms/step - loss: 5.7817 - mse: 5.6890 - val_loss: 5.7462 - val_mse: 5.6540\n",
      "Epoch 2/25\n",
      "162/171 [===========================>..] - ETA: 0s - loss: 5.7390 - mse: 5.6473\n",
      "Epoch 2: val_loss improved from 5.74617 to 5.71954, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e002_vl5.720.h5\n",
      "171/171 [==============================] - 1s 7ms/step - loss: 5.7404 - mse: 5.6487 - val_loss: 5.7195 - val_mse: 5.6283\n",
      "Epoch 3/25\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 5.7184 - mse: 5.6277\n",
      "Epoch 3: val_loss improved from 5.71954 to 5.69610, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e003_vl5.696.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 5.7172 - mse: 5.6265 - val_loss: 5.6961 - val_mse: 5.6058\n",
      "Epoch 4/25\n",
      "166/171 [============================>.] - ETA: 0s - loss: 5.6979 - mse: 5.6081\n",
      "Epoch 4: val_loss improved from 5.69610 to 5.67484, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e004_vl5.675.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 5.6941 - mse: 5.6044 - val_loss: 5.6748 - val_mse: 5.5856\n",
      "Epoch 5/25\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 5.6717 - mse: 5.5831\n",
      "Epoch 5: val_loss improved from 5.67484 to 5.66313, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e005_vl5.663.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 5.6735 - mse: 5.5849 - val_loss: 5.6631 - val_mse: 5.5751\n",
      "Epoch 6/25\n",
      "166/171 [============================>.] - ETA: 0s - loss: 5.6558 - mse: 5.5684\n",
      "Epoch 6: val_loss improved from 5.66313 to 5.64105, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e006_vl5.641.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 5.6544 - mse: 5.5670 - val_loss: 5.6411 - val_mse: 5.5543\n",
      "Epoch 7/25\n",
      "163/171 [===========================>..] - ETA: 0s - loss: 5.6371 - mse: 5.5510\n",
      "Epoch 7: val_loss improved from 5.64105 to 5.61946, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e007_vl5.619.h5\n",
      "171/171 [==============================] - 1s 7ms/step - loss: 5.6366 - mse: 5.5505 - val_loss: 5.6195 - val_mse: 5.5339\n",
      "Epoch 8/25\n",
      "164/171 [===========================>..] - ETA: 0s - loss: 5.6212 - mse: 5.5361\n",
      "Epoch 8: val_loss improved from 5.61946 to 5.60568, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e008_vl5.606.h5\n",
      "171/171 [==============================] - 1s 7ms/step - loss: 5.6200 - mse: 5.5349 - val_loss: 5.6057 - val_mse: 5.5211\n",
      "Epoch 9/25\n",
      "161/171 [===========================>..] - ETA: 0s - loss: 5.6053 - mse: 5.5213\n",
      "Epoch 9: val_loss improved from 5.60568 to 5.59034, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e009_vl5.590.h5\n",
      "171/171 [==============================] - 1s 7ms/step - loss: 5.6041 - mse: 5.5201 - val_loss: 5.5903 - val_mse: 5.5068\n",
      "Epoch 10/25\n",
      "166/171 [============================>.] - ETA: 0s - loss: 5.5896 - mse: 5.5065\n",
      "Epoch 10: val_loss improved from 5.59034 to 5.57307, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e010_vl5.573.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 5.5886 - mse: 5.5055 - val_loss: 5.5731 - val_mse: 5.4907\n",
      "Epoch 11/25\n",
      "169/171 [============================>.] - ETA: 0s - loss: 5.5742 - mse: 5.4923\n",
      "Epoch 11: val_loss improved from 5.57307 to 5.56610, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e011_vl5.566.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 5.5753 - mse: 5.4934 - val_loss: 5.5661 - val_mse: 5.4848\n",
      "Epoch 12/25\n",
      "167/171 [============================>.] - ETA: 0s - loss: 5.5594 - mse: 5.4787\n",
      "Epoch 12: val_loss improved from 5.56610 to 5.54606, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e012_vl5.546.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 5.5625 - mse: 5.4819 - val_loss: 5.5461 - val_mse: 5.4659\n",
      "Epoch 13/25\n",
      "167/171 [============================>.] - ETA: 0s - loss: 5.5449 - mse: 5.4654\n",
      "Epoch 13: val_loss improved from 5.54606 to 5.53936, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e013_vl5.539.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 5.5475 - mse: 5.4680 - val_loss: 5.5394 - val_mse: 5.4605\n",
      "Epoch 14/25\n",
      "169/171 [============================>.] - ETA: 0s - loss: 5.5360 - mse: 5.4578\n",
      "Epoch 14: val_loss improved from 5.53936 to 5.52884, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e014_vl5.529.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 5.5372 - mse: 5.4590 - val_loss: 5.5288 - val_mse: 5.4513\n",
      "Epoch 15/25\n",
      "166/171 [============================>.] - ETA: 0s - loss: 5.5258 - mse: 5.4487\n",
      "Epoch 15: val_loss improved from 5.52884 to 5.51650, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e015_vl5.516.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 5.5239 - mse: 5.4469 - val_loss: 5.5165 - val_mse: 5.4401\n",
      "Epoch 16/25\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 5.5122 - mse: 5.4362\n",
      "Epoch 16: val_loss improved from 5.51650 to 5.50066, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e016_vl5.501.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 5.5141 - mse: 5.4382 - val_loss: 5.5007 - val_mse: 5.4252\n",
      "Epoch 17/25\n",
      "162/171 [===========================>..] - ETA: 0s - loss: 5.5013 - mse: 5.4264\n",
      "Epoch 17: val_loss improved from 5.50066 to 5.49432, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e017_vl5.494.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 5.5033 - mse: 5.4285 - val_loss: 5.4943 - val_mse: 5.4200\n",
      "Epoch 18/25\n",
      "161/171 [===========================>..] - ETA: 0s - loss: 5.4956 - mse: 5.4219\n",
      "Epoch 18: val_loss improved from 5.49432 to 5.48362, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e018_vl5.484.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 5.4906 - mse: 5.4168 - val_loss: 5.4836 - val_mse: 5.4104\n",
      "Epoch 19/25\n",
      "159/171 [==========================>...] - ETA: 0s - loss: 5.4856 - mse: 5.4127\n",
      "Epoch 19: val_loss improved from 5.48362 to 5.46883, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e019_vl5.469.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 5.4803 - mse: 5.4075 - val_loss: 5.4688 - val_mse: 5.3964\n",
      "Epoch 20/25\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 5.4762 - mse: 5.4042\n",
      "Epoch 20: val_loss improved from 5.46883 to 5.46134, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e020_vl5.461.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 5.4730 - mse: 5.4009 - val_loss: 5.4613 - val_mse: 5.3897\n",
      "Epoch 21/25\n",
      "166/171 [============================>.] - ETA: 0s - loss: 5.4645 - mse: 5.3931\n",
      "Epoch 21: val_loss improved from 5.46134 to 5.45093, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e021_vl5.451.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 5.4612 - mse: 5.3898 - val_loss: 5.4509 - val_mse: 5.3798\n",
      "Epoch 22/25\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 5.4575 - mse: 5.3866\n",
      "Epoch 22: val_loss did not improve from 5.45093\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 5.4532 - mse: 5.3822 - val_loss: 5.4561 - val_mse: 5.3855\n",
      "Epoch 23/25\n",
      "163/171 [===========================>..] - ETA: 0s - loss: 5.4474 - mse: 5.3769\n",
      "Epoch 23: val_loss improved from 5.45093 to 5.43374, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e023_vl5.434.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 5.4429 - mse: 5.3725 - val_loss: 5.4337 - val_mse: 5.3636\n",
      "Epoch 24/25\n",
      "171/171 [==============================] - ETA: 0s - loss: 5.4341 - mse: 5.3642\n",
      "Epoch 24: val_loss improved from 5.43374 to 5.42384, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e024_vl5.424.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 5.4341 - mse: 5.3642 - val_loss: 5.4238 - val_mse: 5.3542\n",
      "Epoch 25/25\n",
      "166/171 [============================>.] - ETA: 0s - loss: 5.4274 - mse: 5.3578\n",
      "Epoch 25: val_loss improved from 5.42384 to 5.41714, saving model to checkpoints/ext_0h_l1n2_2hidden_it3.e025_vl5.417.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 5.4267 - mse: 5.3572 - val_loss: 5.4171 - val_mse: 5.3478\n",
      "Time elapsed to train: 25.83 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [1.203 1.053 0.877 1.498 1.074 1.020 0.561 0.639 0.463 0.683 0.507 0.291 0.332]\n",
      "<R> = [1.236 1.062 0.879 1.545 1.093 1.026 0.568 0.636 0.463 0.685 0.510 0.291 0.332]\n",
      "s_R = [0.740 4.776 0.360 1.798 0.888 0.489 0.099 0.677 0.000 1.705 0.357 0.000 0.056]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.9182758 3.187287  6.3684964 ... 3.1979003 4.283054  4.414686 ]\n",
      "mag_pred: [3.9182758 3.187287  6.3684964 ... 3.1979003 4.283054  4.414686 ]\n",
      "Time elapsed to make plots: 19.04 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 344.896      38.438175   74.3476   ...   30.854877   49.825264\n",
      " 1134.3442  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0306\n",
      "  1% : 0.268\n",
      "  10% : 0.785\n",
      "  50% : 4.66\n",
      "  90% : 22.3\n",
      "  99% : 171\n",
      "  100% : 6.93e+03\n",
      "<chi^2/d.o.f.> = 3.67\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 10759 stars (4.25%) based on chi^2/dof > 50.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 68.77486   31.08178  206.9494   ... 127.98863   87.23001   16.204311]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0722\n",
      "  1% : 0.278\n",
      "  10% : 0.777\n",
      "  50% : 4.59\n",
      "  90% : 22.3\n",
      "  99% : 177\n",
      "  100% : 5.39e+03\n",
      "<chi^2/d.o.f.> = 3.64\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 82.68 s\n",
      "learning rate = 0.0005488116294145584\n",
      "setting learning rate to 0.0004493289641172216\n",
      "Iteration 5 of 20.\n",
      "Epoch 1/25\n",
      "161/171 [===========================>..] - ETA: 0s - loss: 4.9635 - mse: 4.8954\n",
      "Epoch 1: val_loss improved from inf to 4.94286, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e001_vl4.943.h5\n",
      "171/171 [==============================] - 2s 8ms/step - loss: 4.9583 - mse: 4.8903 - val_loss: 4.9429 - val_mse: 4.8755\n",
      "Epoch 2/25\n",
      "163/171 [===========================>..] - ETA: 0s - loss: 4.9394 - mse: 4.8724\n",
      "Epoch 2: val_loss improved from 4.94286 to 4.92252, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e002_vl4.923.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 4.9354 - mse: 4.8684 - val_loss: 4.9225 - val_mse: 4.8559\n",
      "Epoch 3/25\n",
      "161/171 [===========================>..] - ETA: 0s - loss: 4.9202 - mse: 4.8539\n",
      "Epoch 3: val_loss improved from 4.92252 to 4.91107, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e003_vl4.911.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 4.9214 - mse: 4.8551 - val_loss: 4.9111 - val_mse: 4.8451\n",
      "Epoch 4/25\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 4.9125 - mse: 4.8468\n",
      "Epoch 4: val_loss improved from 4.91107 to 4.89799, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e004_vl4.898.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 4.9114 - mse: 4.8457 - val_loss: 4.8980 - val_mse: 4.8328\n",
      "Epoch 5/25\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 4.9041 - mse: 4.8392\n",
      "Epoch 5: val_loss improved from 4.89799 to 4.88766, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e005_vl4.888.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 4.8991 - mse: 4.8342 - val_loss: 4.8877 - val_mse: 4.8231\n",
      "Epoch 6/25\n",
      "165/171 [===========================>..] - ETA: 0s - loss: 4.8920 - mse: 4.8277\n",
      "Epoch 6: val_loss improved from 4.88766 to 4.87661, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e006_vl4.877.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 4.8890 - mse: 4.8247 - val_loss: 4.8766 - val_mse: 4.8126\n",
      "Epoch 7/25\n",
      "171/171 [==============================] - ETA: 0s - loss: 4.8807 - mse: 4.8169\n",
      "Epoch 7: val_loss improved from 4.87661 to 4.86922, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e007_vl4.869.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 4.8807 - mse: 4.8169 - val_loss: 4.8692 - val_mse: 4.8057\n",
      "Epoch 8/25\n",
      "171/171 [==============================] - ETA: 0s - loss: 4.8705 - mse: 4.8072\n",
      "Epoch 8: val_loss improved from 4.86922 to 4.86126, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e008_vl4.861.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 4.8705 - mse: 4.8072 - val_loss: 4.8613 - val_mse: 4.7981\n",
      "Epoch 9/25\n",
      "163/171 [===========================>..] - ETA: 0s - loss: 4.8654 - mse: 4.8025\n",
      "Epoch 9: val_loss did not improve from 4.86126\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 4.8620 - mse: 4.7991 - val_loss: 4.8644 - val_mse: 4.8016\n",
      "Epoch 10/25\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 4.8496 - mse: 4.7869\n",
      "Epoch 10: val_loss improved from 4.86126 to 4.84123, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e010_vl4.841.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 4.8533 - mse: 4.7906 - val_loss: 4.8412 - val_mse: 4.7786\n",
      "Epoch 11/25\n",
      "161/171 [===========================>..] - ETA: 0s - loss: 4.8438 - mse: 4.7814\n",
      "Epoch 11: val_loss improved from 4.84123 to 4.83487, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e011_vl4.835.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 4.8452 - mse: 4.7827 - val_loss: 4.8349 - val_mse: 4.7725\n",
      "Epoch 12/25\n",
      "164/171 [===========================>..] - ETA: 0s - loss: 4.8396 - mse: 4.7773\n",
      "Epoch 12: val_loss improved from 4.83487 to 4.83327, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e012_vl4.833.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 4.8370 - mse: 4.7747 - val_loss: 4.8333 - val_mse: 4.7712\n",
      "Epoch 13/25\n",
      "163/171 [===========================>..] - ETA: 0s - loss: 4.8281 - mse: 4.7661\n",
      "Epoch 13: val_loss improved from 4.83327 to 4.81789, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e013_vl4.818.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 4.8293 - mse: 4.7674 - val_loss: 4.8179 - val_mse: 4.7562\n",
      "Epoch 14/25\n",
      "169/171 [============================>.] - ETA: 0s - loss: 4.8221 - mse: 4.7606\n",
      "Epoch 14: val_loss improved from 4.81789 to 4.81307, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e014_vl4.813.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 4.8214 - mse: 4.7599 - val_loss: 4.8131 - val_mse: 4.7516\n",
      "Epoch 15/25\n",
      "161/171 [===========================>..] - ETA: 0s - loss: 4.8151 - mse: 4.7539\n",
      "Epoch 15: val_loss improved from 4.81307 to 4.80287, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e015_vl4.803.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 4.8130 - mse: 4.7518 - val_loss: 4.8029 - val_mse: 4.7419\n",
      "Epoch 16/25\n",
      "158/171 [==========================>...] - ETA: 0s - loss: 4.8055 - mse: 4.7447\n",
      "Epoch 16: val_loss improved from 4.80287 to 4.79834, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e016_vl4.798.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 4.8054 - mse: 4.7446 - val_loss: 4.7983 - val_mse: 4.7378\n",
      "Epoch 17/25\n",
      "162/171 [===========================>..] - ETA: 0s - loss: 4.7948 - mse: 4.7345\n",
      "Epoch 17: val_loss improved from 4.79834 to 4.79459, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e017_vl4.795.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 4.7987 - mse: 4.7384 - val_loss: 4.7946 - val_mse: 4.7346\n",
      "Epoch 18/25\n",
      "166/171 [============================>.] - ETA: 0s - loss: 4.7934 - mse: 4.7336\n",
      "Epoch 18: val_loss improved from 4.79459 to 4.78046, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e018_vl4.780.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 4.7919 - mse: 4.7321 - val_loss: 4.7805 - val_mse: 4.7210\n",
      "Epoch 19/25\n",
      "164/171 [===========================>..] - ETA: 0s - loss: 4.7794 - mse: 4.7202\n",
      "Epoch 19: val_loss improved from 4.78046 to 4.77424, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e019_vl4.774.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 4.7823 - mse: 4.7232 - val_loss: 4.7742 - val_mse: 4.7154\n",
      "Epoch 20/25\n",
      "170/171 [============================>.] - ETA: 0s - loss: 4.7768 - mse: 4.7184\n",
      "Epoch 20: val_loss improved from 4.77424 to 4.76795, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e020_vl4.768.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 4.7757 - mse: 4.7173 - val_loss: 4.7680 - val_mse: 4.7099\n",
      "Epoch 21/25\n",
      "168/171 [============================>.] - ETA: 0s - loss: 4.7675 - mse: 4.7100\n",
      "Epoch 21: val_loss improved from 4.76795 to 4.75948, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e021_vl4.759.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 4.7677 - mse: 4.7101 - val_loss: 4.7595 - val_mse: 4.7023\n",
      "Epoch 22/25\n",
      "167/171 [============================>.] - ETA: 0s - loss: 4.7592 - mse: 4.7024\n",
      "Epoch 22: val_loss improved from 4.75948 to 4.75042, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e022_vl4.750.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 4.7599 - mse: 4.7031 - val_loss: 4.7504 - val_mse: 4.6943\n",
      "Epoch 23/25\n",
      "168/171 [============================>.] - ETA: 0s - loss: 4.7542 - mse: 4.6985\n",
      "Epoch 23: val_loss improved from 4.75042 to 4.74332, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e023_vl4.743.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 4.7519 - mse: 4.6962 - val_loss: 4.7433 - val_mse: 4.6881\n",
      "Epoch 24/25\n",
      "158/171 [==========================>...] - ETA: 0s - loss: 4.7470 - mse: 4.6924\n",
      "Epoch 24: val_loss improved from 4.74332 to 4.74017, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e024_vl4.740.h5\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 4.7464 - mse: 4.6918 - val_loss: 4.7402 - val_mse: 4.6860\n",
      "Epoch 25/25\n",
      "161/171 [===========================>..] - ETA: 0s - loss: 4.7353 - mse: 4.6817\n",
      "Epoch 25: val_loss improved from 4.74017 to 4.72726, saving model to checkpoints/ext_0h_l1n2_2hidden_it4.e025_vl4.727.h5\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 4.7382 - mse: 4.6846 - val_loss: 4.7273 - val_mse: 4.6744\n",
      "Time elapsed to train: 22.96 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [1.404 1.713 1.032 1.952 1.361 1.052 0.795 0.673 0.446 0.338 0.249 0.116 0.125]\n",
      "<R> = [1.439 1.767 1.050 2.005 1.395 1.075 0.805 0.671 0.446 0.339 0.250 0.116 0.125]\n",
      "s_R = [0.642 1.511 0.321 1.402 0.706 0.376 0.166 0.121 0.001 0.241 0.044 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.9095209 3.1763349 6.4265294 ... 3.099351  4.2458563 4.449789 ]\n",
      "mag_pred: [3.9095209 3.1763349 6.4265294 ... 3.099351  4.2458563 4.449789 ]\n",
      "Time elapsed to make plots: 19.53 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 476.07507    29.533627   40.18598  ...   34.60421    39.575333\n",
      " 1228.6432  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.021\n",
      "  1% : 0.23\n",
      "  10% : 0.73\n",
      "  50% : 4.87\n",
      "  90% : 26.6\n",
      "  99% : 209\n",
      "  100% : 7.03e+03\n",
      "<chi^2/d.o.f.> = 3.56\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 16847 stars (6.66%) based on chi^2/dof > 39.8\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 71.52277   26.196083 496.18027  ... 142.59384   90.42714   14.265249]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0521\n",
      "  1% : 0.234\n",
      "  10% : 0.718\n",
      "  50% : 4.76\n",
      "  90% : 26.4\n",
      "  99% : 221\n",
      "  100% : 5.37e+03\n",
      "<chi^2/d.o.f.> = 3.55\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 99.94 s\n",
      "learning rate = 0.0004493289743550122\n",
      "setting learning rate to 0.00036787944117144236\n",
      "Iteration 6 of 20.\n",
      "Epoch 1/25\n",
      "157/167 [===========================>..] - ETA: 0s - loss: 5.0259 - mse: 4.9736\n",
      "Epoch 1: val_loss improved from inf to 5.00754, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e001_vl5.008.h5\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 5.0240 - mse: 4.9716 - val_loss: 5.0075 - val_mse: 4.9557\n",
      "Epoch 2/25\n",
      "162/167 [============================>.] - ETA: 0s - loss: 5.0054 - mse: 4.9539\n",
      "Epoch 2: val_loss improved from 5.00754 to 4.99424, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e002_vl4.994.h5\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 5.0032 - mse: 4.9517 - val_loss: 4.9942 - val_mse: 4.9432\n",
      "Epoch 3/25\n",
      "156/167 [===========================>..] - ETA: 0s - loss: 4.9921 - mse: 4.9414\n",
      "Epoch 3: val_loss improved from 4.99424 to 4.98033, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e003_vl4.980.h5\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4.9913 - mse: 4.9406 - val_loss: 4.9803 - val_mse: 4.9301\n",
      "Epoch 4/25\n",
      "158/167 [===========================>..] - ETA: 0s - loss: 4.9756 - mse: 4.9258\n",
      "Epoch 4: val_loss improved from 4.98033 to 4.97628, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e004_vl4.976.h5\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4.9781 - mse: 4.9284 - val_loss: 4.9763 - val_mse: 4.9269\n",
      "Epoch 5/25\n",
      "161/167 [===========================>..] - ETA: 0s - loss: 4.9698 - mse: 4.9208\n",
      "Epoch 5: val_loss improved from 4.97628 to 4.96195, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e005_vl4.962.h5\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4.9701 - mse: 4.9211 - val_loss: 4.9620 - val_mse: 4.9132\n",
      "Epoch 6/25\n",
      "160/167 [===========================>..] - ETA: 0s - loss: 4.9639 - mse: 4.9155\n",
      "Epoch 6: val_loss improved from 4.96195 to 4.95474, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e006_vl4.955.h5\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4.9601 - mse: 4.9117 - val_loss: 4.9547 - val_mse: 4.9066\n",
      "Epoch 7/25\n",
      "159/167 [===========================>..] - ETA: 0s - loss: 4.9522 - mse: 4.9042\n",
      "Epoch 7: val_loss improved from 4.95474 to 4.94827, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e007_vl4.948.h5\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4.9510 - mse: 4.9030 - val_loss: 4.9483 - val_mse: 4.9005\n",
      "Epoch 8/25\n",
      "155/167 [==========================>...] - ETA: 0s - loss: 4.9425 - mse: 4.8949\n",
      "Epoch 8: val_loss improved from 4.94827 to 4.93911, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e008_vl4.939.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 4.9457 - mse: 4.8982 - val_loss: 4.9391 - val_mse: 4.8919\n",
      "Epoch 9/25\n",
      "160/167 [===========================>..] - ETA: 0s - loss: 4.9320 - mse: 4.8850\n",
      "Epoch 9: val_loss improved from 4.93911 to 4.93124, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e009_vl4.931.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 4.9366 - mse: 4.8895 - val_loss: 4.9312 - val_mse: 4.8844\n",
      "Epoch 10/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 4.9291 - mse: 4.8825\n",
      "Epoch 10: val_loss improved from 4.93124 to 4.92171, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e010_vl4.922.h5\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 4.9291 - mse: 4.8825 - val_loss: 4.9217 - val_mse: 4.8754\n",
      "Epoch 11/25\n",
      "155/167 [==========================>...] - ETA: 0s - loss: 4.9228 - mse: 4.8767\n",
      "Epoch 11: val_loss did not improve from 4.92171\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4.9239 - mse: 4.8778 - val_loss: 4.9219 - val_mse: 4.8760\n",
      "Epoch 12/25\n",
      "157/167 [===========================>..] - ETA: 0s - loss: 4.9237 - mse: 4.8781\n",
      "Epoch 12: val_loss improved from 4.92171 to 4.91069, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e012_vl4.911.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 4.9169 - mse: 4.8713 - val_loss: 4.9107 - val_mse: 4.8654\n",
      "Epoch 13/25\n",
      "160/167 [===========================>..] - ETA: 0s - loss: 4.9127 - mse: 4.8676\n",
      "Epoch 13: val_loss improved from 4.91069 to 4.90960, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e013_vl4.910.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 4.9114 - mse: 4.8664 - val_loss: 4.9096 - val_mse: 4.8649\n",
      "Epoch 14/25\n",
      "159/167 [===========================>..] - ETA: 0s - loss: 4.9130 - mse: 4.8685\n",
      "Epoch 14: val_loss did not improve from 4.90960\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4.9075 - mse: 4.8630 - val_loss: 4.9170 - val_mse: 4.8727\n",
      "Epoch 15/25\n",
      "155/167 [==========================>...] - ETA: 0s - loss: 4.9033 - mse: 4.8593\n",
      "Epoch 15: val_loss improved from 4.90960 to 4.89804, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e015_vl4.898.h5\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4.9025 - mse: 4.8585 - val_loss: 4.8980 - val_mse: 4.8542\n",
      "Epoch 16/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 4.8989 - mse: 4.8555\n",
      "Epoch 16: val_loss improved from 4.89804 to 4.89298, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e016_vl4.893.h5\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4.8978 - mse: 4.8544 - val_loss: 4.8930 - val_mse: 4.8499\n",
      "Epoch 17/25\n",
      "165/167 [============================>.] - ETA: 0s - loss: 4.8943 - mse: 4.8515\n",
      "Epoch 17: val_loss improved from 4.89298 to 4.89044, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e017_vl4.890.h5\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4.8936 - mse: 4.8508 - val_loss: 4.8904 - val_mse: 4.8480\n",
      "Epoch 18/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 4.8918 - mse: 4.8495\n",
      "Epoch 18: val_loss improved from 4.89044 to 4.88399, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e018_vl4.884.h5\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4.8903 - mse: 4.8481 - val_loss: 4.8840 - val_mse: 4.8421\n",
      "Epoch 19/25\n",
      "163/167 [============================>.] - ETA: 0s - loss: 4.8857 - mse: 4.8441\n",
      "Epoch 19: val_loss did not improve from 4.88399\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4.8851 - mse: 4.8435 - val_loss: 4.8858 - val_mse: 4.8446\n",
      "Epoch 20/25\n",
      "158/167 [===========================>..] - ETA: 0s - loss: 4.8808 - mse: 4.8398\n",
      "Epoch 20: val_loss improved from 4.88399 to 4.87861, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e020_vl4.879.h5\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4.8826 - mse: 4.8416 - val_loss: 4.8786 - val_mse: 4.8380\n",
      "Epoch 21/25\n",
      "161/167 [===========================>..] - ETA: 0s - loss: 4.8791 - mse: 4.8388\n",
      "Epoch 21: val_loss improved from 4.87861 to 4.87435, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e021_vl4.874.h5\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4.8781 - mse: 4.8377 - val_loss: 4.8744 - val_mse: 4.8344\n",
      "Epoch 22/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 4.8771 - mse: 4.8375\n",
      "Epoch 22: val_loss did not improve from 4.87435\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 4.8749 - mse: 4.8352 - val_loss: 4.8776 - val_mse: 4.8383\n",
      "Epoch 23/25\n",
      "160/167 [===========================>..] - ETA: 0s - loss: 4.8738 - mse: 4.8348\n",
      "Epoch 23: val_loss improved from 4.87435 to 4.87107, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e023_vl4.871.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 4.8730 - mse: 4.8340 - val_loss: 4.8711 - val_mse: 4.8324\n",
      "Epoch 24/25\n",
      "164/167 [============================>.] - ETA: 0s - loss: 4.8724 - mse: 4.8339\n",
      "Epoch 24: val_loss improved from 4.87107 to 4.86690, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e024_vl4.867.h5\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 4.8693 - mse: 4.8308 - val_loss: 4.8669 - val_mse: 4.8287\n",
      "Epoch 25/25\n",
      "157/167 [===========================>..] - ETA: 0s - loss: 4.8652 - mse: 4.8273\n",
      "Epoch 25: val_loss improved from 4.86690 to 4.86390, saving model to checkpoints/ext_0h_l1n2_2hidden_it5.e025_vl4.864.h5\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 4.8663 - mse: 4.8284 - val_loss: 4.8639 - val_mse: 4.8262\n",
      "Time elapsed to train: 22.76 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.081 2.687 1.509 2.962 2.026 1.532 1.217 0.941 0.649 0.191 0.238 0.043 0.045]\n",
      "<R> = [2.086 2.683 1.505 2.953 2.029 1.531 1.214 0.938 0.647 0.191 0.238 0.043 0.045]\n",
      "s_R = [0.455 0.711 0.396 0.959 0.595 0.322 0.341 0.354 0.158 0.005 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.8843963 3.1226103 6.208749  ... 3.0263314 4.215205  4.5109076]\n",
      "mag_pred: [3.8843963 3.1226103 6.208749  ... 3.0263314 4.215205  4.5109076]\n",
      "Time elapsed to make plots: 17.93 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 459.29672    32.52844    18.726707 ...   35.72437    39.193626\n",
      " 1472.4604  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0265\n",
      "  1% : 0.221\n",
      "  10% : 0.729\n",
      "  50% : 5.19\n",
      "  90% : 36.5\n",
      "  99% : 319\n",
      "  100% : 7.21e+03\n",
      "<chi^2/d.o.f.> = 3.48\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 29088 stars (11.5%) based on chi^2/dof > 31.6\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 74.252106  30.436455 994.72034  ... 163.8388    88.49057   22.967384]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.025\n",
      "  1% : 0.225\n",
      "  10% : 0.705\n",
      "  50% : 5.12\n",
      "  90% : 35.9\n",
      "  99% : 327\n",
      "  100% : 5.29e+03\n",
      "<chi^2/d.o.f.> = 3.42\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 80.73 s\n",
      "learning rate = 0.0003678794309962541\n",
      "setting learning rate to 0.00030119421191220205\n",
      "Iteration 7 of 20.\n",
      "Epoch 1/25\n",
      "155/158 [============================>.] - ETA: 0s - loss: 4.9069 - mse: 4.8686\n",
      "Epoch 1: val_loss improved from inf to 4.90134, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e001_vl4.901.h5\n",
      "158/158 [==============================] - 3s 7ms/step - loss: 4.9051 - mse: 4.8668 - val_loss: 4.9013 - val_mse: 4.8627\n",
      "Epoch 2/25\n",
      "150/158 [===========================>..] - ETA: 0s - loss: 4.8999 - mse: 4.8611\n",
      "Epoch 2: val_loss improved from 4.90134 to 4.90050, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e002_vl4.901.h5\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 4.8950 - mse: 4.8562 - val_loss: 4.9005 - val_mse: 4.8615\n",
      "Epoch 3/25\n",
      "149/158 [===========================>..] - ETA: 0s - loss: 4.8897 - mse: 4.8505\n",
      "Epoch 3: val_loss improved from 4.90050 to 4.89748, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e003_vl4.897.h5\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 4.8907 - mse: 4.8516 - val_loss: 4.8975 - val_mse: 4.8582\n",
      "Epoch 4/25\n",
      "150/158 [===========================>..] - ETA: 0s - loss: 4.8921 - mse: 4.8527\n",
      "Epoch 4: val_loss did not improve from 4.89748\n",
      "158/158 [==============================] - 1s 7ms/step - loss: 4.8910 - mse: 4.8516 - val_loss: 4.9220 - val_mse: 4.8826\n",
      "Epoch 5/25\n",
      "153/158 [============================>.] - ETA: 0s - loss: 4.8887 - mse: 4.8492\n",
      "Epoch 5: val_loss improved from 4.89748 to 4.88406, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e005_vl4.884.h5\n",
      "158/158 [==============================] - 1s 7ms/step - loss: 4.8874 - mse: 4.8479 - val_loss: 4.8841 - val_mse: 4.8444\n",
      "Epoch 6/25\n",
      "156/158 [============================>.] - ETA: 0s - loss: 4.8840 - mse: 4.8444\n",
      "Epoch 6: val_loss did not improve from 4.88406\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 4.8846 - mse: 4.8450 - val_loss: 4.8861 - val_mse: 4.8465\n",
      "Epoch 7/25\n",
      "156/158 [============================>.] - ETA: 0s - loss: 4.8826 - mse: 4.8429\n",
      "Epoch 7: val_loss did not improve from 4.88406\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 4.8811 - mse: 4.8413 - val_loss: 4.8918 - val_mse: 4.8521\n",
      "Epoch 8/25\n",
      "150/158 [===========================>..] - ETA: 0s - loss: 4.8791 - mse: 4.8394\n",
      "Epoch 8: val_loss improved from 4.88406 to 4.88074, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e008_vl4.881.h5\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 4.8779 - mse: 4.8382 - val_loss: 4.8807 - val_mse: 4.8409\n",
      "Epoch 9/25\n",
      "154/158 [============================>.] - ETA: 0s - loss: 4.8767 - mse: 4.8368\n",
      "Epoch 9: val_loss improved from 4.88074 to 4.87620, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e009_vl4.876.h5\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 4.8759 - mse: 4.8360 - val_loss: 4.8762 - val_mse: 4.8363\n",
      "Epoch 10/25\n",
      "156/158 [============================>.] - ETA: 0s - loss: 4.8718 - mse: 4.8319\n",
      "Epoch 10: val_loss improved from 4.87620 to 4.87346, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e010_vl4.873.h5\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 4.8744 - mse: 4.8345 - val_loss: 4.8735 - val_mse: 4.8336\n",
      "Epoch 11/25\n",
      "151/158 [===========================>..] - ETA: 0s - loss: 4.8787 - mse: 4.8388\n",
      "Epoch 11: val_loss did not improve from 4.87346\n",
      "158/158 [==============================] - 1s 5ms/step - loss: 4.8740 - mse: 4.8341 - val_loss: 4.8760 - val_mse: 4.8360\n",
      "Epoch 12/25\n",
      "156/158 [============================>.] - ETA: 0s - loss: 4.8720 - mse: 4.8320\n",
      "Epoch 12: val_loss did not improve from 4.87346\n",
      "158/158 [==============================] - 1s 5ms/step - loss: 4.8704 - mse: 4.8304 - val_loss: 4.8788 - val_mse: 4.8387\n",
      "Epoch 13/25\n",
      "152/158 [===========================>..] - ETA: 0s - loss: 4.8665 - mse: 4.8264\n",
      "Epoch 13: val_loss improved from 4.87346 to 4.86946, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e013_vl4.869.h5\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 4.8698 - mse: 4.8297 - val_loss: 4.8695 - val_mse: 4.8295\n",
      "Epoch 14/25\n",
      "154/158 [============================>.] - ETA: 0s - loss: 4.8663 - mse: 4.8262\n",
      "Epoch 14: val_loss did not improve from 4.86946\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 4.8680 - mse: 4.8279 - val_loss: 4.8699 - val_mse: 4.8298\n",
      "Epoch 15/25\n",
      "154/158 [============================>.] - ETA: 0s - loss: 4.8653 - mse: 4.8252\n",
      "Epoch 15: val_loss improved from 4.86946 to 4.86821, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e015_vl4.868.h5\n",
      "158/158 [==============================] - 1s 5ms/step - loss: 4.8661 - mse: 4.8260 - val_loss: 4.8682 - val_mse: 4.8281\n",
      "Epoch 16/25\n",
      "152/158 [===========================>..] - ETA: 0s - loss: 4.8654 - mse: 4.8253\n",
      "Epoch 16: val_loss improved from 4.86821 to 4.86452, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e016_vl4.865.h5\n",
      "158/158 [==============================] - 1s 5ms/step - loss: 4.8651 - mse: 4.8250 - val_loss: 4.8645 - val_mse: 4.8243\n",
      "Epoch 17/25\n",
      "148/158 [===========================>..] - ETA: 0s - loss: 4.8675 - mse: 4.8273\n",
      "Epoch 17: val_loss improved from 4.86452 to 4.86236, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e017_vl4.862.h5\n",
      "158/158 [==============================] - 1s 5ms/step - loss: 4.8623 - mse: 4.8220 - val_loss: 4.8624 - val_mse: 4.8222\n",
      "Epoch 18/25\n",
      "157/158 [============================>.] - ETA: 0s - loss: 4.8621 - mse: 4.8218\n",
      "Epoch 18: val_loss improved from 4.86236 to 4.86017, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e018_vl4.860.h5\n",
      "158/158 [==============================] - 1s 5ms/step - loss: 4.8618 - mse: 4.8215 - val_loss: 4.8602 - val_mse: 4.8198\n",
      "Epoch 19/25\n",
      "151/158 [===========================>..] - ETA: 0s - loss: 4.8624 - mse: 4.8220\n",
      "Epoch 19: val_loss did not improve from 4.86017\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 4.8601 - mse: 4.8197 - val_loss: 4.8675 - val_mse: 4.8271\n",
      "Epoch 20/25\n",
      "148/158 [===========================>..] - ETA: 0s - loss: 4.8568 - mse: 4.8164\n",
      "Epoch 20: val_loss did not improve from 4.86017\n",
      "158/158 [==============================] - 1s 5ms/step - loss: 4.8578 - mse: 4.8173 - val_loss: 4.8661 - val_mse: 4.8255\n",
      "Epoch 21/25\n",
      "154/158 [============================>.] - ETA: 0s - loss: 4.8580 - mse: 4.8174\n",
      "Epoch 21: val_loss improved from 4.86017 to 4.85620, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e021_vl4.856.h5\n",
      "158/158 [==============================] - 1s 5ms/step - loss: 4.8581 - mse: 4.8175 - val_loss: 4.8562 - val_mse: 4.8156\n",
      "Epoch 22/25\n",
      "147/158 [==========================>...] - ETA: 0s - loss: 4.8545 - mse: 4.8139\n",
      "Epoch 22: val_loss did not improve from 4.85620\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 4.8571 - mse: 4.8165 - val_loss: 4.8567 - val_mse: 4.8161\n",
      "Epoch 23/25\n",
      "156/158 [============================>.] - ETA: 0s - loss: 4.8539 - mse: 4.8132\n",
      "Epoch 23: val_loss improved from 4.85620 to 4.85479, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e023_vl4.855.h5\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 4.8539 - mse: 4.8132 - val_loss: 4.8548 - val_mse: 4.8141\n",
      "Epoch 24/25\n",
      "157/158 [============================>.] - ETA: 0s - loss: 4.8535 - mse: 4.8128\n",
      "Epoch 24: val_loss did not improve from 4.85479\n",
      "158/158 [==============================] - 1s 6ms/step - loss: 4.8532 - mse: 4.8124 - val_loss: 4.8556 - val_mse: 4.8148\n",
      "Epoch 25/25\n",
      "149/158 [===========================>..] - ETA: 0s - loss: 4.8500 - mse: 4.8091\n",
      "Epoch 25: val_loss improved from 4.85479 to 4.85255, saving model to checkpoints/ext_0h_l1n2_2hidden_it6.e025_vl4.853.h5\n",
      "158/158 [==============================] - 1s 5ms/step - loss: 4.8517 - mse: 4.8108 - val_loss: 4.8526 - val_mse: 4.8117\n",
      "Time elapsed to train: 25.27 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.538 3.254 1.858 3.597 2.460 1.920 1.510 1.236 0.855 0.316 0.325 0.019 0.019]\n",
      "<R> = [2.536 3.247 1.853 3.585 2.457 1.915 1.506 1.234 0.853 0.316 0.325 0.019 0.019]\n",
      "s_R = [0.551 0.931 0.495 1.307 0.702 0.420 0.439 0.495 0.228 0.000 0.034 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.847764  3.0977395 5.9675703 ... 3.0306697 4.1411753 4.497052 ]\n",
      "mag_pred: [3.847764  3.0977395 5.9675703 ... 3.0306697 4.1411753 4.497052 ]\n",
      "Time elapsed to make plots: 18.88 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 376.329      48.87822    21.25997  ...   30.677206   49.120865\n",
      " 1926.5093  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0184\n",
      "  1% : 0.227\n",
      "  10% : 0.74\n",
      "  50% : 5.14\n",
      "  90% : 41.7\n",
      "  99% : 375\n",
      "  100% : 7.4e+03\n",
      "<chi^2/d.o.f.> = 3.43\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 39286 stars (15.5%) based on chi^2/dof > 25.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  69.879      35.224174 1112.2485   ...  144.06387    70.29252\n",
      "   54.351696]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0401\n",
      "  1% : 0.228\n",
      "  10% : 0.713\n",
      "  50% : 5.07\n",
      "  90% : 41.1\n",
      "  99% : 374\n",
      "  100% : 5.3e+03\n",
      "<chi^2/d.o.f.> = 3.39\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 79.48 s\n",
      "learning rate = 0.0003011942026205361\n",
      "setting learning rate to 0.00024659696394160646\n",
      "Iteration 8 of 20.\n",
      "Epoch 1/25\n",
      "148/151 [============================>.] - ETA: 0s - loss: 4.3452 - mse: 4.3044\n",
      "Epoch 1: val_loss improved from inf to 4.34822, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e001_vl4.348.h5\n",
      "151/151 [==============================] - 2s 8ms/step - loss: 4.3473 - mse: 4.3065 - val_loss: 4.3482 - val_mse: 4.3075\n",
      "Epoch 2/25\n",
      "144/151 [===========================>..] - ETA: 0s - loss: 4.3453 - mse: 4.3047\n",
      "Epoch 2: val_loss improved from 4.34822 to 4.34639, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e002_vl4.346.h5\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 4.3429 - mse: 4.3023 - val_loss: 4.3464 - val_mse: 4.3058\n",
      "Epoch 3/25\n",
      "148/151 [============================>.] - ETA: 0s - loss: 4.3399 - mse: 4.2993\n",
      "Epoch 3: val_loss improved from 4.34639 to 4.34436, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e003_vl4.344.h5\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 4.3425 - mse: 4.3019 - val_loss: 4.3444 - val_mse: 4.3038\n",
      "Epoch 4/25\n",
      "144/151 [===========================>..] - ETA: 0s - loss: 4.3376 - mse: 4.2971\n",
      "Epoch 4: val_loss improved from 4.34436 to 4.34370, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e004_vl4.344.h5\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 4.3403 - mse: 4.2998 - val_loss: 4.3437 - val_mse: 4.3033\n",
      "Epoch 5/25\n",
      "148/151 [============================>.] - ETA: 0s - loss: 4.3380 - mse: 4.2976\n",
      "Epoch 5: val_loss improved from 4.34370 to 4.34054, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e005_vl4.341.h5\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 4.3383 - mse: 4.2979 - val_loss: 4.3405 - val_mse: 4.3001\n",
      "Epoch 6/25\n",
      "145/151 [===========================>..] - ETA: 0s - loss: 4.3372 - mse: 4.2968\n",
      "Epoch 6: val_loss did not improve from 4.34054\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 4.3386 - mse: 4.2981 - val_loss: 4.3419 - val_mse: 4.3016\n",
      "Epoch 7/25\n",
      "149/151 [============================>.] - ETA: 0s - loss: 4.3370 - mse: 4.2966\n",
      "Epoch 7: val_loss improved from 4.34054 to 4.33903, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e007_vl4.339.h5\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 4.3379 - mse: 4.2975 - val_loss: 4.3390 - val_mse: 4.2986\n",
      "Epoch 8/25\n",
      "151/151 [==============================] - ETA: 0s - loss: 4.3359 - mse: 4.2954\n",
      "Epoch 8: val_loss improved from 4.33903 to 4.33776, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e008_vl4.338.h5\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 4.3359 - mse: 4.2954 - val_loss: 4.3378 - val_mse: 4.2974\n",
      "Epoch 9/25\n",
      "148/151 [============================>.] - ETA: 0s - loss: 4.3342 - mse: 4.2937\n",
      "Epoch 9: val_loss did not improve from 4.33776\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 4.3345 - mse: 4.2941 - val_loss: 4.3458 - val_mse: 4.3053\n",
      "Epoch 10/25\n",
      "147/151 [============================>.] - ETA: 0s - loss: 4.3366 - mse: 4.2962\n",
      "Epoch 10: val_loss improved from 4.33776 to 4.33603, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e010_vl4.336.h5\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 4.3347 - mse: 4.2942 - val_loss: 4.3360 - val_mse: 4.2955\n",
      "Epoch 11/25\n",
      "145/151 [===========================>..] - ETA: 0s - loss: 4.3319 - mse: 4.2913\n",
      "Epoch 11: val_loss did not improve from 4.33603\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 4.3330 - mse: 4.2923 - val_loss: 4.3410 - val_mse: 4.3003\n",
      "Epoch 12/25\n",
      "147/151 [============================>.] - ETA: 0s - loss: 4.3328 - mse: 4.2920\n",
      "Epoch 12: val_loss improved from 4.33603 to 4.33279, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e012_vl4.333.h5\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 4.3329 - mse: 4.2922 - val_loss: 4.3328 - val_mse: 4.2919\n",
      "Epoch 13/25\n",
      "142/151 [===========================>..] - ETA: 0s - loss: 4.3278 - mse: 4.2869\n",
      "Epoch 13: val_loss did not improve from 4.33279\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 4.3303 - mse: 4.2894 - val_loss: 4.3353 - val_mse: 4.2943\n",
      "Epoch 14/25\n",
      "144/151 [===========================>..] - ETA: 0s - loss: 4.3259 - mse: 4.2848\n",
      "Epoch 14: val_loss improved from 4.33279 to 4.33221, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e014_vl4.332.h5\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 4.3295 - mse: 4.2884 - val_loss: 4.3322 - val_mse: 4.2910\n",
      "Epoch 15/25\n",
      "146/151 [============================>.] - ETA: 0s - loss: 4.3290 - mse: 4.2877\n",
      "Epoch 15: val_loss improved from 4.33221 to 4.32999, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e015_vl4.330.h5\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 4.3288 - mse: 4.2875 - val_loss: 4.3300 - val_mse: 4.2885\n",
      "Epoch 16/25\n",
      "142/151 [===========================>..] - ETA: 0s - loss: 4.3246 - mse: 4.2830\n",
      "Epoch 16: val_loss improved from 4.32999 to 4.32917, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e016_vl4.329.h5\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 4.3275 - mse: 4.2859 - val_loss: 4.3292 - val_mse: 4.2874\n",
      "Epoch 17/25\n",
      "147/151 [============================>.] - ETA: 0s - loss: 4.3237 - mse: 4.2818\n",
      "Epoch 17: val_loss improved from 4.32917 to 4.32817, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e017_vl4.328.h5\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 4.3258 - mse: 4.2839 - val_loss: 4.3282 - val_mse: 4.2861\n",
      "Epoch 18/25\n",
      "143/151 [===========================>..] - ETA: 0s - loss: 4.3268 - mse: 4.2845\n",
      "Epoch 18: val_loss did not improve from 4.32817\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 4.3246 - mse: 4.2824 - val_loss: 4.3286 - val_mse: 4.2861\n",
      "Epoch 19/25\n",
      "143/151 [===========================>..] - ETA: 0s - loss: 4.3266 - mse: 4.2839\n",
      "Epoch 19: val_loss did not improve from 4.32817\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 4.3253 - mse: 4.2827 - val_loss: 4.3343 - val_mse: 4.2914\n",
      "Epoch 20/25\n",
      "149/151 [============================>.] - ETA: 0s - loss: 4.3212 - mse: 4.2781\n",
      "Epoch 20: val_loss improved from 4.32817 to 4.32556, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e020_vl4.326.h5\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 4.3229 - mse: 4.2799 - val_loss: 4.3256 - val_mse: 4.2823\n",
      "Epoch 21/25\n",
      "149/151 [============================>.] - ETA: 0s - loss: 4.3208 - mse: 4.2774\n",
      "Epoch 21: val_loss improved from 4.32556 to 4.32242, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e021_vl4.322.h5\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 4.3218 - mse: 4.2783 - val_loss: 4.3224 - val_mse: 4.2786\n",
      "Epoch 22/25\n",
      "142/151 [===========================>..] - ETA: 0s - loss: 4.3213 - mse: 4.2773\n",
      "Epoch 22: val_loss improved from 4.32242 to 4.31959, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e022_vl4.320.h5\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 4.3192 - mse: 4.2752 - val_loss: 4.3196 - val_mse: 4.2753\n",
      "Epoch 23/25\n",
      "144/151 [===========================>..] - ETA: 0s - loss: 4.3184 - mse: 4.2739\n",
      "Epoch 23: val_loss did not improve from 4.31959\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 4.3176 - mse: 4.2731 - val_loss: 4.3225 - val_mse: 4.2776\n",
      "Epoch 24/25\n",
      "144/151 [===========================>..] - ETA: 0s - loss: 4.3146 - mse: 4.2696\n",
      "Epoch 24: val_loss improved from 4.31959 to 4.31905, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e024_vl4.319.h5\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 4.3176 - mse: 4.2726 - val_loss: 4.3190 - val_mse: 4.2737\n",
      "Epoch 25/25\n",
      "151/151 [==============================] - ETA: 0s - loss: 4.3141 - mse: 4.2685\n",
      "Epoch 25: val_loss improved from 4.31905 to 4.31713, saving model to checkpoints/ext_0h_l1n2_2hidden_it7.e025_vl4.317.h5\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 4.3141 - mse: 4.2685 - val_loss: 4.3171 - val_mse: 4.2712\n",
      "Time elapsed to train: 24.72 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.837 3.551 2.123 3.915 2.769 2.201 1.777 1.509 1.097 0.526 0.510 0.011 0.011]\n",
      "<R> = [2.834 3.548 2.117 3.904 2.770 2.196 1.773 1.505 1.093 0.524 0.508 0.011 0.011]\n",
      "s_R = [0.576 0.865 0.539 1.203 0.713 0.500 0.526 0.660 0.391 0.231 0.265 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.8469675 3.071878  5.890853  ... 3.0697505 4.0956783 4.4859457]\n",
      "mag_pred: [3.8469675 3.071878  5.890853  ... 3.0697505 4.0956783 4.4859457]\n",
      "Time elapsed to make plots: 20.03 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 349.50745    55.186264   19.408289 ...   31.406492   51.712044\n",
      " 2287.2852  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0267\n",
      "  1% : 0.227\n",
      "  10% : 0.752\n",
      "  50% : 5.28\n",
      "  90% : 47.3\n",
      "  99% : 430\n",
      "  100% : 7.14e+03\n",
      "<chi^2/d.o.f.> = 3.43\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 50675 stars (20%) based on chi^2/dof > 19.9\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [  73.6018     40.887802 1083.7295   ...  133.91788    64.72587\n",
      "   94.97464 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0632\n",
      "  1% : 0.219\n",
      "  10% : 0.738\n",
      "  50% : 5.22\n",
      "  90% : 46.9\n",
      "  99% : 429\n",
      "  100% : 5.31e+03\n",
      "<chi^2/d.o.f.> = 3.39\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 76.47 s\n",
      "learning rate = 0.00024659695918671787\n",
      "setting learning rate to 0.00020189651799465538\n",
      "Iteration 9 of 20.\n",
      "Epoch 1/25\n",
      "137/143 [===========================>..] - ETA: 0s - loss: 3.8538 - mse: 3.8078\n",
      "Epoch 1: val_loss improved from inf to 3.86059, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e001_vl3.861.h5\n",
      "143/143 [==============================] - 1s 8ms/step - loss: 3.8540 - mse: 3.8080 - val_loss: 3.8606 - val_mse: 3.8144\n",
      "Epoch 2/25\n",
      "141/143 [============================>.] - ETA: 0s - loss: 3.8482 - mse: 3.8018\n",
      "Epoch 2: val_loss improved from 3.86059 to 3.85833, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e002_vl3.858.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.8485 - mse: 3.8021 - val_loss: 3.8583 - val_mse: 3.8116\n",
      "Epoch 3/25\n",
      "142/143 [============================>.] - ETA: 0s - loss: 3.8474 - mse: 3.8005\n",
      "Epoch 3: val_loss did not improve from 3.85833\n",
      "143/143 [==============================] - 1s 7ms/step - loss: 3.8476 - mse: 3.8007 - val_loss: 3.8604 - val_mse: 3.8132\n",
      "Epoch 4/25\n",
      "140/143 [============================>.] - ETA: 0s - loss: 3.8430 - mse: 3.7957\n",
      "Epoch 4: val_loss improved from 3.85833 to 3.85603, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e004_vl3.856.h5\n",
      "143/143 [==============================] - 1s 7ms/step - loss: 3.8445 - mse: 3.7972 - val_loss: 3.8560 - val_mse: 3.8084\n",
      "Epoch 5/25\n",
      "143/143 [==============================] - ETA: 0s - loss: 3.8419 - mse: 3.7941\n",
      "Epoch 5: val_loss improved from 3.85603 to 3.85449, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e005_vl3.854.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.8419 - mse: 3.7941 - val_loss: 3.8545 - val_mse: 3.8064\n",
      "Epoch 6/25\n",
      "136/143 [===========================>..] - ETA: 0s - loss: 3.8400 - mse: 3.7917\n",
      "Epoch 6: val_loss improved from 3.85449 to 3.85074, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e006_vl3.851.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.8405 - mse: 3.7922 - val_loss: 3.8507 - val_mse: 3.8022\n",
      "Epoch 7/25\n",
      "135/143 [===========================>..] - ETA: 0s - loss: 3.8392 - mse: 3.7904\n",
      "Epoch 7: val_loss improved from 3.85074 to 3.84760, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e007_vl3.848.h5\n",
      "143/143 [==============================] - 1s 7ms/step - loss: 3.8384 - mse: 3.7897 - val_loss: 3.8476 - val_mse: 3.7986\n",
      "Epoch 8/25\n",
      "134/143 [===========================>..] - ETA: 0s - loss: 3.8321 - mse: 3.7829\n",
      "Epoch 8: val_loss improved from 3.84760 to 3.84684, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e008_vl3.847.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.8365 - mse: 3.7872 - val_loss: 3.8468 - val_mse: 3.7973\n",
      "Epoch 9/25\n",
      "136/143 [===========================>..] - ETA: 0s - loss: 3.8347 - mse: 3.7850\n",
      "Epoch 9: val_loss improved from 3.84684 to 3.84484, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e009_vl3.845.h5\n",
      "143/143 [==============================] - 1s 7ms/step - loss: 3.8346 - mse: 3.7849 - val_loss: 3.8448 - val_mse: 3.7950\n",
      "Epoch 10/25\n",
      "134/143 [===========================>..] - ETA: 0s - loss: 3.8306 - mse: 3.7805\n",
      "Epoch 10: val_loss improved from 3.84484 to 3.84455, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e010_vl3.845.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.8326 - mse: 3.7825 - val_loss: 3.8445 - val_mse: 3.7942\n",
      "Epoch 11/25\n",
      "141/143 [============================>.] - ETA: 0s - loss: 3.8328 - mse: 3.7823\n",
      "Epoch 11: val_loss improved from 3.84455 to 3.84392, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e011_vl3.844.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.8316 - mse: 3.7812 - val_loss: 3.8439 - val_mse: 3.7933\n",
      "Epoch 12/25\n",
      "143/143 [==============================] - ETA: 0s - loss: 3.8299 - mse: 3.7790\n",
      "Epoch 12: val_loss improved from 3.84392 to 3.83934, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e012_vl3.839.h5\n",
      "143/143 [==============================] - 1s 7ms/step - loss: 3.8299 - mse: 3.7790 - val_loss: 3.8393 - val_mse: 3.7883\n",
      "Epoch 13/25\n",
      "141/143 [============================>.] - ETA: 0s - loss: 3.8281 - mse: 3.7769\n",
      "Epoch 13: val_loss did not improve from 3.83934\n",
      "143/143 [==============================] - 1s 7ms/step - loss: 3.8280 - mse: 3.7768 - val_loss: 3.8441 - val_mse: 3.7927\n",
      "Epoch 14/25\n",
      "139/143 [============================>.] - ETA: 0s - loss: 3.8266 - mse: 3.7751\n",
      "Epoch 14: val_loss improved from 3.83934 to 3.83834, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e014_vl3.838.h5\n",
      "143/143 [==============================] - 1s 7ms/step - loss: 3.8273 - mse: 3.7758 - val_loss: 3.8383 - val_mse: 3.7867\n",
      "Epoch 15/25\n",
      "138/143 [===========================>..] - ETA: 0s - loss: 3.8233 - mse: 3.7714\n",
      "Epoch 15: val_loss did not improve from 3.83834\n",
      "143/143 [==============================] - 1s 7ms/step - loss: 3.8254 - mse: 3.7736 - val_loss: 3.8386 - val_mse: 3.7866\n",
      "Epoch 16/25\n",
      "142/143 [============================>.] - ETA: 0s - loss: 3.8236 - mse: 3.7715\n",
      "Epoch 16: val_loss improved from 3.83834 to 3.83703, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e016_vl3.837.h5\n",
      "143/143 [==============================] - 1s 7ms/step - loss: 3.8236 - mse: 3.7715 - val_loss: 3.8370 - val_mse: 3.7848\n",
      "Epoch 17/25\n",
      "137/143 [===========================>..] - ETA: 0s - loss: 3.8228 - mse: 3.7704\n",
      "Epoch 17: val_loss improved from 3.83703 to 3.83629, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e017_vl3.836.h5\n",
      "143/143 [==============================] - 1s 7ms/step - loss: 3.8234 - mse: 3.7711 - val_loss: 3.8363 - val_mse: 3.7838\n",
      "Epoch 18/25\n",
      "135/143 [===========================>..] - ETA: 0s - loss: 3.8194 - mse: 3.7669\n",
      "Epoch 18: val_loss did not improve from 3.83629\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.8218 - mse: 3.7692 - val_loss: 3.8493 - val_mse: 3.7966\n",
      "Epoch 19/25\n",
      "134/143 [===========================>..] - ETA: 0s - loss: 3.8162 - mse: 3.7634\n",
      "Epoch 19: val_loss did not improve from 3.83629\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.8214 - mse: 3.7687 - val_loss: 3.8386 - val_mse: 3.7857\n",
      "Epoch 20/25\n",
      "137/143 [===========================>..] - ETA: 0s - loss: 3.8219 - mse: 3.7689\n",
      "Epoch 20: val_loss improved from 3.83629 to 3.83355, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e020_vl3.834.h5\n",
      "143/143 [==============================] - 1s 7ms/step - loss: 3.8211 - mse: 3.7681 - val_loss: 3.8335 - val_mse: 3.7805\n",
      "Epoch 21/25\n",
      "143/143 [==============================] - ETA: 0s - loss: 3.8187 - mse: 3.7655\n",
      "Epoch 21: val_loss improved from 3.83355 to 3.83159, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e021_vl3.832.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.8187 - mse: 3.7655 - val_loss: 3.8316 - val_mse: 3.7783\n",
      "Epoch 22/25\n",
      "142/143 [============================>.] - ETA: 0s - loss: 3.8184 - mse: 3.7651\n",
      "Epoch 22: val_loss did not improve from 3.83159\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.8184 - mse: 3.7651 - val_loss: 3.8353 - val_mse: 3.7818\n",
      "Epoch 23/25\n",
      "142/143 [============================>.] - ETA: 0s - loss: 3.8158 - mse: 3.7623\n",
      "Epoch 23: val_loss improved from 3.83159 to 3.83103, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e023_vl3.831.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.8163 - mse: 3.7628 - val_loss: 3.8310 - val_mse: 3.7774\n",
      "Epoch 24/25\n",
      "133/143 [==========================>...] - ETA: 0s - loss: 3.8140 - mse: 3.7603\n",
      "Epoch 24: val_loss improved from 3.83103 to 3.83053, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e024_vl3.831.h5\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 3.8152 - mse: 3.7615 - val_loss: 3.8305 - val_mse: 3.7768\n",
      "Epoch 25/25\n",
      "134/143 [===========================>..] - ETA: 0s - loss: 3.8171 - mse: 3.7633\n",
      "Epoch 25: val_loss improved from 3.83053 to 3.82817, saving model to checkpoints/ext_0h_l1n2_2hidden_it8.e025_vl3.828.h5\n",
      "143/143 [==============================] - 1s 7ms/step - loss: 3.8148 - mse: 3.7610 - val_loss: 3.8282 - val_mse: 3.7743\n",
      "Time elapsed to train: 23.92 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [3.107 3.807 2.388 4.159 3.042 2.473 2.036 1.767 1.365 0.785 0.776 0.007 0.007]\n",
      "<R> = [3.103 3.807 2.381 4.150 3.041 2.466 2.028 1.760 1.359 0.780 0.770 0.007 0.007]\n",
      "s_R = [0.676 0.772 0.770 0.916 0.758 0.733 0.836 1.047 1.176 2.466 2.528 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.8494813 3.0524626 5.838346  ... 3.1058848 4.060949  4.4734025]\n",
      "mag_pred: [3.8494813 3.0524626 5.838346  ... 3.1058848 4.060949  4.4734025]\n",
      "Time elapsed to make plots: 17.56 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 331.02597    51.16689    24.444061 ...   26.87717    52.697525\n",
      " 2390.1465  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.014\n",
      "  1% : 0.204\n",
      "  10% : 0.7\n",
      "  50% : 4.97\n",
      "  90% : 48.9\n",
      "  99% : 437\n",
      "  100% : 7.09e+03\n",
      "<chi^2/d.o.f.> = 3.35\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 59172 stars (23.4%) based on chi^2/dof > 15.8\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 66.980194  47.1412   881.67267  ... 152.60042   57.12031  123.6734  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0306\n",
      "  1% : 0.195\n",
      "  10% : 0.696\n",
      "  50% : 4.9\n",
      "  90% : 48.4\n",
      "  99% : 427\n",
      "  100% : 5.32e+03\n",
      "<chi^2/d.o.f.> = 3.31\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 74.87 s\n",
      "learning rate = 0.00020189651695545763\n",
      "setting learning rate to 0.00016529888822158653\n",
      "Iteration 10 of 20.\n",
      "Epoch 1/25\n",
      "131/137 [===========================>..] - ETA: 0s - loss: 3.3525 - mse: 3.2981\n",
      "Epoch 1: val_loss improved from inf to 3.35397, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e001_vl3.354.h5\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 3.3566 - mse: 3.3022 - val_loss: 3.3540 - val_mse: 3.2990\n",
      "Epoch 2/25\n",
      "135/137 [============================>.] - ETA: 0s - loss: 3.3447 - mse: 3.2894\n",
      "Epoch 2: val_loss improved from 3.35397 to 3.34635, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e002_vl3.346.h5\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 3.3458 - mse: 3.2905 - val_loss: 3.3463 - val_mse: 3.2906\n",
      "Epoch 3/25\n",
      "136/137 [============================>.] - ETA: 0s - loss: 3.3410 - mse: 3.2850\n",
      "Epoch 3: val_loss improved from 3.34635 to 3.34354, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e003_vl3.344.h5\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 3.3419 - mse: 3.2858 - val_loss: 3.3435 - val_mse: 3.2872\n",
      "Epoch 4/25\n",
      "130/137 [===========================>..] - ETA: 0s - loss: 3.3403 - mse: 3.2838\n",
      "Epoch 4: val_loss improved from 3.34354 to 3.34249, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e004_vl3.342.h5\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 3.3393 - mse: 3.2828 - val_loss: 3.3425 - val_mse: 3.2856\n",
      "Epoch 5/25\n",
      "134/137 [============================>.] - ETA: 0s - loss: 3.3368 - mse: 3.2798\n",
      "Epoch 5: val_loss improved from 3.34249 to 3.33885, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e005_vl3.339.h5\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 3.3375 - mse: 3.2805 - val_loss: 3.3388 - val_mse: 3.2817\n",
      "Epoch 6/25\n",
      "130/137 [===========================>..] - ETA: 0s - loss: 3.3350 - mse: 3.2777\n",
      "Epoch 6: val_loss improved from 3.33885 to 3.33765, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e006_vl3.338.h5\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 3.3356 - mse: 3.2782 - val_loss: 3.3376 - val_mse: 3.2802\n",
      "Epoch 7/25\n",
      "129/137 [===========================>..] - ETA: 0s - loss: 3.3363 - mse: 3.2787\n",
      "Epoch 7: val_loss improved from 3.33765 to 3.33727, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e007_vl3.337.h5\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 3.3342 - mse: 3.2767 - val_loss: 3.3373 - val_mse: 3.2796\n",
      "Epoch 8/25\n",
      "132/137 [===========================>..] - ETA: 0s - loss: 3.3323 - mse: 3.2745\n",
      "Epoch 8: val_loss improved from 3.33727 to 3.33537, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e008_vl3.335.h5\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 3.3324 - mse: 3.2745 - val_loss: 3.3354 - val_mse: 3.2775\n",
      "Epoch 9/25\n",
      "129/137 [===========================>..] - ETA: 0s - loss: 3.3336 - mse: 3.2757\n",
      "Epoch 9: val_loss improved from 3.33537 to 3.33385, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e009_vl3.334.h5\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 3.3316 - mse: 3.2737 - val_loss: 3.3338 - val_mse: 3.2759\n",
      "Epoch 10/25\n",
      "135/137 [============================>.] - ETA: 0s - loss: 3.3301 - mse: 3.2720\n",
      "Epoch 10: val_loss improved from 3.33385 to 3.33363, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e010_vl3.334.h5\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 3.3310 - mse: 3.2729 - val_loss: 3.3336 - val_mse: 3.2755\n",
      "Epoch 11/25\n",
      "133/137 [============================>.] - ETA: 0s - loss: 3.3294 - mse: 3.2712\n",
      "Epoch 11: val_loss improved from 3.33363 to 3.33103, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e011_vl3.331.h5\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 3.3297 - mse: 3.2715 - val_loss: 3.3310 - val_mse: 3.2728\n",
      "Epoch 12/25\n",
      "137/137 [==============================] - ETA: 0s - loss: 3.3285 - mse: 3.2702\n",
      "Epoch 12: val_loss improved from 3.33103 to 3.33101, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e012_vl3.331.h5\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 3.3285 - mse: 3.2702 - val_loss: 3.3310 - val_mse: 3.2727\n",
      "Epoch 13/25\n",
      "131/137 [===========================>..] - ETA: 0s - loss: 3.3305 - mse: 3.2721\n",
      "Epoch 13: val_loss improved from 3.33101 to 3.32968, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e013_vl3.330.h5\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 3.3285 - mse: 3.2702 - val_loss: 3.3297 - val_mse: 3.2713\n",
      "Epoch 14/25\n",
      "135/137 [============================>.] - ETA: 0s - loss: 3.3261 - mse: 3.2677\n",
      "Epoch 14: val_loss did not improve from 3.32968\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 3.3271 - mse: 3.2687 - val_loss: 3.3310 - val_mse: 3.2727\n",
      "Epoch 15/25\n",
      "129/137 [===========================>..] - ETA: 0s - loss: 3.3270 - mse: 3.2686\n",
      "Epoch 15: val_loss improved from 3.32968 to 3.32719, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e015_vl3.327.h5\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 3.3268 - mse: 3.2684 - val_loss: 3.3272 - val_mse: 3.2688\n",
      "Epoch 16/25\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 3.3234 - mse: 3.2649\n",
      "Epoch 16: val_loss did not improve from 3.32719\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 3.3264 - mse: 3.2679 - val_loss: 3.3288 - val_mse: 3.2703\n",
      "Epoch 17/25\n",
      "128/137 [===========================>..] - ETA: 0s - loss: 3.3254 - mse: 3.2669\n",
      "Epoch 17: val_loss improved from 3.32719 to 3.32693, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e017_vl3.327.h5\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 3.3253 - mse: 3.2668 - val_loss: 3.3269 - val_mse: 3.2684\n",
      "Epoch 18/25\n",
      "136/137 [============================>.] - ETA: 0s - loss: 3.3249 - mse: 3.2664\n",
      "Epoch 18: val_loss did not improve from 3.32693\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 3.3246 - mse: 3.2661 - val_loss: 3.3276 - val_mse: 3.2691\n",
      "Epoch 19/25\n",
      "128/137 [===========================>..] - ETA: 0s - loss: 3.3224 - mse: 3.2638\n",
      "Epoch 19: val_loss did not improve from 3.32693\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 3.3240 - mse: 3.2654 - val_loss: 3.3282 - val_mse: 3.2697\n",
      "Epoch 20/25\n",
      "130/137 [===========================>..] - ETA: 0s - loss: 3.3238 - mse: 3.2652\n",
      "Epoch 20: val_loss improved from 3.32693 to 3.32447, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e020_vl3.324.h5\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 3.3228 - mse: 3.2643 - val_loss: 3.3245 - val_mse: 3.2659\n",
      "Epoch 21/25\n",
      "128/137 [===========================>..] - ETA: 0s - loss: 3.3242 - mse: 3.2656\n",
      "Epoch 21: val_loss did not improve from 3.32447\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 3.3221 - mse: 3.2635 - val_loss: 3.3251 - val_mse: 3.2665\n",
      "Epoch 22/25\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 3.3213 - mse: 3.2627\n",
      "Epoch 22: val_loss improved from 3.32447 to 3.32382, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e022_vl3.324.h5\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 3.3214 - mse: 3.2628 - val_loss: 3.3238 - val_mse: 3.2652\n",
      "Epoch 23/25\n",
      "137/137 [==============================] - ETA: 0s - loss: 3.3204 - mse: 3.2618\n",
      "Epoch 23: val_loss improved from 3.32382 to 3.32230, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e023_vl3.322.h5\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 3.3204 - mse: 3.2618 - val_loss: 3.3223 - val_mse: 3.2637\n",
      "Epoch 24/25\n",
      "135/137 [============================>.] - ETA: 0s - loss: 3.3204 - mse: 3.2618\n",
      "Epoch 24: val_loss did not improve from 3.32230\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 3.3204 - mse: 3.2617 - val_loss: 3.3224 - val_mse: 3.2637\n",
      "Epoch 25/25\n",
      "131/137 [===========================>..] - ETA: 0s - loss: 3.3202 - mse: 3.2615\n",
      "Epoch 25: val_loss improved from 3.32230 to 3.32157, saving model to checkpoints/ext_0h_l1n2_2hidden_it9.e025_vl3.322.h5\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 3.3196 - mse: 3.2609 - val_loss: 3.3216 - val_mse: 3.2629\n",
      "Time elapsed to train: 22.14 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [3.251 3.925 2.554 4.253 3.207 2.631 2.208 1.945 1.563 0.990 0.981 0.004 0.005]\n",
      "<R> = [3.254 3.946 2.546 4.275 3.213 2.623 2.200 1.938 1.556 0.983 0.976 0.004 0.005]\n",
      "s_R = [0.729 0.751 0.892 0.812 0.806 0.843 1.032 1.277 1.713 4.405 4.619 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.8485472 3.029981  5.809525  ... 3.127589  4.0414295 4.459251 ]\n",
      "mag_pred: [3.8485472 3.029981  5.809525  ... 3.127589  4.0414295 4.459251 ]\n",
      "Time elapsed to make plots: 19.63 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 305.66696    48.15928    33.8263   ...   23.127224   53.323055\n",
      " 2584.0144  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0281\n",
      "  1% : 0.198\n",
      "  10% : 0.677\n",
      "  50% : 4.77\n",
      "  90% : 51.2\n",
      "  99% : 454\n",
      "  100% : 7.08e+03\n",
      "<chi^2/d.o.f.> = 3.28\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 69177 stars (27.3%) based on chi^2/dof > 12.6\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 59.22589   52.974884 825.89734  ... 180.63565   52.37996  166.37909 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0363\n",
      "  1% : 0.186\n",
      "  10% : 0.671\n",
      "  50% : 4.72\n",
      "  90% : 50.5\n",
      "  99% : 449\n",
      "  100% : 5.34e+03\n",
      "<chi^2/d.o.f.> = 3.27\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 74.74 s\n",
      "learning rate = 0.00016529888671357185\n",
      "setting learning rate to 0.0001353352832366127\n",
      "Iteration 11 of 20.\n",
      "Epoch 1/25\n",
      "127/130 [============================>.] - ETA: 0s - loss: 2.8936 - mse: 2.8351\n",
      "Epoch 1: val_loss improved from inf to 2.88996, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e001_vl2.890.h5\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 2.8946 - mse: 2.8360 - val_loss: 2.8900 - val_mse: 2.8314\n",
      "Epoch 2/25\n",
      "121/130 [==========================>...] - ETA: 0s - loss: 2.8916 - mse: 2.8331\n",
      "Epoch 2: val_loss did not improve from 2.88996\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.8917 - mse: 2.8332 - val_loss: 2.8900 - val_mse: 2.8316\n",
      "Epoch 3/25\n",
      "121/130 [==========================>...] - ETA: 0s - loss: 2.8925 - mse: 2.8342\n",
      "Epoch 3: val_loss improved from 2.88996 to 2.88833, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e003_vl2.888.h5\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 2.8909 - mse: 2.8325 - val_loss: 2.8883 - val_mse: 2.8300\n",
      "Epoch 4/25\n",
      "124/130 [===========================>..] - ETA: 0s - loss: 2.8897 - mse: 2.8314\n",
      "Epoch 4: val_loss improved from 2.88833 to 2.88653, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e004_vl2.887.h5\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 2.8899 - mse: 2.8316 - val_loss: 2.8865 - val_mse: 2.8282\n",
      "Epoch 5/25\n",
      "122/130 [===========================>..] - ETA: 0s - loss: 2.8896 - mse: 2.8314\n",
      "Epoch 5: val_loss improved from 2.88653 to 2.88596, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e005_vl2.886.h5\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 2.8893 - mse: 2.8310 - val_loss: 2.8860 - val_mse: 2.8277\n",
      "Epoch 6/25\n",
      "127/130 [============================>.] - ETA: 0s - loss: 2.8882 - mse: 2.8301\n",
      "Epoch 6: val_loss improved from 2.88596 to 2.88527, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e006_vl2.885.h5\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 2.8886 - mse: 2.8304 - val_loss: 2.8853 - val_mse: 2.8271\n",
      "Epoch 7/25\n",
      "129/130 [============================>.] - ETA: 0s - loss: 2.8884 - mse: 2.8302\n",
      "Epoch 7: val_loss improved from 2.88527 to 2.88493, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e007_vl2.885.h5\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 2.8881 - mse: 2.8299 - val_loss: 2.8849 - val_mse: 2.8268\n",
      "Epoch 8/25\n",
      "120/130 [==========================>...] - ETA: 0s - loss: 2.8878 - mse: 2.8298\n",
      "Epoch 8: val_loss did not improve from 2.88493\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.8880 - mse: 2.8299 - val_loss: 2.8864 - val_mse: 2.8283\n",
      "Epoch 9/25\n",
      "129/130 [============================>.] - ETA: 0s - loss: 2.8875 - mse: 2.8295\n",
      "Epoch 9: val_loss improved from 2.88493 to 2.88415, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e009_vl2.884.h5\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 2.8875 - mse: 2.8295 - val_loss: 2.8841 - val_mse: 2.8261\n",
      "Epoch 10/25\n",
      "125/130 [===========================>..] - ETA: 0s - loss: 2.8864 - mse: 2.8284\n",
      "Epoch 10: val_loss did not improve from 2.88415\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 2.8866 - mse: 2.8286 - val_loss: 2.8842 - val_mse: 2.8263\n",
      "Epoch 11/25\n",
      "123/130 [===========================>..] - ETA: 0s - loss: 2.8853 - mse: 2.8274\n",
      "Epoch 11: val_loss improved from 2.88415 to 2.88204, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e011_vl2.882.h5\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 2.8864 - mse: 2.8285 - val_loss: 2.8820 - val_mse: 2.8241\n",
      "Epoch 12/25\n",
      "129/130 [============================>.] - ETA: 0s - loss: 2.8854 - mse: 2.8276\n",
      "Epoch 12: val_loss did not improve from 2.88204\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.8856 - mse: 2.8277 - val_loss: 2.8827 - val_mse: 2.8248\n",
      "Epoch 13/25\n",
      "121/130 [==========================>...] - ETA: 0s - loss: 2.8869 - mse: 2.8291\n",
      "Epoch 13: val_loss improved from 2.88204 to 2.88164, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e013_vl2.882.h5\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 2.8856 - mse: 2.8278 - val_loss: 2.8816 - val_mse: 2.8239\n",
      "Epoch 14/25\n",
      "126/130 [============================>.] - ETA: 0s - loss: 2.8851 - mse: 2.8274\n",
      "Epoch 14: val_loss improved from 2.88164 to 2.88029, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e014_vl2.880.h5\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 2.8846 - mse: 2.8268 - val_loss: 2.8803 - val_mse: 2.8226\n",
      "Epoch 15/25\n",
      "127/130 [============================>.] - ETA: 0s - loss: 2.8843 - mse: 2.8266\n",
      "Epoch 15: val_loss did not improve from 2.88029\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 2.8837 - mse: 2.8260 - val_loss: 2.8804 - val_mse: 2.8227\n",
      "Epoch 16/25\n",
      "125/130 [===========================>..] - ETA: 0s - loss: 2.8843 - mse: 2.8266\n",
      "Epoch 16: val_loss did not improve from 2.88029\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 2.8840 - mse: 2.8264 - val_loss: 2.8806 - val_mse: 2.8230\n",
      "Epoch 17/25\n",
      "126/130 [============================>.] - ETA: 0s - loss: 2.8831 - mse: 2.8255\n",
      "Epoch 17: val_loss improved from 2.88029 to 2.87954, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e017_vl2.880.h5\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 2.8833 - mse: 2.8257 - val_loss: 2.8795 - val_mse: 2.8220\n",
      "Epoch 18/25\n",
      "127/130 [============================>.] - ETA: 0s - loss: 2.8819 - mse: 2.8244\n",
      "Epoch 18: val_loss did not improve from 2.87954\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 2.8828 - mse: 2.8252 - val_loss: 2.8801 - val_mse: 2.8226\n",
      "Epoch 19/25\n",
      "127/130 [============================>.] - ETA: 0s - loss: 2.8812 - mse: 2.8238\n",
      "Epoch 19: val_loss did not improve from 2.87954\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.8820 - mse: 2.8245 - val_loss: 2.8818 - val_mse: 2.8243\n",
      "Epoch 20/25\n",
      "124/130 [===========================>..] - ETA: 0s - loss: 2.8816 - mse: 2.8241\n",
      "Epoch 20: val_loss improved from 2.87954 to 2.87813, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e020_vl2.878.h5\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 2.8825 - mse: 2.8251 - val_loss: 2.8781 - val_mse: 2.8207\n",
      "Epoch 21/25\n",
      "127/130 [============================>.] - ETA: 0s - loss: 2.8821 - mse: 2.8247\n",
      "Epoch 21: val_loss improved from 2.87813 to 2.87793, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e021_vl2.878.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.8819 - mse: 2.8245 - val_loss: 2.8779 - val_mse: 2.8206\n",
      "Epoch 22/25\n",
      "121/130 [==========================>...] - ETA: 0s - loss: 2.8813 - mse: 2.8240\n",
      "Epoch 22: val_loss improved from 2.87793 to 2.87715, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e022_vl2.877.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.8811 - mse: 2.8238 - val_loss: 2.8771 - val_mse: 2.8198\n",
      "Epoch 23/25\n",
      "125/130 [===========================>..] - ETA: 0s - loss: 2.8824 - mse: 2.8251\n",
      "Epoch 23: val_loss did not improve from 2.87715\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.8811 - mse: 2.8238 - val_loss: 2.8778 - val_mse: 2.8206\n",
      "Epoch 24/25\n",
      "128/130 [============================>.] - ETA: 0s - loss: 2.8814 - mse: 2.8242\n",
      "Epoch 24: val_loss improved from 2.87715 to 2.87612, saving model to checkpoints/ext_0h_l1n2_2hidden_it10.e024_vl2.876.h5\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.8804 - mse: 2.8232 - val_loss: 2.8761 - val_mse: 2.8189\n",
      "Epoch 25/25\n",
      "128/130 [============================>.] - ETA: 0s - loss: 2.8798 - mse: 2.8226\n",
      "Epoch 25: val_loss did not improve from 2.87612\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.8794 - mse: 2.8222 - val_loss: 2.8784 - val_mse: 2.8213\n",
      "Time elapsed to train: 21.92 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [3.378 4.043 2.678 4.346 3.343 2.755 2.323 2.051 1.681 1.117 1.100 0.003 0.003]\n",
      "<R> = [3.380 4.063 2.670 4.369 3.345 2.747 2.313 2.041 1.673 1.110 1.094 0.003 0.003]\n",
      "s_R = [0.770 0.762 0.935 0.790 0.846 0.896 1.084 1.259 1.756 4.088 4.468 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.8352091 3.0004797 5.8160644 ... 3.1078203 4.024414  4.444971 ]\n",
      "mag_pred: [3.8352091 3.0004797 5.8160644 ... 3.1078203 4.024414  4.444971 ]\n",
      "Time elapsed to make plots: 17.68 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 291.1408     43.67328    43.543602 ...   21.316158   51.549286\n",
      " 2619.5054  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0125\n",
      "  1% : 0.192\n",
      "  10% : 0.654\n",
      "  50% : 4.56\n",
      "  90% : 51\n",
      "  99% : 437\n",
      "  100% : 7.2e+03\n",
      "<chi^2/d.o.f.> = 3.21\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 79136 stars (31.3%) based on chi^2/dof > 10.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 54.96157   56.832176 808.9049   ... 224.92186   49.08632  186.88281 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.041\n",
      "  1% : 0.185\n",
      "  10% : 0.641\n",
      "  50% : 4.53\n",
      "  90% : 50.6\n",
      "  99% : 435\n",
      "  100% : 5.34e+03\n",
      "<chi^2/d.o.f.> = 3.2\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 71.69 s\n",
      "learning rate = 0.00013533528544940054\n",
      "setting learning rate to 0.00011080315836233387\n",
      "Iteration 12 of 20.\n",
      "Epoch 1/25\n",
      "123/123 [==============================] - ETA: 0s - loss: 2.4690 - mse: 2.4120\n",
      "Epoch 1: val_loss improved from inf to 2.47455, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e001_vl2.475.h5\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 2.4690 - mse: 2.4120 - val_loss: 2.4745 - val_mse: 2.4176\n",
      "Epoch 2/25\n",
      "114/123 [==========================>...] - ETA: 0s - loss: 2.4679 - mse: 2.4111\n",
      "Epoch 2: val_loss improved from 2.47455 to 2.47359, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e002_vl2.474.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 2.4671 - mse: 2.4103 - val_loss: 2.4736 - val_mse: 2.4169\n",
      "Epoch 3/25\n",
      "122/123 [============================>.] - ETA: 0s - loss: 2.4664 - mse: 2.4097\n",
      "Epoch 3: val_loss did not improve from 2.47359\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 2.4665 - mse: 2.4098 - val_loss: 2.4736 - val_mse: 2.4170\n",
      "Epoch 4/25\n",
      "117/123 [===========================>..] - ETA: 0s - loss: 2.4671 - mse: 2.4106\n",
      "Epoch 4: val_loss improved from 2.47359 to 2.47234, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e004_vl2.472.h5\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 2.4664 - mse: 2.4099 - val_loss: 2.4723 - val_mse: 2.4159\n",
      "Epoch 5/25\n",
      "119/123 [============================>.] - ETA: 0s - loss: 2.4666 - mse: 2.4103\n",
      "Epoch 5: val_loss improved from 2.47234 to 2.47193, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e005_vl2.472.h5\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 2.4658 - mse: 2.4095 - val_loss: 2.4719 - val_mse: 2.4157\n",
      "Epoch 6/25\n",
      "120/123 [============================>.] - ETA: 0s - loss: 2.4664 - mse: 2.4102\n",
      "Epoch 6: val_loss improved from 2.47193 to 2.47070, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e006_vl2.471.h5\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 2.4656 - mse: 2.4094 - val_loss: 2.4707 - val_mse: 2.4146\n",
      "Epoch 7/25\n",
      "117/123 [===========================>..] - ETA: 0s - loss: 2.4647 - mse: 2.4086\n",
      "Epoch 7: val_loss improved from 2.47070 to 2.47070, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e007_vl2.471.h5\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 2.4650 - mse: 2.4089 - val_loss: 2.4707 - val_mse: 2.4147\n",
      "Epoch 8/25\n",
      "114/123 [==========================>...] - ETA: 0s - loss: 2.4634 - mse: 2.4075\n",
      "Epoch 8: val_loss did not improve from 2.47070\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 2.4645 - mse: 2.4086 - val_loss: 2.4712 - val_mse: 2.4153\n",
      "Epoch 9/25\n",
      "120/123 [============================>.] - ETA: 0s - loss: 2.4645 - mse: 2.4087\n",
      "Epoch 9: val_loss did not improve from 2.47070\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 2.4643 - mse: 2.4085 - val_loss: 2.4710 - val_mse: 2.4153\n",
      "Epoch 10/25\n",
      "114/123 [==========================>...] - ETA: 0s - loss: 2.4618 - mse: 2.4061\n",
      "Epoch 10: val_loss improved from 2.47070 to 2.46951, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e010_vl2.470.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 2.4638 - mse: 2.4082 - val_loss: 2.4695 - val_mse: 2.4139\n",
      "Epoch 11/25\n",
      "117/123 [===========================>..] - ETA: 0s - loss: 2.4632 - mse: 2.4077\n",
      "Epoch 11: val_loss improved from 2.46951 to 2.46893, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e011_vl2.469.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 2.4637 - mse: 2.4082 - val_loss: 2.4689 - val_mse: 2.4134\n",
      "Epoch 12/25\n",
      "122/123 [============================>.] - ETA: 0s - loss: 2.4634 - mse: 2.4080\n",
      "Epoch 12: val_loss did not improve from 2.46893\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 2.4631 - mse: 2.4077 - val_loss: 2.4690 - val_mse: 2.4136\n",
      "Epoch 13/25\n",
      "114/123 [==========================>...] - ETA: 0s - loss: 2.4599 - mse: 2.4045\n",
      "Epoch 13: val_loss improved from 2.46893 to 2.46870, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e013_vl2.469.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 2.4631 - mse: 2.4077 - val_loss: 2.4687 - val_mse: 2.4134\n",
      "Epoch 14/25\n",
      "115/123 [===========================>..] - ETA: 0s - loss: 2.4630 - mse: 2.4078\n",
      "Epoch 14: val_loss improved from 2.46870 to 2.46847, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e014_vl2.468.h5\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 2.4629 - mse: 2.4077 - val_loss: 2.4685 - val_mse: 2.4133\n",
      "Epoch 15/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 2.4632 - mse: 2.4080\n",
      "Epoch 15: val_loss improved from 2.46847 to 2.46792, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e015_vl2.468.h5\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 2.4629 - mse: 2.4077 - val_loss: 2.4679 - val_mse: 2.4129\n",
      "Epoch 16/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 2.4620 - mse: 2.4069\n",
      "Epoch 16: val_loss did not improve from 2.46792\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 2.4623 - mse: 2.4073 - val_loss: 2.4695 - val_mse: 2.4146\n",
      "Epoch 17/25\n",
      "114/123 [==========================>...] - ETA: 0s - loss: 2.4604 - mse: 2.4055\n",
      "Epoch 17: val_loss improved from 2.46792 to 2.46744, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e017_vl2.467.h5\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 2.4625 - mse: 2.4076 - val_loss: 2.4674 - val_mse: 2.4126\n",
      "Epoch 18/25\n",
      "117/123 [===========================>..] - ETA: 0s - loss: 2.4614 - mse: 2.4066\n",
      "Epoch 18: val_loss did not improve from 2.46744\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 2.4618 - mse: 2.4070 - val_loss: 2.4678 - val_mse: 2.4131\n",
      "Epoch 19/25\n",
      "123/123 [==============================] - ETA: 0s - loss: 2.4616 - mse: 2.4069\n",
      "Epoch 19: val_loss improved from 2.46744 to 2.46679, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e019_vl2.467.h5\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 2.4616 - mse: 2.4069 - val_loss: 2.4668 - val_mse: 2.4122\n",
      "Epoch 20/25\n",
      "116/123 [===========================>..] - ETA: 0s - loss: 2.4614 - mse: 2.4068\n",
      "Epoch 20: val_loss did not improve from 2.46679\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 2.4611 - mse: 2.4065 - val_loss: 2.4680 - val_mse: 2.4134\n",
      "Epoch 21/25\n",
      "119/123 [============================>.] - ETA: 0s - loss: 2.4616 - mse: 2.4071\n",
      "Epoch 21: val_loss improved from 2.46679 to 2.46605, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e021_vl2.466.h5\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 2.4608 - mse: 2.4063 - val_loss: 2.4661 - val_mse: 2.4116\n",
      "Epoch 22/25\n",
      "119/123 [============================>.] - ETA: 0s - loss: 2.4618 - mse: 2.4074\n",
      "Epoch 22: val_loss did not improve from 2.46605\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 2.4609 - mse: 2.4065 - val_loss: 2.4662 - val_mse: 2.4119\n",
      "Epoch 23/25\n",
      "113/123 [==========================>...] - ETA: 0s - loss: 2.4587 - mse: 2.4044\n",
      "Epoch 23: val_loss improved from 2.46605 to 2.46531, saving model to checkpoints/ext_0h_l1n2_2hidden_it11.e023_vl2.465.h5\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 2.4608 - mse: 2.4065 - val_loss: 2.4653 - val_mse: 2.4110\n",
      "Epoch 24/25\n",
      "118/123 [===========================>..] - ETA: 0s - loss: 2.4598 - mse: 2.4056\n",
      "Epoch 24: val_loss did not improve from 2.46531\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 2.4605 - mse: 2.4063 - val_loss: 2.4661 - val_mse: 2.4119\n",
      "Epoch 25/25\n",
      "120/123 [============================>.] - ETA: 0s - loss: 2.4601 - mse: 2.4060\n",
      "Epoch 25: val_loss did not improve from 2.46531\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 2.4602 - mse: 2.4061 - val_loss: 2.4657 - val_mse: 2.4117\n",
      "Time elapsed to train: 20.33 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [3.477 4.156 2.767 4.468 3.449 2.844 2.401 2.129 1.753 1.185 1.167 0.003 0.003]\n",
      "<R> = [3.476 4.167 2.759 4.478 3.448 2.836 2.392 2.119 1.743 1.177 1.160 0.003 0.003]\n",
      "s_R = [0.749 0.745 0.896 0.785 0.807 0.863 1.027 1.176 1.565 3.200 3.533 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.810719  2.9476216 5.8362155 ... 3.0780878 3.9993024 4.422793 ]\n",
      "mag_pred: [3.810719  2.9476216 5.8362155 ... 3.0780878 3.9993024 4.422793 ]\n",
      "Time elapsed to make plots: 21.11 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 288.515      42.913757   54.87036  ...   18.105442   51.273476\n",
      " 2561.9248  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0165\n",
      "  1% : 0.182\n",
      "  10% : 0.623\n",
      "  50% : 4.33\n",
      "  90% : 50.7\n",
      "  99% : 423\n",
      "  100% : 7.5e+03\n",
      "<chi^2/d.o.f.> = 3.12\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 89601 stars (35.4%) based on chi^2/dof > 7.9\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 48.47947   61.040783 780.3967   ... 285.51154   44.186577 202.93878 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0373\n",
      "  1% : 0.18\n",
      "  10% : 0.615\n",
      "  50% : 4.29\n",
      "  90% : 50.5\n",
      "  99% : 425\n",
      "  100% : 5.33e+03\n",
      "<chi^2/d.o.f.> = 3.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 70.91 s\n",
      "learning rate = 0.00011080315744038671\n",
      "setting learning rate to 9.071795328941248e-05\n",
      "Iteration 13 of 20.\n",
      "Epoch 1/25\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 2.1025 - mse: 2.0485\n",
      "Epoch 1: val_loss improved from inf to 2.10134, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e001_vl2.101.h5\n",
      "116/116 [==============================] - 1s 8ms/step - loss: 2.1013 - mse: 2.0473 - val_loss: 2.1013 - val_mse: 2.0474\n",
      "Epoch 2/25\n",
      "111/116 [===========================>..] - ETA: 0s - loss: 2.0972 - mse: 2.0434\n",
      "Epoch 2: val_loss improved from 2.10134 to 2.10092, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e002_vl2.101.h5\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.0998 - mse: 2.0460 - val_loss: 2.1009 - val_mse: 2.0472\n",
      "Epoch 3/25\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 2.0976 - mse: 2.0440\n",
      "Epoch 3: val_loss improved from 2.10092 to 2.10038, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e003_vl2.100.h5\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.0996 - mse: 2.0459 - val_loss: 2.1004 - val_mse: 2.0468\n",
      "Epoch 4/25\n",
      "106/116 [==========================>...] - ETA: 0s - loss: 2.0995 - mse: 2.0460\n",
      "Epoch 4: val_loss improved from 2.10038 to 2.10011, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e004_vl2.100.h5\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.0994 - mse: 2.0458 - val_loss: 2.1001 - val_mse: 2.0466\n",
      "Epoch 5/25\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 2.1007 - mse: 2.0472\n",
      "Epoch 5: val_loss improved from 2.10011 to 2.09995, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e005_vl2.100.h5\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.0990 - mse: 2.0455 - val_loss: 2.0999 - val_mse: 2.0466\n",
      "Epoch 6/25\n",
      "111/116 [===========================>..] - ETA: 0s - loss: 2.0985 - mse: 2.0452\n",
      "Epoch 6: val_loss improved from 2.09995 to 2.09987, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e006_vl2.100.h5\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.0986 - mse: 2.0453 - val_loss: 2.0999 - val_mse: 2.0466\n",
      "Epoch 7/25\n",
      "114/116 [============================>.] - ETA: 0s - loss: 2.0975 - mse: 2.0443\n",
      "Epoch 7: val_loss did not improve from 2.09987\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.0985 - mse: 2.0453 - val_loss: 2.1004 - val_mse: 2.0472\n",
      "Epoch 8/25\n",
      "115/116 [============================>.] - ETA: 0s - loss: 2.0984 - mse: 2.0453\n",
      "Epoch 8: val_loss improved from 2.09987 to 2.09894, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e008_vl2.099.h5\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 2.0984 - mse: 2.0453 - val_loss: 2.0989 - val_mse: 2.0459\n",
      "Epoch 9/25\n",
      "112/116 [===========================>..] - ETA: 0s - loss: 2.1003 - mse: 2.0473\n",
      "Epoch 9: val_loss improved from 2.09894 to 2.09840, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e009_vl2.098.h5\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.0981 - mse: 2.0451 - val_loss: 2.0984 - val_mse: 2.0455\n",
      "Epoch 10/25\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 2.0983 - mse: 2.0454\n",
      "Epoch 10: val_loss did not improve from 2.09840\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.0980 - mse: 2.0451 - val_loss: 2.0991 - val_mse: 2.0463\n",
      "Epoch 11/25\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0976 - mse: 2.0448\n",
      "Epoch 11: val_loss did not improve from 2.09840\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 2.0976 - mse: 2.0448 - val_loss: 2.0996 - val_mse: 2.0469\n",
      "Epoch 12/25\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0977 - mse: 2.0450\n",
      "Epoch 12: val_loss improved from 2.09840 to 2.09786, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e012_vl2.098.h5\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.0977 - mse: 2.0450 - val_loss: 2.0979 - val_mse: 2.0452\n",
      "Epoch 13/25\n",
      "110/116 [===========================>..] - ETA: 0s - loss: 2.0973 - mse: 2.0448\n",
      "Epoch 13: val_loss did not improve from 2.09786\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.0972 - mse: 2.0446 - val_loss: 2.0979 - val_mse: 2.0453\n",
      "Epoch 14/25\n",
      "107/116 [==========================>...] - ETA: 0s - loss: 2.0980 - mse: 2.0455\n",
      "Epoch 14: val_loss did not improve from 2.09786\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.0974 - mse: 2.0449 - val_loss: 2.0980 - val_mse: 2.0455\n",
      "Epoch 15/25\n",
      "114/116 [============================>.] - ETA: 0s - loss: 2.0963 - mse: 2.0440\n",
      "Epoch 15: val_loss improved from 2.09786 to 2.09739, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e015_vl2.097.h5\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.0973 - mse: 2.0449 - val_loss: 2.0974 - val_mse: 2.0451\n",
      "Epoch 16/25\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0966 - mse: 2.0444\n",
      "Epoch 16: val_loss did not improve from 2.09739\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.0966 - mse: 2.0444 - val_loss: 2.0979 - val_mse: 2.0457\n",
      "Epoch 17/25\n",
      "106/116 [==========================>...] - ETA: 0s - loss: 2.0983 - mse: 2.0461\n",
      "Epoch 17: val_loss did not improve from 2.09739\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.0964 - mse: 2.0443 - val_loss: 2.0977 - val_mse: 2.0456\n",
      "Epoch 18/25\n",
      "115/116 [============================>.] - ETA: 0s - loss: 2.0970 - mse: 2.0449\n",
      "Epoch 18: val_loss did not improve from 2.09739\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.0966 - mse: 2.0445 - val_loss: 2.0983 - val_mse: 2.0463\n",
      "Epoch 19/25\n",
      "112/116 [===========================>..] - ETA: 0s - loss: 2.0961 - mse: 2.0442\n",
      "Epoch 19: val_loss improved from 2.09739 to 2.09656, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e019_vl2.097.h5\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 2.0963 - mse: 2.0443 - val_loss: 2.0966 - val_mse: 2.0446\n",
      "Epoch 20/25\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 2.0961 - mse: 2.0442\n",
      "Epoch 20: val_loss improved from 2.09656 to 2.09648, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e020_vl2.096.h5\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 2.0964 - mse: 2.0446 - val_loss: 2.0965 - val_mse: 2.0446\n",
      "Epoch 21/25\n",
      "113/116 [============================>.] - ETA: 0s - loss: 2.0952 - mse: 2.0434\n",
      "Epoch 21: val_loss did not improve from 2.09648\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 2.0959 - mse: 2.0441 - val_loss: 2.0965 - val_mse: 2.0447\n",
      "Epoch 22/25\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 2.0944 - mse: 2.0426\n",
      "Epoch 22: val_loss did not improve from 2.09648\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.0957 - mse: 2.0440 - val_loss: 2.0970 - val_mse: 2.0453\n",
      "Epoch 23/25\n",
      "107/116 [==========================>...] - ETA: 0s - loss: 2.0951 - mse: 2.0435\n",
      "Epoch 23: val_loss did not improve from 2.09648\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.0955 - mse: 2.0439 - val_loss: 2.0966 - val_mse: 2.0450\n",
      "Epoch 24/25\n",
      "106/116 [==========================>...] - ETA: 0s - loss: 2.0936 - mse: 2.0421\n",
      "Epoch 24: val_loss did not improve from 2.09648\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.0954 - mse: 2.0439 - val_loss: 2.0968 - val_mse: 2.0454\n",
      "Epoch 25/25\n",
      "106/116 [==========================>...] - ETA: 0s - loss: 2.0968 - mse: 2.0453\n",
      "Epoch 25: val_loss improved from 2.09648 to 2.09587, saving model to checkpoints/ext_0h_l1n2_2hidden_it12.e025_vl2.096.h5\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 2.0954 - mse: 2.0440 - val_loss: 2.0959 - val_mse: 2.0445\n",
      "Time elapsed to train: 19.11 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [3.549 4.236 2.829 4.553 3.522 2.903 2.455 2.178 1.804 1.232 1.214 0.002 0.002]\n",
      "<R> = [3.547 4.245 2.821 4.558 3.519 2.896 2.446 2.169 1.795 1.224 1.206 0.002 0.002]\n",
      "s_R = [0.700 0.690 0.844 0.732 0.755 0.810 0.956 1.083 1.401 2.644 2.949 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.79403   2.8931568 5.862057  ... 3.0401995 3.9829903 4.4073453]\n",
      "mag_pred: [3.79403   2.8931568 5.862057  ... 3.0401995 3.9829903 4.4073453]\n",
      "Time elapsed to make plots: 17.67 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 281.9624     42.37863    67.37225  ...   15.902901   50.495792\n",
      " 2534.6763  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0125\n",
      "  1% : 0.176\n",
      "  10% : 0.599\n",
      "  50% : 4.16\n",
      "  90% : 50.8\n",
      "  99% : 413\n",
      "  100% : 7.88e+03\n",
      "<chi^2/d.o.f.> = 3.05\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 101114 stars (40%) based on chi^2/dof > 6.3\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 43.95004   64.32575  765.93176  ... 346.31793   39.503265 225.73077 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0466\n",
      "  1% : 0.175\n",
      "  10% : 0.59\n",
      "  50% : 4.11\n",
      "  90% : 50.5\n",
      "  99% : 414\n",
      "  100% : 5.31e+03\n",
      "<chi^2/d.o.f.> = 3.03\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 70.43 s\n",
      "learning rate = 9.071795648196712e-05\n",
      "setting learning rate to 7.427357821433387e-05\n",
      "Iteration 14 of 20.\n",
      "Epoch 1/25\n",
      "102/108 [===========================>..] - ETA: 0s - loss: 1.7785 - mse: 1.7272\n",
      "Epoch 1: val_loss improved from inf to 1.78459, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e001_vl1.785.h5\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 1.7796 - mse: 1.7283 - val_loss: 1.7846 - val_mse: 1.7334\n",
      "Epoch 2/25\n",
      "100/108 [==========================>...] - ETA: 0s - loss: 1.7760 - mse: 1.7249\n",
      "Epoch 2: val_loss improved from 1.78459 to 1.78384, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e002_vl1.784.h5\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 1.7783 - mse: 1.7271 - val_loss: 1.7838 - val_mse: 1.7328\n",
      "Epoch 3/25\n",
      " 99/108 [==========================>...] - ETA: 0s - loss: 1.7778 - mse: 1.7268\n",
      "Epoch 3: val_loss improved from 1.78384 to 1.78339, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e003_vl1.783.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7782 - mse: 1.7272 - val_loss: 1.7834 - val_mse: 1.7325\n",
      "Epoch 4/25\n",
      "108/108 [==============================] - ETA: 0s - loss: 1.7777 - mse: 1.7269\n",
      "Epoch 4: val_loss improved from 1.78339 to 1.78334, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e004_vl1.783.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7777 - mse: 1.7269 - val_loss: 1.7833 - val_mse: 1.7326\n",
      "Epoch 5/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.7777 - mse: 1.7270\n",
      "Epoch 5: val_loss improved from 1.78334 to 1.78324, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e005_vl1.783.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7775 - mse: 1.7268 - val_loss: 1.7832 - val_mse: 1.7326\n",
      "Epoch 6/25\n",
      "100/108 [==========================>...] - ETA: 0s - loss: 1.7790 - mse: 1.7284\n",
      "Epoch 6: val_loss improved from 1.78324 to 1.78295, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e006_vl1.783.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7773 - mse: 1.7267 - val_loss: 1.7829 - val_mse: 1.7324\n",
      "Epoch 7/25\n",
      "103/108 [===========================>..] - ETA: 0s - loss: 1.7791 - mse: 1.7285\n",
      "Epoch 7: val_loss did not improve from 1.78295\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7773 - mse: 1.7268 - val_loss: 1.7835 - val_mse: 1.7330\n",
      "Epoch 8/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.7771 - mse: 1.7267\n",
      "Epoch 8: val_loss improved from 1.78295 to 1.78245, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e008_vl1.782.h5\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 1.7770 - mse: 1.7266 - val_loss: 1.7824 - val_mse: 1.7321\n",
      "Epoch 9/25\n",
      "104/108 [===========================>..] - ETA: 0s - loss: 1.7774 - mse: 1.7271\n",
      "Epoch 9: val_loss improved from 1.78245 to 1.78234, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e009_vl1.782.h5\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 1.7768 - mse: 1.7265 - val_loss: 1.7823 - val_mse: 1.7321\n",
      "Epoch 10/25\n",
      "100/108 [==========================>...] - ETA: 0s - loss: 1.7776 - mse: 1.7274\n",
      "Epoch 10: val_loss improved from 1.78234 to 1.78216, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e010_vl1.782.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7766 - mse: 1.7264 - val_loss: 1.7822 - val_mse: 1.7320\n",
      "Epoch 11/25\n",
      " 98/108 [==========================>...] - ETA: 0s - loss: 1.7774 - mse: 1.7273\n",
      "Epoch 11: val_loss did not improve from 1.78216\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7766 - mse: 1.7265 - val_loss: 1.7822 - val_mse: 1.7322\n",
      "Epoch 12/25\n",
      "101/108 [===========================>..] - ETA: 0s - loss: 1.7766 - mse: 1.7266\n",
      "Epoch 12: val_loss improved from 1.78216 to 1.78160, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e012_vl1.782.h5\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 1.7764 - mse: 1.7264 - val_loss: 1.7816 - val_mse: 1.7317\n",
      "Epoch 13/25\n",
      " 99/108 [==========================>...] - ETA: 0s - loss: 1.7757 - mse: 1.7258\n",
      "Epoch 13: val_loss improved from 1.78160 to 1.78147, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e013_vl1.781.h5\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 1.7762 - mse: 1.7263 - val_loss: 1.7815 - val_mse: 1.7316\n",
      "Epoch 14/25\n",
      "105/108 [============================>.] - ETA: 0s - loss: 1.7773 - mse: 1.7275\n",
      "Epoch 14: val_loss improved from 1.78147 to 1.78141, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e014_vl1.781.h5\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 1.7762 - mse: 1.7264 - val_loss: 1.7814 - val_mse: 1.7317\n",
      "Epoch 15/25\n",
      "106/108 [============================>.] - ETA: 0s - loss: 1.7764 - mse: 1.7267\n",
      "Epoch 15: val_loss did not improve from 1.78141\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7761 - mse: 1.7264 - val_loss: 1.7819 - val_mse: 1.7322\n",
      "Epoch 16/25\n",
      " 99/108 [==========================>...] - ETA: 0s - loss: 1.7759 - mse: 1.7263\n",
      "Epoch 16: val_loss improved from 1.78141 to 1.78126, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e016_vl1.781.h5\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 1.7758 - mse: 1.7262 - val_loss: 1.7813 - val_mse: 1.7317\n",
      "Epoch 17/25\n",
      "103/108 [===========================>..] - ETA: 0s - loss: 1.7766 - mse: 1.7271\n",
      "Epoch 17: val_loss did not improve from 1.78126\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 1.7758 - mse: 1.7263 - val_loss: 1.7813 - val_mse: 1.7318\n",
      "Epoch 18/25\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.7754 - mse: 1.7260\n",
      "Epoch 18: val_loss did not improve from 1.78126\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 1.7755 - mse: 1.7261 - val_loss: 1.7824 - val_mse: 1.7331\n",
      "Epoch 19/25\n",
      "100/108 [==========================>...] - ETA: 0s - loss: 1.7757 - mse: 1.7264\n",
      "Epoch 19: val_loss improved from 1.78126 to 1.78111, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e019_vl1.781.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7755 - mse: 1.7262 - val_loss: 1.7811 - val_mse: 1.7319\n",
      "Epoch 20/25\n",
      "106/108 [============================>.] - ETA: 0s - loss: 1.7750 - mse: 1.7258\n",
      "Epoch 20: val_loss did not improve from 1.78111\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7753 - mse: 1.7261 - val_loss: 1.7816 - val_mse: 1.7324\n",
      "Epoch 21/25\n",
      "108/108 [==============================] - ETA: 0s - loss: 1.7763 - mse: 1.7271\n",
      "Epoch 21: val_loss improved from 1.78111 to 1.78065, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e021_vl1.781.h5\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7763 - mse: 1.7271 - val_loss: 1.7806 - val_mse: 1.7315\n",
      "Epoch 22/25\n",
      "103/108 [===========================>..] - ETA: 0s - loss: 1.7742 - mse: 1.7251\n",
      "Epoch 22: val_loss improved from 1.78065 to 1.78038, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e022_vl1.780.h5\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 1.7751 - mse: 1.7260 - val_loss: 1.7804 - val_mse: 1.7313\n",
      "Epoch 23/25\n",
      " 99/108 [==========================>...] - ETA: 0s - loss: 1.7756 - mse: 1.7266\n",
      "Epoch 23: val_loss did not improve from 1.78038\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 1.7751 - mse: 1.7261 - val_loss: 1.7811 - val_mse: 1.7321\n",
      "Epoch 24/25\n",
      "106/108 [============================>.] - ETA: 0s - loss: 1.7756 - mse: 1.7267\n",
      "Epoch 24: val_loss did not improve from 1.78038\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7749 - mse: 1.7260 - val_loss: 1.7804 - val_mse: 1.7315\n",
      "Epoch 25/25\n",
      "103/108 [===========================>..] - ETA: 0s - loss: 1.7750 - mse: 1.7262\n",
      "Epoch 25: val_loss improved from 1.78038 to 1.77988, saving model to checkpoints/ext_0h_l1n2_2hidden_it13.e025_vl1.780.h5\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 1.7749 - mse: 1.7261 - val_loss: 1.7799 - val_mse: 1.7311\n",
      "Time elapsed to train: 18.14 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [3.604 4.301 2.874 4.622 3.579 2.947 2.490 2.210 1.831 1.255 1.238 0.002 0.002]\n",
      "<R> = [3.601 4.305 2.866 4.622 3.574 2.940 2.481 2.201 1.823 1.247 1.229 0.002 0.002]\n",
      "s_R = [0.641 0.635 0.780 0.680 0.700 0.751 0.878 0.992 1.249 2.228 2.478 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.775574  2.8398533 5.8855643 ... 2.9980564 3.9662824 4.3914585]\n",
      "mag_pred: [3.775574  2.8398533 5.8855643 ... 2.9980564 3.9662824 4.3914585]\n",
      "Time elapsed to make plots: 20.91 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 274.698      41.241203   80.606544 ...   13.852386   49.4041\n",
      " 2464.9846  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00834\n",
      "  1% : 0.173\n",
      "  10% : 0.581\n",
      "  50% : 4.01\n",
      "  90% : 50.5\n",
      "  99% : 403\n",
      "  100% : 8.23e+03\n",
      "<chi^2/d.o.f.> = 2.98\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 112974 stars (44.6%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 39.675106  67.41515  760.07965  ... 409.16132   35.52414  244.26971 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0386\n",
      "  1% : 0.169\n",
      "  10% : 0.575\n",
      "  50% : 4\n",
      "  90% : 50.2\n",
      "  99% : 399\n",
      "  100% : 5.3e+03\n",
      "<chi^2/d.o.f.> = 2.96\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 65.49 s\n",
      "learning rate = 7.427357923006639e-05\n",
      "setting learning rate to 6.0810062625217954e-05\n",
      "Iteration 15 of 20.\n",
      "Epoch 1/25\n",
      "90/99 [==========================>...] - ETA: 0s - loss: 1.5088 - mse: 1.4601\n",
      "Epoch 1: val_loss improved from inf to 1.50928, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e001_vl1.509.h5\n",
      "99/99 [==============================] - 1s 8ms/step - loss: 1.5078 - mse: 1.4591 - val_loss: 1.5093 - val_mse: 1.4607\n",
      "Epoch 2/25\n",
      "94/99 [===========================>..] - ETA: 0s - loss: 1.5071 - mse: 1.4585\n",
      "Epoch 2: val_loss improved from 1.50928 to 1.50893, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e002_vl1.509.h5\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.5067 - mse: 1.4582 - val_loss: 1.5089 - val_mse: 1.4604\n",
      "Epoch 3/25\n",
      "97/99 [============================>.] - ETA: 0s - loss: 1.5071 - mse: 1.4586\n",
      "Epoch 3: val_loss did not improve from 1.50893\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.5065 - mse: 1.4581 - val_loss: 1.5089 - val_mse: 1.4606\n",
      "Epoch 4/25\n",
      "97/99 [============================>.] - ETA: 0s - loss: 1.5069 - mse: 1.4586\n",
      "Epoch 4: val_loss improved from 1.50893 to 1.50866, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e004_vl1.509.h5\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 1.5064 - mse: 1.4580 - val_loss: 1.5087 - val_mse: 1.4604\n",
      "Epoch 5/25\n",
      "95/99 [===========================>..] - ETA: 0s - loss: 1.5057 - mse: 1.4575\n",
      "Epoch 5: val_loss improved from 1.50866 to 1.50825, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e005_vl1.508.h5\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 1.5060 - mse: 1.4578 - val_loss: 1.5082 - val_mse: 1.4601\n",
      "Epoch 6/25\n",
      "99/99 [==============================] - ETA: 0s - loss: 1.5059 - mse: 1.4578\n",
      "Epoch 6: val_loss improved from 1.50825 to 1.50816, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e006_vl1.508.h5\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 1.5059 - mse: 1.4578 - val_loss: 1.5082 - val_mse: 1.4601\n",
      "Epoch 7/25\n",
      "89/99 [=========================>....] - ETA: 0s - loss: 1.5052 - mse: 1.4572\n",
      "Epoch 7: val_loss improved from 1.50816 to 1.50796, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e007_vl1.508.h5\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.5059 - mse: 1.4579 - val_loss: 1.5080 - val_mse: 1.4600\n",
      "Epoch 8/25\n",
      "95/99 [===========================>..] - ETA: 0s - loss: 1.5058 - mse: 1.4580\n",
      "Epoch 8: val_loss did not improve from 1.50796\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.5056 - mse: 1.4577 - val_loss: 1.5082 - val_mse: 1.4604\n",
      "Epoch 9/25\n",
      "95/99 [===========================>..] - ETA: 0s - loss: 1.5051 - mse: 1.4573\n",
      "Epoch 9: val_loss did not improve from 1.50796\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.5055 - mse: 1.4577 - val_loss: 1.5086 - val_mse: 1.4609\n",
      "Epoch 10/25\n",
      "94/99 [===========================>..] - ETA: 0s - loss: 1.5060 - mse: 1.4583\n",
      "Epoch 10: val_loss improved from 1.50796 to 1.50747, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e010_vl1.507.h5\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 1.5053 - mse: 1.4576 - val_loss: 1.5075 - val_mse: 1.4599\n",
      "Epoch 11/25\n",
      "93/99 [===========================>..] - ETA: 0s - loss: 1.5055 - mse: 1.4580\n",
      "Epoch 11: val_loss did not improve from 1.50747\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 1.5051 - mse: 1.4575 - val_loss: 1.5076 - val_mse: 1.4601\n",
      "Epoch 12/25\n",
      "98/99 [============================>.] - ETA: 0s - loss: 1.5048 - mse: 1.4573\n",
      "Epoch 12: val_loss improved from 1.50747 to 1.50737, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e012_vl1.507.h5\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 1.5050 - mse: 1.4575 - val_loss: 1.5074 - val_mse: 1.4600\n",
      "Epoch 13/25\n",
      "96/99 [============================>.] - ETA: 0s - loss: 1.5043 - mse: 1.4570\n",
      "Epoch 13: val_loss improved from 1.50737 to 1.50731, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e013_vl1.507.h5\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.5048 - mse: 1.4575 - val_loss: 1.5073 - val_mse: 1.4600\n",
      "Epoch 14/25\n",
      "92/99 [==========================>...] - ETA: 0s - loss: 1.5040 - mse: 1.4567\n",
      "Epoch 14: val_loss improved from 1.50731 to 1.50690, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e014_vl1.507.h5\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.5048 - mse: 1.4576 - val_loss: 1.5069 - val_mse: 1.4597\n",
      "Epoch 15/25\n",
      "97/99 [============================>.] - ETA: 0s - loss: 1.5053 - mse: 1.4582\n",
      "Epoch 15: val_loss improved from 1.50690 to 1.50678, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e015_vl1.507.h5\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.5046 - mse: 1.4575 - val_loss: 1.5068 - val_mse: 1.4597\n",
      "Epoch 16/25\n",
      "98/99 [============================>.] - ETA: 0s - loss: 1.5045 - mse: 1.4574\n",
      "Epoch 16: val_loss improved from 1.50678 to 1.50677, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e016_vl1.507.h5\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.5045 - mse: 1.4575 - val_loss: 1.5068 - val_mse: 1.4598\n",
      "Epoch 17/25\n",
      "91/99 [==========================>...] - ETA: 0s - loss: 1.5060 - mse: 1.4591\n",
      "Epoch 17: val_loss improved from 1.50677 to 1.50652, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e017_vl1.507.h5\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.5045 - mse: 1.4576 - val_loss: 1.5065 - val_mse: 1.4596\n",
      "Epoch 18/25\n",
      "95/99 [===========================>..] - ETA: 0s - loss: 1.5053 - mse: 1.4584\n",
      "Epoch 18: val_loss did not improve from 1.50652\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.5045 - mse: 1.4577 - val_loss: 1.5070 - val_mse: 1.4602\n",
      "Epoch 19/25\n",
      "95/99 [===========================>..] - ETA: 0s - loss: 1.5046 - mse: 1.4579\n",
      "Epoch 19: val_loss did not improve from 1.50652\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.5043 - mse: 1.4576 - val_loss: 1.5066 - val_mse: 1.4599\n",
      "Epoch 20/25\n",
      "92/99 [==========================>...] - ETA: 0s - loss: 1.5033 - mse: 1.4566\n",
      "Epoch 20: val_loss did not improve from 1.50652\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.5044 - mse: 1.4577 - val_loss: 1.5065 - val_mse: 1.4600\n",
      "Epoch 21/25\n",
      "94/99 [===========================>..] - ETA: 0s - loss: 1.5047 - mse: 1.4582\n",
      "Epoch 21: val_loss improved from 1.50652 to 1.50638, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e021_vl1.506.h5\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.5040 - mse: 1.4574 - val_loss: 1.5064 - val_mse: 1.4599\n",
      "Epoch 22/25\n",
      "99/99 [==============================] - ETA: 0s - loss: 1.5038 - mse: 1.4574\n",
      "Epoch 22: val_loss improved from 1.50638 to 1.50625, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e022_vl1.506.h5\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 1.5038 - mse: 1.4574 - val_loss: 1.5062 - val_mse: 1.4599\n",
      "Epoch 23/25\n",
      "98/99 [============================>.] - ETA: 0s - loss: 1.5043 - mse: 1.4579\n",
      "Epoch 23: val_loss did not improve from 1.50625\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 1.5038 - mse: 1.4574 - val_loss: 1.5063 - val_mse: 1.4600\n",
      "Epoch 24/25\n",
      "90/99 [==========================>...] - ETA: 0s - loss: 1.5031 - mse: 1.4569\n",
      "Epoch 24: val_loss improved from 1.50625 to 1.50597, saving model to checkpoints/ext_0h_l1n2_2hidden_it14.e024_vl1.506.h5\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.5038 - mse: 1.4575 - val_loss: 1.5060 - val_mse: 1.4598\n",
      "Epoch 25/25\n",
      "91/99 [==========================>...] - ETA: 0s - loss: 1.5019 - mse: 1.4557\n",
      "Epoch 25: val_loss did not improve from 1.50597\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.5037 - mse: 1.4575 - val_loss: 1.5062 - val_mse: 1.4601\n",
      "Time elapsed to train: 16.54 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [3.651 4.360 2.905 4.691 3.624 2.978 2.512 2.225 1.842 1.258 1.242 0.002 0.002]\n",
      "<R> = [3.647 4.358 2.898 4.684 3.618 2.971 2.504 2.217 1.835 1.251 1.234 0.002 0.002]\n",
      "s_R = [0.585 0.579 0.716 0.632 0.645 0.693 0.806 0.897 1.099 1.872 2.081 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.770021  2.7940726 5.917923  ... 2.9655247 3.960868  4.3859787]\n",
      "mag_pred: [3.770021  2.7940726 5.917923  ... 2.9655247 3.960868  4.3859787]\n",
      "Time elapsed to make plots: 17.49 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 276.63577    39.126198   91.25081  ...   12.584593   47.156876\n",
      " 2374.2334  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0108\n",
      "  1% : 0.17\n",
      "  10% : 0.565\n",
      "  50% : 3.89\n",
      "  90% : 49.5\n",
      "  99% : 390\n",
      "  100% : 8.53e+03\n",
      "<chi^2/d.o.f.> = 2.94\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 111367 stars (44%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 36.934338  68.3226   766.39075  ... 456.10806   32.778652 251.60425 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0354\n",
      "  1% : 0.164\n",
      "  10% : 0.559\n",
      "  50% : 3.88\n",
      "  90% : 49.2\n",
      "  99% : 389\n",
      "  100% : 5.28e+03\n",
      "<chi^2/d.o.f.> = 2.92\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 68.13 s\n",
      "learning rate = 6.0810063587268814e-05\n",
      "setting learning rate to 4.9787068367863945e-05\n",
      "Iteration 16 of 20.\n",
      "Epoch 1/25\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1.4850 - mse: 1.4390\n",
      "Epoch 1: val_loss improved from inf to 1.48601, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e001_vl1.486.h5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1.4849 - mse: 1.4389 - val_loss: 1.4860 - val_mse: 1.4400\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4846 - mse: 1.4387\n",
      "Epoch 2: val_loss improved from 1.48601 to 1.48580, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e002_vl1.486.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4846 - mse: 1.4387 - val_loss: 1.4858 - val_mse: 1.4399\n",
      "Epoch 3/25\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1.4839 - mse: 1.4381\n",
      "Epoch 3: val_loss improved from 1.48580 to 1.48553, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e003_vl1.486.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4845 - mse: 1.4386 - val_loss: 1.4855 - val_mse: 1.4397\n",
      "Epoch 4/25\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1.4854 - mse: 1.4397\n",
      "Epoch 4: val_loss did not improve from 1.48553\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4843 - mse: 1.4385 - val_loss: 1.4856 - val_mse: 1.4399\n",
      "Epoch 5/25\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1.4841 - mse: 1.4384\n",
      "Epoch 5: val_loss improved from 1.48553 to 1.48519, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e005_vl1.485.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4842 - mse: 1.4385 - val_loss: 1.4852 - val_mse: 1.4396\n",
      "Epoch 6/25\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1.4839 - mse: 1.4383\n",
      "Epoch 6: val_loss improved from 1.48519 to 1.48505, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e006_vl1.485.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4841 - mse: 1.4385 - val_loss: 1.4851 - val_mse: 1.4395\n",
      "Epoch 7/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.4836 - mse: 1.4381\n",
      "Epoch 7: val_loss did not improve from 1.48505\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4840 - mse: 1.4385 - val_loss: 1.4853 - val_mse: 1.4398\n",
      "Epoch 8/25\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1.4846 - mse: 1.4392\n",
      "Epoch 8: val_loss did not improve from 1.48505\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4838 - mse: 1.4384 - val_loss: 1.4854 - val_mse: 1.4400\n",
      "Epoch 9/25\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1.4837 - mse: 1.4384\n",
      "Epoch 9: val_loss improved from 1.48505 to 1.48473, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e009_vl1.485.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4839 - mse: 1.4386 - val_loss: 1.4847 - val_mse: 1.4394\n",
      "Epoch 10/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4835 - mse: 1.4382\n",
      "Epoch 10: val_loss did not improve from 1.48473\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4835 - mse: 1.4382 - val_loss: 1.4848 - val_mse: 1.4396\n",
      "Epoch 11/25\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1.4841 - mse: 1.4389\n",
      "Epoch 11: val_loss improved from 1.48473 to 1.48451, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e011_vl1.485.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4835 - mse: 1.4384 - val_loss: 1.4845 - val_mse: 1.4394\n",
      "Epoch 12/25\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4822 - mse: 1.4371\n",
      "Epoch 12: val_loss did not improve from 1.48451\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4835 - mse: 1.4384 - val_loss: 1.4848 - val_mse: 1.4398\n",
      "Epoch 13/25\n",
      " 90/100 [==========================>...] - ETA: 0s - loss: 1.4851 - mse: 1.4401\n",
      "Epoch 13: val_loss improved from 1.48451 to 1.48419, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e013_vl1.484.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4833 - mse: 1.4382 - val_loss: 1.4842 - val_mse: 1.4392\n",
      "Epoch 14/25\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1.4835 - mse: 1.4385\n",
      "Epoch 14: val_loss did not improve from 1.48419\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4834 - mse: 1.4384 - val_loss: 1.4843 - val_mse: 1.4394\n",
      "Epoch 15/25\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 1.4834 - mse: 1.4385\n",
      "Epoch 15: val_loss did not improve from 1.48419\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4832 - mse: 1.4383 - val_loss: 1.4844 - val_mse: 1.4395\n",
      "Epoch 16/25\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1.4818 - mse: 1.4370\n",
      "Epoch 16: val_loss did not improve from 1.48419\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4832 - mse: 1.4384 - val_loss: 1.4843 - val_mse: 1.4395\n",
      "Epoch 17/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.4828 - mse: 1.4381\n",
      "Epoch 17: val_loss improved from 1.48419 to 1.48415, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e017_vl1.484.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4831 - mse: 1.4384 - val_loss: 1.4842 - val_mse: 1.4395\n",
      "Epoch 18/25\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 1.4817 - mse: 1.4370\n",
      "Epoch 18: val_loss improved from 1.48415 to 1.48379, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e018_vl1.484.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4830 - mse: 1.4383 - val_loss: 1.4838 - val_mse: 1.4392\n",
      "Epoch 19/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.4828 - mse: 1.4382\n",
      "Epoch 19: val_loss did not improve from 1.48379\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4828 - mse: 1.4382 - val_loss: 1.4840 - val_mse: 1.4394\n",
      "Epoch 20/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4827 - mse: 1.4382\n",
      "Epoch 20: val_loss did not improve from 1.48379\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4827 - mse: 1.4382 - val_loss: 1.4838 - val_mse: 1.4394\n",
      "Epoch 21/25\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1.4821 - mse: 1.4376\n",
      "Epoch 21: val_loss did not improve from 1.48379\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4827 - mse: 1.4382 - val_loss: 1.4841 - val_mse: 1.4397\n",
      "Epoch 22/25\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 1.4819 - mse: 1.4375\n",
      "Epoch 22: val_loss did not improve from 1.48379\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4825 - mse: 1.4381 - val_loss: 1.4838 - val_mse: 1.4395\n",
      "Epoch 23/25\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 1.4836 - mse: 1.4393\n",
      "Epoch 23: val_loss improved from 1.48379 to 1.48368, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e023_vl1.484.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4826 - mse: 1.4383 - val_loss: 1.4837 - val_mse: 1.4394\n",
      "Epoch 24/25\n",
      " 90/100 [==========================>...] - ETA: 0s - loss: 1.4831 - mse: 1.4389\n",
      "Epoch 24: val_loss improved from 1.48368 to 1.48348, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e024_vl1.483.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4824 - mse: 1.4382 - val_loss: 1.4835 - val_mse: 1.4393\n",
      "Epoch 25/25\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1.4833 - mse: 1.4391\n",
      "Epoch 25: val_loss improved from 1.48348 to 1.48330, saving model to checkpoints/ext_0h_l1n2_2hidden_it15.e025_vl1.483.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4823 - mse: 1.4382 - val_loss: 1.4833 - val_mse: 1.4392\n",
      "Time elapsed to train: 17.07 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [3.688 4.411 2.933 4.748 3.662 3.005 2.532 2.243 1.854 1.260 1.243 0.002 0.002]\n",
      "<R> = [3.684 4.409 2.926 4.741 3.657 2.999 2.524 2.235 1.847 1.254 1.236 0.002 0.002]\n",
      "s_R = [0.532 0.532 0.657 0.595 0.595 0.634 0.734 0.815 0.974 1.567 1.753 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7665095 2.7723014 5.947873  ... 2.9565015 3.9534454 4.377213 ]\n",
      "mag_pred: [3.7665095 2.7723014 5.947873  ... 2.9565015 3.9534454 4.377213 ]\n",
      "Time elapsed to make plots: 17.55 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 276.90247    40.24035   100.46875  ...   11.691433   47.98976\n",
      " 2422.7327  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00684\n",
      "  1% : 0.166\n",
      "  10% : 0.557\n",
      "  50% : 3.88\n",
      "  90% : 50.3\n",
      "  99% : 392\n",
      "  100% : 8.71e+03\n",
      "<chi^2/d.o.f.> = 2.92\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 111249 stars (44%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 35.317783  69.404396 790.7549   ... 477.69366   31.15012  277.11472 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0376\n",
      "  1% : 0.159\n",
      "  10% : 0.557\n",
      "  50% : 3.86\n",
      "  90% : 49.8\n",
      "  99% : 389\n",
      "  100% : 5.28e+03\n",
      "<chi^2/d.o.f.> = 2.89\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 67.25 s\n",
      "learning rate = 4.978706783731468e-05\n",
      "setting learning rate to 4.0762203978366214e-05\n",
      "Iteration 17 of 20.\n",
      "Epoch 1/25\n",
      " 92/101 [==========================>...] - ETA: 0s - loss: 1.4725 - mse: 1.4284\n",
      "Epoch 1: val_loss improved from inf to 1.47563, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e001_vl1.476.h5\n",
      "101/101 [==============================] - 1s 8ms/step - loss: 1.4725 - mse: 1.4284 - val_loss: 1.4756 - val_mse: 1.4316\n",
      "Epoch 2/25\n",
      " 92/101 [==========================>...] - ETA: 0s - loss: 1.4732 - mse: 1.4292\n",
      "Epoch 2: val_loss improved from 1.47563 to 1.47553, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e002_vl1.476.h5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 1.4725 - mse: 1.4285 - val_loss: 1.4755 - val_mse: 1.4316\n",
      "Epoch 3/25\n",
      "100/101 [============================>.] - ETA: 0s - loss: 1.4725 - mse: 1.4286\n",
      "Epoch 3: val_loss did not improve from 1.47553\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 1.4725 - mse: 1.4286 - val_loss: 1.4756 - val_mse: 1.4317\n",
      "Epoch 4/25\n",
      " 91/101 [==========================>...] - ETA: 0s - loss: 1.4718 - mse: 1.4279\n",
      "Epoch 4: val_loss did not improve from 1.47553\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4726 - mse: 1.4287 - val_loss: 1.4758 - val_mse: 1.4320\n",
      "Epoch 5/25\n",
      " 92/101 [==========================>...] - ETA: 0s - loss: 1.4740 - mse: 1.4302\n",
      "Epoch 5: val_loss improved from 1.47553 to 1.47533, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e005_vl1.475.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4727 - mse: 1.4288 - val_loss: 1.4753 - val_mse: 1.4315\n",
      "Epoch 6/25\n",
      " 99/101 [============================>.] - ETA: 0s - loss: 1.4728 - mse: 1.4290\n",
      "Epoch 6: val_loss improved from 1.47533 to 1.47483, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e006_vl1.475.h5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 1.4722 - mse: 1.4284 - val_loss: 1.4748 - val_mse: 1.4311\n",
      "Epoch 7/25\n",
      " 95/101 [===========================>..] - ETA: 0s - loss: 1.4715 - mse: 1.4278\n",
      "Epoch 7: val_loss did not improve from 1.47483\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4720 - mse: 1.4283 - val_loss: 1.4751 - val_mse: 1.4314\n",
      "Epoch 8/25\n",
      " 93/101 [==========================>...] - ETA: 0s - loss: 1.4712 - mse: 1.4276\n",
      "Epoch 8: val_loss did not improve from 1.47483\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 1.4722 - mse: 1.4286 - val_loss: 1.4753 - val_mse: 1.4317\n",
      "Epoch 9/25\n",
      "100/101 [============================>.] - ETA: 0s - loss: 1.4726 - mse: 1.4291\n",
      "Epoch 9: val_loss improved from 1.47483 to 1.47467, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e009_vl1.475.h5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 1.4726 - mse: 1.4291 - val_loss: 1.4747 - val_mse: 1.4311\n",
      "Epoch 10/25\n",
      " 97/101 [===========================>..] - ETA: 0s - loss: 1.4730 - mse: 1.4295\n",
      "Epoch 10: val_loss did not improve from 1.47467\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4721 - mse: 1.4286 - val_loss: 1.4749 - val_mse: 1.4314\n",
      "Epoch 11/25\n",
      " 98/101 [============================>.] - ETA: 0s - loss: 1.4715 - mse: 1.4281\n",
      "Epoch 11: val_loss did not improve from 1.47467\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4717 - mse: 1.4283 - val_loss: 1.4749 - val_mse: 1.4315\n",
      "Epoch 12/25\n",
      " 92/101 [==========================>...] - ETA: 0s - loss: 1.4721 - mse: 1.4287\n",
      "Epoch 12: val_loss did not improve from 1.47467\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4719 - mse: 1.4285 - val_loss: 1.4748 - val_mse: 1.4315\n",
      "Epoch 13/25\n",
      " 99/101 [============================>.] - ETA: 0s - loss: 1.4718 - mse: 1.4285\n",
      "Epoch 13: val_loss improved from 1.47467 to 1.47441, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e013_vl1.474.h5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 1.4717 - mse: 1.4284 - val_loss: 1.4744 - val_mse: 1.4311\n",
      "Epoch 14/25\n",
      " 94/101 [==========================>...] - ETA: 0s - loss: 1.4712 - mse: 1.4280\n",
      "Epoch 14: val_loss did not improve from 1.47441\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4714 - mse: 1.4282 - val_loss: 1.4745 - val_mse: 1.4313\n",
      "Epoch 15/25\n",
      " 94/101 [==========================>...] - ETA: 0s - loss: 1.4721 - mse: 1.4289\n",
      "Epoch 15: val_loss did not improve from 1.47441\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4714 - mse: 1.4282 - val_loss: 1.4747 - val_mse: 1.4316\n",
      "Epoch 16/25\n",
      " 93/101 [==========================>...] - ETA: 0s - loss: 1.4722 - mse: 1.4291\n",
      "Epoch 16: val_loss did not improve from 1.47441\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4715 - mse: 1.4284 - val_loss: 1.4764 - val_mse: 1.4333\n",
      "Epoch 17/25\n",
      " 94/101 [==========================>...] - ETA: 0s - loss: 1.4731 - mse: 1.4300\n",
      "Epoch 17: val_loss improved from 1.47441 to 1.47422, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e017_vl1.474.h5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 1.4717 - mse: 1.4286 - val_loss: 1.4742 - val_mse: 1.4312\n",
      "Epoch 18/25\n",
      " 98/101 [============================>.] - ETA: 0s - loss: 1.4705 - mse: 1.4275\n",
      "Epoch 18: val_loss did not improve from 1.47422\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 1.4712 - mse: 1.4282 - val_loss: 1.4753 - val_mse: 1.4323\n",
      "Epoch 19/25\n",
      "101/101 [==============================] - ETA: 0s - loss: 1.4716 - mse: 1.4286\n",
      "Epoch 19: val_loss did not improve from 1.47422\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4716 - mse: 1.4286 - val_loss: 1.4742 - val_mse: 1.4313\n",
      "Epoch 20/25\n",
      " 92/101 [==========================>...] - ETA: 0s - loss: 1.4720 - mse: 1.4291\n",
      "Epoch 20: val_loss did not improve from 1.47422\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4713 - mse: 1.4284 - val_loss: 1.4747 - val_mse: 1.4318\n",
      "Epoch 21/25\n",
      " 98/101 [============================>.] - ETA: 0s - loss: 1.4711 - mse: 1.4283\n",
      "Epoch 21: val_loss improved from 1.47422 to 1.47420, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e021_vl1.474.h5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 1.4711 - mse: 1.4283 - val_loss: 1.4742 - val_mse: 1.4314\n",
      "Epoch 22/25\n",
      " 95/101 [===========================>..] - ETA: 0s - loss: 1.4716 - mse: 1.4288\n",
      "Epoch 22: val_loss did not improve from 1.47420\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4711 - mse: 1.4284 - val_loss: 1.4749 - val_mse: 1.4322\n",
      "Epoch 23/25\n",
      " 97/101 [===========================>..] - ETA: 0s - loss: 1.4711 - mse: 1.4284\n",
      "Epoch 23: val_loss improved from 1.47420 to 1.47408, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e023_vl1.474.h5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 1.4714 - mse: 1.4287 - val_loss: 1.4741 - val_mse: 1.4314\n",
      "Epoch 24/25\n",
      " 94/101 [==========================>...] - ETA: 0s - loss: 1.4712 - mse: 1.4286\n",
      "Epoch 24: val_loss improved from 1.47408 to 1.47403, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e024_vl1.474.h5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 1.4711 - mse: 1.4285 - val_loss: 1.4740 - val_mse: 1.4314\n",
      "Epoch 25/25\n",
      "100/101 [============================>.] - ETA: 0s - loss: 1.4710 - mse: 1.4284\n",
      "Epoch 25: val_loss improved from 1.47403 to 1.47368, saving model to checkpoints/ext_0h_l1n2_2hidden_it16.e025_vl1.474.h5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.4710 - mse: 1.4284 - val_loss: 1.4737 - val_mse: 1.4311\n",
      "Time elapsed to train: 16.92 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [3.714 4.448 2.951 4.790 3.688 3.024 2.547 2.255 1.862 1.262 1.245 0.001 0.002]\n",
      "<R> = [3.711 4.445 2.944 4.784 3.683 3.018 2.540 2.248 1.855 1.256 1.238 0.001 0.002]\n",
      "s_R = [0.489 0.496 0.609 0.565 0.554 0.588 0.676 0.749 0.876 1.336 1.497 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.761801  2.7510388 5.9633684 ... 2.944815  3.9496596 4.3714733]\n",
      "mag_pred: [3.761801  2.7510388 5.9633684 ... 2.944815  3.9496596 4.3714733]\n",
      "Time elapsed to make plots: 22.32 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 272.49835    40.90991   110.55047  ...   11.237614   48.206234\n",
      " 2487.591   ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00762\n",
      "  1% : 0.167\n",
      "  10% : 0.557\n",
      "  50% : 3.9\n",
      "  90% : 51.7\n",
      "  99% : 397\n",
      "  100% : 8.79e+03\n",
      "<chi^2/d.o.f.> = 2.91\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 111729 stars (44.2%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 34.48657   71.33946  821.7155   ... 496.22723   30.141584 299.6618  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0339\n",
      "  1% : 0.161\n",
      "  10% : 0.554\n",
      "  50% : 3.87\n",
      "  90% : 51.5\n",
      "  99% : 397\n",
      "  100% : 5.28e+03\n",
      "<chi^2/d.o.f.> = 2.88\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 68.30 s\n",
      "learning rate = 4.076220284332521e-05\n",
      "setting learning rate to 3.337326996032607e-05\n",
      "Iteration 18 of 20.\n",
      "Epoch 1/25\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1.4667 - mse: 1.4242\n",
      "Epoch 1: val_loss improved from inf to 1.46702, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e001_vl1.467.h5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1.4657 - mse: 1.4232 - val_loss: 1.4670 - val_mse: 1.4245\n",
      "Epoch 2/25\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1.4657 - mse: 1.4233\n",
      "Epoch 2: val_loss did not improve from 1.46702\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4655 - mse: 1.4230 - val_loss: 1.4671 - val_mse: 1.4246\n",
      "Epoch 3/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.4653 - mse: 1.4228\n",
      "Epoch 3: val_loss improved from 1.46702 to 1.46684, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e003_vl1.467.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4655 - mse: 1.4231 - val_loss: 1.4668 - val_mse: 1.4244\n",
      "Epoch 4/25\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 1.4642 - mse: 1.4219\n",
      "Epoch 4: val_loss did not improve from 1.46684\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4654 - mse: 1.4230 - val_loss: 1.4669 - val_mse: 1.4245\n",
      "Epoch 5/25\n",
      " 90/100 [==========================>...] - ETA: 0s - loss: 1.4666 - mse: 1.4243\n",
      "Epoch 5: val_loss improved from 1.46684 to 1.46663, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e005_vl1.467.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4653 - mse: 1.4230 - val_loss: 1.4666 - val_mse: 1.4243\n",
      "Epoch 6/25\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1.4649 - mse: 1.4226\n",
      "Epoch 6: val_loss did not improve from 1.46663\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4652 - mse: 1.4230 - val_loss: 1.4668 - val_mse: 1.4245\n",
      "Epoch 7/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.4652 - mse: 1.4230\n",
      "Epoch 7: val_loss improved from 1.46663 to 1.46652, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e007_vl1.467.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4652 - mse: 1.4230 - val_loss: 1.4665 - val_mse: 1.4243\n",
      "Epoch 8/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.4651 - mse: 1.4229\n",
      "Epoch 8: val_loss did not improve from 1.46652\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4652 - mse: 1.4231 - val_loss: 1.4666 - val_mse: 1.4245\n",
      "Epoch 9/25\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1.4656 - mse: 1.4235\n",
      "Epoch 9: val_loss improved from 1.46652 to 1.46643, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e009_vl1.466.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4651 - mse: 1.4230 - val_loss: 1.4664 - val_mse: 1.4244\n",
      "Epoch 10/25\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1.4646 - mse: 1.4226\n",
      "Epoch 10: val_loss did not improve from 1.46643\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4651 - mse: 1.4230 - val_loss: 1.4665 - val_mse: 1.4244\n",
      "Epoch 11/25\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1.4649 - mse: 1.4229\n",
      "Epoch 11: val_loss improved from 1.46643 to 1.46641, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e011_vl1.466.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4651 - mse: 1.4231 - val_loss: 1.4664 - val_mse: 1.4244\n",
      "Epoch 12/25\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1.4649 - mse: 1.4230\n",
      "Epoch 12: val_loss improved from 1.46641 to 1.46630, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e012_vl1.466.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4650 - mse: 1.4230 - val_loss: 1.4663 - val_mse: 1.4244\n",
      "Epoch 13/25\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4654 - mse: 1.4235\n",
      "Epoch 13: val_loss did not improve from 1.46630\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4648 - mse: 1.4229 - val_loss: 1.4663 - val_mse: 1.4244\n",
      "Epoch 14/25\n",
      " 90/100 [==========================>...] - ETA: 0s - loss: 1.4654 - mse: 1.4236\n",
      "Epoch 14: val_loss improved from 1.46630 to 1.46626, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e014_vl1.466.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4649 - mse: 1.4230 - val_loss: 1.4663 - val_mse: 1.4244\n",
      "Epoch 15/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.4646 - mse: 1.4228\n",
      "Epoch 15: val_loss improved from 1.46626 to 1.46609, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e015_vl1.466.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4648 - mse: 1.4230 - val_loss: 1.4661 - val_mse: 1.4243\n",
      "Epoch 16/25\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1.4644 - mse: 1.4227\n",
      "Epoch 16: val_loss did not improve from 1.46609\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4648 - mse: 1.4230 - val_loss: 1.4661 - val_mse: 1.4244\n",
      "Epoch 17/25\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1.4645 - mse: 1.4228\n",
      "Epoch 17: val_loss did not improve from 1.46609\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4647 - mse: 1.4230 - val_loss: 1.4661 - val_mse: 1.4245\n",
      "Epoch 18/25\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1.4655 - mse: 1.4239\n",
      "Epoch 18: val_loss improved from 1.46609 to 1.46606, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e018_vl1.466.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4647 - mse: 1.4231 - val_loss: 1.4661 - val_mse: 1.4245\n",
      "Epoch 19/25\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1.4639 - mse: 1.4223\n",
      "Epoch 19: val_loss did not improve from 1.46606\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4646 - mse: 1.4230 - val_loss: 1.4661 - val_mse: 1.4245\n",
      "Epoch 20/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.4645 - mse: 1.4230\n",
      "Epoch 20: val_loss improved from 1.46606 to 1.46578, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e020_vl1.466.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4645 - mse: 1.4230 - val_loss: 1.4658 - val_mse: 1.4243\n",
      "Epoch 21/25\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1.4642 - mse: 1.4228\n",
      "Epoch 21: val_loss did not improve from 1.46578\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4645 - mse: 1.4230 - val_loss: 1.4658 - val_mse: 1.4244\n",
      "Epoch 22/25\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4641 - mse: 1.4227\n",
      "Epoch 22: val_loss improved from 1.46578 to 1.46572, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e022_vl1.466.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4643 - mse: 1.4229 - val_loss: 1.4657 - val_mse: 1.4243\n",
      "Epoch 23/25\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1.4649 - mse: 1.4236\n",
      "Epoch 23: val_loss did not improve from 1.46572\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4644 - mse: 1.4230 - val_loss: 1.4658 - val_mse: 1.4245\n",
      "Epoch 24/25\n",
      " 91/100 [==========================>...] - ETA: 0s - loss: 1.4650 - mse: 1.4237\n",
      "Epoch 24: val_loss improved from 1.46572 to 1.46569, saving model to checkpoints/ext_0h_l1n2_2hidden_it17.e024_vl1.466.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4643 - mse: 1.4230 - val_loss: 1.4657 - val_mse: 1.4244\n",
      "Epoch 25/25\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1.4644 - mse: 1.4232\n",
      "Epoch 25: val_loss did not improve from 1.46569\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4642 - mse: 1.4230 - val_loss: 1.4658 - val_mse: 1.4246\n",
      "Time elapsed to train: 16.81 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [3.736 4.476 2.968 4.822 3.709 3.041 2.560 2.268 1.871 1.266 1.248 0.001 0.002]\n",
      "<R> = [3.733 4.474 2.962 4.815 3.705 3.036 2.554 2.261 1.865 1.259 1.241 0.001 0.002]\n",
      "s_R = [0.454 0.461 0.570 0.531 0.520 0.549 0.632 0.699 0.808 1.187 1.330 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7652538 2.7465866 5.9763546 ... 2.9484355 3.9491222 4.370579 ]\n",
      "mag_pred: [3.7652538 2.7465866 5.9763546 ... 2.9484355 3.9491222 4.370579 ]\n",
      "Time elapsed to make plots: 17.93 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 273.6692     40.386864  117.83348  ...   11.364334   47.50621\n",
      " 2569.016   ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00813\n",
      "  1% : 0.168\n",
      "  10% : 0.559\n",
      "  50% : 3.94\n",
      "  90% : 52.7\n",
      "  99% : 402\n",
      "  100% : 8.82e+03\n",
      "<chi^2/d.o.f.> = 2.92\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 112300 stars (44.4%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 34.644623  71.59544  850.7285   ... 498.9074    29.608532 320.39676 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0376\n",
      "  1% : 0.162\n",
      "  10% : 0.554\n",
      "  50% : 3.91\n",
      "  90% : 52.7\n",
      "  99% : 405\n",
      "  100% : 5.27e+03\n",
      "<chi^2/d.o.f.> = 2.88\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 71.09 s\n",
      "learning rate = 3.337327143526636e-05\n",
      "setting learning rate to 2.732372244729256e-05\n",
      "Iteration 19 of 20.\n",
      "Epoch 1/25\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4641 - mse: 1.4229\n",
      "Epoch 1: val_loss improved from inf to 1.46377, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e001_vl1.464.h5\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1.4647 - mse: 1.4235 - val_loss: 1.4638 - val_mse: 1.4226\n",
      "Epoch 2/25\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4644 - mse: 1.4232\n",
      "Epoch 2: val_loss improved from 1.46377 to 1.46371, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e002_vl1.464.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4646 - mse: 1.4234 - val_loss: 1.4637 - val_mse: 1.4226\n",
      "Epoch 3/25\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 1.4641 - mse: 1.4230\n",
      "Epoch 3: val_loss improved from 1.46371 to 1.46368, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e003_vl1.464.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4645 - mse: 1.4233 - val_loss: 1.4637 - val_mse: 1.4226\n",
      "Epoch 4/25\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 1.4633 - mse: 1.4222\n",
      "Epoch 4: val_loss did not improve from 1.46368\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4645 - mse: 1.4234 - val_loss: 1.4638 - val_mse: 1.4227\n",
      "Epoch 5/25\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1.4652 - mse: 1.4241\n",
      "Epoch 5: val_loss improved from 1.46368 to 1.46361, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e005_vl1.464.h5\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4645 - mse: 1.4235 - val_loss: 1.4636 - val_mse: 1.4226\n",
      "Epoch 6/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.4644 - mse: 1.4234\n",
      "Epoch 6: val_loss improved from 1.46361 to 1.46355, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e006_vl1.464.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4643 - mse: 1.4233 - val_loss: 1.4636 - val_mse: 1.4226\n",
      "Epoch 7/25\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 1.4639 - mse: 1.4229\n",
      "Epoch 7: val_loss improved from 1.46355 to 1.46340, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e007_vl1.463.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4643 - mse: 1.4234 - val_loss: 1.4634 - val_mse: 1.4225\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4643 - mse: 1.4234\n",
      "Epoch 8: val_loss did not improve from 1.46340\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4643 - mse: 1.4234 - val_loss: 1.4636 - val_mse: 1.4227\n",
      "Epoch 9/25\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1.4650 - mse: 1.4242\n",
      "Epoch 9: val_loss improved from 1.46340 to 1.46334, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e009_vl1.463.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4642 - mse: 1.4233 - val_loss: 1.4633 - val_mse: 1.4225\n",
      "Epoch 10/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.4644 - mse: 1.4236\n",
      "Epoch 10: val_loss did not improve from 1.46334\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4642 - mse: 1.4234 - val_loss: 1.4637 - val_mse: 1.4230\n",
      "Epoch 11/25\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 1.4645 - mse: 1.4238\n",
      "Epoch 11: val_loss did not improve from 1.46334\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4642 - mse: 1.4234 - val_loss: 1.4634 - val_mse: 1.4226\n",
      "Epoch 12/25\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1.4641 - mse: 1.4234\n",
      "Epoch 12: val_loss did not improve from 1.46334\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4641 - mse: 1.4233 - val_loss: 1.4635 - val_mse: 1.4228\n",
      "Epoch 13/25\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 1.4635 - mse: 1.4228\n",
      "Epoch 13: val_loss improved from 1.46334 to 1.46322, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e013_vl1.463.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4641 - mse: 1.4234 - val_loss: 1.4632 - val_mse: 1.4226\n",
      "Epoch 14/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.4642 - mse: 1.4236\n",
      "Epoch 14: val_loss improved from 1.46322 to 1.46313, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e014_vl1.463.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4641 - mse: 1.4234 - val_loss: 1.4631 - val_mse: 1.4225\n",
      "Epoch 15/25\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 1.4637 - mse: 1.4231\n",
      "Epoch 15: val_loss improved from 1.46313 to 1.46308, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e015_vl1.463.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4639 - mse: 1.4234 - val_loss: 1.4631 - val_mse: 1.4225\n",
      "Epoch 16/25\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4643 - mse: 1.4238\n",
      "Epoch 16: val_loss improved from 1.46308 to 1.46308, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e016_vl1.463.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4639 - mse: 1.4233 - val_loss: 1.4631 - val_mse: 1.4226\n",
      "Epoch 17/25\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 1.4645 - mse: 1.4240\n",
      "Epoch 17: val_loss did not improve from 1.46308\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4639 - mse: 1.4234 - val_loss: 1.4632 - val_mse: 1.4227\n",
      "Epoch 18/25\n",
      " 89/100 [=========================>....] - ETA: 0s - loss: 1.4644 - mse: 1.4239\n",
      "Epoch 18: val_loss did not improve from 1.46308\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4639 - mse: 1.4234 - val_loss: 1.4632 - val_mse: 1.4227\n",
      "Epoch 19/25\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 1.4639 - mse: 1.4235\n",
      "Epoch 19: val_loss improved from 1.46308 to 1.46286, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e019_vl1.463.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4637 - mse: 1.4233 - val_loss: 1.4629 - val_mse: 1.4225\n",
      "Epoch 20/25\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1.4643 - mse: 1.4239\n",
      "Epoch 20: val_loss did not improve from 1.46286\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4638 - mse: 1.4234 - val_loss: 1.4629 - val_mse: 1.4226\n",
      "Epoch 21/25\n",
      " 90/100 [==========================>...] - ETA: 0s - loss: 1.4639 - mse: 1.4235\n",
      "Epoch 21: val_loss did not improve from 1.46286\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4637 - mse: 1.4234 - val_loss: 1.4629 - val_mse: 1.4226\n",
      "Epoch 22/25\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1.4627 - mse: 1.4224\n",
      "Epoch 22: val_loss did not improve from 1.46286\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4637 - mse: 1.4234 - val_loss: 1.4629 - val_mse: 1.4227\n",
      "Epoch 23/25\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 1.4634 - mse: 1.4232\n",
      "Epoch 23: val_loss did not improve from 1.46286\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4636 - mse: 1.4234 - val_loss: 1.4629 - val_mse: 1.4226\n",
      "Epoch 24/25\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 1.4633 - mse: 1.4231\n",
      "Epoch 24: val_loss improved from 1.46286 to 1.46269, saving model to checkpoints/ext_0h_l1n2_2hidden_it18.e024_vl1.463.h5\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 1.4636 - mse: 1.4234 - val_loss: 1.4627 - val_mse: 1.4225\n",
      "Epoch 25/25\n",
      " 88/100 [=========================>....] - ETA: 0s - loss: 1.4626 - mse: 1.4225\n",
      "Epoch 25: val_loss did not improve from 1.46269\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 1.4635 - mse: 1.4233 - val_loss: 1.4628 - val_mse: 1.4227\n",
      "Time elapsed to train: 16.99 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [3.754 4.499 2.982 4.847 3.727 3.056 2.573 2.279 1.880 1.270 1.252 0.001 0.002]\n",
      "<R> = [3.751 4.497 2.976 4.841 3.723 3.050 2.567 2.273 1.874 1.264 1.245 0.001 0.002]\n",
      "s_R = [0.421 0.429 0.537 0.500 0.489 0.517 0.596 0.662 0.758 1.085 1.211 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7596393 2.7326717 5.975071  ... 2.9388213 3.9420066 4.362667 ]\n",
      "mag_pred: [3.7596393 2.7326717 5.975071  ... 2.9388213 3.9420066 4.362667 ]\n",
      "Time elapsed to make plots: 17.77 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 10: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Band 11: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 253053 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 269.11414    41.815468  127.19023  ...   10.801879   48.40969\n",
      " 2642.2744  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.00841\n",
      "  1% : 0.166\n",
      "  10% : 0.558\n",
      "  50% : 3.96\n",
      "  90% : 54.2\n",
      "  99% : 409\n",
      "  100% : 8.87e+03\n",
      "<chi^2/d.o.f.> = 2.91\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 112900 stars (44.6%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 33.6912    73.111824 881.5947   ... 511.32452   28.996567 343.16647 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0312\n",
      "  1% : 0.163\n",
      "  10% : 0.556\n",
      "  50% : 3.93\n",
      "  90% : 54.1\n",
      "  99% : 414\n",
      "  100% : 5.28e+03\n",
      "<chi^2/d.o.f.> = 2.88\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 68.65 s\n",
      "learning rate = 2.732372195168864e-05\n",
      "setting learning rate to 2.2370771856165592e-05\n",
      "Iteration 20 of 20.\n",
      "Epoch 1/25\n",
      "98/99 [============================>.] - ETA: 0s - loss: 1.4597 - mse: 1.4196\n",
      "Epoch 1: val_loss improved from inf to 1.45981, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e001_vl1.460.h5\n",
      "99/99 [==============================] - 1s 9ms/step - loss: 1.4601 - mse: 1.4200 - val_loss: 1.4598 - val_mse: 1.4197\n",
      "Epoch 2/25\n",
      "97/99 [============================>.] - ETA: 0s - loss: 1.4606 - mse: 1.4205\n",
      "Epoch 2: val_loss improved from 1.45981 to 1.45972, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e002_vl1.460.h5\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 1.4600 - mse: 1.4199 - val_loss: 1.4597 - val_mse: 1.4197\n",
      "Epoch 3/25\n",
      "99/99 [==============================] - ETA: 0s - loss: 1.4599 - mse: 1.4198\n",
      "Epoch 3: val_loss did not improve from 1.45972\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4599 - mse: 1.4198 - val_loss: 1.4597 - val_mse: 1.4197\n",
      "Epoch 4/25\n",
      "93/99 [===========================>..] - ETA: 0s - loss: 1.4602 - mse: 1.4202\n",
      "Epoch 4: val_loss improved from 1.45972 to 1.45971, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e004_vl1.460.h5\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 1.4598 - mse: 1.4198 - val_loss: 1.4597 - val_mse: 1.4197\n",
      "Epoch 5/25\n",
      "93/99 [===========================>..] - ETA: 0s - loss: 1.4608 - mse: 1.4208\n",
      "Epoch 5: val_loss did not improve from 1.45971\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 1.4600 - mse: 1.4200 - val_loss: 1.4598 - val_mse: 1.4198\n",
      "Epoch 6/25\n",
      "89/99 [=========================>....] - ETA: 0s - loss: 1.4602 - mse: 1.4203\n",
      "Epoch 6: val_loss improved from 1.45971 to 1.45959, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e006_vl1.460.h5\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4597 - mse: 1.4198 - val_loss: 1.4596 - val_mse: 1.4197\n",
      "Epoch 7/25\n",
      "91/99 [==========================>...] - ETA: 0s - loss: 1.4586 - mse: 1.4187\n",
      "Epoch 7: val_loss did not improve from 1.45959\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 1.4598 - mse: 1.4199 - val_loss: 1.4596 - val_mse: 1.4198\n",
      "Epoch 8/25\n",
      "96/99 [============================>.] - ETA: 0s - loss: 1.4602 - mse: 1.4203\n",
      "Epoch 8: val_loss improved from 1.45959 to 1.45940, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e008_vl1.459.h5\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4597 - mse: 1.4199 - val_loss: 1.4594 - val_mse: 1.4196\n",
      "Epoch 9/25\n",
      "99/99 [==============================] - ETA: 0s - loss: 1.4597 - mse: 1.4199\n",
      "Epoch 9: val_loss did not improve from 1.45940\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4597 - mse: 1.4199 - val_loss: 1.4597 - val_mse: 1.4199\n",
      "Epoch 10/25\n",
      "93/99 [===========================>..] - ETA: 0s - loss: 1.4591 - mse: 1.4193\n",
      "Epoch 10: val_loss did not improve from 1.45940\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 1.4596 - mse: 1.4199 - val_loss: 1.4595 - val_mse: 1.4197\n",
      "Epoch 11/25\n",
      "91/99 [==========================>...] - ETA: 0s - loss: 1.4606 - mse: 1.4209\n",
      "Epoch 11: val_loss did not improve from 1.45940\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4596 - mse: 1.4199 - val_loss: 1.4594 - val_mse: 1.4197\n",
      "Epoch 12/25\n",
      "91/99 [==========================>...] - ETA: 0s - loss: 1.4581 - mse: 1.4184\n",
      "Epoch 12: val_loss did not improve from 1.45940\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4597 - mse: 1.4200 - val_loss: 1.4594 - val_mse: 1.4197\n",
      "Epoch 13/25\n",
      "91/99 [==========================>...] - ETA: 0s - loss: 1.4590 - mse: 1.4193\n",
      "Epoch 13: val_loss improved from 1.45940 to 1.45932, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e013_vl1.459.h5\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4595 - mse: 1.4199 - val_loss: 1.4593 - val_mse: 1.4197\n",
      "Epoch 14/25\n",
      "98/99 [============================>.] - ETA: 0s - loss: 1.4595 - mse: 1.4198\n",
      "Epoch 14: val_loss improved from 1.45932 to 1.45931, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e014_vl1.459.h5\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 1.4595 - mse: 1.4199 - val_loss: 1.4593 - val_mse: 1.4197\n",
      "Epoch 15/25\n",
      "97/99 [============================>.] - ETA: 0s - loss: 1.4591 - mse: 1.4195\n",
      "Epoch 15: val_loss improved from 1.45931 to 1.45924, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e015_vl1.459.h5\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 1.4594 - mse: 1.4198 - val_loss: 1.4592 - val_mse: 1.4197\n",
      "Epoch 16/25\n",
      "94/99 [===========================>..] - ETA: 0s - loss: 1.4597 - mse: 1.4201\n",
      "Epoch 16: val_loss improved from 1.45924 to 1.45907, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e016_vl1.459.h5\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 1.4594 - mse: 1.4199 - val_loss: 1.4591 - val_mse: 1.4196\n",
      "Epoch 17/25\n",
      "94/99 [===========================>..] - ETA: 0s - loss: 1.4587 - mse: 1.4192\n",
      "Epoch 17: val_loss did not improve from 1.45907\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4594 - mse: 1.4199 - val_loss: 1.4594 - val_mse: 1.4199\n",
      "Epoch 18/25\n",
      "96/99 [============================>.] - ETA: 0s - loss: 1.4589 - mse: 1.4194\n",
      "Epoch 18: val_loss did not improve from 1.45907\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4594 - mse: 1.4199 - val_loss: 1.4592 - val_mse: 1.4198\n",
      "Epoch 19/25\n",
      "89/99 [=========================>....] - ETA: 0s - loss: 1.4619 - mse: 1.4225\n",
      "Epoch 19: val_loss did not improve from 1.45907\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4593 - mse: 1.4198 - val_loss: 1.4592 - val_mse: 1.4198\n",
      "Epoch 20/25\n",
      "98/99 [============================>.] - ETA: 0s - loss: 1.4593 - mse: 1.4199\n",
      "Epoch 20: val_loss did not improve from 1.45907\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4592 - mse: 1.4199 - val_loss: 1.4591 - val_mse: 1.4197\n",
      "Epoch 21/25\n",
      "98/99 [============================>.] - ETA: 0s - loss: 1.4593 - mse: 1.4199\n",
      "Epoch 21: val_loss did not improve from 1.45907\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4592 - mse: 1.4198 - val_loss: 1.4591 - val_mse: 1.4198\n",
      "Epoch 22/25\n",
      "95/99 [===========================>..] - ETA: 0s - loss: 1.4592 - mse: 1.4199\n",
      "Epoch 22: val_loss improved from 1.45907 to 1.45889, saving model to checkpoints/ext_0h_l1n2_2hidden_it19.e022_vl1.459.h5\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 1.4591 - mse: 1.4198 - val_loss: 1.4589 - val_mse: 1.4196\n",
      "Epoch 23/25\n",
      "99/99 [==============================] - ETA: 0s - loss: 1.4592 - mse: 1.4199\n",
      "Epoch 23: val_loss did not improve from 1.45889\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4592 - mse: 1.4199 - val_loss: 1.4595 - val_mse: 1.4202\n",
      "Epoch 24/25\n",
      "94/99 [===========================>..] - ETA: 0s - loss: 1.4593 - mse: 1.4200\n",
      "Epoch 24: val_loss did not improve from 1.45889\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 1.4592 - mse: 1.4199 - val_loss: 1.4590 - val_mse: 1.4198\n",
      "Epoch 25/25\n",
      "97/99 [============================>.] - ETA: 0s - loss: 1.4594 - mse: 1.4202\n",
      "Epoch 25: val_loss did not improve from 1.45889\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 1.4591 - mse: 1.4199 - val_loss: 1.4590 - val_mse: 1.4198\n",
      "Time elapsed to train: 16.63 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [3.769 4.519 2.994 4.868 3.742 3.068 2.583 2.289 1.887 1.274 1.255 0.001 0.001]\n",
      "<R> = [3.767 4.517 2.988 4.863 3.738 3.063 2.577 2.282 1.881 1.268 1.249 0.001 0.001]\n",
      "s_R = [0.394 0.402 0.510 0.475 0.463 0.490 0.567 0.630 0.717 1.001 1.118 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7636576 2.7298944 5.9814186 ... 2.9427512 3.9435775 4.3633094]\n",
      "mag_pred: [3.7636576 2.7298944 5.9814186 ... 2.9427512 3.9435775 4.3633094]\n",
      "Time elapsed to make plots: 22.65 s\n"
     ]
    }
   ],
   "source": [
    "for k in range(0, n_iterations):\n",
    "    # Transform data to inputs and outputs\n",
    "    # On subsequent iterations, inflate errors using\n",
    "    # gradients dM/dtheta from trained model, and derive new\n",
    "    # estimates of the reddenings of the stars.\n",
    "    t0 = time()\n",
    "    io_train = get_inputs_outputs(\n",
    "        d_train,\n",
    "        pretrained_model=None if k == 0 else nn_model,\n",
    "        recalc_reddening=True,\n",
    "        rchisq_max=rchisq_max[k]\n",
    "    )                                                                         \n",
    "    io_test = get_inputs_outputs(                                                      #\n",
    "        d_test,                                                                        #\n",
    "        pretrained_model=None if k == 0 else nn_model,                                 #\n",
    "        recalc_reddening=True,                                                         #\n",
    "    )                                                                                  #                                                                        \n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to prepare data: {t1-t0:.2f} s')\n",
    "\n",
    "    # Set learning rate based on the iteration\n",
    "    lr = 0.001 * np.exp(-0.2*k)\n",
    "    print('learning rate = {}'.format(K.get_value(nn_model.optimizer.lr)))\n",
    "    print('setting learning rate to {}'.format(lr))\n",
    "    K.set_value(nn_model.optimizer.lr, lr)\n",
    "\n",
    "    # Train the model\n",
    "    print('Iteration {} of {}.'.format(k+1, n_iterations))\n",
    "    t0 = time()\n",
    "    train_model(\n",
    "        nn_model,\n",
    "        io_train,\n",
    "        epochs=25,\n",
    "        checkpoint_fn='{:s}_{:d}hidden_it{:d}'.format(\n",
    "            nn_name, n_hidden, k\n",
    "        ),\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to train: {t1-t0:.2f} s')\n",
    "    nn_model.save(\n",
    "        'models/{:s}_{:d}hidden_it{:d}.h5'.format(\n",
    "            nn_name, n_hidden, k\n",
    "        )\n",
    "    )\n",
    "    nn_model = keras.models.load_model(                                                #\n",
    "       'models/{:s}_{:d}hidden_it{:d}.h5'.format(nn_name, n_hidden, k)                 #\n",
    "    )                                                                                  #\n",
    "                                                                                       #\n",
    "    # Plot results on test set                                                         #\n",
    "    print('Diagnostic plots ...')                                                      #\n",
    "    t0 = time()                                                                        #\n",
    "    diagnostic_plots(                                                                  #\n",
    "       nn_model,                                                                       #\n",
    "       io_test,                                                                        #\n",
    "       d_test,                                                                         #\n",
    "       #io_train,                                                                      #\n",
    "       #d_train,                                                                       #\n",
    "       suffix='{:s}_{:d}hidden_it{:d}'.format(nn_name, n_hidden, k)                    #\n",
    "    )                                                                                  #\n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to make plots: {t1-t0:.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1d8de09-5d9d-43a1-b6ad-5aa70393a40a",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating covariances and reddening estimates of test dataset ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 10: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Band 11: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 28118 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 33.973194  73.333664 913.15454  ... 510.45343   28.64132  362.21814 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0305\n",
      "  1% : 0.164\n",
      "  10% : 0.559\n",
      "  50% : 3.96\n",
      "  90% : 55\n",
      "  99% : 419\n",
      "  100% : 5.28e+03\n",
      "<chi^2/d.o.f.> = 2.89\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to update covariances and reddenings: 8.71 s\n"
     ]
    }
   ],
   "source": [
    "print('Updating covariances and reddening estimates of test dataset ...')\n",
    "t0 = time()\n",
    "io_test = get_inputs_outputs(\n",
    "    d_test,\n",
    "    pretrained_model=nn_model,\n",
    "    recalc_reddening=True\n",
    ")\n",
    "t1 = time()\n",
    "print(f'Time elapsed to update covariances and reddenings: {t1-t0:.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fe20ad0-6076-42e4-b5fa-0a8b44b55833",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: [1.460394263267517, 1.421215534210205]\n",
      "train loss: [1.4589722156524658, 1.4197936058044434]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance on (train, validation and test sets)\n",
    "loss = {}\n",
    "for n,io_eval in (('test',io_test), ('train',io_train)):\n",
    "    loss[n] = evaluate_model(\n",
    "        nn_model,\n",
    "        io_eval,\n",
    "        batch_size=batch_size,\n",
    "        rchisq_max=rchisq_max[-1]\n",
    "    )\n",
    "    print(f'{n} loss: {loss[n]}')\n",
    "fname = 'loss_{:s}_{:d}hidden_it{:d}.json'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "with open(fname, 'w') as f:\n",
    "    json.dump(loss, f, indent=2, sort_keys=True)\n",
    "\n",
    "fname = 'predictions_{:s}_{:d}hidden_it{:d}.h5'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "save_predictions(fname, nn_model, d_test, io_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ef83a49-55d7-41f4-be9e-87606f86734e",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving covariance components for small subset of test dataset ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 1000 bad. Replacing with 14.23750.\n",
      "Band 1: 0 of 1000 bad. Replacing with 14.61455.\n",
      "Band 2: 0 of 1000 bad. Replacing with 13.69537.\n",
      "Band 3: 147 of 1000 bad. Replacing with 14.96300.\n",
      "Band 4: 250 of 1000 bad. Replacing with 14.65440.\n",
      "Band 5: 310 of 1000 bad. Replacing with 14.59245.\n",
      "Band 6: 192 of 1000 bad. Replacing with 14.30900.\n",
      "Band 7: 33 of 1000 bad. Replacing with 14.03010.\n",
      "Band 8: 0 of 1000 bad. Replacing with 13.05500.\n",
      "Band 9: 1 of 1000 bad. Replacing with 15.26814.\n",
      "Band 10: 2 of 1000 bad. Replacing with 15.92215.\n",
      "Band 11: 0 of 1000 bad. Replacing with 0.00000.\n",
      "Band 12: 0 of 1000 bad. Replacing with 0.00000.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 1000 of 1000 (100.000%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [6.18310852e+01 1.19933960e+02 1.19631529e+01 6.79900932e+00\n",
      " 2.20457153e+01 3.66962242e+01 4.97389832e+01 5.06791321e+02\n",
      " 7.27627716e+01 5.96252174e+01 5.89915771e+01 2.71959801e+01\n",
      " 2.28990662e+02 5.90218468e+01 2.27276459e+01 2.60441284e+01\n",
      " 7.38729019e+01 1.72326233e+02 2.12585220e+01 1.29376648e+02\n",
      " 2.05785103e+01 1.65121651e+01 8.66102371e+01 5.39412308e+01\n",
      " 6.25274124e+01 3.39320946e+00 1.13624438e+03 3.60320831e+02\n",
      " 2.95227165e+01 2.08590759e+02 2.23767014e+02 5.41753922e+01\n",
      " 6.31665649e+02 5.59178314e+01 8.80058098e+00 5.11343098e+00\n",
      " 1.75165939e+01 9.88640594e+00 1.47461777e+02 7.62972450e+00\n",
      " 1.21726051e+02 8.39565582e+01 1.51543961e+01 7.04307175e+00\n",
      " 6.90334320e+00 2.59733002e+02 1.94448662e+01 2.52539654e+01\n",
      " 1.91591827e+02 6.83832502e+00 7.37120914e+00 8.20263958e+00\n",
      " 8.31613183e-01 8.61090012e+01 8.22656860e+01 1.39003744e+01\n",
      " 4.46993027e+01 2.74863472e+01 2.70936523e+02 4.05856228e+00\n",
      " 7.85685959e+01 5.51405716e+00 8.79400253e+00 8.82037720e+02\n",
      " 2.77766815e+02 2.34546265e+02 2.68965912e+01 4.69335461e+00\n",
      " 3.05282288e+02 3.35890732e+01 1.69568970e+02 3.66328522e+02\n",
      " 3.42486763e+01 9.48151093e+01 2.45756474e+01 7.96351624e+01\n",
      " 5.43753418e+02 2.43558941e+01 1.72456741e+02 1.11672156e+03\n",
      " 1.21636028e+01 2.19189262e+01 9.97065735e+00 1.04107037e+01\n",
      " 6.55879354e+00 3.40598030e+01 1.63870716e+01 4.22174568e+01\n",
      " 2.02235432e+01 3.06253700e+01 6.30547867e+01 1.03406693e+02\n",
      " 4.44923706e+01 2.68236923e+01 2.04606476e+02 4.10002289e+01\n",
      " 5.94203369e+02 5.92830620e+01 2.80128365e+01 2.86291790e+01\n",
      " 3.95108986e+01 9.85445557e+02 7.83742447e+01 1.52808895e+01\n",
      " 1.16154007e+02 4.53371124e+01 2.29208008e+03 1.98699856e+01\n",
      " 1.56798523e+02 7.06565018e+01 2.17899460e+02 4.18387604e+01\n",
      " 1.95465107e+01 9.26621857e+01 3.10657837e+02 3.96072159e+01\n",
      " 1.45317200e+02 2.43113632e+01 9.93111572e+01 2.67921848e+01\n",
      " 1.65858688e+01 1.34036926e+02 1.63391960e+00 3.13755727e+00\n",
      " 8.22906113e+01 7.11995983e+00 2.74856091e+01 3.59669037e+02\n",
      " 2.15175024e+03 5.07606262e+02 8.63460064e+00 3.14069397e+02\n",
      " 3.86353779e+00 2.43571224e+01 5.92942627e+02 6.57679749e+00\n",
      " 5.78667831e+01 3.18412838e+01 3.55527420e+01 6.70510674e+00\n",
      " 5.25697517e+00 5.40964355e+01 1.08640442e+02 6.32724428e+00\n",
      " 5.50296898e+01 1.22416611e+02 2.85172668e+02 7.03752869e+02\n",
      " 3.67689095e+01 4.15615129e+00 1.32722473e+02 6.64421143e+02\n",
      " 4.19291382e+01 2.00689233e+03 7.98411608e+00 6.58808231e+00\n",
      " 2.99835277e+00 9.23885155e+00 7.33431320e+01 6.10171631e+02\n",
      " 7.22641754e+00 8.43737488e+01 4.88702278e+01 3.96538239e+01\n",
      " 2.18743000e+01 2.66533928e+01 1.83812256e+02 2.80589485e+01\n",
      " 6.55218887e+00 1.20138342e+03 7.58854370e+01 2.23289452e+01\n",
      " 1.64846420e+01 3.22882446e+02 1.89087982e+02 1.43982811e+01\n",
      " 4.01695480e+01 2.10658966e+02 2.10718079e+01 8.08172703e+00\n",
      " 2.18757294e+02 1.78680458e+01 2.00537903e+02 3.41483337e+02\n",
      " 5.96630493e+02 9.67910194e+00 1.57510284e+02 1.61813766e+02\n",
      " 4.61063156e+01 7.24053711e+02 3.62540100e+02 3.00059834e+01\n",
      " 2.19683094e+01 7.97225571e+01 9.74839211e+00 1.39550915e+01\n",
      " 1.58149872e+02 2.33411011e+02 3.16240906e+02 8.04659843e+00\n",
      " 3.99008423e+02 1.74804291e+02 6.10665512e+00 1.33737656e+02\n",
      " 2.57226009e+01 7.29819183e+01 8.64350220e+02 2.15408688e+01\n",
      " 1.21598663e+02 8.80729771e+00 4.07261181e+00 2.02764473e+01\n",
      " 1.20692844e+01 5.15019150e+01 4.35686417e+01 8.20613003e+00\n",
      " 6.79754410e+01 1.62079887e+01 3.60365982e+01 7.02649292e+02\n",
      " 1.34331512e+01 4.45924683e+02 1.30238663e+02 2.15318222e+01\n",
      " 2.79160614e+01 3.02020752e+02 2.10266190e+02 2.17594547e+01\n",
      " 8.77924500e+01 3.80381104e+02 7.77365780e+00 7.31572449e+02\n",
      " 8.17298737e+01 1.56164198e+01 9.91942883e+00 2.06495914e+01\n",
      " 7.05549393e+01 5.34692192e+01 1.29418762e+02 1.80817070e+01\n",
      " 4.94371521e+02 9.30695629e+00 1.08799953e+01 1.13769409e+03\n",
      " 8.91557884e+00 5.03810196e+01 8.05654144e+00 1.43666801e+01\n",
      " 1.42071747e+02 7.57400055e+01 1.46405659e+01 8.18211136e+01\n",
      " 3.12105522e+01 1.72962780e+01 3.85007629e+01 3.15853558e+01\n",
      " 1.18029404e+01 6.60570526e+00 4.35315186e+02 3.00038727e+02\n",
      " 1.59785461e+02 9.37659454e+00 9.76317749e+01 1.14817981e+03\n",
      " 1.62219086e+01 5.66783829e+01 2.65067043e+01 5.10134460e+02\n",
      " 3.53705864e+01 8.99006119e+01 7.09441471e+00 3.78378868e+01\n",
      " 7.42169523e+00 8.82166958e+00 7.73077698e+01 1.46057606e+01\n",
      " 8.93204193e+01 1.54818654e+00 1.55071930e+02 7.07954468e+02\n",
      " 7.77843933e+01 3.24872620e+02 2.39045410e+01 3.20643349e+01\n",
      " 9.23068008e+01 1.53560425e+02 5.44840088e+01 6.89867401e+01\n",
      " 9.16012878e+01 2.54041245e+02 8.69302490e+02 8.91577148e+01\n",
      " 2.22772179e+01 2.47858696e+01 1.08717796e+02 2.62595701e+00\n",
      " 3.45432510e+01 2.92957420e+01 7.72539139e+01 4.90138474e+01\n",
      " 3.25980492e+01 1.51623550e+02 7.93839111e+01 2.24478626e+01\n",
      " 2.42417641e+01 1.16956294e+00 7.74614441e+02 2.09883809e+00\n",
      " 3.44649017e+02 5.01356659e+01 4.14310455e+01 4.97716766e+02\n",
      " 8.33103848e+00 6.70542221e+01 5.10332584e+00 1.40822096e+01\n",
      " 1.44099064e+01 6.52940979e+01 2.81163864e+01 1.98946342e+01\n",
      " 4.00326691e+01 1.55208044e+01 1.31858017e+02 8.60525024e+02\n",
      " 2.95630670e+00 1.04833969e+02 1.26961157e+03 1.90197906e+01\n",
      " 8.79483261e+01 1.10285873e+02 2.46648026e+02 6.41781158e+01\n",
      " 6.08713388e+00 6.36972961e+02 2.73447723e+01 1.36263371e+01\n",
      " 3.42755066e+02 1.02757820e+02 6.14910221e+00 7.49467041e+02\n",
      " 3.62084778e+02 4.61038256e+00 1.33055206e+02 5.73677063e+00\n",
      " 6.07577095e+01 8.76645660e+01 5.23575623e+02 4.84425232e+02\n",
      " 9.03826447e+01 2.26320000e+01 2.92335148e+01 2.60577393e+01\n",
      " 9.92853165e+01 3.99572693e+02 6.09446594e+02 4.65600357e+01\n",
      " 5.97661438e+01 5.10453430e+02 1.70895447e+02 1.89775906e+01\n",
      " 7.90999222e+01 3.07500529e+00 1.12354080e+02 1.17160139e+01\n",
      " 2.31830444e+02 1.30942856e+02 1.63418488e+02 2.38272018e+01\n",
      " 2.21961479e+01 6.44719696e+01 1.06470627e+02 2.32914867e+01\n",
      " 7.73177643e+01 6.10242081e+00 5.98501282e+01 7.31601486e+01\n",
      " 2.06669197e+01 1.82378174e+02 4.67989044e+01 5.00893326e+01\n",
      " 1.22094978e+02 2.28089561e+01 4.10258026e+01 7.55609741e+01\n",
      " 1.03785416e+02 8.67858887e+01 7.91475525e+01 3.11771259e+01\n",
      " 5.38470612e+01 7.02275543e+01 7.21991272e+01 3.98594170e+01\n",
      " 9.27486084e+02 2.07544041e+00 5.38400650e+01 1.46512354e+03\n",
      " 9.79027176e+00 9.23343849e+00 2.98522606e+01 6.94212265e+01\n",
      " 1.48731125e+02 1.80456944e+01 6.26123123e+01 1.02029896e+01\n",
      " 1.70369720e+02 2.31229004e+02 3.59553711e+02 1.75071964e+01\n",
      " 2.15129399e+00 5.95651913e+00 1.60266785e+02 8.70549072e+02\n",
      " 6.32984085e+01 8.67729492e+03 9.04579773e+01 2.45426979e+01\n",
      " 2.94166870e+02 1.79975605e+01 3.48970261e+01 1.30952637e+02\n",
      " 1.05563068e+01 8.59596176e+01 8.84884766e+02 1.52988312e+02\n",
      " 1.74010345e+02 2.95320206e+01 1.82131805e+02 4.08255959e+01\n",
      " 7.84120560e+00 4.40393921e+02 9.59296703e+00 1.05492844e+02\n",
      " 2.64659882e+01 4.68020630e+02 1.97470062e+02 1.65629292e+01\n",
      " 1.16525249e+01 3.20939514e+02 6.38966179e+01 3.48009033e+01\n",
      " 1.04729519e+01 1.41773972e+02 5.57961559e+00 1.35675995e+02\n",
      " 2.74343033e+01 3.41941757e+01 8.71027660e+00 1.23977127e+01\n",
      " 5.87703896e+01 2.54672241e+02 1.31003052e+02 2.31571140e+01\n",
      " 1.97821167e+03 1.12625723e+01 6.91328812e+01 1.17540588e+02\n",
      " 2.13415924e+02 2.10576248e+01 1.25944214e+02 2.63763062e+02\n",
      " 2.59940872e+01 6.92277298e+01 2.68154564e+01 2.37711029e+01\n",
      " 1.88020081e+02 1.92086649e+00 1.54619942e+01 1.65943279e+01\n",
      " 1.74768814e+02 4.19286823e+00 1.04791613e+01 1.10110664e+00\n",
      " 3.95434952e+01 1.42267685e+02 1.25529102e+03 1.56580963e+02\n",
      " 7.48034821e+01 9.20899506e+01 1.97416954e+01 2.07546021e+02\n",
      " 1.83521500e+01 1.41579714e+01 6.82657776e+01 6.04202295e+03\n",
      " 4.37994843e+01 3.11406059e+01 2.61973190e+01 2.59450340e+01\n",
      " 1.92760223e+02 1.56877899e+02 8.36940460e+01 5.04795715e+02\n",
      " 1.02920246e+01 1.64118710e+01 3.60685992e+00 4.91230072e+02\n",
      " 4.95273590e+00 6.35035133e+00 2.77227139e+00 1.05639795e+03\n",
      " 5.85701599e+02 5.46449375e+00 1.57513702e+02 3.06567955e+00\n",
      " 3.75613556e+01 5.33842611e+00 1.18975861e+02 8.15645504e+00\n",
      " 3.41127396e+01 7.33481201e+02 9.71293701e+02 4.14234619e+01\n",
      " 1.62285614e+01 8.60718822e+00 3.03637581e+01 5.21182434e+02\n",
      " 7.25956543e+02 4.39437828e+01 2.97081604e+02 1.93865540e+02\n",
      " 5.57702732e+00 8.92593765e+00 2.15941429e+01 1.70512829e+01\n",
      " 8.97553825e+00 2.97606277e+01 3.92086182e+02 3.54658937e+00\n",
      " 1.26536049e+02 1.94879150e+01 7.34615040e+00 6.92377930e+01\n",
      " 4.95318848e+03 6.91553406e+02 1.84590569e+01 2.66515808e+01\n",
      " 3.39559460e+00 2.27595978e+01 3.27680054e+01 7.80085659e+00\n",
      " 8.23747349e+00 3.48047638e+02 2.80013924e+01 4.44641647e+01\n",
      " 2.49049683e+01 1.97654980e+03 1.07039993e+02 4.94606781e+00\n",
      " 9.18674278e+00 2.28712597e+01 5.82555151e+00 6.11174088e+01\n",
      " 6.66003723e+01 4.93368164e+02 6.56247044e+00 2.53535290e+01\n",
      " 2.19956879e+02 1.60479050e+01 5.94735985e+01 1.72828033e+02\n",
      " 1.82497025e+00 1.04136734e+02 4.45413086e+02 8.25853634e+00\n",
      " 4.36888232e+03 3.24780006e+01 6.88761806e+00 1.05311554e+02\n",
      " 3.19075985e+01 3.61538506e+00 3.00204086e+01 1.72401169e+02\n",
      " 1.02747894e+02 2.95576111e+02 4.11653198e+02 9.96366501e+01\n",
      " 7.08878250e+01 1.87854614e+03 6.85244446e+01 1.98127502e+02\n",
      " 7.62837677e+01 2.86894417e+01 7.59920597e+00 7.42560434e+00\n",
      " 1.71567650e+01 1.81168766e+01 3.37766724e+01 1.77648270e+02\n",
      " 1.46919418e+02 8.56244469e+00 3.39295349e+01 6.30481100e+00\n",
      " 2.11523843e+00 3.89448639e+02 1.02041454e+01 8.73313808e+00\n",
      " 1.02619495e+01 1.59408783e+02 8.30368118e+01 5.45073738e+01\n",
      " 4.04790421e+01 9.09903259e+01 2.17609921e+01 5.73352146e+00\n",
      " 5.46151562e+03 4.36791748e+02 7.50943565e+00 3.78064880e+01\n",
      " 1.11767149e+01 2.65231293e+02 5.94259024e+00 7.73913956e+01\n",
      " 1.49599350e+02 5.48700684e+02 1.83347321e+01 8.80048370e+00\n",
      " 1.39058502e+02 3.51329956e+01 1.69848442e+01 3.03797874e+01\n",
      " 3.04460382e+00 1.07750008e+02 1.16878653e+01 1.30481949e+02\n",
      " 2.31947968e+02 2.07045221e+00 2.51335697e+01 1.96454248e+03\n",
      " 2.22968435e+00 1.48209442e+02 8.50782013e+01 5.95747461e+03\n",
      " 1.03129253e+01 1.41623328e+03 7.10322189e+00 4.91303539e+00\n",
      " 2.23231010e+01 2.07045410e+02 6.63727760e+00 3.13408241e+01\n",
      " 4.29293671e+01 1.02952480e+01 6.36131287e+00 7.53015900e+01\n",
      " 6.34549866e+02 1.00469093e+02 1.23850693e+02 3.54695034e+00\n",
      " 2.43856964e+01 6.77022076e+00 4.24501709e+02 7.35672760e+01\n",
      " 3.08295803e+01 1.17929077e+01 9.56485748e+00 9.20614319e+01\n",
      " 2.15245679e+03 7.29935547e+02 5.92475098e+03 2.55703545e+00\n",
      " 3.21409225e+01 1.41241531e+02 1.27976669e+02 7.98155670e+01\n",
      " 1.06609909e+02 1.01028351e+02 1.11667938e+01 2.96728287e+01\n",
      " 2.76497326e+01 1.34108410e+01 2.25536489e+00 2.75700073e+01\n",
      " 8.18857117e+01 6.73330994e+01 9.41180725e+02 1.90116005e+01\n",
      " 6.82557011e+00 1.27704782e+01 2.02362854e+03 1.94246323e+02\n",
      " 1.64567146e+01 8.34998550e+01 2.71920853e+01 3.12595520e+01\n",
      " 1.68879614e+03 2.23365135e+01 5.47753479e+02 2.25899372e+01\n",
      " 2.64616165e+01 3.39665909e+01 8.45762253e+00 3.52445831e+01\n",
      " 3.16856781e+02 7.92440081e+00 1.20562851e+02 8.20811768e+01\n",
      " 2.11071730e+00 5.03044605e+00 4.55147886e+00 8.92104340e+01\n",
      " 1.72171860e+02 5.16973686e+01 1.09511871e+02 1.92053003e+03\n",
      " 1.91163666e+02 4.02475769e+02 5.00521851e+00 8.42028999e+00\n",
      " 8.38643555e+02 2.65934563e+01 4.32929688e+01 3.83901062e+02\n",
      " 5.65514832e+01 1.50200302e+02 1.89194000e+02 6.15590897e+01\n",
      " 2.83293772e+00 3.51248765e+00 6.21682215e+00 6.38713112e+01\n",
      " 1.20133850e+02 5.26949644e+00 1.30646881e+02 2.62291794e+01\n",
      " 6.32575111e+01 9.92288132e+01 1.40446758e+01 6.11750671e+02\n",
      " 1.12159225e+02 8.40510330e+01 4.92198639e+01 1.88596436e+02\n",
      " 9.09584717e+02 2.51876755e+01 4.56409424e+02 5.93696070e+00\n",
      " 1.73417683e+01 1.07480888e+01 1.05968542e+01 3.46505396e+03\n",
      " 6.87959061e+01 5.16700268e+00 6.27932978e+00 8.49649334e+00\n",
      " 4.24798492e+02 5.04710693e+01 1.27126587e+02 1.68773529e+02\n",
      " 3.72452888e+01 3.00733161e+00 3.89877281e+01 9.15416260e+01\n",
      " 9.68470001e+00 2.49890289e+02 4.97391907e+02 2.23586777e+02\n",
      " 6.58881073e+01 2.65496979e+01 2.52409836e+02 1.49317078e+02\n",
      " 3.84167328e+01 6.43712769e+01 3.73886871e+00 5.74178123e+00\n",
      " 4.03278275e+01 3.61162500e+03 1.58155746e+01 1.55970752e+03\n",
      " 3.29878662e+02 4.43176041e+01 1.94553089e+01 1.16987534e+02\n",
      " 4.51891022e+01 3.81335716e+01 4.02170288e+02 1.39932739e+03\n",
      " 6.68743420e+00 1.57492533e+01 3.78050756e+00 6.54851227e+01\n",
      " 9.39454880e+01 1.79437733e+01 2.10625946e+02 4.35000381e+01\n",
      " 9.22408447e+01 9.40211258e+01 9.34587669e+00 1.00339500e+02\n",
      " 3.17856789e+01 2.28512268e+01 7.33904877e+01 2.45757217e+01\n",
      " 3.41318207e+01 1.84741650e+01 1.63582260e+02 1.74194717e+01\n",
      " 1.89373853e+03 1.58010773e+02 3.81830673e+01 5.13100624e+00\n",
      " 7.63482819e+01 1.59322113e+02 9.07333984e+01 1.26869031e+03\n",
      " 1.28567905e+01 8.16185188e+00 9.02787781e+01 6.76266708e+01\n",
      " 2.60345123e+02 2.58246429e+02 1.75536148e+02 3.20351990e+02\n",
      " 8.18884430e+01 7.48751020e+00 1.40523281e+01 5.21092911e+01\n",
      " 4.04149048e+02 8.15442688e+02 1.04898987e+02 6.25865269e+00\n",
      " 9.75596237e+01 1.92028942e+01 1.00273145e+03 2.30048714e+01\n",
      " 8.62174454e+01 3.79525261e+01 7.45470703e+02 3.67649536e+01\n",
      " 2.58959312e+01 2.29876175e+01 1.70933380e+02 3.63443359e+03\n",
      " 3.92030273e+02 1.51606491e+02 1.33118164e+02 6.58076239e+00\n",
      " 7.57097351e+02 5.79179993e+01 1.08075790e+01 6.82406769e+01\n",
      " 1.76786346e+01 1.93796069e+03 2.45590615e+00 4.41082497e+01\n",
      " 1.85793629e+01 3.29272095e+02 1.71299515e+01 6.31990242e+00\n",
      " 6.98394775e+01 1.50303925e+02 2.78216133e+01 3.72967377e+02\n",
      " 1.03285084e+01 2.45210205e+02 3.72413208e+02 1.70106735e+01\n",
      " 5.99153564e+02 9.12062550e+00 1.63136169e+02 3.49073863e+00\n",
      " 1.30491095e+01 2.10377712e+01 3.74130554e+01 1.58273438e+02\n",
      " 1.46689014e+01 4.97806854e+01 9.80255432e+01 3.35414368e+02\n",
      " 2.81602802e+01 4.85125046e+01 4.28565369e+01 7.04801941e+01\n",
      " 1.78432465e+00 5.19391298e+00 1.06330249e+03 8.94070312e+02\n",
      " 6.63654785e+01 3.74065628e+01 8.97365494e+01 9.32102112e+02\n",
      " 2.02920822e+02 5.00635242e+00 1.17285252e+01 1.30732841e+01\n",
      " 2.56781250e+02 2.20336246e+01 3.77901367e+02 1.69678345e+01\n",
      " 5.46014465e+02 1.43264206e+02 8.41384277e+01 1.13068896e+03\n",
      " 3.32583008e+02 8.25465851e+01 1.50593929e+01 5.54610303e+03\n",
      " 2.53085693e+02 1.94414612e+02 2.14760468e+02 6.51034393e+01\n",
      " 9.78404427e+00 2.70413494e+00 1.53152563e+03 6.94427919e+00\n",
      " 2.69344597e+01 4.99395981e+01 5.90705750e+02 4.08326025e+03\n",
      " 5.21989746e+01 4.94625664e+00 2.63126144e+01 1.84905908e+03\n",
      " 7.07013893e+00 4.04407349e+01 1.48096724e+01 3.88515615e+00\n",
      " 7.28680878e+01 3.17421188e+01 1.04828911e+01 2.42302551e+02\n",
      " 5.27565861e+00 9.85608768e+00 6.16752663e+01 2.91594452e+02\n",
      " 2.98139557e+02 3.68057892e+02 3.05148163e+01 1.03564224e+02\n",
      " 3.04496880e+01 3.49961967e+01 2.89635611e+00 8.17882568e+02\n",
      " 3.57291527e+01 5.68327942e+01 3.47658730e+01 4.18644409e+02\n",
      " 4.11292458e+00 2.12403687e+02 4.81405258e+01 1.15791807e+01\n",
      " 4.36733856e+01 1.88156033e+01 6.62994814e+00 8.87614136e+02\n",
      " 2.80481781e+02 6.01839066e+01 1.11887720e+03 9.24622250e+00\n",
      " 6.74507629e+02 2.19062004e+01 2.59575024e+03 3.13389587e+02\n",
      " 4.96791363e+00 5.44343662e+00 8.32147675e+01 1.44513403e+03\n",
      " 2.57580811e+02 1.25845547e+01 2.09565010e+01 7.74163147e+02\n",
      " 6.57862625e+01 5.25233459e+02 3.08696804e+01 8.57597256e+00\n",
      " 2.89155083e+01 9.44107742e+01 2.14498806e+00 1.04255298e+03\n",
      " 1.14890396e+02 1.25376883e+01 3.84731817e+00 4.08354340e+02\n",
      " 1.39916344e+01 1.14454031e+01 3.74467373e+00 2.09964466e+00\n",
      " 1.36870966e+01 8.01859436e+01 5.19604445e+00 3.14437819e+00\n",
      " 5.27217913e+00 3.84052696e+01 3.72479935e+01 3.74808846e+01\n",
      " 1.72958923e+02 2.76162529e+00 2.80450684e+02 4.82740692e+02\n",
      " 9.15580673e+01 2.39974632e+01 6.10758018e+01 5.89679623e+00\n",
      " 1.49656387e+02 1.31142456e+02 6.49395905e+01 4.16510963e+01\n",
      " 3.17879734e+01 2.88861866e+01 7.25062561e+00 3.74018860e+00]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0693\n",
      "  1% : 0.175\n",
      "  10% : 0.544\n",
      "  50% : 4.35\n",
      "  90% : 54.2\n",
      "  99% : 341\n",
      "  100% : 745\n",
      "<chi^2/d.o.f.> = 2.86\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n"
     ]
    }
   ],
   "source": [
    "print('Saving covariance components for small subset of test dataset ...')\n",
    "# Fix random seed (same subset every run)\n",
    "np.random.seed(3)\n",
    "idx = np.arange(d_test.size)\n",
    "np.random.shuffle(idx)\n",
    "idx = idx[:1000]\n",
    "d_comp = d_test[idx]\n",
    "io_comp = get_inputs_outputs(\n",
    "    d_comp,\n",
    "    pretrained_model=nn_model,\n",
    "    recalc_reddening=True,\n",
    "    return_cov_components=True\n",
    ")\n",
    "fname = 'predictions_{:s}_{:d}hidden_it{:d}_comp.h5'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "save_predictions(fname, nn_model, d_comp, io_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bf3ec27-6103-4713-9c21-1222e68e39f1",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data and reddening estimates of subset of test dataset ...\n"
     ]
    }
   ],
   "source": [
    "print('Saving data and reddening estimates of subset of test dataset ...')\n",
    "np.random.seed(5)\n",
    "idx = np.arange(d_test.size)\n",
    "np.random.shuffle(idx)\n",
    "idx = idx[:10000]\n",
    "d_small = d_test[idx]\n",
    "r_fit_small = io_test['r'][idx]\n",
    "r_var_small = io_test['r_var'][idx]\n",
    "fname = 'test_data_small_{:s}_{:d}hidden.h5'.format(\n",
    "    nn_name, n_hidden\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82da0ebc-697f-4f8b-ae07-05ba4f0e7217",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving subset to test_data_small_ext_0h_l1n2_2hidden.h5 ...\n"
     ]
    }
   ],
   "source": [
    "print(f'Saving subset to {fname} ...')\n",
    "with h5py.File(fname, 'w') as f:\n",
    "    dset = f.create_dataset(\n",
    "        'data',\n",
    "        data=d_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )\n",
    "    for key in d_attrs:\n",
    "        dset.attrs[key] = d_attrs[key]\n",
    "\n",
    "    # Store updated reddening estimates\n",
    "    dset = f.create_dataset(\n",
    "        'r_fit',\n",
    "        data=r_fit_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )\n",
    "    dset = f.create_dataset(\n",
    "        'r_var',\n",
    "        data=r_var_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 2,
      "defaultCellHeight": 40,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
