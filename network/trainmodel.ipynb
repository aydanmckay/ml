{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b43db49-f88d-44af-8188-9c546a2bb2e1",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "source": [
    "Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12337364-915d-45e0-aa68-ff9ad349e998",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "# # Tell Tensorflow not to allocate all GPU memory right away.\n",
    "# # This is very important in shared environments!\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU') \n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from glob import glob\n",
    "from time import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b0b4d-d609-4535-82f4-76f5979bb893",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### The dataloder used by Green+2020 which will be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f39968a5-1090-448f-a6dc-b53829db1f41",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(fname, return_attrs=False):\n",
    "    print(f'Loading {fname} ...')\n",
    "    attrs = {}\n",
    "    with h5py.File(fname, 'r') as f:\n",
    "        dset = f['io_data']\n",
    "        for key in dset.attrs.keys():\n",
    "            attrs[key] = dset.attrs[key]\n",
    "        d = dset[:]\n",
    "    \n",
    "    if return_attrs:\n",
    "        return d, attrs\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a7c2e5-f232-46ff-b235-d6604c1b5d35",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Obtaining a correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e0eccc-4ffd-4904-a210-7b430692c477",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_corr_matrix(cov):\n",
    "    rho = cov.copy()\n",
    "    sqrt_cov_diag = np.sqrt(cov[np.diag_indices(cov.shape[0])])\n",
    "    rho /= sqrt_cov_diag[:,None]\n",
    "    rho /= sqrt_cov_diag[None,:]\n",
    "    rho[np.diag_indices(cov.shape[0])] = sqrt_cov_diag\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f2ec3-9dba-4970-ab73-494dddd61534",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Cannot be explained in one markdown cell above, need to look through it more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72257ca9-2c06-4d52-9589-9b9086876356",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_inputs_outputs(d, pretrained_model=None,\n",
    "                          recalc_reddening=False,\n",
    "                          rchisq_max=None,\n",
    "                          return_cov_components=False):\n",
    "    n_bands = 13 # Gaia (G, BP, RP), PS1 (grizy), 2MASS (JHK), unWISE (W1,W2)\n",
    "    n_atm_params = 3 # (T_eff, logg, [M/H])\n",
    "    \n",
    "    large_err = 999.\n",
    "\n",
    "    # Stellar spectroscopic parameters\n",
    "    print('Fill in stellar atmospheric parameters ...')\n",
    "    x = np.empty((d.size,3), dtype='f4')\n",
    "    x[:] = d['atm_param'][:]\n",
    "\n",
    "    x_p = np.empty((d.size,3), dtype='f4')\n",
    "    x_p = d['atm_param_p'][:]\n",
    "\n",
    "    # Magnitudes\n",
    "    print('Fill in stellar magnitudes ...')\n",
    "    y = np.empty((d.size,n_bands), dtype='f4')\n",
    "    y[:] = d['mag'][:]\n",
    "\n",
    "    # Covariance of y\n",
    "    print('Empty covariance matrix ...')\n",
    "    cov_y = np.zeros((d.size,n_bands,n_bands), dtype='f4')\n",
    "\n",
    "    # \\delta m\n",
    "    print('Covariance: \\delta m ...')\n",
    "    for i in range(n_bands):\n",
    "        cov_y[:,i,i] = d['mag_err'][:,i]**2\n",
    "\n",
    "    # Replace NaN magnitudes with median (in each band).\n",
    "    # Also set corresponding variances to large number.\n",
    "    print('Replace NaN magnitudes ...')\n",
    "    for b in range(n_bands):\n",
    "        idx = (\n",
    "              ~np.isfinite(y[:,b])\n",
    "            | ~np.isfinite(cov_y[:,b,b])\n",
    "        )\n",
    "        n_bad = np.count_nonzero(idx)\n",
    "        n_tot = idx.size\n",
    "        y0 = np.median(y[~idx,b])\n",
    "        if np.isnan(y0):\n",
    "            y0 = 0.\n",
    "        print(f'Band {b}: {n_bad} of {n_tot} bad. Replacing with {y0:.5f}.')\n",
    "        y[idx,b] = y0\n",
    "        cov_y[idx,b,b] = large_err**2.\n",
    "\n",
    "    # Transform both y and its covariance\n",
    "    B = np.identity(n_bands, dtype='f4')\n",
    "    B[1:,0] = -1.\n",
    "    \n",
    "    print('Transform y -> B y ...')\n",
    "    y = np.einsum('ij,nj->ni', B, y) # y' = B y\n",
    "    print('Transform C -> B C B^T ...')\n",
    "    #cov_y = np.einsum('ik,nkl,jl->nij', B, cov_y, B) # C' = B C B^T\n",
    "    cov_y = np.einsum('nik,jk->nij', cov_y, B)\n",
    "    cov_y = np.einsum('ik,nkj->nij', B, cov_y)\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp = {\n",
    "            'delta_m': cov_y.copy()\n",
    "        }\n",
    "    \n",
    "    # Add in dM/dtheta and dR/dtheta terms\n",
    "    if pretrained_model is not None:\n",
    "        print('Calculate J = dM/dtheta ...')\n",
    "        J_M = calc_dmag_color_dtheta(pretrained_model, x_p)\n",
    "        cov_x = d['atm_param_cov_p']\n",
    "        print('Covariance: J C_theta J^T ...')\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_M)\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['dM/dtheta'] = np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_M)\n",
    "\n",
    "    # If pretrained model provided, could calculate reduced chi^2\n",
    "    # with maximum-likelihood (mu, E) here.\n",
    "\n",
    "    # \\delta \\mu (must be added in after transformation,\n",
    "    #             due to possibly infinite terms).\n",
    "    print('{:d} NaN parallaxes'.format(\n",
    "        np.count_nonzero(np.isnan(d['parallax']))\n",
    "    ))\n",
    "    err_over_plx = d['parallax_err'] / d['parallax']\n",
    "    print('Covariance: DM uncertainty term ...')\n",
    "    cov_y[:,0,0] += (5./np.log(10.) * err_over_plx)**2.\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp['dm'] = np.zeros_like(cov_y)\n",
    "        cov_comp['dm'][:,0,0] = (5./np.log(10.) * err_over_plx)**2.\n",
    "\n",
    "    # Subtract distance modulus from m_G\n",
    "    #dm = -5. * (np.log10(d['parallax']) - 2.)\n",
    "    #dm_corr = 0.5 * err_over_plx**2 + 0.75 * err_over_plx**4\n",
    "    #dm_corr_pct = np.percentile(dm_corr, [1., 5., 10., 50., 90., 95., 99.])\n",
    "    #print(dm_corr_pct)\n",
    "\n",
    "    print('Estimate DM ...')\n",
    "    dm = 10. - 5.*np.log10(d['parallax'])# + 5./np.log(10.)*dm_corr\n",
    "    y[:,0] -= dm\n",
    "\n",
    "    # Don't attempt to predict M_G for poor plx/err or when plx < 0\n",
    "    print('Filter out M_G for poor parallax measurements ...')\n",
    "    idx = (\n",
    "          (err_over_plx > 0.2)\n",
    "        | (d['parallax'] < 1.e-8)\n",
    "        | ~np.isfinite(d['parallax'])\n",
    "        | ~np.isfinite(d['parallax_err'])\n",
    "    )\n",
    "    n_use = idx.size - np.count_nonzero(idx)\n",
    "    print(r'Using {:d} of {:d} ({:.3f}%) of stellar parallaxes.'.format(\n",
    "        n_use, idx.size, n_use/idx.size*100.\n",
    "    ))\n",
    "    cov_y[idx,0,0] = large_err**2\n",
    "    y[idx,0] = np.nanmedian(y[:,0])\n",
    "    \n",
    "    if return_cov_components:\n",
    "        cov_comp['dm'][idx,0,0] = large_err**2\n",
    "\n",
    "    # Reddenings\n",
    "    print('Copy reddenings ...')\n",
    "    r = np.empty((d.size,), dtype='f4')\n",
    "    r[:] = d['r'][:]\n",
    "    \n",
    "    if pretrained_model is None:\n",
    "        # If R has not yet been estimated, then\n",
    "        # cut out stars with sigma_r > 0.2 mag.\n",
    "        idx = (d['r_err'] > 0.2)\n",
    "        print(f'Cutting {np.count_nonzero(idx)} stars with large sigma_r.')\n",
    "        for k in range(cov_y.shape[1]):\n",
    "            cov_y[idx,k,k] += large_err**2\n",
    "\n",
    "    if pretrained_model is not None:\n",
    "        # Update reddenings, based on vector R and (y_obs - y_pred).\n",
    "        # Use provided reddenings as a prior.\n",
    "\n",
    "        # First, need to calculate inv_cov_y\n",
    "        print('Invert C_y matrices ...')\n",
    "        inv_cov_y = np.stack([np.linalg.inv(c) for c in cov_y])\n",
    "\n",
    "        # Predict M & R for each star based on atm. params\n",
    "        M_pred = predict_M(pretrained_model, x_p)\n",
    "        R = predict_R(pretrained_model, x_p)\n",
    "        \n",
    "        r_var = d['r_err']**2\n",
    "        \n",
    "        # Calculate posterior on reddening\n",
    "        if recalc_reddening:\n",
    "            print('Calculate posterior on reddening ...')\n",
    "            r_pred, r_var = update_reddenings(\n",
    "                M_pred, R, y,\n",
    "                inv_cov_y,\n",
    "                r, r_var\n",
    "            )\n",
    "            \n",
    "            # Clip mean and variance of reddenings\n",
    "            print('Clip reddenings and reddening variances ...')\n",
    "            r[:] = np.clip(r_pred, 0., 10.) # TODO: Update upper limit?\n",
    "        \n",
    "        # TODO: Different lower bounds on error for different sources?\n",
    "        r_var[:] = np.clip(r_var, 0.02**2 + (0.1*r)**2, 10.**2)\n",
    "        \n",
    "        # Reddening uncertainty term in covariance of y\n",
    "        print('Covariance: reddening uncertainty term ...')\n",
    "        cov_y += r_var[:,None,None] * R[:,:,None]*R[:,None,:]\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['r'] = r_var[:,None,None] * R[:,:,None]*R[:,None,:]\n",
    "        \n",
    "        # Propagate uncertainty in theta to uncertainty in R\n",
    "        print('Calculate J = dA/dtheta ...')\n",
    "        J_A = calc_dext_red_dtheta(pretrained_model, x_p, r)\n",
    "        cov_x = d['atm_param_cov_p']\n",
    "        print('Covariance: J C_theta J^T ...')\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_A)\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_A)\n",
    "        cov_y += np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_M)\n",
    "        \n",
    "        if return_cov_components:\n",
    "            cov_comp['dA/dtheta'] = np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_A)\n",
    "            cov_comp['dMA/dtheta'] = np.einsum('nik,nkl,njl->nij', J_M, cov_x, J_A)\n",
    "            cov_comp['dAM/dtheta'] = np.einsum('nik,nkl,njl->nij', J_A, cov_x, J_M)\n",
    "        \n",
    "        # Calculate chi^2 for each star\n",
    "        chisq = calc_chisq(M_pred+r[:,None]*R-y, inv_cov_y)\n",
    "        print('chisq =', chisq)\n",
    "\n",
    "        # Calculate d.o.f. of each star\n",
    "        print('Calculate d.o.f. of each star ...')\n",
    "        n_dof = np.zeros(d.size, dtype='i4')\n",
    "        for k in range(n_bands):\n",
    "            n_dof += (cov_y[:,k,k] < (large_err-1.)**2).astype('i4')\n",
    "        #print('n_dof =', n_dof)\n",
    "\n",
    "        # Calculate reduced chi^2 for each star\n",
    "        print('Calculate chi^2/d.o.f. for each star ...')\n",
    "        rchisq = chisq / (n_dof - 1.)\n",
    "        pct = (0., 1., 10., 50., 90., 99., 100.)\n",
    "        rchisq_pct = np.percentile(rchisq[np.isfinite(rchisq)], pct)\n",
    "        print('chi^2/dof percentiles:')\n",
    "        for p,rc in zip(pct,rchisq_pct):\n",
    "            print(rf'  {p:.0f}% : {rc:.3g}')\n",
    "        idx_rchisq = (rchisq < 10.)\n",
    "        print(f'<chi^2/d.o.f.> = {np.mean(rchisq[idx_rchisq]):.3g}')\n",
    "        \n",
    "        # Filter on reduced chi^2\n",
    "        if rchisq_max is not None:\n",
    "            print('Filter on chi^2/d.o.f. ...')\n",
    "            idx = np.isfinite(rchisq) & (rchisq > 0.) & (rchisq < rchisq_max)\n",
    "            n_filt = np.count_nonzero(~idx)\n",
    "            pct_filt = 100. * n_filt / idx.size\n",
    "            print(\n",
    "                rf'Filtering {n_filt:d} stars ({pct_filt:.3g}%) ' +\n",
    "                rf'based on chi^2/dof > {rchisq_max:.1f}'\n",
    "            )\n",
    "            x = x[idx]\n",
    "            x_p = x_p[idx]\n",
    "            r = r[idx]\n",
    "            y = y[idx]\n",
    "            cov_y = cov_y[idx]\n",
    "            r_var = r_var[idx]\n",
    "            rchisq = rchisq[idx]\n",
    "            \n",
    "            if return_cov_components:\n",
    "                for key in cov_comp:\n",
    "                    cov_comp[key] = cov_comp[key][idx]\n",
    "\n",
    "    # Cholesky transform of inverse covariance: L L^T = C^(-1).\n",
    "    print('Cholesky transform of each stellar covariance matrix ...')\n",
    "    LT = np.empty_like(cov_y)\n",
    "    inv_cov_y = np.empty_like(cov_y)\n",
    "    for k,c in enumerate(cov_y):\n",
    "        try:\n",
    "            # Inflate diagonal of cov slightly, to ensure\n",
    "            # positive-definiteness\n",
    "            c_diag = c[np.diag_indices_from(c)]\n",
    "            c[np.diag_indices_from(c)] += 1.e-4 + 1.e-3 * c_diag\n",
    "            \n",
    "            inv_cov_y[k] = np.linalg.inv(c)\n",
    "            LT[k] = np.linalg.cholesky(inv_cov_y[k]).T\n",
    "            #ic = np.linalg.inv(c)\n",
    "            #LT.append(np.linalg.cholesky(ic).T)\n",
    "            #inv_cov_y.append(ic)\n",
    "        except np.linalg.LinAlgError as e:\n",
    "            rho = get_corr_matrix(c)\n",
    "            print('Offending correlation matrix:')\n",
    "            print(np.array2string(\n",
    "                rho[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >7.4f}'.format(z)}\n",
    "            ))\n",
    "            print('Offending covariance matrix:')\n",
    "            print(np.array2string(\n",
    "                c[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >9.6f}'.format(z)}\n",
    "            ))\n",
    "            print('Covariance matrix of (normed) atmospheric parameters:')\n",
    "            print(d['atm_param_cov_p'][k])\n",
    "            if pretrained_model is not None:\n",
    "                print(f'Variance of r: {r_var[k]:.8f}')\n",
    "            \n",
    "            # Inflate errors along the diagonal and try again\n",
    "            c_diag = c[np.diag_indices_from(c)]\n",
    "            c[np.diag_indices_from(c)] += 0.02 + 0.02 * c_diag\n",
    "            rho = get_corr_matrix(c)\n",
    "            print('Inflated correlation matrix:')\n",
    "            print(np.array2string(\n",
    "                rho[:6,:6],\n",
    "                formatter={'float_kind':lambda z:'{: >7.4f}'.format(z)}\n",
    "            ))\n",
    "            \n",
    "            inv_cov_y[k] = np.linalg.inv(c)\n",
    "            LT[k] = np.linalg.cholesky(inv_cov_y[k]).T\n",
    "            #raise e\n",
    "\n",
    "    #print('Stack L^T matrices ...')\n",
    "    #LT = np.stack(LT)\n",
    "    #print('Stack C^(-1) matrices ...')\n",
    "    #inv_cov_y = np.stack(inv_cov_y)\n",
    "\n",
    "    # L^T y\n",
    "    print('Calculate L^T y ...')\n",
    "    LTy = np.einsum('nij,nj->ni', LT, y)\n",
    "\n",
    "    print('Gather inputs and outputs and return ...')\n",
    "    inputs_outputs = {\n",
    "        'x':x, 'x_p':x_p, 'r':r, 'y':y,\n",
    "        'LT':LT, 'LTy':LTy,\n",
    "        'cov_y':cov_y, 'inv_cov_y':inv_cov_y,\n",
    "    }\n",
    "    \n",
    "    if return_cov_components:\n",
    "        inputs_outputs['cov_comp'] = cov_comp\n",
    "    \n",
    "    if pretrained_model is not None:\n",
    "        inputs_outputs['r_var'] = r_var\n",
    "        inputs_outputs['rchisq'] = rchisq\n",
    "\n",
    "    # Check that there are no NaNs or Infs in results\n",
    "    for key in inputs_outputs:\n",
    "        if isinstance(inputs_outputs[key], dict):\n",
    "            continue\n",
    "        if key == 'rchisq': # Infs appear when d.o.f. = 1\n",
    "            continue\n",
    "        if np.any(~np.isfinite(inputs_outputs[key])):\n",
    "            raise ValueError(f'NaNs or Infs detected in {key}.')\n",
    "\n",
    "    return inputs_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caad35d-51ad-4e5f-8e27-57ac56e80468",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Predicts the absolute magnitude in the Gaia G-band and the colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb5329ec-4d17-4a14-9ec3-936b60844ca9",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_M(nn_model, x_p):\n",
    "    \"\"\"\n",
    "    Predicts (absmag0,color1,color2,...) for input\n",
    "    normalized stellar parameters.\n",
    "\n",
    "    Inputs:\n",
    "        nn_model (keras.Model): Neural network model.\n",
    "        x_p (np.ndarray): Normalized stellar parameters.\n",
    "            Shape = (n_stars, 3).\n",
    "    \n",
    "    Outputs:\n",
    "        M (np.ndarray): Shape = (n_stars, n_bands).\n",
    "    \"\"\"\n",
    "    inputs = nn_model.get_layer(name='theta').input\n",
    "    outputs = nn_model.get_layer(name='BM').output\n",
    "    mag_color_model = keras.Model(inputs, outputs)\n",
    "    M = mag_color_model.predict(x_p)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14482c31-4986-4451-b4f7-295c2b3530b0",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Predicting the redenning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b36fc92-d995-4531-a1e4-994b63a9a954",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_R(nn_model, x_p=None):\n",
    "    inputs = nn_model.get_layer(name='theta').input\n",
    "    outputs = nn_model.get_layer(name='R').output\n",
    "    R_model = keras.Model(inputs, outputs)\n",
    "    if x_p is None:\n",
    "        R = R_model.predict(np.array([[0.,0.,0.]]))[0]\n",
    "        R[1:] -= R[0]\n",
    "    else:\n",
    "        R = R_model.predict(x_p)\n",
    "        R[:,1:] -= R[:,0][:,None]\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2cab63-a66c-4c34-a7f1-50cb9568337b",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Saving the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52ee4e30-e866-45c2-a60f-37f5d8996b9f",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_predictions(fname, nn_model, d_test, io_test):\n",
    "    M_pred = predict_M(nn_model, io_test['x_p'])\n",
    "    R_pred = predict_R(nn_model, io_test['x_p'])\n",
    "    R0 = predict_R(nn_model)\n",
    "    \n",
    "    with h5py.File(fname, 'w') as f:\n",
    "        f.create_dataset('/data', data=d_test, chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/y_obs', data=io_test['y'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/cov_y', data=io_test['cov_y'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/r_fit', data=io_test['r'], chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/M_pred', data=M_pred, chunks=True,\n",
    "                         compression='gzip', compression_opts=3)\n",
    "        f.create_dataset('/R_pred', data=R_pred, chunks=True,\n",
    "                        compression='gzip', compression_opts=3)\n",
    "        f.attrs['R0'] = R0\n",
    "        \n",
    "        if 'cov_comp' in io_test:\n",
    "            for key in io_test['cov_comp']:\n",
    "                f.create_dataset(\n",
    "                    f'/cov_comp/{key.replace(r\"/\",\"_\")}',\n",
    "                    data=io_test['cov_comp'][key],\n",
    "                    chunks=True,\n",
    "                    compression='gzip',\n",
    "                    compression_opts=3\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9dbfb5-0fa8-47b6-b59e-5507d8182916",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Updates the redenning, as in the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12ce532d-8584-46ea-b538-a65837b35597",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_reddenings(M_pred, R, y_obs, inv_cov_y, r0, r_var0):\n",
    "    \"\"\"\n",
    "    Updates the posterior on reddening of each star, given\n",
    "    the predicted absolute magnitudes, reddening vector,\n",
    "    observed magnitudes, inverse covariance matrix, and priors on\n",
    "    reddening.\n",
    "    \n",
    "    The model is given by\n",
    "    \n",
    "        y_obs = M_pred + R r,\n",
    "    \n",
    "    with the uncertainties in y_obs described by inv_cov_y, and\n",
    "    with a prior on r described by (r0, r_var0). We solve for\n",
    "    the Gaussian posterior on r: p(r|y_obs,M_pred,R,r0,r_var0).\n",
    "    \n",
    "    Let n = # of bands, k = # of stars.\n",
    "\n",
    "    Inputs:\n",
    "        M_pred (np.ndarray): Shape-(k,n) array containing predicted\n",
    "            zero-reddening asbolute magnitude & colors for each star.\n",
    "        R (np.ndarray): Shape-(k,n) array containing reddening vector\n",
    "            for each star.\n",
    "        inv_cov_y (np.ndarray): Shape-(k,n,n) array containing\n",
    "            covariance matrix of y_obs-y_pred for each star.\n",
    "        y_obs (np.ndarray): Shape-(k,n) array containing observed\n",
    "            magnitude (minus distance modulus) & colors for each star.\n",
    "        r0 (np.ndarray): Shape-(k,) array containing mean of prior on\n",
    "            reddening for each star.\n",
    "        r_var0 (np.ndarray): Shape-(k,) array containing variance of\n",
    "            prior on reddening for each star.\n",
    "\n",
    "    Outputs:\n",
    "        r_mean (np.ndarray): Shape-(k,) array containing mean posterior\n",
    "            reddening of each star.\n",
    "        r_var (np.ndarray): Shape-(k,) array containing variance of\n",
    "            reddening posterior for each star.\n",
    "    \"\"\"\n",
    "    print('Updating reddenings:')\n",
    "    print('  * R^T C_y^(-1) ...')\n",
    "    RT_Cinv = np.einsum('ni,nij->nj', R, inv_cov_y)\n",
    "    print('  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...')\n",
    "    num = r0/r_var0 + np.einsum('ni,ni->n', RT_Cinv, y_obs - M_pred)\n",
    "    print('  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...')\n",
    "    den = np.einsum('ni,ni->n', RT_Cinv, R) + 1./r_var0\n",
    "    print('  * r_mean, r_var ...')\n",
    "    r_mean = num / den\n",
    "    r_var = 1. / den\n",
    "\n",
    "    return r_mean, r_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d6a72-37ab-4d7a-bfb3-cd329804a9ca",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### calculates the chi^2, as in docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c76cf577-6ee4-41db-a3ea-bada40e97afb",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_chisq(dy, inv_cov_y):\n",
    "    \"\"\"\n",
    "    Returns the chi^2 for each observation, given\n",
    "    an array of residuals and inverse covariance matrices.\n",
    "    \n",
    "        chi^2 = dy^T C^{-1} dy.\n",
    "    \n",
    "    Inputs:\n",
    "        dy (np.ndarray): Residual values. Shape = (n_obs, n_dim),\n",
    "            where n_obs is the number of observations, and n_dim is\n",
    "            the dimensionality of the vector space.\n",
    "        inv_cov_y (np.ndarray): Inverse covariance matrices.\n",
    "            Shape = (n_obs, n_dim, n_dim).\n",
    "    \n",
    "    Returns:\n",
    "        chisq (np.ndarray): Chi^2 for each observation. Shape=(n_obs,).\n",
    "    \"\"\"\n",
    "    C_inv_dy = np.einsum('nij,nj->ni', inv_cov_y, dy)\n",
    "    chisq = np.einsum('ni,ni->n', dy, C_inv_dy)\n",
    "    return chisq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50c262-4e28-419e-83d5-8b75ec32470b",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Creates the architecture of the NN as described in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45204db0-8dfb-448f-879b-11102036d543",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_nn_model(n_hidden_layers=1, hidden_size=32, l1=1.e0, l2=1.e-4, n_bands=13):\n",
    "    # Stellar model: B M(theta)\n",
    "    atm = keras.Input(shape=(3,), name='theta')\n",
    "    x = atm\n",
    "    for i in range(n_hidden_layers):\n",
    "        x = keras.layers.Dense(\n",
    "            hidden_size,\n",
    "            activation='sigmoid',\n",
    "            # kernel_regularizer=keras.regularizers.l2(l=l2),\n",
    "            kernel_regularizer=keras.regularizers.l1(l=l1),\n",
    "            name=f'stellar_model_hidden_{i+1}'\n",
    "        )(x)\n",
    "    mag_color = keras.layers.Dense(n_bands, name='BM')(x)\n",
    "\n",
    "    # Reddening measurement E\n",
    "    red = keras.Input(shape=(1,), name='E')\n",
    "    \n",
    "    # Extinction vector: R(theta)\n",
    "    r = atm\n",
    "    #for i in range(n_hidden_layers):\n",
    "    #    r = keras.layers.Dense(\n",
    "    #        6,\n",
    "    #        use_bias=True,\n",
    "    #        activation='sigmoid',\n",
    "    #        kernel_regularizer=keras.regularizers.l2(l=l2),\n",
    "    #        name=f'extinction_model_hidden_{i+1}'\n",
    "    #    )(r)\n",
    "    ext_vec = keras.layers.Dense(\n",
    "        n_bands,\n",
    "        use_bias=True,\n",
    "        activation='exponential',\n",
    "        #kernel_regularizer=keras.regularizers.l1_l2(l1=1.e0, l2=1.e0),\n",
    "        kernel_regularizer=keras.regularizers.l1(l=l1),\n",
    "        name='R'\n",
    "    )(r)\n",
    "    \n",
    "    # Extinction A = ER\n",
    "    ext = keras.layers.Multiply(name='A')([red, ext_vec])\n",
    "    \n",
    "    # Transform extinction to extinction,reddening using B: BA\n",
    "    B = np.identity(n_bands, dtype='f4')\n",
    "    B[1:,0] = -1.\n",
    "    ext_red = keras.layers.Dense(\n",
    "        n_bands,\n",
    "        use_bias=False,\n",
    "        trainable=False,\n",
    "        weights=[B.T],\n",
    "        name='BA'\n",
    "    )(ext)\n",
    "\n",
    "    # Predicted mag,color, B(M+A)\n",
    "    y = keras.layers.Add(name='B_M_plus_A')([mag_color, ext_red])\n",
    "\n",
    "    # Cholesky decomposition of inverse covariance matrix, L L^T = C^(-1)\n",
    "    LT = keras.Input(shape=(n_bands,n_bands), name='LT')\n",
    "\n",
    "    # Multiply y_pred by L^T, since loss is given by |L^T (y_pred - y_obs)|^2,\n",
    "    # where y_pred = B(M+A), and y_obs = B(m-mu).\n",
    "    LTy = keras.layers.Dot((2,1), name='LT_B_M_plus_A')([LT, y])\n",
    "\n",
    "    # Compile model\n",
    "    model = keras.Model(\n",
    "        inputs=[atm,red,LT],\n",
    "        outputs=LTy,\n",
    "        name='stellar_photometry_model'\n",
    "    )\n",
    "    model.compile(\n",
    "        # loss='mse',\n",
    "        loss='mae',\n",
    "        optimizer='Adam',\n",
    "        # metrics=['mse']\n",
    "        metrics=['mae']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c98052-09ff-4591-830a-446eedd1c701",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### splits the dataset according to a fraction selected by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f096cf60-242d-4eef-8d91-59430a2672dc",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_dataset(frac, *args):\n",
    "    assert len(args) != 0\n",
    "\n",
    "    n_tot = args[0].shape[0]\n",
    "    idx = np.arange(n_tot)\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    n = int(frac * n_tot)\n",
    "    idx_left = idx[:n]\n",
    "    idx_right = idx[n:]\n",
    "\n",
    "    left, right = [], []\n",
    "\n",
    "    for x in args:\n",
    "        left.append(x[idx_left])\n",
    "        right.append(x[idx_right])\n",
    "    \n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a650c5-2ed5-4cfd-bd99-92ff0587e213",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7632b11-b152-4bbf-833b-53c16c38e4c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "class PlotLearning(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback to plot the learning curves of the model during training.\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.metrics = {}\n",
    "        for metric in logs:\n",
    "            self.metrics[metric] = []\n",
    "            \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Storing metrics\n",
    "        for metric in logs:\n",
    "            if metric in self.metrics:\n",
    "                self.metrics[metric].append(logs.get(metric))\n",
    "            else:\n",
    "                self.metrics[metric] = [logs.get(metric)]\n",
    "        \n",
    "        # Plotting\n",
    "        metrics = [x for x in logs if 'val' not in x]\n",
    "        \n",
    "        f, axs = plt.subplots(1, len(metrics), figsize=(15,5))\n",
    "        # clear_output(wait=True)\n",
    "\n",
    "        for i, metric in enumerate(metrics):\n",
    "            axs[i].plot(range(1, epoch + 2), \n",
    "                        self.metrics[metric], \n",
    "                        label=metric)\n",
    "            if logs['val_' + metric]:\n",
    "                axs[i].plot(range(1, epoch + 2), \n",
    "                            self.metrics['val_' + metric], \n",
    "                            label='val_' + metric)\n",
    "                \n",
    "            axs[i].legend()\n",
    "            axs[i].grid()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d4f6eac-a9dd-4e9d-9d27-f9995997b7a2",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(nn_model, io_train, k, n_iterations, epochs=100,\n",
    "                checkpoint_fn='checkpoint', batch_size=32,\n",
    "                suff='_'):\n",
    "    checkpoint_fn = (\n",
    "          'checkpoints/'\n",
    "        + checkpoint_fn\n",
    "        + '.e{epoch:03d}_vl{val_loss:.3f}.h5'\n",
    "    )\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_fn,\n",
    "            save_best_only=True,\n",
    "            monitor='val_loss',\n",
    "            verbose=1\n",
    "        )#, PlotLearning()\n",
    "    ]\n",
    "    inputs = [io_train['x_p'], io_train['r'], io_train['LT']]\n",
    "    outputs = io_train['LTy']\n",
    "    nn_model.fit(\n",
    "        inputs, outputs,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.25/0.9,\n",
    "        callbacks=callbacks,\n",
    "        batch_size=batch_size,\n",
    "        verbose=True\n",
    "    )\n",
    "    plt.title('Loss: Iteration {} of {}.'.format(k+1, n_iterations))\n",
    "    plt.plot(range(1,epochs+1),nn_model.history.history['loss'],label='loss')\n",
    "    plt.plot(range(1,epochs+1),nn_model.history.history['val_loss'],label='val_loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig('/arc/home/aydanmckay/networkplots/train_val_loss'+suff+'.svg', dpi=150)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d76b11-59a7-41ca-a531-13411c1a6ce9",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### tests and makes sure the loss is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7eb14a0f-a62d-4d46-ab6d-4b33476566da",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(nn_model, io_eval, batch_size=32, rchisq_max=None):\n",
    "    \"\"\"\n",
    "    Runs the model on the given inputs and outputs, and returns the\n",
    "    MSE and loss.\n",
    "    \n",
    "    Inputs:\n",
    "        nn_model (keras.Model): The neural network model.\n",
    "        io_eval (dict): A dictionary containing, among other things,\n",
    "            x_p, r, LT and LTy. If rchisq_max is provided, then the\n",
    "            dictionary must also contain rchisq.\n",
    "        batch_size (int): Defaults to 32.\n",
    "        rchisq_max (float): Stars with greater than this reduced chi^2\n",
    "            will not be included in the calculation. Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "        A list containing the MSE and loss.\n",
    "    \"\"\"\n",
    "    inputs = [io_eval['x_p'], io_eval['r'], io_eval['LT']]\n",
    "    outputs = io_eval['LTy']\n",
    "    \n",
    "    if rchisq_max is not None:\n",
    "        idx = (io_eval['rchisq'] < rchisq_max)\n",
    "        inputs = [x[idx] for x in inputs]\n",
    "        outputs = outputs[idx]\n",
    "    \n",
    "    loss = nn_model.evaluate(\n",
    "        inputs,\n",
    "        outputs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    loss = [float(x) for x in loss] # Make JSON serializable\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd030e3e-55e6-419d-9a07-ce0a6baeb62c",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### plots? follow up here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d65e396c-7677-41d8-b229-8c3b2377a7b6",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def diagnostic_plots(nn_model, io_test, d_test, suffix=None):\n",
    "    if suffix is None:\n",
    "        suff = ''\n",
    "    else:\n",
    "        suff = '_' + suffix\n",
    "    \n",
    "    inputs = [\n",
    "        nn_model.get_layer(name='theta').input,\n",
    "        nn_model.get_layer(name='E').input\n",
    "    ]\n",
    "    outputs = nn_model.get_layer(name='B_M_plus_A').output\n",
    "    absmag_model = keras.Model(inputs, outputs)\n",
    "\n",
    "    # Predict y for the test dataset\n",
    "    test_pred = {\n",
    "        'y': absmag_model.predict([\n",
    "            io_test['x_p'],\n",
    "            io_test['r']\n",
    "        ]),\n",
    "        'y_dered': absmag_model.predict([\n",
    "            io_test['x_p'],\n",
    "            np.zeros_like(io_test['r'])\n",
    "        ])\n",
    "    }\n",
    "    test_pred['y_resid'] = io_test['y'] - test_pred['y']\n",
    "\n",
    "    # Get the extinction vector\n",
    "    R = predict_R(nn_model)\n",
    "    R[1:] += R[0]\n",
    "    print(\n",
    "          'R(<theta>) = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,R)))\n",
    "        + ']'\n",
    "    )\n",
    "    R_all = predict_R(nn_model, io_test['x_p'])\n",
    "    R_all[:,1:] += R_all[:,0][:,None]\n",
    "    print(\n",
    "          '<R> = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,np.median(R_all,axis=0))))\n",
    "        + ']'\n",
    "    )\n",
    "    print(\n",
    "          's_R = ['\n",
    "        + ' '.join(list(map('{:.3f}'.format,np.std(R_all,axis=0))))\n",
    "        + ']'\n",
    "    )\n",
    "\n",
    "    # Read out colors, magnitudes\n",
    "    g = io_test['y'][:,3] + io_test['y'][:,0]\n",
    "    ri = io_test['y'][:,4] - io_test['y'][:,5]\n",
    "    gr = io_test['y'][:,3] - io_test['y'][:,4]\n",
    "    g_pred = test_pred['y'][:,3] + test_pred['y'][:,0]\n",
    "    ri_pred = test_pred['y'][:,4] - test_pred['y'][:,5]\n",
    "    gr_pred = test_pred['y'][:,3] - test_pred['y'][:,4]\n",
    "    g_pred_dered = test_pred['y_dered'][:,3] + test_pred['y_dered'][:,0]\n",
    "    ri_pred_dered = test_pred['y_dered'][:,4] - test_pred['y_dered'][:,5]\n",
    "    gr_pred_dered = test_pred['y_dered'][:,3] - test_pred['y_dered'][:,4]\n",
    "    A_g = 0.25 * R[3]\n",
    "    E_ri = 0.25 * (R[4] - R[5])\n",
    "    E_gr = 0.25 * (R[3] - R[4])\n",
    "\n",
    "    gaia_g = io_test['y'][:,0]\n",
    "    bp_rp = io_test['y'][:,1] - io_test['y'][:,2]\n",
    "    gaia_g_pred = test_pred['y'][:,0]\n",
    "    bp_rp_pred = test_pred['y'][:,1] - test_pred['y'][:,2]\n",
    "    gaia_g_pred_dered = test_pred['y_dered'][:,0]\n",
    "    gaia_bp_rp_pred_dered = test_pred['y_dered'][:,1] - test_pred['y_dered'][:,2]\n",
    "    A_gaia_g = 0.25 * R[0]\n",
    "    E_bp_rp = 0.25 * (R[1] - R[2])\n",
    "\n",
    "    print('g =', g)\n",
    "    print('ri =', ri)\n",
    "    print('gr =', gr)\n",
    "    print('gaia_g =', gaia_g)\n",
    "    print('bp_rp =', bp_rp)\n",
    "\n",
    "    # Plot HRD\n",
    "    params = {\n",
    "        'density': (None, r'$N$', (None, None)),\n",
    "        'teff': (d_test['atm_param'][:,0], r'$T_{\\mathrm{eff}}$', (4000., 8000.)),\n",
    "        'logg': (d_test['atm_param'][:,1], r'$\\log \\left( g \\right)$', (0., 5.)),\n",
    "        'mh': (d_test['atm_param'][:,2], r'$\\left[ \\mathrm{M} / \\mathrm{H} \\right]$', (-2.5, 0.5))\n",
    "    }\n",
    "\n",
    "    plot_spec = [\n",
    "        {\n",
    "            'colors': [(1,2), (4,5)],\n",
    "            'mag': 0\n",
    "        },\n",
    "        {\n",
    "            'colors': [(3,4), (4,5)],\n",
    "            'mag': 0\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    idx_goodobs = np.isfinite(d_test['mag_err'])\n",
    "    idx_goodobs &= (np.abs(io_test['cov_y'][:,0,0]) < 90.)[:,None]\n",
    "    idx_goodobs = idx_goodobs.T\n",
    "\n",
    "    def scatter_or_hexbin(ax, x, y, c, vmin, vmax, extent):\n",
    "        if p == 'density':\n",
    "            im = ax.hexbin(\n",
    "                x, y,\n",
    "                extent=extent,\n",
    "                bins='log',\n",
    "                rasterized=True\n",
    "            )\n",
    "        else:\n",
    "            im = ax.scatter(\n",
    "                x,\n",
    "                y,\n",
    "                c=c,\n",
    "                edgecolors='none',\n",
    "                alpha=0.1,\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "                rasterized=True\n",
    "            )\n",
    "        return im\n",
    "\n",
    "    def get_lim(*args, **kwargs):\n",
    "        expand = kwargs.get('expand', 0.4)\n",
    "        expand_low = kwargs.get('expand_low', expand)\n",
    "        expand_high = kwargs.get('expand_high', expand)\n",
    "        pct = kwargs.get('pct', 1.)\n",
    "        lim = [np.inf, -np.inf]\n",
    "        for a in args:\n",
    "            a0,a1 = np.nanpercentile(a, [pct, 100.-pct])\n",
    "            lim[0] = min(a0, lim[0])\n",
    "            lim[1] = max(a1, lim[1])\n",
    "        w = lim[1] - lim[0]\n",
    "        lim[0] -= expand_low * w\n",
    "        lim[1] += expand_high * w\n",
    "        return lim\n",
    "\n",
    "    labels = ['G', 'BP', 'RP', 'g', 'r', 'i', 'z', 'y']\n",
    "\n",
    "    for ps in plot_spec:\n",
    "        mag_label = r'$M_{{ {} }}$'.format(labels[ps['mag']])\n",
    "        mag_obs = io_test['y'][:,ps['mag']]\n",
    "        mag_pred = test_pred['y'][:,ps['mag']]\n",
    "        mag_pred_dered = test_pred['y_dered'][:,ps['mag']]\n",
    "        A_vec = 0.25 * R[ps['mag']]\n",
    "        print('mag_pred:',mag_pred)\n",
    "\n",
    "        if ps['mag'] != 0:\n",
    "            mag_obs += io_test['y'][:,0]\n",
    "            mag_pred += io_test['y'][:,0]\n",
    "            mag_pred_dered += io_test['y'][:,0]\n",
    "            A_vec += 0.25 * R[0]\n",
    "\n",
    "        color_labels = []\n",
    "        colors_obs = []\n",
    "        colors_pred = []\n",
    "        colors_pred_dered = []\n",
    "        idx_colors_obs = []\n",
    "        E_vec = []\n",
    "        for i1,i2 in ps['colors']:\n",
    "            color_labels.append(r'${} - {}$'.format(labels[i1], labels[i2]))\n",
    "            colors_obs.append(io_test['y'][:,i1] - io_test['y'][:,i2])\n",
    "            colors_pred.append(test_pred['y'][:,i1] - test_pred['y'][:,i2])\n",
    "            colors_pred_dered.append(\n",
    "                test_pred['y_dered'][:,i1] - test_pred['y_dered'][:,i2]\n",
    "            )\n",
    "            idx_colors_obs.append(idx_goodobs[i1] & idx_goodobs[i2])\n",
    "            E_vec.append(0.25 * (R[i1] - R[i2]))\n",
    "\n",
    "        mag_lim = get_lim(\n",
    "            mag_obs[idx_goodobs[ps['mag']]],\n",
    "            pct=2.\n",
    "        )[::-1]\n",
    "        color_lim = [\n",
    "            get_lim(c[idx_colors_obs[k]], expand_low=0.5, expand_high=0.4)\n",
    "            for k,c in enumerate(colors_obs)\n",
    "        ]\n",
    "        \n",
    "        for p in params.keys():\n",
    "            c, label, (vmin,vmax) = params[p]\n",
    "            \n",
    "            fig = plt.figure(figsize=(14,4.5), dpi=150)\n",
    "            fig.patch.set_alpha(0.)\n",
    "            gs = GridSpec(\n",
    "                1,4,\n",
    "                width_ratios=[1,1,1,0.1],\n",
    "                left=0.07, right=0.93,\n",
    "                bottom=0.10, top=0.92\n",
    "            )\n",
    "            ax_obs = fig.add_subplot(gs[0,0], facecolor='gray')\n",
    "            ax_pred = fig.add_subplot(gs[0,1], facecolor='gray')\n",
    "            ax_dered = fig.add_subplot(gs[0,2], facecolor='gray')\n",
    "            cax = fig.add_subplot(gs[0,3], facecolor='w')\n",
    "\n",
    "            extent = color_lim[0] + mag_lim\n",
    "\n",
    "            idx = (\n",
    "                  idx_goodobs[ps['mag']]\n",
    "                & idx_goodobs[ps['colors'][0][0]]\n",
    "                & idx_goodobs[ps['colors'][0][1]]\n",
    "            )\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_obs,\n",
    "                colors_obs[0][idx],\n",
    "                mag_obs[idx],\n",
    "                c if c is None else c[idx],\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "                #(-0.3,1.0,11.5,-2.0)\n",
    "            )\n",
    "\n",
    "            ax_obs.set_xlim(color_lim[0])\n",
    "            ax_obs.set_ylim(mag_lim)\n",
    "            ax_obs.set_xlabel(color_labels[0])\n",
    "            ax_obs.set_ylabel(mag_label)\n",
    "            ax_obs.grid('on', alpha=0.3)\n",
    "            ax_obs.set_title(r'$\\mathrm{Observed}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_pred,\n",
    "                colors_pred[0],\n",
    "                mag_pred,\n",
    "                c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "\n",
    "            ax_pred.set_xlim(color_lim[0])\n",
    "            ax_pred.set_ylim(mag_lim)\n",
    "            ax_pred.set_xlabel(color_labels[0])\n",
    "            ax_pred.grid('on', alpha=0.3)\n",
    "            ax_pred.set_title(r'$\\mathrm{Predicted}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_dered,\n",
    "                colors_pred_dered[0],\n",
    "                mag_pred_dered,\n",
    "                c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "\n",
    "            ax_dered.set_xlim(color_lim[0])\n",
    "            ax_dered.set_ylim(mag_lim)\n",
    "            ax_dered.set_xlabel(color_labels[0])\n",
    "            ax_dered.grid('on', alpha=0.3)\n",
    "            ax_dered.set_title(r'$\\mathrm{Predicted+Dereddened}$')\n",
    "\n",
    "            ax_dered.annotate(\n",
    "                '',\n",
    "                xy=(0.35+E_vec[0], 1.+A_vec),\n",
    "                xytext=(0.35, 1.),\n",
    "                arrowprops=dict(color='r', width=1., headwidth=5., headlength=5.)\n",
    "            )\n",
    "\n",
    "            cb = fig.colorbar(im, cax=cax)\n",
    "            cb.set_label(label)\n",
    "            cb.set_alpha(1.)\n",
    "            cb.draw_all()\n",
    "\n",
    "            cm_desc = '{}_vs_{}{}'.format(\n",
    "                labels[ps['mag']],\n",
    "                labels[ps['colors'][0][0]],\n",
    "                labels[ps['colors'][0][1]]\n",
    "            )\n",
    "            fig.savefig(\n",
    "                '/arc/home/aydanmckay/networkplots/nn_predictions_'+cm_desc+'_'+p+suff+'.svg',\n",
    "                dpi=150,\n",
    "                facecolor=fig.get_facecolor(),\n",
    "                edgecolor='none'\n",
    "            )\n",
    "            plt.close(fig)\n",
    "\n",
    "            # Color-color diagrams\n",
    "            fig = plt.figure(figsize=(14,4.5), dpi=150)\n",
    "            fig.patch.set_alpha(0.)\n",
    "            gs = GridSpec(\n",
    "                1,4,\n",
    "                width_ratios=[1,1,1,0.1],\n",
    "                left=0.07, right=0.93,\n",
    "                bottom=0.10, top=0.92\n",
    "            )\n",
    "            ax_obs = fig.add_subplot(gs[0,0], facecolor='gray')\n",
    "            ax_pred = fig.add_subplot(gs[0,1], facecolor='gray')\n",
    "            ax_dered = fig.add_subplot(gs[0,2], facecolor='gray')\n",
    "            cax = fig.add_subplot(gs[0,3], facecolor='w')\n",
    "\n",
    "            extent = color_lim[0] + color_lim[1]\n",
    "\n",
    "            idx = (\n",
    "                  idx_goodobs[ps['colors'][0][0]]\n",
    "                & idx_goodobs[ps['colors'][0][1]]\n",
    "                & idx_goodobs[ps['colors'][1][0]]\n",
    "                & idx_goodobs[ps['colors'][1][1]]\n",
    "            )\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_obs,\n",
    "                colors_obs[0][idx],\n",
    "                colors_obs[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "                #(-0.2,1.5,-0.15,0.8)\n",
    "            )\n",
    "            ax_obs.set_xlim(color_lim[0])\n",
    "            ax_obs.set_ylim(color_lim[1])\n",
    "            ax_obs.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_obs.set_ylabel(color_labels[1], fontsize=14)\n",
    "            ax_obs.grid('on', alpha=0.3)\n",
    "            ax_obs.set_title(r'$\\mathrm{Observed}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_pred,\n",
    "                colors_pred[0][idx],\n",
    "                colors_pred[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                #c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "            ax_pred.set_xlim(color_lim[0])\n",
    "            ax_pred.set_ylim(color_lim[1])\n",
    "            ax_pred.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_pred.grid('on', alpha=0.3)\n",
    "            ax_pred.set_title(r'$\\mathrm{Predicted}$')\n",
    "\n",
    "            im = scatter_or_hexbin(\n",
    "                ax_dered,\n",
    "                colors_pred_dered[0][idx],\n",
    "                colors_pred_dered[1][idx],\n",
    "                c if c is None else c[idx],\n",
    "                #c,\n",
    "                vmin, vmax,\n",
    "                extent\n",
    "            )\n",
    "            ax_dered.set_xlim(color_lim[0])\n",
    "            ax_dered.set_ylim(color_lim[1])\n",
    "            ax_dered.set_xlabel(color_labels[0], fontsize=14)\n",
    "            ax_dered.grid('on', alpha=0.3)\n",
    "            ax_dered.set_title(r'$\\mathrm{Predicted+Dereddened}$')\n",
    "\n",
    "            ax_dered.annotate(\n",
    "                '',\n",
    "                xy=(0.4+E_vec[0], 0.3+E_vec[1]),\n",
    "                xytext=(0.4, 0.3),\n",
    "                arrowprops=dict(color='r', width=1., headwidth=5., headlength=5.)\n",
    "            )\n",
    "\n",
    "            cb = fig.colorbar(im, cax=cax)\n",
    "            cb.set_label(label, fontsize=14)\n",
    "            cb.set_alpha(1.)\n",
    "            cb.draw_all()\n",
    "\n",
    "            cc_desc = '{}{}_vs_{}{}'.format(\n",
    "                labels[ps['colors'][0][0]],\n",
    "                labels[ps['colors'][0][1]],\n",
    "                labels[ps['colors'][1][0]],\n",
    "                labels[ps['colors'][1][1]]\n",
    "            )\n",
    "            fig.savefig(\n",
    "                '/arc/home/aydanmckay/networkplots/test_'+cc_desc+'_'+p+suff+'.svg',\n",
    "                dpi=150,\n",
    "                facecolor=fig.get_facecolor(),\n",
    "                edgecolor='none'\n",
    "            )\n",
    "            plt.close(fig)\n",
    "    \n",
    "    # Plot histograms of residuals\n",
    "    dr = (io_test['r'] - d_test['r'])/np.hypot(np.nanstd(d_test['r']),.01)\n",
    "    # dmag = (io_test['LTy'] - d_test['mag'])\n",
    "    # dm1,dm2,dm3,dm4,dm5,dm6,dm7,dm8,dm9,dm10,dm11,dm12,dm13 = dmag.T\n",
    "    names = ['G','(BP-G)','(RP-G)','(g-G)','(r-G)','(i-G)','(z-G)','(y-G)','(J-G)','(H-G)','(K_s-G)','(W_1-G)','(W_2-G)']\n",
    "    # ds = [dm1,dm2,dm3,dm4,dm5,dm6,dm7,dm8,dm9,dm10,dm11,dm12,dm13]\n",
    "    fig = plt.figure(figsize=(12,18))\n",
    "    ax = fig.add_subplot(5,3,1)\n",
    "    dr_mean = np.nanmean(dr)\n",
    "    dr_std = np.nanstd(dr)\n",
    "    ax.hist(dr, bins=50)\n",
    "    dr_skew = scipy.stats.moment(dr, moment=3, nan_policy='omit')\n",
    "    dr_txt = r'$\\Delta E = {:+.3f} \\pm {:.3f}$'.format(dr_mean, dr_std)\n",
    "    dr_skew /= (dr_std**1.5 + 1.e-5)\n",
    "    dr_txt += '\\n' + r'$\\tilde{{\\mu}}_3 = {:+.3f}$'.format(dr_skew)\n",
    "    ax.text(0.05, 0.95, dr_txt, ha='left', va='top', transform=ax.transAxes)\n",
    "    ax.set_xlabel(r'$\\Delta E \\ \\left( \\mathrm{estimated} - \\mathrm{Bayestar19} \\right)$',fontsize=10)\n",
    "    for it,(io,dm,name) in enumerate(zip(io_test['LTy'].T,d_test['mag'].T,names)):\n",
    "        dd = (io - dm)/np.hypot(np.nanstd(dm),.01)\n",
    "        ax = fig.add_subplot(5,3,it+2)\n",
    "        dd_mean = np.nanmean(dd)\n",
    "        dd_std = np.nanstd(dd)\n",
    "        ax.hist(dd, bins=50)\n",
    "        dd_skew = scipy.stats.moment(dd, moment=3, nan_policy='omit')\n",
    "        dd_txt = r'$\\Delta '+name+r' = {:+.3f} \\pm {:.3f}$'.format(dd_mean, dd_std)\n",
    "        dd_skew /= (dd_std**1.5 + 1.e-5)\n",
    "        dd_txt += '\\n' + r'$\\tilde{{\\mu}}_3 = {:+.3f}$'.format(dd_skew)\n",
    "        ax.text(0.05, 0.95, dd_txt, ha='left', va='top', transform=ax.transAxes)\n",
    "        ax.set_xlabel(r'$\\Delta '+name+r'\\ \\left( \\mathrm{estimated} - \\mathrm{observed} \\right)$',fontsize=10)\n",
    "    fig.savefig('/arc/home/aydanmckay/networkplots/test_z-score_dE'+suff+'.svg', dpi=150)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc50d23-d49f-4732-87e4-a7e1ec8fc816",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "source": [
    "##### Calculates the derivative of the stellar model portion for gradient descent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8c296da-d523-4953-87b3-738be2e038fe",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_dmag_color_dtheta(nn_model, x_p):\n",
    "    m = keras.Model(\n",
    "        inputs=nn_model.get_layer(name='theta').input,\n",
    "        outputs=nn_model.get_layer(name='BM').output\n",
    "    )\n",
    "    with tf.GradientTape() as g:\n",
    "        x_p = tf.constant(x_p)\n",
    "        g.watch(x_p)\n",
    "        mag_color = m(x_p)\n",
    "    J = g.batch_jacobian(mag_color, x_p).numpy()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb05c4c2-5d82-4311-b6f2-b46532797a41",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Calculates the derivative of the extinction model portion for gradient descent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2af63500-d06a-4ba6-bcc1-5fd5c3df6247",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_dext_red_dtheta(nn_model, x_p, r):\n",
    "    A_model = keras.Model(\n",
    "        inputs=[\n",
    "            nn_model.get_layer(name='theta').input,\n",
    "            nn_model.get_layer(name='E').input\n",
    "        ],\n",
    "        outputs=nn_model.get_layer(name='BA').output\n",
    "    )\n",
    "    r = tf.constant(np.reshape(r, (r.size,1)))\n",
    "    #r = tf.reshape(r, (tf.size(r), 1))\n",
    "    with tf.GradientTape() as g:\n",
    "        x_p = tf.constant(x_p)\n",
    "        g.watch(x_p)\n",
    "        A = A_model([x_p, r])\n",
    "    J = g.batch_jacobian(A, x_p).numpy()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fb7f2c-5df5-4b99-aae0-39035aa43797",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### Saves the normalizations, which seen in the tutorial is useful for scaling and shifting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86cef280-6cca-48f4-93ce-a8f4b7336300",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_theta_norm(d_attrs, fname):\n",
    "    d = {\n",
    "        'theta_med': d_attrs['atm_param_med'].tolist(),\n",
    "        'theta_std': d_attrs['atm_param_std'].tolist()\n",
    "    }\n",
    "    with open(fname, 'w') as f:\n",
    "        json.dump(d, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab8ecb-d1c9-438d-8794-1ff0b7eceef3",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "##### start of main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b834ddb7-6836-4e26-b7d7-81ce6cf146fd",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"stellar_photometry_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " theta (InputLayer)             [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " stellar_model_hidden_1 (Dense)  (None, 32)          128         ['theta[0][0]']                  \n",
      "                                                                                                  \n",
      " E (InputLayer)                 [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " R (Dense)                      (None, 13)           52          ['theta[0][0]']                  \n",
      "                                                                                                  \n",
      " stellar_model_hidden_2 (Dense)  (None, 32)          1056        ['stellar_model_hidden_1[0][0]'] \n",
      "                                                                                                  \n",
      " A (Multiply)                   (None, 13)           0           ['E[0][0]',                      \n",
      "                                                                  'R[0][0]']                      \n",
      "                                                                                                  \n",
      " BM (Dense)                     (None, 13)           429         ['stellar_model_hidden_2[0][0]'] \n",
      "                                                                                                  \n",
      " BA (Dense)                     (None, 13)           169         ['A[0][0]']                      \n",
      "                                                                                                  \n",
      " LT (InputLayer)                [(None, 13, 13)]     0           []                               \n",
      "                                                                                                  \n",
      " B_M_plus_A (Add)               (None, 13)           0           ['BM[0][0]',                     \n",
      "                                                                  'BA[0][0]']                     \n",
      "                                                                                                  \n",
      " LT_B_M_plus_A (Dot)            (None, 13)           0           ['LT[0][0]',                     \n",
      "                                                                  'B_M_plus_A[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,834\n",
      "Trainable params: 1,665\n",
      "Non-trainable params: 169\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load/create neural network\n",
    "nn_name = 'ext_2h_l1mae_lr01-002_mb256_l1n2'\n",
    "n_hidden = 2\n",
    "nn_model = get_nn_model(n_hidden_layers=n_hidden, l2=1.e-4, l1=1.e-2)\n",
    "#nn_model = keras.models.load_model(\n",
    "#    'models/{:s}_{:d}hidden_it14.h5'.format(nn_name, n_hidden)\n",
    "#)\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07e4514b-44a8-4a5c-8512-e7feaa15e94e",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Loading /arc/home/aydanmckay/ml/network/datav2.h5 ...\n"
     ]
    }
   ],
   "source": [
    "# Load stellar data\n",
    "print('Loading data ...')\n",
    "fname = '/arc/home/aydanmckay/ml/network/datasets/datav2.h5'\n",
    "d, d_attrs = load_data(fname, return_attrs=True)\n",
    "#d = d[::25]\n",
    "save_theta_norm(d_attrs, 'thetanorms/2_theta_normalization.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d54baa9f-60d9-4fc0-acb7-e4c49cd83a66",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    253053 training/validation stars.\n",
      "     28118 test stars.\n"
     ]
    }
   ],
   "source": [
    "# (training+validation) / test split\n",
    "# Fix random seed (same split every run)\n",
    "np.random.seed(7)\n",
    "(d_train,), (d_test,) = split_dataset(0.9, d)\n",
    "np.random.shuffle(d_train) # Want d_train to be in random order\n",
    "print(f'{d_train.size: >10d} training/validation stars.')\n",
    "print(f'{d_test.size: >10d} test stars.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa8b04a6-3b93-4b72-9d3f-8855c3111e8c",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi^2/dof = [None, 100.00000000000004, 79.41833348134496, 63.07271692954115, 50.09130066684769, 39.78167620874025, 31.593944275926187, 25.091384024965357, 19.927159040031896, 15.825817619770502, 12.56860061341878, 9.981773149103292, 7.927357886906197, 6.295775522882865, 4.999999999999999, 5.0, 5.0, 5.0, 5.0, 5.0]\n"
     ]
    }
   ],
   "source": [
    "# Iteratively update dM/dtheta contribution to uncertainties,\n",
    "# reddening estimates and reduced chi^2 cut, and retrain.\n",
    "n_iterations = 20\n",
    "\n",
    "# On GPU, use large batch sizes for memory transfer efficiency\n",
    "# batch_size = 1024\n",
    "batch_size = 256\n",
    "\n",
    "rchisq_max_init = 100.\n",
    "rchisq_max_final = 5.\n",
    "rchisq_max = np.exp(np.linspace(\n",
    "    np.log(rchisq_max_init),\n",
    "    np.log(rchisq_max_final),\n",
    "    n_iterations-6\n",
    "))\n",
    "rchisq_max = [None] + rchisq_max.tolist() + 5*[rchisq_max_final]\n",
    "print('chi^2/dof = {}'.format(rchisq_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3ee798-6cee-458d-b5e3-e6f014c0c873",
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Cutting 0 stars with large sigma_r.\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Cutting 0 stars with large sigma_r.\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 35.30 s\n",
      "learning rate = 0.0010000000474974513\n",
      "setting learning rate to 0.01\n",
      "Iteration 1 of 20.\n",
      "Epoch 1/25\n",
      "703/714 [============================>.] - ETA: 0s - loss: 3.8724 - mae: 3.0589\n",
      "Epoch 1: val_loss improved from inf to 2.69583, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it0.e001_vl2.696.h5\n",
      "714/714 [==============================] - 3s 3ms/step - loss: 3.8541 - mae: 3.0451 - val_loss: 2.6958 - val_mae: 2.1763\n",
      "Epoch 2/25\n",
      "711/714 [============================>.] - ETA: 0s - loss: 2.5689 - mae: 2.0935\n",
      "Epoch 2: val_loss improved from 2.69583 to 2.41798, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it0.e002_vl2.418.h5\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.5683 - mae: 2.0930 - val_loss: 2.4180 - val_mae: 1.9667\n",
      "Epoch 3/25\n",
      "713/714 [============================>.] - ETA: 0s - loss: 2.4053 - mae: 1.9874\n",
      "Epoch 3: val_loss improved from 2.41798 to 2.35947, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it0.e003_vl2.359.h5\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.4056 - mae: 1.9878 - val_loss: 2.3595 - val_mae: 1.9811\n",
      "Epoch 4/25\n",
      "700/714 [============================>.] - ETA: 0s - loss: 2.3264 - mae: 1.9756\n",
      "Epoch 4: val_loss improved from 2.35947 to 2.26672, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it0.e004_vl2.267.h5\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.3236 - mae: 1.9733 - val_loss: 2.2667 - val_mae: 1.9390\n",
      "Epoch 5/25\n",
      "708/714 [============================>.] - ETA: 0s - loss: 2.2700 - mae: 1.9539\n",
      "Epoch 5: val_loss did not improve from 2.26672\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.2695 - mae: 1.9535 - val_loss: 2.3202 - val_mae: 2.0129\n",
      "Epoch 6/25\n",
      "703/714 [============================>.] - ETA: 0s - loss: 2.2263 - mae: 1.9298\n",
      "Epoch 6: val_loss improved from 2.26672 to 2.18051, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it0.e006_vl2.181.h5\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.2268 - mae: 1.9305 - val_loss: 2.1805 - val_mae: 1.8958\n",
      "Epoch 7/25\n",
      "714/714 [==============================] - ETA: 0s - loss: 2.1997 - mae: 1.9209\n",
      "Epoch 7: val_loss improved from 2.18051 to 2.16100, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it0.e007_vl2.161.h5\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.1997 - mae: 1.9209 - val_loss: 2.1610 - val_mae: 1.8896\n",
      "Epoch 8/25\n",
      "713/714 [============================>.] - ETA: 0s - loss: 2.1782 - mae: 1.9128\n",
      "Epoch 8: val_loss improved from 2.16100 to 2.13255, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it0.e008_vl2.133.h5\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.1788 - mae: 1.9133 - val_loss: 2.1325 - val_mae: 1.8740\n",
      "Epoch 9/25\n",
      "713/714 [============================>.] - ETA: 0s - loss: 2.1589 - mae: 1.9047\n",
      "Epoch 9: val_loss did not improve from 2.13255\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.1591 - mae: 1.9049 - val_loss: 2.1497 - val_mae: 1.8978\n",
      "Epoch 10/25\n",
      "702/714 [============================>.] - ETA: 0s - loss: 2.1465 - mae: 1.9007\n",
      "Epoch 10: val_loss improved from 2.13255 to 2.11445, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it0.e010_vl2.114.h5\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.1455 - mae: 1.8998 - val_loss: 2.1145 - val_mae: 1.8751\n",
      "Epoch 11/25\n",
      "711/714 [============================>.] - ETA: 0s - loss: 2.1266 - mae: 1.8901\n",
      "Epoch 11: val_loss improved from 2.11445 to 2.10856, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it0.e011_vl2.109.h5\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.1273 - mae: 1.8908 - val_loss: 2.1086 - val_mae: 1.8771\n",
      "Epoch 12/25\n",
      "695/714 [============================>.] - ETA: 0s - loss: 2.1152 - mae: 1.8909\n",
      "Epoch 12: val_loss did not improve from 2.10856\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.1151 - mae: 1.8910 - val_loss: 2.1217 - val_mae: 1.9055\n",
      "Epoch 13/25\n",
      "701/714 [============================>.] - ETA: 0s - loss: 2.1029 - mae: 1.8936\n",
      "Epoch 13: val_loss improved from 2.10856 to 2.06691, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it0.e013_vl2.067.h5\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.1020 - mae: 1.8928 - val_loss: 2.0669 - val_mae: 1.8625\n",
      "Epoch 14/25\n",
      "701/714 [============================>.] - ETA: 0s - loss: 2.0841 - mae: 1.8812\n",
      "Epoch 14: val_loss did not improve from 2.06691\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.0853 - mae: 1.8824 - val_loss: 2.1258 - val_mae: 1.9227\n",
      "Epoch 15/25\n",
      "711/714 [============================>.] - ETA: 0s - loss: 2.0878 - mae: 1.8885\n",
      "Epoch 15: val_loss improved from 2.06691 to 2.05551, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it0.e015_vl2.056.h5\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.0876 - mae: 1.8883 - val_loss: 2.0555 - val_mae: 1.8592\n",
      "Epoch 16/25\n",
      "712/714 [============================>.] - ETA: 0s - loss: 2.0707 - mae: 1.8750\n",
      "Epoch 16: val_loss did not improve from 2.05551\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.0710 - mae: 1.8753 - val_loss: 2.0750 - val_mae: 1.8823\n",
      "Epoch 17/25\n",
      "694/714 [============================>.] - ETA: 0s - loss: 2.0694 - mae: 1.8759\n",
      "Epoch 17: val_loss did not improve from 2.05551\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.0696 - mae: 1.8761 - val_loss: 2.0759 - val_mae: 1.8834\n",
      "Epoch 18/25\n",
      "702/714 [============================>.] - ETA: 0s - loss: 2.0663 - mae: 1.8743\n",
      "Epoch 18: val_loss did not improve from 2.05551\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.0662 - mae: 1.8743 - val_loss: 2.0773 - val_mae: 1.8874\n",
      "Epoch 19/25\n",
      "711/714 [============================>.] - ETA: 0s - loss: 2.0676 - mae: 1.8778\n",
      "Epoch 19: val_loss did not improve from 2.05551\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.0677 - mae: 1.8779 - val_loss: 2.0640 - val_mae: 1.8768\n",
      "Epoch 20/25\n",
      "695/714 [============================>.] - ETA: 0s - loss: 2.0637 - mae: 1.8758\n",
      "Epoch 20: val_loss improved from 2.05551 to 2.04240, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it0.e020_vl2.042.h5\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.0628 - mae: 1.8749 - val_loss: 2.0424 - val_mae: 1.8569\n",
      "Epoch 21/25\n",
      "706/714 [============================>.] - ETA: 0s - loss: 2.0520 - mae: 1.8660\n",
      "Epoch 21: val_loss improved from 2.04240 to 2.04194, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it0.e021_vl2.042.h5\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.0521 - mae: 1.8661 - val_loss: 2.0419 - val_mae: 1.8569\n",
      "Epoch 22/25\n",
      "703/714 [============================>.] - ETA: 0s - loss: 2.0556 - mae: 1.8709\n",
      "Epoch 22: val_loss improved from 2.04194 to 2.03905, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it0.e022_vl2.039.h5\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.0558 - mae: 1.8712 - val_loss: 2.0390 - val_mae: 1.8546\n",
      "Epoch 23/25\n",
      "696/714 [============================>.] - ETA: 0s - loss: 2.0505 - mae: 1.8677\n",
      "Epoch 23: val_loss did not improve from 2.03905\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.0506 - mae: 1.8678 - val_loss: 2.0520 - val_mae: 1.8696\n",
      "Epoch 24/25\n",
      "698/714 [============================>.] - ETA: 0s - loss: 2.0526 - mae: 1.8713\n",
      "Epoch 24: val_loss did not improve from 2.03905\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.0528 - mae: 1.8714 - val_loss: 2.0531 - val_mae: 1.8717\n",
      "Epoch 25/25\n",
      "699/714 [============================>.] - ETA: 0s - loss: 2.0486 - mae: 1.8687\n",
      "Epoch 25: val_loss improved from 2.03905 to 2.02633, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it0.e025_vl2.026.h5\n",
      "714/714 [==============================] - 2s 3ms/step - loss: 2.0483 - mae: 1.8684 - val_loss: 2.0263 - val_mae: 1.8471\n",
      "Time elapsed to train: 54.15 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.380 3.037 1.690 3.357 2.393 1.783 1.316 1.050 0.723 0.470 0.328 0.237 0.199]\n",
      "<R> = [2.382 3.035 1.692 3.353 2.394 1.783 1.315 1.051 0.724 0.470 0.328 0.237 0.199]\n",
      "s_R = [0.046 0.044 0.033 0.079 0.027 0.013 0.013 0.007 0.003 0.002 0.001 0.001 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7883675 2.8644764 6.4981613 ... 2.3423154 4.1316223 4.5515566]\n",
      "mag_pred: [3.7883675 2.8644764 6.4981613 ... 2.3423154 4.1316223 4.5515566]\n",
      "Time elapsed to make plots: 19.31 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [30.784607  24.261715   9.378563  ...  2.7684278 37.742332   9.488201 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0138\n",
      "  1% : 0.131\n",
      "  10% : 0.257\n",
      "  50% : 0.631\n",
      "  90% : 3.29\n",
      "  99% : 90.4\n",
      "  100% : 7.37e+03\n",
      "<chi^2/d.o.f.> = 1.04\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 2369 stars (0.936%) based on chi^2/dof > 100.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.289699 31.955025 11.153788 ...  3.84654   5.620231 16.106003]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0307\n",
      "  1% : 0.13\n",
      "  10% : 0.257\n",
      "  50% : 0.634\n",
      "  90% : 3.14\n",
      "  99% : 94.8\n",
      "  100% : 5.21e+03\n",
      "<chi^2/d.o.f.> = 1.03\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 77.08 s\n",
      "learning rate = 0.009999999776482582\n",
      "setting learning rate to 0.009801986733067553\n",
      "Iteration 2 of 20.\n",
      "Epoch 1/25\n",
      "689/708 [============================>.] - ETA: 0s - loss: 0.7995 - mae: 0.6350\n",
      "Epoch 1: val_loss improved from inf to 0.79688, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it1.e001_vl0.797.h5\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7993 - mae: 0.6351 - val_loss: 0.7969 - val_mae: 0.6369\n",
      "Epoch 2/25\n",
      "687/708 [============================>.] - ETA: 0s - loss: 0.7879 - mae: 0.6305\n",
      "Epoch 2: val_loss improved from 0.79688 to 0.79154, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it1.e002_vl0.792.h5\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7879 - mae: 0.6307 - val_loss: 0.7915 - val_mae: 0.6366\n",
      "Epoch 3/25\n",
      "691/708 [============================>.] - ETA: 0s - loss: 0.7774 - mae: 0.6246\n",
      "Epoch 3: val_loss improved from 0.79154 to 0.79047, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it1.e003_vl0.790.h5\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7772 - mae: 0.6244 - val_loss: 0.7905 - val_mae: 0.6403\n",
      "Epoch 4/25\n",
      "692/708 [============================>.] - ETA: 0s - loss: 0.7739 - mae: 0.6262\n",
      "Epoch 4: val_loss improved from 0.79047 to 0.76718, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it1.e004_vl0.767.h5\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7738 - mae: 0.6262 - val_loss: 0.7672 - val_mae: 0.6217\n",
      "Epoch 5/25\n",
      "704/708 [============================>.] - ETA: 0s - loss: 0.7664 - mae: 0.6233\n",
      "Epoch 5: val_loss improved from 0.76718 to 0.75501, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it1.e005_vl0.755.h5\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7662 - mae: 0.6231 - val_loss: 0.7550 - val_mae: 0.6150\n",
      "Epoch 6/25\n",
      "695/708 [============================>.] - ETA: 0s - loss: 0.7639 - mae: 0.6280\n",
      "Epoch 6: val_loss improved from 0.75501 to 0.74658, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it1.e006_vl0.747.h5\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7636 - mae: 0.6279 - val_loss: 0.7466 - val_mae: 0.6156\n",
      "Epoch 7/25\n",
      "702/708 [============================>.] - ETA: 0s - loss: 0.7523 - mae: 0.6233\n",
      "Epoch 7: val_loss did not improve from 0.74658\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7522 - mae: 0.6232 - val_loss: 0.7662 - val_mae: 0.6392\n",
      "Epoch 8/25\n",
      "708/708 [==============================] - ETA: 0s - loss: 0.7556 - mae: 0.6297\n",
      "Epoch 8: val_loss did not improve from 0.74658\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7556 - mae: 0.6297 - val_loss: 0.7793 - val_mae: 0.6554\n",
      "Epoch 9/25\n",
      "702/708 [============================>.] - ETA: 0s - loss: 0.7473 - mae: 0.6250\n",
      "Epoch 9: val_loss improved from 0.74658 to 0.74401, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it1.e009_vl0.744.h5\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7474 - mae: 0.6252 - val_loss: 0.7440 - val_mae: 0.6225\n",
      "Epoch 10/25\n",
      "706/708 [============================>.] - ETA: 0s - loss: 0.7440 - mae: 0.6241\n",
      "Epoch 10: val_loss did not improve from 0.74401\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7441 - mae: 0.6242 - val_loss: 0.7677 - val_mae: 0.6496\n",
      "Epoch 11/25\n",
      "691/708 [============================>.] - ETA: 0s - loss: 0.7411 - mae: 0.6232\n",
      "Epoch 11: val_loss did not improve from 0.74401\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7411 - mae: 0.6232 - val_loss: 0.7475 - val_mae: 0.6302\n",
      "Epoch 12/25\n",
      "696/708 [============================>.] - ETA: 0s - loss: 0.7402 - mae: 0.6236\n",
      "Epoch 12: val_loss improved from 0.74401 to 0.73998, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it1.e012_vl0.740.h5\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7400 - mae: 0.6233 - val_loss: 0.7400 - val_mae: 0.6236\n",
      "Epoch 13/25\n",
      "700/708 [============================>.] - ETA: 0s - loss: 0.7382 - mae: 0.6227\n",
      "Epoch 13: val_loss did not improve from 0.73998\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7381 - mae: 0.6225 - val_loss: 0.7405 - val_mae: 0.6253\n",
      "Epoch 14/25\n",
      "696/708 [============================>.] - ETA: 0s - loss: 0.7364 - mae: 0.6221\n",
      "Epoch 14: val_loss did not improve from 0.73998\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7366 - mae: 0.6223 - val_loss: 0.7473 - val_mae: 0.6318\n",
      "Epoch 15/25\n",
      "694/708 [============================>.] - ETA: 0s - loss: 0.7334 - mae: 0.6203\n",
      "Epoch 15: val_loss did not improve from 0.73998\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7334 - mae: 0.6203 - val_loss: 0.7681 - val_mae: 0.6560\n",
      "Epoch 16/25\n",
      "695/708 [============================>.] - ETA: 0s - loss: 0.7335 - mae: 0.6217\n",
      "Epoch 16: val_loss improved from 0.73998 to 0.72892, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it1.e016_vl0.729.h5\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7334 - mae: 0.6216 - val_loss: 0.7289 - val_mae: 0.6180\n",
      "Epoch 17/25\n",
      "694/708 [============================>.] - ETA: 0s - loss: 0.7312 - mae: 0.6204\n",
      "Epoch 17: val_loss improved from 0.72892 to 0.72592, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it1.e017_vl0.726.h5\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7312 - mae: 0.6204 - val_loss: 0.7259 - val_mae: 0.6146\n",
      "Epoch 18/25\n",
      "700/708 [============================>.] - ETA: 0s - loss: 0.7292 - mae: 0.6189\n",
      "Epoch 18: val_loss did not improve from 0.72592\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7292 - mae: 0.6189 - val_loss: 0.7686 - val_mae: 0.6568\n",
      "Epoch 19/25\n",
      "691/708 [============================>.] - ETA: 0s - loss: 0.7308 - mae: 0.6213\n",
      "Epoch 19: val_loss did not improve from 0.72592\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7303 - mae: 0.6207 - val_loss: 0.7336 - val_mae: 0.6251\n",
      "Epoch 20/25\n",
      "696/708 [============================>.] - ETA: 0s - loss: 0.7264 - mae: 0.6175\n",
      "Epoch 20: val_loss did not improve from 0.72592\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7266 - mae: 0.6176 - val_loss: 0.7298 - val_mae: 0.6216\n",
      "Epoch 21/25\n",
      "704/708 [============================>.] - ETA: 0s - loss: 0.7268 - mae: 0.6185\n",
      "Epoch 21: val_loss did not improve from 0.72592\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7267 - mae: 0.6185 - val_loss: 0.7584 - val_mae: 0.6504\n",
      "Epoch 22/25\n",
      "698/708 [============================>.] - ETA: 0s - loss: 0.7251 - mae: 0.6175\n",
      "Epoch 22: val_loss did not improve from 0.72592\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7252 - mae: 0.6175 - val_loss: 0.7361 - val_mae: 0.6291\n",
      "Epoch 23/25\n",
      "689/708 [============================>.] - ETA: 0s - loss: 0.7237 - mae: 0.6169\n",
      "Epoch 23: val_loss did not improve from 0.72592\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7238 - mae: 0.6170 - val_loss: 0.7315 - val_mae: 0.6247\n",
      "Epoch 24/25\n",
      "703/708 [============================>.] - ETA: 0s - loss: 0.7233 - mae: 0.6171\n",
      "Epoch 24: val_loss did not improve from 0.72592\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7233 - mae: 0.6171 - val_loss: 0.7457 - val_mae: 0.6393\n",
      "Epoch 25/25\n",
      "701/708 [============================>.] - ETA: 0s - loss: 0.7219 - mae: 0.6165\n",
      "Epoch 25: val_loss did not improve from 0.72592\n",
      "708/708 [==============================] - 2s 3ms/step - loss: 0.7220 - mae: 0.6165 - val_loss: 0.7404 - val_mae: 0.6340\n",
      "Time elapsed to train: 52.58 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.332 3.033 1.628 3.378 2.365 1.720 1.264 0.976 0.637 0.378 0.222 0.124 0.075]\n",
      "<R> = [2.332 3.033 1.628 3.378 2.366 1.720 1.263 0.975 0.637 0.378 0.222 0.124 0.075]\n",
      "s_R = [0.018 0.075 0.021 0.158 0.060 0.009 0.013 0.016 0.003 0.001 0.001 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7478921 3.4496365 6.2019286 ... 2.6242356 4.0896916 4.4979873]\n",
      "mag_pred: [3.7478921 3.4496365 6.2019286 ... 2.6242356 4.0896916 4.4979873]\n",
      "Time elapsed to make plots: 19.12 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7f9e62cb93a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7f9e62c1b670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [32.468098  19.564203   8.3944845 ...  3.2883756 28.09196   13.196346 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0156\n",
      "  1% : 0.139\n",
      "  10% : 0.285\n",
      "  50% : 0.689\n",
      "  90% : 3.28\n",
      "  99% : 96.6\n",
      "  100% : 1.82e+04\n",
      "<chi^2/d.o.f.> = 1.07\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 2901 stars (1.15%) based on chi^2/dof > 79.4\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [10.961898  32.92875   20.288395  ...  2.4372633  6.814746  15.077877 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0367\n",
      "  1% : 0.139\n",
      "  10% : 0.285\n",
      "  50% : 0.695\n",
      "  90% : 3.13\n",
      "  99% : 104\n",
      "  100% : 5.21e+03\n",
      "<chi^2/d.o.f.> = 1.06\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 80.19 s\n",
      "learning rate = 0.009801986627280712\n",
      "setting learning rate to 0.009607894391523233\n",
      "Iteration 3 of 20.\n",
      "Epoch 1/25\n",
      "698/706 [============================>.] - ETA: 0s - loss: 0.7112 - mae: 0.6059\n",
      "Epoch 1: val_loss improved from inf to 0.71009, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it2.e001_vl0.710.h5\n",
      "706/706 [==============================] - 3s 3ms/step - loss: 0.7113 - mae: 0.6061 - val_loss: 0.7101 - val_mae: 0.6051\n",
      "Epoch 2/25\n",
      "695/706 [============================>.] - ETA: 0s - loss: 0.7104 - mae: 0.6063\n",
      "Epoch 2: val_loss improved from 0.71009 to 0.70635, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it2.e002_vl0.706.h5\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.7103 - mae: 0.6062 - val_loss: 0.7064 - val_mae: 0.6032\n",
      "Epoch 3/25\n",
      "695/706 [============================>.] - ETA: 0s - loss: 0.7084 - mae: 0.6053\n",
      "Epoch 3: val_loss did not improve from 0.70635\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.7085 - mae: 0.6054 - val_loss: 0.7083 - val_mae: 0.6048\n",
      "Epoch 4/25\n",
      "693/706 [============================>.] - ETA: 0s - loss: 0.7076 - mae: 0.6057\n",
      "Epoch 4: val_loss did not improve from 0.70635\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.7075 - mae: 0.6056 - val_loss: 0.7128 - val_mae: 0.6113\n",
      "Epoch 5/25\n",
      "703/706 [============================>.] - ETA: 0s - loss: 0.7073 - mae: 0.6067\n",
      "Epoch 5: val_loss did not improve from 0.70635\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.7073 - mae: 0.6067 - val_loss: 0.7274 - val_mae: 0.6267\n",
      "Epoch 6/25\n",
      "702/706 [============================>.] - ETA: 0s - loss: 0.7048 - mae: 0.6044\n",
      "Epoch 6: val_loss improved from 0.70635 to 0.70115, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it2.e006_vl0.701.h5\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.7048 - mae: 0.6044 - val_loss: 0.7012 - val_mae: 0.6011\n",
      "Epoch 7/25\n",
      "689/706 [============================>.] - ETA: 0s - loss: 0.7061 - mae: 0.6061\n",
      "Epoch 7: val_loss improved from 0.70115 to 0.69816, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it2.e007_vl0.698.h5\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.7058 - mae: 0.6058 - val_loss: 0.6982 - val_mae: 0.5974\n",
      "Epoch 8/25\n",
      "699/706 [============================>.] - ETA: 0s - loss: 0.7034 - mae: 0.6036\n",
      "Epoch 8: val_loss improved from 0.69816 to 0.69683, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it2.e008_vl0.697.h5\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.7034 - mae: 0.6036 - val_loss: 0.6968 - val_mae: 0.5972\n",
      "Epoch 9/25\n",
      "703/706 [============================>.] - ETA: 0s - loss: 0.7020 - mae: 0.6026\n",
      "Epoch 9: val_loss did not improve from 0.69683\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.7020 - mae: 0.6026 - val_loss: 0.7049 - val_mae: 0.6055\n",
      "Epoch 10/25\n",
      "687/706 [============================>.] - ETA: 0s - loss: 0.7024 - mae: 0.6034\n",
      "Epoch 10: val_loss did not improve from 0.69683\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.7026 - mae: 0.6036 - val_loss: 0.7096 - val_mae: 0.6104\n",
      "Epoch 11/25\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.7013 - mae: 0.6027\n",
      "Epoch 11: val_loss did not improve from 0.69683\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.7013 - mae: 0.6027 - val_loss: 0.6970 - val_mae: 0.5989\n",
      "Epoch 12/25\n",
      "695/706 [============================>.] - ETA: 0s - loss: 0.7005 - mae: 0.6023\n",
      "Epoch 12: val_loss improved from 0.69683 to 0.69333, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it2.e012_vl0.693.h5\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.7004 - mae: 0.6021 - val_loss: 0.6933 - val_mae: 0.5953\n",
      "Epoch 13/25\n",
      "695/706 [============================>.] - ETA: 0s - loss: 0.7004 - mae: 0.6023\n",
      "Epoch 13: val_loss did not improve from 0.69333\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.7004 - mae: 0.6023 - val_loss: 0.7040 - val_mae: 0.6058\n",
      "Epoch 14/25\n",
      "703/706 [============================>.] - ETA: 0s - loss: 0.6997 - mae: 0.6020\n",
      "Epoch 14: val_loss did not improve from 0.69333\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.6997 - mae: 0.6020 - val_loss: 0.6947 - val_mae: 0.5976\n",
      "Epoch 15/25\n",
      "689/706 [============================>.] - ETA: 0s - loss: 0.6983 - mae: 0.6010\n",
      "Epoch 15: val_loss improved from 0.69333 to 0.69134, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it2.e015_vl0.691.h5\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.6983 - mae: 0.6010 - val_loss: 0.6913 - val_mae: 0.5950\n",
      "Epoch 16/25\n",
      "690/706 [============================>.] - ETA: 0s - loss: 0.6998 - mae: 0.6029\n",
      "Epoch 16: val_loss did not improve from 0.69134\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.6999 - mae: 0.6029 - val_loss: 0.6923 - val_mae: 0.5964\n",
      "Epoch 17/25\n",
      "704/706 [============================>.] - ETA: 0s - loss: 0.6986 - mae: 0.6020\n",
      "Epoch 17: val_loss did not improve from 0.69134\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.6987 - mae: 0.6020 - val_loss: 0.6925 - val_mae: 0.5954\n",
      "Epoch 18/25\n",
      "691/706 [============================>.] - ETA: 0s - loss: 0.6977 - mae: 0.6013\n",
      "Epoch 18: val_loss did not improve from 0.69134\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.6976 - mae: 0.6012 - val_loss: 0.7079 - val_mae: 0.6111\n",
      "Epoch 19/25\n",
      "689/706 [============================>.] - ETA: 0s - loss: 0.6972 - mae: 0.6009\n",
      "Epoch 19: val_loss did not improve from 0.69134\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.6969 - mae: 0.6007 - val_loss: 0.6978 - val_mae: 0.6021\n",
      "Epoch 20/25\n",
      "689/706 [============================>.] - ETA: 0s - loss: 0.6973 - mae: 0.6014\n",
      "Epoch 20: val_loss improved from 0.69134 to 0.69033, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it2.e020_vl0.690.h5\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.6971 - mae: 0.6013 - val_loss: 0.6903 - val_mae: 0.5945\n",
      "Epoch 21/25\n",
      "703/706 [============================>.] - ETA: 0s - loss: 0.6979 - mae: 0.6024\n",
      "Epoch 21: val_loss did not improve from 0.69033\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.6979 - mae: 0.6024 - val_loss: 0.6947 - val_mae: 0.5989\n",
      "Epoch 22/25\n",
      "693/706 [============================>.] - ETA: 0s - loss: 0.6946 - mae: 0.5995\n",
      "Epoch 22: val_loss improved from 0.69033 to 0.68887, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it2.e022_vl0.689.h5\n",
      "706/706 [==============================] - 2s 4ms/step - loss: 0.6946 - mae: 0.5995 - val_loss: 0.6889 - val_mae: 0.5943\n",
      "Epoch 23/25\n",
      "687/706 [============================>.] - ETA: 0s - loss: 0.6951 - mae: 0.6003\n",
      "Epoch 23: val_loss did not improve from 0.68887\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.6955 - mae: 0.6006 - val_loss: 0.7115 - val_mae: 0.6169\n",
      "Epoch 24/25\n",
      "686/706 [============================>.] - ETA: 0s - loss: 0.6955 - mae: 0.6009\n",
      "Epoch 24: val_loss did not improve from 0.68887\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.6956 - mae: 0.6010 - val_loss: 0.6983 - val_mae: 0.6043\n",
      "Epoch 25/25\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.6947 - mae: 0.6003\n",
      "Epoch 25: val_loss did not improve from 0.68887\n",
      "706/706 [==============================] - 2s 3ms/step - loss: 0.6947 - mae: 0.6003 - val_loss: 0.7015 - val_mae: 0.6070\n",
      "Time elapsed to train: 54.85 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.349 3.094 1.636 3.438 2.388 1.733 1.241 0.969 0.623 0.355 0.196 0.089 0.034]\n",
      "<R> = [2.348 3.096 1.634 3.438 2.388 1.734 1.241 0.969 0.623 0.355 0.196 0.089 0.034]\n",
      "s_R = [0.020 0.057 0.008 0.146 0.076 0.010 0.011 0.004 0.002 0.002 0.001 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6465628 3.2882085 6.253805  ... 2.3196232 4.0009413 4.4317203]\n",
      "mag_pred: [3.6465628 3.2882085 6.253805  ... 2.3196232 4.0009413 4.4317203]\n",
      "Time elapsed to make plots: 19.47 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [34.62979   24.390339   8.7037945 ...  3.8973334 29.314629  15.822414 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0148\n",
      "  1% : 0.119\n",
      "  10% : 0.259\n",
      "  50% : 0.653\n",
      "  90% : 2.99\n",
      "  99% : 90.6\n",
      "  100% : 1.87e+04\n",
      "<chi^2/d.o.f.> = 1.02\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 3256 stars (1.29%) based on chi^2/dof > 63.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [12.200972  34.774967  12.8763    ...  2.3845344  7.38956   14.11784  ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0127\n",
      "  1% : 0.12\n",
      "  10% : 0.259\n",
      "  50% : 0.655\n",
      "  90% : 2.87\n",
      "  99% : 98.5\n",
      "  100% : 5.21e+03\n",
      "<chi^2/d.o.f.> = 1.01\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 78.72 s\n",
      "learning rate = 0.009607894346117973\n",
      "setting learning rate to 0.009417645335842488\n",
      "Iteration 4 of 20.\n",
      "Epoch 1/25\n",
      "687/705 [============================>.] - ETA: 0s - loss: 0.6851 - mae: 0.5916\n",
      "Epoch 1: val_loss improved from inf to 0.68663, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it3.e001_vl0.687.h5\n",
      "705/705 [==============================] - 3s 3ms/step - loss: 0.6850 - mae: 0.5915 - val_loss: 0.6866 - val_mae: 0.5930\n",
      "Epoch 2/25\n",
      "696/705 [============================>.] - ETA: 0s - loss: 0.6847 - mae: 0.5915\n",
      "Epoch 2: val_loss did not improve from 0.68663\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6847 - mae: 0.5915 - val_loss: 0.6970 - val_mae: 0.6045\n",
      "Epoch 3/25\n",
      "700/705 [============================>.] - ETA: 0s - loss: 0.6845 - mae: 0.5916\n",
      "Epoch 3: val_loss improved from 0.68663 to 0.67569, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it3.e003_vl0.676.h5\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6846 - mae: 0.5917 - val_loss: 0.6757 - val_mae: 0.5831\n",
      "Epoch 4/25\n",
      "686/705 [============================>.] - ETA: 0s - loss: 0.6834 - mae: 0.5906\n",
      "Epoch 4: val_loss did not improve from 0.67569\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6834 - mae: 0.5906 - val_loss: 0.6980 - val_mae: 0.6061\n",
      "Epoch 5/25\n",
      "697/705 [============================>.] - ETA: 0s - loss: 0.6844 - mae: 0.5919\n",
      "Epoch 5: val_loss did not improve from 0.67569\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6841 - mae: 0.5917 - val_loss: 0.6823 - val_mae: 0.5896\n",
      "Epoch 6/25\n",
      "697/705 [============================>.] - ETA: 0s - loss: 0.6829 - mae: 0.5906\n",
      "Epoch 6: val_loss did not improve from 0.67569\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6831 - mae: 0.5909 - val_loss: 0.6803 - val_mae: 0.5882\n",
      "Epoch 7/25\n",
      "703/705 [============================>.] - ETA: 0s - loss: 0.6832 - mae: 0.5912\n",
      "Epoch 7: val_loss did not improve from 0.67569\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6833 - mae: 0.5912 - val_loss: 0.6857 - val_mae: 0.5925\n",
      "Epoch 8/25\n",
      "705/705 [==============================] - ETA: 0s - loss: 0.6827 - mae: 0.5908\n",
      "Epoch 8: val_loss did not improve from 0.67569\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6827 - mae: 0.5908 - val_loss: 0.6914 - val_mae: 0.5999\n",
      "Epoch 9/25\n",
      "686/705 [============================>.] - ETA: 0s - loss: 0.6823 - mae: 0.5906\n",
      "Epoch 9: val_loss did not improve from 0.67569\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6827 - mae: 0.5910 - val_loss: 0.6856 - val_mae: 0.5939\n",
      "Epoch 10/25\n",
      "697/705 [============================>.] - ETA: 0s - loss: 0.6822 - mae: 0.5907\n",
      "Epoch 10: val_loss did not improve from 0.67569\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6822 - mae: 0.5907 - val_loss: 0.6867 - val_mae: 0.5959\n",
      "Epoch 11/25\n",
      "695/705 [============================>.] - ETA: 0s - loss: 0.6817 - mae: 0.5904\n",
      "Epoch 11: val_loss did not improve from 0.67569\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6816 - mae: 0.5903 - val_loss: 0.6855 - val_mae: 0.5941\n",
      "Epoch 12/25\n",
      "684/705 [============================>.] - ETA: 0s - loss: 0.6820 - mae: 0.5909\n",
      "Epoch 12: val_loss did not improve from 0.67569\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6815 - mae: 0.5904 - val_loss: 0.6907 - val_mae: 0.5994\n",
      "Epoch 13/25\n",
      "700/705 [============================>.] - ETA: 0s - loss: 0.6824 - mae: 0.5916\n",
      "Epoch 13: val_loss did not improve from 0.67569\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6823 - mae: 0.5915 - val_loss: 0.6855 - val_mae: 0.5947\n",
      "Epoch 14/25\n",
      "698/705 [============================>.] - ETA: 0s - loss: 0.6810 - mae: 0.5903\n",
      "Epoch 14: val_loss did not improve from 0.67569\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6810 - mae: 0.5903 - val_loss: 0.6781 - val_mae: 0.5884\n",
      "Epoch 15/25\n",
      "702/705 [============================>.] - ETA: 0s - loss: 0.6818 - mae: 0.5913\n",
      "Epoch 15: val_loss did not improve from 0.67569\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6818 - mae: 0.5913 - val_loss: 0.6766 - val_mae: 0.5854\n",
      "Epoch 16/25\n",
      "700/705 [============================>.] - ETA: 0s - loss: 0.6814 - mae: 0.5910\n",
      "Epoch 16: val_loss did not improve from 0.67569\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6812 - mae: 0.5909 - val_loss: 0.6805 - val_mae: 0.5900\n",
      "Epoch 17/25\n",
      "696/705 [============================>.] - ETA: 0s - loss: 0.6808 - mae: 0.5906\n",
      "Epoch 17: val_loss did not improve from 0.67569\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6807 - mae: 0.5906 - val_loss: 0.6864 - val_mae: 0.5970\n",
      "Epoch 18/25\n",
      "702/705 [============================>.] - ETA: 0s - loss: 0.6808 - mae: 0.5908\n",
      "Epoch 18: val_loss did not improve from 0.67569\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6809 - mae: 0.5909 - val_loss: 0.6773 - val_mae: 0.5872\n",
      "Epoch 19/25\n",
      "701/705 [============================>.] - ETA: 0s - loss: 0.6791 - mae: 0.5893\n",
      "Epoch 19: val_loss did not improve from 0.67569\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6791 - mae: 0.5894 - val_loss: 0.6851 - val_mae: 0.5951\n",
      "Epoch 20/25\n",
      "702/705 [============================>.] - ETA: 0s - loss: 0.6802 - mae: 0.5906\n",
      "Epoch 20: val_loss did not improve from 0.67569\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6802 - mae: 0.5906 - val_loss: 0.6790 - val_mae: 0.5895\n",
      "Epoch 21/25\n",
      "692/705 [============================>.] - ETA: 0s - loss: 0.6804 - mae: 0.5909\n",
      "Epoch 21: val_loss did not improve from 0.67569\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6803 - mae: 0.5908 - val_loss: 0.6813 - val_mae: 0.5917\n",
      "Epoch 22/25\n",
      "697/705 [============================>.] - ETA: 0s - loss: 0.6794 - mae: 0.5901\n",
      "Epoch 22: val_loss did not improve from 0.67569\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6795 - mae: 0.5902 - val_loss: 0.6921 - val_mae: 0.6027\n",
      "Epoch 23/25\n",
      "689/705 [============================>.] - ETA: 0s - loss: 0.6801 - mae: 0.5910\n",
      "Epoch 23: val_loss did not improve from 0.67569\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6800 - mae: 0.5909 - val_loss: 0.6823 - val_mae: 0.5930\n",
      "Epoch 24/25\n",
      "699/705 [============================>.] - ETA: 0s - loss: 0.6784 - mae: 0.5894\n",
      "Epoch 24: val_loss did not improve from 0.67569\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6785 - mae: 0.5895 - val_loss: 0.6792 - val_mae: 0.5906\n",
      "Epoch 25/25\n",
      "697/705 [============================>.] - ETA: 0s - loss: 0.6794 - mae: 0.5906\n",
      "Epoch 25: val_loss did not improve from 0.67569\n",
      "705/705 [==============================] - 2s 3ms/step - loss: 0.6794 - mae: 0.5906 - val_loss: 0.6820 - val_mae: 0.5937\n",
      "Time elapsed to train: 54.91 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.305 3.031 1.607 3.359 2.338 1.699 1.212 0.939 0.590 0.322 0.174 0.067 0.012]\n",
      "<R> = [2.306 3.030 1.608 3.357 2.337 1.699 1.212 0.939 0.590 0.322 0.174 0.067 0.012]\n",
      "s_R = [0.018 0.059 0.016 0.101 0.064 0.013 0.011 0.004 0.005 0.001 0.001 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6527154 3.4789813 6.2392173 ... 2.5920115 3.9431531 4.3744745]\n",
      "mag_pred: [3.6527154 3.4789813 6.2392173 ... 2.5920115 3.9431531 4.3744745]\n",
      "Time elapsed to make plots: 18.86 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [36.19074   26.653078   8.526954  ...  3.2992544 31.084236  19.053894 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0165\n",
      "  1% : 0.124\n",
      "  10% : 0.261\n",
      "  50% : 0.654\n",
      "  90% : 2.94\n",
      "  99% : 89.3\n",
      "  100% : 1.9e+04\n",
      "<chi^2/d.o.f.> = 1.02\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 3787 stars (1.5%) based on chi^2/dof > 50.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [10.788004  36.49135   12.163607  ...  2.658023   5.9765387 14.421462 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0183\n",
      "  1% : 0.125\n",
      "  10% : 0.261\n",
      "  50% : 0.66\n",
      "  90% : 2.81\n",
      "  99% : 97.5\n",
      "  100% : 5.21e+03\n",
      "<chi^2/d.o.f.> = 1.01\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 82.48 s\n",
      "learning rate = 0.009417645633220673\n",
      "setting learning rate to 0.009231163463866357\n",
      "Iteration 5 of 20.\n",
      "Epoch 1/25\n",
      "698/704 [============================>.] - ETA: 0s - loss: 0.6731 - mae: 0.5847\n",
      "Epoch 1: val_loss improved from inf to 0.68167, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it4.e001_vl0.682.h5\n",
      "704/704 [==============================] - 3s 4ms/step - loss: 0.6730 - mae: 0.5846 - val_loss: 0.6817 - val_mae: 0.5939\n",
      "Epoch 2/25\n",
      "695/704 [============================>.] - ETA: 0s - loss: 0.6740 - mae: 0.5858\n",
      "Epoch 2: val_loss did not improve from 0.68167\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6741 - mae: 0.5859 - val_loss: 0.7066 - val_mae: 0.6183\n",
      "Epoch 3/25\n",
      "689/704 [============================>.] - ETA: 0s - loss: 0.6733 - mae: 0.5852\n",
      "Epoch 3: val_loss improved from 0.68167 to 0.67276, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it4.e003_vl0.673.h5\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6734 - mae: 0.5853 - val_loss: 0.6728 - val_mae: 0.5841\n",
      "Epoch 4/25\n",
      "694/704 [============================>.] - ETA: 0s - loss: 0.6734 - mae: 0.5854\n",
      "Epoch 4: val_loss did not improve from 0.67276\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6734 - mae: 0.5854 - val_loss: 0.6826 - val_mae: 0.5949\n",
      "Epoch 5/25\n",
      "689/704 [============================>.] - ETA: 0s - loss: 0.6738 - mae: 0.5859\n",
      "Epoch 5: val_loss improved from 0.67276 to 0.67067, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it4.e005_vl0.671.h5\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6737 - mae: 0.5858 - val_loss: 0.6707 - val_mae: 0.5836\n",
      "Epoch 6/25\n",
      "691/704 [============================>.] - ETA: 0s - loss: 0.6732 - mae: 0.5855\n",
      "Epoch 6: val_loss improved from 0.67067 to 0.66874, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it4.e006_vl0.669.h5\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6731 - mae: 0.5854 - val_loss: 0.6687 - val_mae: 0.5811\n",
      "Epoch 7/25\n",
      "698/704 [============================>.] - ETA: 0s - loss: 0.6728 - mae: 0.5853\n",
      "Epoch 7: val_loss did not improve from 0.66874\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6729 - mae: 0.5853 - val_loss: 0.6776 - val_mae: 0.5898\n",
      "Epoch 8/25\n",
      "693/704 [============================>.] - ETA: 0s - loss: 0.6727 - mae: 0.5853\n",
      "Epoch 8: val_loss did not improve from 0.66874\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6728 - mae: 0.5854 - val_loss: 0.6784 - val_mae: 0.5912\n",
      "Epoch 9/25\n",
      "696/704 [============================>.] - ETA: 0s - loss: 0.6731 - mae: 0.5858\n",
      "Epoch 9: val_loss did not improve from 0.66874\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6730 - mae: 0.5858 - val_loss: 0.6721 - val_mae: 0.5848\n",
      "Epoch 10/25\n",
      "694/704 [============================>.] - ETA: 0s - loss: 0.6721 - mae: 0.5849\n",
      "Epoch 10: val_loss did not improve from 0.66874\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6720 - mae: 0.5848 - val_loss: 0.6744 - val_mae: 0.5871\n",
      "Epoch 11/25\n",
      "689/704 [============================>.] - ETA: 0s - loss: 0.6727 - mae: 0.5858\n",
      "Epoch 11: val_loss did not improve from 0.66874\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6728 - mae: 0.5858 - val_loss: 0.6782 - val_mae: 0.5913\n",
      "Epoch 12/25\n",
      "702/704 [============================>.] - ETA: 0s - loss: 0.6717 - mae: 0.5848\n",
      "Epoch 12: val_loss improved from 0.66874 to 0.66442, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it4.e012_vl0.664.h5\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6717 - mae: 0.5848 - val_loss: 0.6644 - val_mae: 0.5774\n",
      "Epoch 13/25\n",
      "698/704 [============================>.] - ETA: 0s - loss: 0.6716 - mae: 0.5849\n",
      "Epoch 13: val_loss did not improve from 0.66442\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6715 - mae: 0.5849 - val_loss: 0.6826 - val_mae: 0.5965\n",
      "Epoch 14/25\n",
      "701/704 [============================>.] - ETA: 0s - loss: 0.6717 - mae: 0.5851\n",
      "Epoch 14: val_loss did not improve from 0.66442\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6716 - mae: 0.5851 - val_loss: 0.6751 - val_mae: 0.5883\n",
      "Epoch 15/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 0.6724 - mae: 0.5860\n",
      "Epoch 15: val_loss did not improve from 0.66442\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6724 - mae: 0.5860 - val_loss: 0.6922 - val_mae: 0.6057\n",
      "Epoch 16/25\n",
      "695/704 [============================>.] - ETA: 0s - loss: 0.6715 - mae: 0.5853\n",
      "Epoch 16: val_loss did not improve from 0.66442\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6716 - mae: 0.5853 - val_loss: 0.6841 - val_mae: 0.5975\n",
      "Epoch 17/25\n",
      "704/704 [==============================] - ETA: 0s - loss: 0.6718 - mae: 0.5854\n",
      "Epoch 17: val_loss did not improve from 0.66442\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6718 - mae: 0.5854 - val_loss: 0.6732 - val_mae: 0.5864\n",
      "Epoch 18/25\n",
      "699/704 [============================>.] - ETA: 0s - loss: 0.6712 - mae: 0.5851\n",
      "Epoch 18: val_loss did not improve from 0.66442\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6713 - mae: 0.5852 - val_loss: 0.6697 - val_mae: 0.5834\n",
      "Epoch 19/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 0.6707 - mae: 0.5848\n",
      "Epoch 19: val_loss did not improve from 0.66442\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6707 - mae: 0.5848 - val_loss: 0.6782 - val_mae: 0.5924\n",
      "Epoch 20/25\n",
      "693/704 [============================>.] - ETA: 0s - loss: 0.6712 - mae: 0.5854\n",
      "Epoch 20: val_loss improved from 0.66442 to 0.66275, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it4.e020_vl0.663.h5\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6711 - mae: 0.5852 - val_loss: 0.6627 - val_mae: 0.5773\n",
      "Epoch 21/25\n",
      "700/704 [============================>.] - ETA: 0s - loss: 0.6701 - mae: 0.5844\n",
      "Epoch 21: val_loss did not improve from 0.66275\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6702 - mae: 0.5845 - val_loss: 0.6718 - val_mae: 0.5860\n",
      "Epoch 22/25\n",
      "695/704 [============================>.] - ETA: 0s - loss: 0.6704 - mae: 0.5848\n",
      "Epoch 22: val_loss did not improve from 0.66275\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6703 - mae: 0.5848 - val_loss: 0.6758 - val_mae: 0.5906\n",
      "Epoch 23/25\n",
      "690/704 [============================>.] - ETA: 0s - loss: 0.6708 - mae: 0.5854\n",
      "Epoch 23: val_loss did not improve from 0.66275\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6706 - mae: 0.5851 - val_loss: 0.6755 - val_mae: 0.5897\n",
      "Epoch 24/25\n",
      "697/704 [============================>.] - ETA: 0s - loss: 0.6698 - mae: 0.5845\n",
      "Epoch 24: val_loss did not improve from 0.66275\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6698 - mae: 0.5845 - val_loss: 0.6758 - val_mae: 0.5907\n",
      "Epoch 25/25\n",
      "691/704 [============================>.] - ETA: 0s - loss: 0.6707 - mae: 0.5855\n",
      "Epoch 25: val_loss did not improve from 0.66275\n",
      "704/704 [==============================] - 2s 3ms/step - loss: 0.6705 - mae: 0.5853 - val_loss: 0.6756 - val_mae: 0.5906\n",
      "Time elapsed to train: 55.98 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.276 2.975 1.580 3.304 2.308 1.674 1.195 0.920 0.570 0.306 0.160 0.056 0.003]\n",
      "<R> = [2.279 2.976 1.580 3.303 2.307 1.673 1.195 0.920 0.570 0.306 0.160 0.056 0.003]\n",
      "s_R = [0.019 0.028 0.015 0.099 0.061 0.009 0.024 0.008 0.004 0.001 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7146845 3.5958412 6.278814  ... 2.7912655 3.987425  4.4093723]\n",
      "mag_pred: [3.7146845 3.5958412 6.278814  ... 2.7912655 3.987425  4.4093723]\n",
      "Time elapsed to make plots: 19.65 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [37.437424  26.534191   5.3055925 ...  2.9656405 33.91558   13.687285 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0148\n",
      "  1% : 0.118\n",
      "  10% : 0.254\n",
      "  50% : 0.653\n",
      "  90% : 3.02\n",
      "  99% : 86.3\n",
      "  100% : 1.94e+04\n",
      "<chi^2/d.o.f.> = 1.03\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 4331 stars (1.71%) based on chi^2/dof > 39.8\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [11.653365  32.314613  12.359619  ...  2.7101889  7.4344416 15.816722 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.031\n",
      "  1% : 0.119\n",
      "  10% : 0.254\n",
      "  50% : 0.656\n",
      "  90% : 2.89\n",
      "  99% : 93.5\n",
      "  100% : 5.21e+03\n",
      "<chi^2/d.o.f.> = 1.02\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 81.28 s\n",
      "learning rate = 0.009231163188815117\n",
      "setting learning rate to 0.009048374180359595\n",
      "Iteration 6 of 20.\n",
      "Epoch 1/25\n",
      "698/702 [============================>.] - ETA: 0s - loss: 0.6640 - mae: 0.5792\n",
      "Epoch 1: val_loss improved from inf to 0.66380, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it5.e001_vl0.664.h5\n",
      "702/702 [==============================] - 3s 3ms/step - loss: 0.6640 - mae: 0.5792 - val_loss: 0.6638 - val_mae: 0.5787\n",
      "Epoch 2/25\n",
      "695/702 [============================>.] - ETA: 0s - loss: 0.6631 - mae: 0.5784\n",
      "Epoch 2: val_loss did not improve from 0.66380\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6630 - mae: 0.5784 - val_loss: 0.6651 - val_mae: 0.5805\n",
      "Epoch 3/25\n",
      "693/702 [============================>.] - ETA: 0s - loss: 0.6634 - mae: 0.5788\n",
      "Epoch 3: val_loss did not improve from 0.66380\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6634 - mae: 0.5789 - val_loss: 0.6673 - val_mae: 0.5833\n",
      "Epoch 4/25\n",
      "686/702 [============================>.] - ETA: 0s - loss: 0.6628 - mae: 0.5783\n",
      "Epoch 4: val_loss improved from 0.66380 to 0.66014, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it5.e004_vl0.660.h5\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6626 - mae: 0.5781 - val_loss: 0.6601 - val_mae: 0.5750\n",
      "Epoch 5/25\n",
      "697/702 [============================>.] - ETA: 0s - loss: 0.6627 - mae: 0.5783\n",
      "Epoch 5: val_loss improved from 0.66014 to 0.65588, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it5.e005_vl0.656.h5\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6626 - mae: 0.5783 - val_loss: 0.6559 - val_mae: 0.5726\n",
      "Epoch 6/25\n",
      "698/702 [============================>.] - ETA: 0s - loss: 0.6634 - mae: 0.5792\n",
      "Epoch 6: val_loss did not improve from 0.65588\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6634 - mae: 0.5792 - val_loss: 0.6699 - val_mae: 0.5857\n",
      "Epoch 7/25\n",
      "692/702 [============================>.] - ETA: 0s - loss: 0.6631 - mae: 0.5790\n",
      "Epoch 7: val_loss did not improve from 0.65588\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6631 - mae: 0.5790 - val_loss: 0.6617 - val_mae: 0.5780\n",
      "Epoch 8/25\n",
      "686/702 [============================>.] - ETA: 0s - loss: 0.6629 - mae: 0.5790\n",
      "Epoch 8: val_loss did not improve from 0.65588\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6629 - mae: 0.5790 - val_loss: 0.6648 - val_mae: 0.5810\n",
      "Epoch 9/25\n",
      "702/702 [==============================] - ETA: 0s - loss: 0.6623 - mae: 0.5784\n",
      "Epoch 9: val_loss did not improve from 0.65588\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6623 - mae: 0.5784 - val_loss: 0.6678 - val_mae: 0.5846\n",
      "Epoch 10/25\n",
      "698/702 [============================>.] - ETA: 0s - loss: 0.6623 - mae: 0.5786\n",
      "Epoch 10: val_loss improved from 0.65588 to 0.65561, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it5.e010_vl0.656.h5\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6623 - mae: 0.5785 - val_loss: 0.6556 - val_mae: 0.5724\n",
      "Epoch 11/25\n",
      "692/702 [============================>.] - ETA: 0s - loss: 0.6623 - mae: 0.5786\n",
      "Epoch 11: val_loss did not improve from 0.65561\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6623 - mae: 0.5786 - val_loss: 0.6671 - val_mae: 0.5838\n",
      "Epoch 12/25\n",
      "701/702 [============================>.] - ETA: 0s - loss: 0.6623 - mae: 0.5787\n",
      "Epoch 12: val_loss did not improve from 0.65561\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6623 - mae: 0.5787 - val_loss: 0.6593 - val_mae: 0.5756\n",
      "Epoch 13/25\n",
      "688/702 [============================>.] - ETA: 0s - loss: 0.6625 - mae: 0.5790\n",
      "Epoch 13: val_loss did not improve from 0.65561\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6624 - mae: 0.5789 - val_loss: 0.6622 - val_mae: 0.5783\n",
      "Epoch 14/25\n",
      "701/702 [============================>.] - ETA: 0s - loss: 0.6613 - mae: 0.5779\n",
      "Epoch 14: val_loss did not improve from 0.65561\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6613 - mae: 0.5779 - val_loss: 0.6664 - val_mae: 0.5833\n",
      "Epoch 15/25\n",
      "702/702 [==============================] - ETA: 0s - loss: 0.6623 - mae: 0.5791\n",
      "Epoch 15: val_loss did not improve from 0.65561\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6623 - mae: 0.5791 - val_loss: 0.6579 - val_mae: 0.5748\n",
      "Epoch 16/25\n",
      "698/702 [============================>.] - ETA: 0s - loss: 0.6616 - mae: 0.5784\n",
      "Epoch 16: val_loss did not improve from 0.65561\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6617 - mae: 0.5785 - val_loss: 0.6662 - val_mae: 0.5825\n",
      "Epoch 17/25\n",
      "685/702 [============================>.] - ETA: 0s - loss: 0.6618 - mae: 0.5787\n",
      "Epoch 17: val_loss did not improve from 0.65561\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6618 - mae: 0.5786 - val_loss: 0.6655 - val_mae: 0.5828\n",
      "Epoch 18/25\n",
      "701/702 [============================>.] - ETA: 0s - loss: 0.6619 - mae: 0.5788\n",
      "Epoch 18: val_loss did not improve from 0.65561\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6619 - mae: 0.5789 - val_loss: 0.6651 - val_mae: 0.5822\n",
      "Epoch 19/25\n",
      "700/702 [============================>.] - ETA: 0s - loss: 0.6617 - mae: 0.5787\n",
      "Epoch 19: val_loss did not improve from 0.65561\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6618 - mae: 0.5788 - val_loss: 0.6592 - val_mae: 0.5751\n",
      "Epoch 20/25\n",
      "697/702 [============================>.] - ETA: 0s - loss: 0.6609 - mae: 0.5781\n",
      "Epoch 20: val_loss did not improve from 0.65561\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6609 - mae: 0.5781 - val_loss: 0.6607 - val_mae: 0.5784\n",
      "Epoch 21/25\n",
      "699/702 [============================>.] - ETA: 0s - loss: 0.6615 - mae: 0.5787\n",
      "Epoch 21: val_loss did not improve from 0.65561\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6614 - mae: 0.5787 - val_loss: 0.6618 - val_mae: 0.5796\n",
      "Epoch 22/25\n",
      "694/702 [============================>.] - ETA: 0s - loss: 0.6619 - mae: 0.5793\n",
      "Epoch 22: val_loss did not improve from 0.65561\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6619 - mae: 0.5792 - val_loss: 0.6654 - val_mae: 0.5831\n",
      "Epoch 23/25\n",
      "691/702 [============================>.] - ETA: 0s - loss: 0.6608 - mae: 0.5782\n",
      "Epoch 23: val_loss did not improve from 0.65561\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6610 - mae: 0.5784 - val_loss: 0.6690 - val_mae: 0.5859\n",
      "Epoch 24/25\n",
      "689/702 [============================>.] - ETA: 0s - loss: 0.6609 - mae: 0.5785\n",
      "Epoch 24: val_loss did not improve from 0.65561\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6607 - mae: 0.5782 - val_loss: 0.6608 - val_mae: 0.5783\n",
      "Epoch 25/25\n",
      "695/702 [============================>.] - ETA: 0s - loss: 0.6610 - mae: 0.5786\n",
      "Epoch 25: val_loss did not improve from 0.65561\n",
      "702/702 [==============================] - 2s 3ms/step - loss: 0.6610 - mae: 0.5787 - val_loss: 0.6556 - val_mae: 0.5735\n",
      "Time elapsed to train: 55.31 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.282 2.980 1.573 3.308 2.304 1.655 1.187 0.916 0.573 0.317 0.158 0.051 0.000]\n",
      "<R> = [2.285 2.973 1.574 3.308 2.306 1.655 1.186 0.916 0.574 0.318 0.158 0.051 0.000]\n",
      "s_R = [0.033 0.056 0.016 0.104 0.067 0.008 0.019 0.002 0.005 0.001 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.698703  3.5457036 6.2711463 ... 2.707977  3.9856646 4.406705 ]\n",
      "mag_pred: [3.698703  3.5457036 6.2711463 ... 2.707977  3.9856646 4.406705 ]\n",
      "Time elapsed to make plots: 19.36 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [34.852386  26.2568     7.7771754 ...  2.871317  31.835949  14.963404 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0152\n",
      "  1% : 0.112\n",
      "  10% : 0.24\n",
      "  50% : 0.624\n",
      "  90% : 2.96\n",
      "  99% : 85.8\n",
      "  100% : 1.78e+04\n",
      "<chi^2/d.o.f.> = 1\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 5002 stars (1.98%) based on chi^2/dof > 31.6\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.591582  33.31927   13.221586  ...  2.2875667  6.5846157 14.273589 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0223\n",
      "  1% : 0.113\n",
      "  10% : 0.239\n",
      "  50% : 0.63\n",
      "  90% : 2.84\n",
      "  99% : 93\n",
      "  100% : 5.2e+03\n",
      "<chi^2/d.o.f.> = 0.989\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 79.70 s\n",
      "learning rate = 0.009048374369740486\n",
      "setting learning rate to 0.008869204367171575\n",
      "Iteration 7 of 20.\n",
      "Epoch 1/25\n",
      "687/700 [============================>.] - ETA: 0s - loss: 0.6525 - mae: 0.5705\n",
      "Epoch 1: val_loss improved from inf to 0.64906, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it6.e001_vl0.649.h5\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.6523 - mae: 0.5703 - val_loss: 0.6491 - val_mae: 0.5670\n",
      "Epoch 2/25\n",
      "691/700 [============================>.] - ETA: 0s - loss: 0.6516 - mae: 0.5698\n",
      "Epoch 2: val_loss did not improve from 0.64906\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6518 - mae: 0.5699 - val_loss: 0.6500 - val_mae: 0.5682\n",
      "Epoch 3/25\n",
      "681/700 [============================>.] - ETA: 0s - loss: 0.6529 - mae: 0.5711\n",
      "Epoch 3: val_loss did not improve from 0.64906\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6528 - mae: 0.5710 - val_loss: 0.6520 - val_mae: 0.5703\n",
      "Epoch 4/25\n",
      "688/700 [============================>.] - ETA: 0s - loss: 0.6525 - mae: 0.5707\n",
      "Epoch 4: val_loss improved from 0.64906 to 0.64858, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it6.e004_vl0.649.h5\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6523 - mae: 0.5705 - val_loss: 0.6486 - val_mae: 0.5669\n",
      "Epoch 5/25\n",
      "690/700 [============================>.] - ETA: 0s - loss: 0.6519 - mae: 0.5703\n",
      "Epoch 5: val_loss did not improve from 0.64858\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6519 - mae: 0.5702 - val_loss: 0.6561 - val_mae: 0.5753\n",
      "Epoch 6/25\n",
      "696/700 [============================>.] - ETA: 0s - loss: 0.6515 - mae: 0.5699\n",
      "Epoch 6: val_loss did not improve from 0.64858\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6515 - mae: 0.5699 - val_loss: 0.6535 - val_mae: 0.5721\n",
      "Epoch 7/25\n",
      "685/700 [============================>.] - ETA: 0s - loss: 0.6519 - mae: 0.5705\n",
      "Epoch 7: val_loss did not improve from 0.64858\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6521 - mae: 0.5707 - val_loss: 0.6683 - val_mae: 0.5866\n",
      "Epoch 8/25\n",
      "683/700 [============================>.] - ETA: 0s - loss: 0.6520 - mae: 0.5705\n",
      "Epoch 8: val_loss did not improve from 0.64858\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6518 - mae: 0.5704 - val_loss: 0.6503 - val_mae: 0.5690\n",
      "Epoch 9/25\n",
      "685/700 [============================>.] - ETA: 0s - loss: 0.6510 - mae: 0.5697\n",
      "Epoch 9: val_loss did not improve from 0.64858\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6511 - mae: 0.5698 - val_loss: 0.6548 - val_mae: 0.5729\n",
      "Epoch 10/25\n",
      "687/700 [============================>.] - ETA: 0s - loss: 0.6525 - mae: 0.5713\n",
      "Epoch 10: val_loss did not improve from 0.64858\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6524 - mae: 0.5712 - val_loss: 0.6516 - val_mae: 0.5706\n",
      "Epoch 11/25\n",
      "693/700 [============================>.] - ETA: 0s - loss: 0.6511 - mae: 0.5699\n",
      "Epoch 11: val_loss improved from 0.64858 to 0.64773, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it6.e011_vl0.648.h5\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6511 - mae: 0.5700 - val_loss: 0.6477 - val_mae: 0.5667\n",
      "Epoch 12/25\n",
      "685/700 [============================>.] - ETA: 0s - loss: 0.6518 - mae: 0.5707\n",
      "Epoch 12: val_loss did not improve from 0.64773\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6518 - mae: 0.5707 - val_loss: 0.6552 - val_mae: 0.5745\n",
      "Epoch 13/25\n",
      "696/700 [============================>.] - ETA: 0s - loss: 0.6510 - mae: 0.5700\n",
      "Epoch 13: val_loss did not improve from 0.64773\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6510 - mae: 0.5700 - val_loss: 0.6529 - val_mae: 0.5716\n",
      "Epoch 14/25\n",
      "687/700 [============================>.] - ETA: 0s - loss: 0.6516 - mae: 0.5706\n",
      "Epoch 14: val_loss improved from 0.64773 to 0.64698, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it6.e014_vl0.647.h5\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6517 - mae: 0.5708 - val_loss: 0.6470 - val_mae: 0.5659\n",
      "Epoch 15/25\n",
      "699/700 [============================>.] - ETA: 0s - loss: 0.6507 - mae: 0.5699\n",
      "Epoch 15: val_loss improved from 0.64698 to 0.64592, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it6.e015_vl0.646.h5\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6507 - mae: 0.5699 - val_loss: 0.6459 - val_mae: 0.5651\n",
      "Epoch 16/25\n",
      "686/700 [============================>.] - ETA: 0s - loss: 0.6510 - mae: 0.5702\n",
      "Epoch 16: val_loss did not improve from 0.64592\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6512 - mae: 0.5703 - val_loss: 0.6588 - val_mae: 0.5778\n",
      "Epoch 17/25\n",
      "682/700 [============================>.] - ETA: 0s - loss: 0.6517 - mae: 0.5710\n",
      "Epoch 17: val_loss did not improve from 0.64592\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6518 - mae: 0.5711 - val_loss: 0.6513 - val_mae: 0.5709\n",
      "Epoch 18/25\n",
      "692/700 [============================>.] - ETA: 0s - loss: 0.6509 - mae: 0.5703\n",
      "Epoch 18: val_loss did not improve from 0.64592\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6509 - mae: 0.5702 - val_loss: 0.6496 - val_mae: 0.5686\n",
      "Epoch 19/25\n",
      "682/700 [============================>.] - ETA: 0s - loss: 0.6499 - mae: 0.5694\n",
      "Epoch 19: val_loss did not improve from 0.64592\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6501 - mae: 0.5695 - val_loss: 0.6548 - val_mae: 0.5739\n",
      "Epoch 20/25\n",
      "680/700 [============================>.] - ETA: 0s - loss: 0.6505 - mae: 0.5700\n",
      "Epoch 20: val_loss did not improve from 0.64592\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6509 - mae: 0.5704 - val_loss: 0.6613 - val_mae: 0.5802\n",
      "Epoch 21/25\n",
      "697/700 [============================>.] - ETA: 0s - loss: 0.6508 - mae: 0.5704\n",
      "Epoch 21: val_loss did not improve from 0.64592\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6509 - mae: 0.5705 - val_loss: 0.6633 - val_mae: 0.5828\n",
      "Epoch 22/25\n",
      "699/700 [============================>.] - ETA: 0s - loss: 0.6508 - mae: 0.5705\n",
      "Epoch 22: val_loss did not improve from 0.64592\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6508 - mae: 0.5705 - val_loss: 0.6489 - val_mae: 0.5676\n",
      "Epoch 23/25\n",
      "685/700 [============================>.] - ETA: 0s - loss: 0.6507 - mae: 0.5705\n",
      "Epoch 23: val_loss did not improve from 0.64592\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6509 - mae: 0.5706 - val_loss: 0.6573 - val_mae: 0.5771\n",
      "Epoch 24/25\n",
      "694/700 [============================>.] - ETA: 0s - loss: 0.6494 - mae: 0.5693\n",
      "Epoch 24: val_loss did not improve from 0.64592\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6497 - mae: 0.5695 - val_loss: 0.6506 - val_mae: 0.5702\n",
      "Epoch 25/25\n",
      "686/700 [============================>.] - ETA: 0s - loss: 0.6506 - mae: 0.5705\n",
      "Epoch 25: val_loss improved from 0.64592 to 0.64576, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it6.e025_vl0.646.h5\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6507 - mae: 0.5706 - val_loss: 0.6458 - val_mae: 0.5655\n",
      "Time elapsed to train: 56.83 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.261 2.976 1.574 3.299 2.308 1.664 1.188 0.909 0.568 0.305 0.154 0.051 0.000]\n",
      "<R> = [2.263 2.976 1.574 3.299 2.308 1.664 1.187 0.909 0.568 0.305 0.154 0.051 0.000]\n",
      "s_R = [0.032 0.025 0.008 0.109 0.041 0.007 0.005 0.005 0.005 0.001 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7031543 3.4683168 6.3209133 ... 2.5339432 4.012483  4.445793 ]\n",
      "mag_pred: [3.7031543 3.4683168 6.3209133 ... 2.5339432 4.012483  4.445793 ]\n",
      "Time elapsed to make plots: 18.02 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [34.733513  24.830372   7.555509  ...  2.9318452 31.500092  13.725552 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0121\n",
      "  1% : 0.106\n",
      "  10% : 0.235\n",
      "  50% : 0.62\n",
      "  90% : 2.97\n",
      "  99% : 86.3\n",
      "  100% : 1.82e+04\n",
      "<chi^2/d.o.f.> = 0.998\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 5938 stars (2.35%) based on chi^2/dof > 25.1\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [10.188137  33.776154  11.877558  ...  1.9069748  7.270037  13.737859 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0235\n",
      "  1% : 0.106\n",
      "  10% : 0.235\n",
      "  50% : 0.627\n",
      "  90% : 2.84\n",
      "  99% : 93.2\n",
      "  100% : 5.2e+03\n",
      "<chi^2/d.o.f.> = 0.987\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 78.37 s\n",
      "learning rate = 0.008869204670190811\n",
      "setting learning rate to 0.00869358235398806\n",
      "Iteration 8 of 20.\n",
      "Epoch 1/25\n",
      "694/698 [============================>.] - ETA: 0s - loss: 0.6423 - mae: 0.5626\n",
      "Epoch 1: val_loss improved from inf to 0.65968, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it7.e001_vl0.660.h5\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.6423 - mae: 0.5626 - val_loss: 0.6597 - val_mae: 0.5807\n",
      "Epoch 2/25\n",
      "698/698 [==============================] - ETA: 0s - loss: 0.6425 - mae: 0.5629\n",
      "Epoch 2: val_loss improved from 0.65968 to 0.64973, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it7.e002_vl0.650.h5\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6425 - mae: 0.5629 - val_loss: 0.6497 - val_mae: 0.5700\n",
      "Epoch 3/25\n",
      "695/698 [============================>.] - ETA: 0s - loss: 0.6425 - mae: 0.5629\n",
      "Epoch 3: val_loss improved from 0.64973 to 0.64356, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it7.e003_vl0.644.h5\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6424 - mae: 0.5628 - val_loss: 0.6436 - val_mae: 0.5643\n",
      "Epoch 4/25\n",
      "683/698 [============================>.] - ETA: 0s - loss: 0.6423 - mae: 0.5627\n",
      "Epoch 4: val_loss did not improve from 0.64356\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6422 - mae: 0.5626 - val_loss: 0.6486 - val_mae: 0.5694\n",
      "Epoch 5/25\n",
      "698/698 [==============================] - ETA: 0s - loss: 0.6416 - mae: 0.5622\n",
      "Epoch 5: val_loss did not improve from 0.64356\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6416 - mae: 0.5622 - val_loss: 0.6463 - val_mae: 0.5667\n",
      "Epoch 6/25\n",
      "687/698 [============================>.] - ETA: 0s - loss: 0.6424 - mae: 0.5629\n",
      "Epoch 6: val_loss improved from 0.64356 to 0.64280, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it7.e006_vl0.643.h5\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6423 - mae: 0.5628 - val_loss: 0.6428 - val_mae: 0.5633\n",
      "Epoch 7/25\n",
      "681/698 [============================>.] - ETA: 0s - loss: 0.6418 - mae: 0.5625\n",
      "Epoch 7: val_loss did not improve from 0.64280\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6420 - mae: 0.5626 - val_loss: 0.6542 - val_mae: 0.5751\n",
      "Epoch 8/25\n",
      "693/698 [============================>.] - ETA: 0s - loss: 0.6417 - mae: 0.5625\n",
      "Epoch 8: val_loss improved from 0.64280 to 0.63858, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it7.e008_vl0.639.h5\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6417 - mae: 0.5624 - val_loss: 0.6386 - val_mae: 0.5589\n",
      "Epoch 9/25\n",
      "687/698 [============================>.] - ETA: 0s - loss: 0.6422 - mae: 0.5630\n",
      "Epoch 9: val_loss did not improve from 0.63858\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6421 - mae: 0.5629 - val_loss: 0.6445 - val_mae: 0.5651\n",
      "Epoch 10/25\n",
      "687/698 [============================>.] - ETA: 0s - loss: 0.6411 - mae: 0.5620\n",
      "Epoch 10: val_loss did not improve from 0.63858\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6411 - mae: 0.5620 - val_loss: 0.6403 - val_mae: 0.5613\n",
      "Epoch 11/25\n",
      "685/698 [============================>.] - ETA: 0s - loss: 0.6414 - mae: 0.5624\n",
      "Epoch 11: val_loss did not improve from 0.63858\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6413 - mae: 0.5623 - val_loss: 0.6400 - val_mae: 0.5610\n",
      "Epoch 12/25\n",
      "692/698 [============================>.] - ETA: 0s - loss: 0.6421 - mae: 0.5631\n",
      "Epoch 12: val_loss did not improve from 0.63858\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6421 - mae: 0.5631 - val_loss: 0.6552 - val_mae: 0.5760\n",
      "Epoch 13/25\n",
      "687/698 [============================>.] - ETA: 0s - loss: 0.6422 - mae: 0.5632\n",
      "Epoch 13: val_loss did not improve from 0.63858\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6422 - mae: 0.5632 - val_loss: 0.6562 - val_mae: 0.5777\n",
      "Epoch 14/25\n",
      "692/698 [============================>.] - ETA: 0s - loss: 0.6412 - mae: 0.5624\n",
      "Epoch 14: val_loss did not improve from 0.63858\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6412 - mae: 0.5624 - val_loss: 0.6741 - val_mae: 0.5950\n",
      "Epoch 15/25\n",
      "698/698 [==============================] - ETA: 0s - loss: 0.6420 - mae: 0.5632\n",
      "Epoch 15: val_loss did not improve from 0.63858\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6420 - mae: 0.5632 - val_loss: 0.6501 - val_mae: 0.5716\n",
      "Epoch 16/25\n",
      "681/698 [============================>.] - ETA: 0s - loss: 0.6421 - mae: 0.5634\n",
      "Epoch 16: val_loss did not improve from 0.63858\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6421 - mae: 0.5634 - val_loss: 0.6522 - val_mae: 0.5736\n",
      "Epoch 17/25\n",
      "691/698 [============================>.] - ETA: 0s - loss: 0.6417 - mae: 0.5630\n",
      "Epoch 17: val_loss did not improve from 0.63858\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6417 - mae: 0.5630 - val_loss: 0.6475 - val_mae: 0.5687\n",
      "Epoch 18/25\n",
      "690/698 [============================>.] - ETA: 0s - loss: 0.6418 - mae: 0.5631\n",
      "Epoch 18: val_loss did not improve from 0.63858\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6419 - mae: 0.5632 - val_loss: 0.6453 - val_mae: 0.5667\n",
      "Epoch 19/25\n",
      "685/698 [============================>.] - ETA: 0s - loss: 0.6410 - mae: 0.5624\n",
      "Epoch 19: val_loss did not improve from 0.63858\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6410 - mae: 0.5624 - val_loss: 0.6541 - val_mae: 0.5754\n",
      "Epoch 20/25\n",
      "697/698 [============================>.] - ETA: 0s - loss: 0.6410 - mae: 0.5624\n",
      "Epoch 20: val_loss did not improve from 0.63858\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6410 - mae: 0.5624 - val_loss: 0.6445 - val_mae: 0.5658\n",
      "Epoch 21/25\n",
      "686/698 [============================>.] - ETA: 0s - loss: 0.6410 - mae: 0.5624\n",
      "Epoch 21: val_loss did not improve from 0.63858\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6411 - mae: 0.5625 - val_loss: 0.6500 - val_mae: 0.5717\n",
      "Epoch 22/25\n",
      "692/698 [============================>.] - ETA: 0s - loss: 0.6407 - mae: 0.5624\n",
      "Epoch 22: val_loss did not improve from 0.63858\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6408 - mae: 0.5624 - val_loss: 0.6400 - val_mae: 0.5615\n",
      "Epoch 23/25\n",
      "677/698 [============================>.] - ETA: 0s - loss: 0.6410 - mae: 0.5625\n",
      "Epoch 23: val_loss did not improve from 0.63858\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6411 - mae: 0.5627 - val_loss: 0.6439 - val_mae: 0.5650\n",
      "Epoch 24/25\n",
      "697/698 [============================>.] - ETA: 0s - loss: 0.6404 - mae: 0.5620\n",
      "Epoch 24: val_loss did not improve from 0.63858\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6404 - mae: 0.5620 - val_loss: 0.6574 - val_mae: 0.5788\n",
      "Epoch 25/25\n",
      "678/698 [============================>.] - ETA: 0s - loss: 0.6409 - mae: 0.5626\n",
      "Epoch 25: val_loss improved from 0.63858 to 0.63727, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it7.e025_vl0.637.h5\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.6408 - mae: 0.5625 - val_loss: 0.6373 - val_mae: 0.5588\n",
      "Time elapsed to train: 56.56 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.253 2.958 1.561 3.296 2.273 1.640 1.180 0.918 0.561 0.297 0.145 0.048 0.000]\n",
      "<R> = [2.253 2.961 1.563 3.297 2.272 1.640 1.181 0.917 0.561 0.297 0.145 0.048 0.000]\n",
      "s_R = [0.050 0.034 0.016 0.088 0.049 0.008 0.006 0.004 0.003 0.000 0.001 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7307053 3.525682  6.333153  ... 2.655287  4.030141  4.451803 ]\n",
      "mag_pred: [3.7307053 3.525682  6.333153  ... 2.655287  4.030141  4.451803 ]\n",
      "Time elapsed to make plots: 20.10 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [36.904877  24.953882   7.044418  ...  2.8556747 30.557816  13.668791 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0112\n",
      "  1% : 0.109\n",
      "  10% : 0.24\n",
      "  50% : 0.621\n",
      "  90% : 2.92\n",
      "  99% : 86\n",
      "  100% : 1.74e+04\n",
      "<chi^2/d.o.f.> = 0.993\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 6832 stars (2.7%) based on chi^2/dof > 19.9\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [11.107505  34.078915  12.998915  ...  1.7444756  6.5048738 14.325207 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0251\n",
      "  1% : 0.112\n",
      "  10% : 0.238\n",
      "  50% : 0.625\n",
      "  90% : 2.81\n",
      "  99% : 93.5\n",
      "  100% : 5.2e+03\n",
      "<chi^2/d.o.f.> = 0.981\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 82.94 s\n",
      "learning rate = 0.008693582378327847\n",
      "setting learning rate to 0.008521437889662113\n",
      "Iteration 9 of 20.\n",
      "Epoch 1/25\n",
      "682/695 [============================>.] - ETA: 0s - loss: 0.6320 - mae: 0.5542\n",
      "Epoch 1: val_loss improved from inf to 0.63580, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it8.e001_vl0.636.h5\n",
      "695/695 [==============================] - 3s 3ms/step - loss: 0.6322 - mae: 0.5544 - val_loss: 0.6358 - val_mae: 0.5584\n",
      "Epoch 2/25\n",
      "679/695 [============================>.] - ETA: 0s - loss: 0.6330 - mae: 0.5553\n",
      "Epoch 2: val_loss improved from 0.63580 to 0.63125, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it8.e002_vl0.631.h5\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6329 - mae: 0.5552 - val_loss: 0.6312 - val_mae: 0.5538\n",
      "Epoch 3/25\n",
      "675/695 [============================>.] - ETA: 0s - loss: 0.6318 - mae: 0.5541\n",
      "Epoch 3: val_loss improved from 0.63125 to 0.63021, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it8.e003_vl0.630.h5\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6320 - mae: 0.5543 - val_loss: 0.6302 - val_mae: 0.5525\n",
      "Epoch 4/25\n",
      "686/695 [============================>.] - ETA: 0s - loss: 0.6326 - mae: 0.5550\n",
      "Epoch 4: val_loss did not improve from 0.63021\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6326 - mae: 0.5550 - val_loss: 0.6332 - val_mae: 0.5556\n",
      "Epoch 5/25\n",
      "694/695 [============================>.] - ETA: 0s - loss: 0.6323 - mae: 0.5548\n",
      "Epoch 5: val_loss did not improve from 0.63021\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6324 - mae: 0.5548 - val_loss: 0.6354 - val_mae: 0.5583\n",
      "Epoch 6/25\n",
      "684/695 [============================>.] - ETA: 0s - loss: 0.6318 - mae: 0.5543\n",
      "Epoch 6: val_loss improved from 0.63021 to 0.62713, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it8.e006_vl0.627.h5\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6319 - mae: 0.5544 - val_loss: 0.6271 - val_mae: 0.5502\n",
      "Epoch 7/25\n",
      "679/695 [============================>.] - ETA: 0s - loss: 0.6318 - mae: 0.5544\n",
      "Epoch 7: val_loss did not improve from 0.62713\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6319 - mae: 0.5545 - val_loss: 0.6339 - val_mae: 0.5565\n",
      "Epoch 8/25\n",
      "688/695 [============================>.] - ETA: 0s - loss: 0.6328 - mae: 0.5555\n",
      "Epoch 8: val_loss did not improve from 0.62713\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6328 - mae: 0.5554 - val_loss: 0.6341 - val_mae: 0.5558\n",
      "Epoch 9/25\n",
      "683/695 [============================>.] - ETA: 0s - loss: 0.6320 - mae: 0.5547\n",
      "Epoch 9: val_loss did not improve from 0.62713\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6319 - mae: 0.5546 - val_loss: 0.6307 - val_mae: 0.5524\n",
      "Epoch 10/25\n",
      "685/695 [============================>.] - ETA: 0s - loss: 0.6318 - mae: 0.5546\n",
      "Epoch 10: val_loss did not improve from 0.62713\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6317 - mae: 0.5545 - val_loss: 0.6295 - val_mae: 0.5524\n",
      "Epoch 11/25\n",
      "681/695 [============================>.] - ETA: 0s - loss: 0.6313 - mae: 0.5541\n",
      "Epoch 11: val_loss did not improve from 0.62713\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6314 - mae: 0.5542 - val_loss: 0.6373 - val_mae: 0.5599\n",
      "Epoch 12/25\n",
      "683/695 [============================>.] - ETA: 0s - loss: 0.6315 - mae: 0.5544\n",
      "Epoch 12: val_loss did not improve from 0.62713\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6317 - mae: 0.5546 - val_loss: 0.6355 - val_mae: 0.5588\n",
      "Epoch 13/25\n",
      "693/695 [============================>.] - ETA: 0s - loss: 0.6320 - mae: 0.5549\n",
      "Epoch 13: val_loss did not improve from 0.62713\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6320 - mae: 0.5550 - val_loss: 0.6314 - val_mae: 0.5546\n",
      "Epoch 14/25\n",
      "679/695 [============================>.] - ETA: 0s - loss: 0.6319 - mae: 0.5549\n",
      "Epoch 14: val_loss did not improve from 0.62713\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6321 - mae: 0.5551 - val_loss: 0.6365 - val_mae: 0.5595\n",
      "Epoch 15/25\n",
      "684/695 [============================>.] - ETA: 0s - loss: 0.6307 - mae: 0.5537\n",
      "Epoch 15: val_loss did not improve from 0.62713\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6309 - mae: 0.5539 - val_loss: 0.6278 - val_mae: 0.5508\n",
      "Epoch 16/25\n",
      "686/695 [============================>.] - ETA: 0s - loss: 0.6312 - mae: 0.5543\n",
      "Epoch 16: val_loss did not improve from 0.62713\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6313 - mae: 0.5544 - val_loss: 0.6366 - val_mae: 0.5588\n",
      "Epoch 17/25\n",
      "686/695 [============================>.] - ETA: 0s - loss: 0.6319 - mae: 0.5550\n",
      "Epoch 17: val_loss did not improve from 0.62713\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6321 - mae: 0.5552 - val_loss: 0.6317 - val_mae: 0.5544\n",
      "Epoch 18/25\n",
      "677/695 [============================>.] - ETA: 0s - loss: 0.6310 - mae: 0.5541\n",
      "Epoch 18: val_loss did not improve from 0.62713\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6311 - mae: 0.5542 - val_loss: 0.6329 - val_mae: 0.5567\n",
      "Epoch 19/25\n",
      "675/695 [============================>.] - ETA: 0s - loss: 0.6323 - mae: 0.5555\n",
      "Epoch 19: val_loss did not improve from 0.62713\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6322 - mae: 0.5555 - val_loss: 0.6367 - val_mae: 0.5599\n",
      "Epoch 20/25\n",
      "678/695 [============================>.] - ETA: 0s - loss: 0.6320 - mae: 0.5553\n",
      "Epoch 20: val_loss did not improve from 0.62713\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6320 - mae: 0.5553 - val_loss: 0.6362 - val_mae: 0.5590\n",
      "Epoch 21/25\n",
      "682/695 [============================>.] - ETA: 0s - loss: 0.6312 - mae: 0.5545\n",
      "Epoch 21: val_loss did not improve from 0.62713\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6314 - mae: 0.5547 - val_loss: 0.6331 - val_mae: 0.5558\n",
      "Epoch 22/25\n",
      "687/695 [============================>.] - ETA: 0s - loss: 0.6314 - mae: 0.5548\n",
      "Epoch 22: val_loss did not improve from 0.62713\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6314 - mae: 0.5548 - val_loss: 0.6391 - val_mae: 0.5631\n",
      "Epoch 23/25\n",
      "681/695 [============================>.] - ETA: 0s - loss: 0.6313 - mae: 0.5547\n",
      "Epoch 23: val_loss did not improve from 0.62713\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6314 - mae: 0.5548 - val_loss: 0.6317 - val_mae: 0.5550\n",
      "Epoch 24/25\n",
      "689/695 [============================>.] - ETA: 0s - loss: 0.6313 - mae: 0.5548\n",
      "Epoch 24: val_loss did not improve from 0.62713\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6312 - mae: 0.5547 - val_loss: 0.6342 - val_mae: 0.5579\n",
      "Epoch 25/25\n",
      "675/695 [============================>.] - ETA: 0s - loss: 0.6312 - mae: 0.5547\n",
      "Epoch 25: val_loss did not improve from 0.62713\n",
      "695/695 [==============================] - 2s 3ms/step - loss: 0.6314 - mae: 0.5549 - val_loss: 0.6312 - val_mae: 0.5539\n",
      "Time elapsed to train: 56.82 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.251 2.941 1.560 3.255 2.275 1.644 1.172 0.912 0.557 0.297 0.143 0.046 0.000]\n",
      "<R> = [2.253 2.938 1.561 3.255 2.276 1.645 1.172 0.912 0.557 0.297 0.143 0.046 0.000]\n",
      "s_R = [0.021 0.031 0.026 0.109 0.032 0.008 0.013 0.005 0.003 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7249384 3.526071  6.2645006 ... 2.6997774 4.019194  4.4227915]\n",
      "mag_pred: [3.7249384 3.526071  6.2645006 ... 2.6997774 4.019194  4.4227915]\n",
      "Time elapsed to make plots: 18.47 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [35.37338   25.126045   6.9898868 ...  3.2252808 29.79784   14.272332 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0148\n",
      "  1% : 0.114\n",
      "  10% : 0.244\n",
      "  50% : 0.624\n",
      "  90% : 2.94\n",
      "  99% : 85.7\n",
      "  100% : 1.61e+04\n",
      "<chi^2/d.o.f.> = 0.999\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 8000 stars (3.16%) based on chi^2/dof > 15.8\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [10.635703  34.045174  13.156335  ...  2.3894804  5.882144  14.989303 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0295\n",
      "  1% : 0.114\n",
      "  10% : 0.242\n",
      "  50% : 0.629\n",
      "  90% : 2.83\n",
      "  99% : 93.7\n",
      "  100% : 5.2e+03\n",
      "<chi^2/d.o.f.> = 0.984\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 80.34 s\n",
      "learning rate = 0.008521437644958496\n",
      "setting learning rate to 0.008352702114112721\n",
      "Iteration 10 of 20.\n",
      "Epoch 1/25\n",
      "691/692 [============================>.] - ETA: 0s - loss: 0.6243 - mae: 0.5481\n",
      "Epoch 1: val_loss improved from inf to 0.62959, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it9.e001_vl0.630.h5\n",
      "692/692 [==============================] - 3s 4ms/step - loss: 0.6243 - mae: 0.5481 - val_loss: 0.6296 - val_mae: 0.5529\n",
      "Epoch 2/25\n",
      "679/692 [============================>.] - ETA: 0s - loss: 0.6250 - mae: 0.5488\n",
      "Epoch 2: val_loss improved from 0.62959 to 0.62534, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it9.e002_vl0.625.h5\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6250 - mae: 0.5488 - val_loss: 0.6253 - val_mae: 0.5488\n",
      "Epoch 3/25\n",
      "679/692 [============================>.] - ETA: 0s - loss: 0.6252 - mae: 0.5491\n",
      "Epoch 3: val_loss improved from 0.62534 to 0.62308, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it9.e003_vl0.623.h5\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6251 - mae: 0.5489 - val_loss: 0.6231 - val_mae: 0.5475\n",
      "Epoch 4/25\n",
      "689/692 [============================>.] - ETA: 0s - loss: 0.6249 - mae: 0.5488\n",
      "Epoch 4: val_loss did not improve from 0.62308\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6250 - mae: 0.5489 - val_loss: 0.6261 - val_mae: 0.5506\n",
      "Epoch 5/25\n",
      "673/692 [============================>.] - ETA: 0s - loss: 0.6247 - mae: 0.5487\n",
      "Epoch 5: val_loss did not improve from 0.62308\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6248 - mae: 0.5488 - val_loss: 0.6325 - val_mae: 0.5556\n",
      "Epoch 6/25\n",
      "690/692 [============================>.] - ETA: 0s - loss: 0.6242 - mae: 0.5482\n",
      "Epoch 6: val_loss did not improve from 0.62308\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6242 - mae: 0.5483 - val_loss: 0.6343 - val_mae: 0.5574\n",
      "Epoch 7/25\n",
      "692/692 [==============================] - ETA: 0s - loss: 0.6243 - mae: 0.5484\n",
      "Epoch 7: val_loss did not improve from 0.62308\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6243 - mae: 0.5484 - val_loss: 0.6255 - val_mae: 0.5490\n",
      "Epoch 8/25\n",
      "678/692 [============================>.] - ETA: 0s - loss: 0.6248 - mae: 0.5488\n",
      "Epoch 8: val_loss did not improve from 0.62308\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6247 - mae: 0.5487 - val_loss: 0.6234 - val_mae: 0.5477\n",
      "Epoch 9/25\n",
      "677/692 [============================>.] - ETA: 0s - loss: 0.6246 - mae: 0.5488\n",
      "Epoch 9: val_loss did not improve from 0.62308\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6247 - mae: 0.5488 - val_loss: 0.6284 - val_mae: 0.5516\n",
      "Epoch 10/25\n",
      "675/692 [============================>.] - ETA: 0s - loss: 0.6241 - mae: 0.5482\n",
      "Epoch 10: val_loss did not improve from 0.62308\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6242 - mae: 0.5483 - val_loss: 0.6395 - val_mae: 0.5639\n",
      "Epoch 11/25\n",
      "685/692 [============================>.] - ETA: 0s - loss: 0.6248 - mae: 0.5490\n",
      "Epoch 11: val_loss did not improve from 0.62308\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6248 - mae: 0.5490 - val_loss: 0.6249 - val_mae: 0.5493\n",
      "Epoch 12/25\n",
      "675/692 [============================>.] - ETA: 0s - loss: 0.6242 - mae: 0.5485\n",
      "Epoch 12: val_loss did not improve from 0.62308\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6241 - mae: 0.5484 - val_loss: 0.6261 - val_mae: 0.5497\n",
      "Epoch 13/25\n",
      "692/692 [==============================] - ETA: 0s - loss: 0.6243 - mae: 0.5486\n",
      "Epoch 13: val_loss did not improve from 0.62308\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6243 - mae: 0.5486 - val_loss: 0.6335 - val_mae: 0.5579\n",
      "Epoch 14/25\n",
      "692/692 [==============================] - ETA: 0s - loss: 0.6237 - mae: 0.5480\n",
      "Epoch 14: val_loss improved from 0.62308 to 0.62241, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it9.e014_vl0.622.h5\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6237 - mae: 0.5480 - val_loss: 0.6224 - val_mae: 0.5471\n",
      "Epoch 15/25\n",
      "684/692 [============================>.] - ETA: 0s - loss: 0.6244 - mae: 0.5488\n",
      "Epoch 15: val_loss did not improve from 0.62241\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6245 - mae: 0.5488 - val_loss: 0.6263 - val_mae: 0.5506\n",
      "Epoch 16/25\n",
      "680/692 [============================>.] - ETA: 0s - loss: 0.6234 - mae: 0.5479\n",
      "Epoch 16: val_loss did not improve from 0.62241\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6233 - mae: 0.5478 - val_loss: 0.6327 - val_mae: 0.5560\n",
      "Epoch 17/25\n",
      "684/692 [============================>.] - ETA: 0s - loss: 0.6247 - mae: 0.5491\n",
      "Epoch 17: val_loss did not improve from 0.62241\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6247 - mae: 0.5491 - val_loss: 0.6285 - val_mae: 0.5528\n",
      "Epoch 18/25\n",
      "678/692 [============================>.] - ETA: 0s - loss: 0.6242 - mae: 0.5487\n",
      "Epoch 18: val_loss did not improve from 0.62241\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6243 - mae: 0.5488 - val_loss: 0.6250 - val_mae: 0.5498\n",
      "Epoch 19/25\n",
      "679/692 [============================>.] - ETA: 0s - loss: 0.6239 - mae: 0.5484\n",
      "Epoch 19: val_loss did not improve from 0.62241\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6238 - mae: 0.5483 - val_loss: 0.6305 - val_mae: 0.5553\n",
      "Epoch 20/25\n",
      "686/692 [============================>.] - ETA: 0s - loss: 0.6245 - mae: 0.5491\n",
      "Epoch 20: val_loss did not improve from 0.62241\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6245 - mae: 0.5492 - val_loss: 0.6342 - val_mae: 0.5582\n",
      "Epoch 21/25\n",
      "685/692 [============================>.] - ETA: 0s - loss: 0.6244 - mae: 0.5490\n",
      "Epoch 21: val_loss did not improve from 0.62241\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6245 - mae: 0.5491 - val_loss: 0.6249 - val_mae: 0.5499\n",
      "Epoch 22/25\n",
      "678/692 [============================>.] - ETA: 0s - loss: 0.6241 - mae: 0.5488\n",
      "Epoch 22: val_loss did not improve from 0.62241\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6241 - mae: 0.5487 - val_loss: 0.6276 - val_mae: 0.5525\n",
      "Epoch 23/25\n",
      "688/692 [============================>.] - ETA: 0s - loss: 0.6254 - mae: 0.5501\n",
      "Epoch 23: val_loss did not improve from 0.62241\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6254 - mae: 0.5501 - val_loss: 0.6317 - val_mae: 0.5560\n",
      "Epoch 24/25\n",
      "692/692 [==============================] - ETA: 0s - loss: 0.6238 - mae: 0.5485\n",
      "Epoch 24: val_loss improved from 0.62241 to 0.62101, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it9.e024_vl0.621.h5\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6238 - mae: 0.5485 - val_loss: 0.6210 - val_mae: 0.5455\n",
      "Epoch 25/25\n",
      "679/692 [============================>.] - ETA: 0s - loss: 0.6234 - mae: 0.5482\n",
      "Epoch 25: val_loss did not improve from 0.62101\n",
      "692/692 [==============================] - 2s 3ms/step - loss: 0.6234 - mae: 0.5482 - val_loss: 0.6257 - val_mae: 0.5501\n",
      "Time elapsed to train: 56.80 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.250 2.944 1.558 3.293 2.282 1.636 1.171 0.899 0.552 0.292 0.142 0.047 0.000]\n",
      "<R> = [2.250 2.943 1.560 3.293 2.283 1.636 1.171 0.899 0.551 0.292 0.142 0.047 0.000]\n",
      "s_R = [0.055 0.020 0.013 0.086 0.043 0.009 0.012 0.003 0.002 0.001 0.001 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.725306  3.4631517 6.315223  ... 2.6164007 4.0395126 4.454452 ]\n",
      "mag_pred: [3.725306  3.4631517 6.315223  ... 2.6164007 4.0395126 4.454452 ]\n",
      "Time elapsed to make plots: 18.08 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [35.159477  26.671095   7.1822677 ...  2.3397522 32.904053  14.001012 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0177\n",
      "  1% : 0.11\n",
      "  10% : 0.24\n",
      "  50% : 0.625\n",
      "  90% : 2.97\n",
      "  99% : 85.9\n",
      "  100% : 1.63e+04\n",
      "<chi^2/d.o.f.> = 1\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 9305 stars (3.68%) based on chi^2/dof > 12.6\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [10.441693  35.120945  10.995592  ...  1.8155162  7.0444694 13.136864 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0367\n",
      "  1% : 0.111\n",
      "  10% : 0.24\n",
      "  50% : 0.627\n",
      "  90% : 2.85\n",
      "  99% : 93\n",
      "  100% : 5.2e+03\n",
      "<chi^2/d.o.f.> = 0.992\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 78.06 s\n",
      "learning rate = 0.008352702483534813\n",
      "setting learning rate to 0.008187307530779819\n",
      "Iteration 11 of 20.\n",
      "Epoch 1/25\n",
      "673/688 [============================>.] - ETA: 0s - loss: 0.6141 - mae: 0.5391\n",
      "Epoch 1: val_loss improved from inf to 0.61443, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it10.e001_vl0.614.h5\n",
      "688/688 [==============================] - 3s 3ms/step - loss: 0.6143 - mae: 0.5393 - val_loss: 0.6144 - val_mae: 0.5392\n",
      "Epoch 2/25\n",
      "680/688 [============================>.] - ETA: 0s - loss: 0.6151 - mae: 0.5402\n",
      "Epoch 2: val_loss did not improve from 0.61443\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6151 - mae: 0.5403 - val_loss: 0.6182 - val_mae: 0.5432\n",
      "Epoch 3/25\n",
      "672/688 [============================>.] - ETA: 0s - loss: 0.6147 - mae: 0.5399\n",
      "Epoch 3: val_loss did not improve from 0.61443\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6147 - mae: 0.5398 - val_loss: 0.6146 - val_mae: 0.5402\n",
      "Epoch 4/25\n",
      "681/688 [============================>.] - ETA: 0s - loss: 0.6145 - mae: 0.5397\n",
      "Epoch 4: val_loss improved from 0.61443 to 0.61165, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it10.e004_vl0.612.h5\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6146 - mae: 0.5397 - val_loss: 0.6117 - val_mae: 0.5364\n",
      "Epoch 5/25\n",
      "676/688 [============================>.] - ETA: 0s - loss: 0.6148 - mae: 0.5401\n",
      "Epoch 5: val_loss did not improve from 0.61165\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6147 - mae: 0.5400 - val_loss: 0.6206 - val_mae: 0.5453\n",
      "Epoch 6/25\n",
      "670/688 [============================>.] - ETA: 0s - loss: 0.6148 - mae: 0.5400\n",
      "Epoch 6: val_loss did not improve from 0.61165\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6147 - mae: 0.5398 - val_loss: 0.6193 - val_mae: 0.5445\n",
      "Epoch 7/25\n",
      "683/688 [============================>.] - ETA: 0s - loss: 0.6147 - mae: 0.5400\n",
      "Epoch 7: val_loss did not improve from 0.61165\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6146 - mae: 0.5399 - val_loss: 0.6133 - val_mae: 0.5385\n",
      "Epoch 8/25\n",
      "682/688 [============================>.] - ETA: 0s - loss: 0.6146 - mae: 0.5399\n",
      "Epoch 8: val_loss did not improve from 0.61165\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6145 - mae: 0.5399 - val_loss: 0.6126 - val_mae: 0.5379\n",
      "Epoch 9/25\n",
      "681/688 [============================>.] - ETA: 0s - loss: 0.6145 - mae: 0.5398\n",
      "Epoch 9: val_loss did not improve from 0.61165\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6145 - mae: 0.5398 - val_loss: 0.6150 - val_mae: 0.5404\n",
      "Epoch 10/25\n",
      "671/688 [============================>.] - ETA: 0s - loss: 0.6142 - mae: 0.5395\n",
      "Epoch 10: val_loss did not improve from 0.61165\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6142 - mae: 0.5395 - val_loss: 0.6119 - val_mae: 0.5376\n",
      "Epoch 11/25\n",
      "673/688 [============================>.] - ETA: 0s - loss: 0.6139 - mae: 0.5393\n",
      "Epoch 11: val_loss did not improve from 0.61165\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6137 - mae: 0.5392 - val_loss: 0.6156 - val_mae: 0.5414\n",
      "Epoch 12/25\n",
      "681/688 [============================>.] - ETA: 0s - loss: 0.6146 - mae: 0.5401\n",
      "Epoch 12: val_loss improved from 0.61165 to 0.61071, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it10.e012_vl0.611.h5\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6145 - mae: 0.5400 - val_loss: 0.6107 - val_mae: 0.5361\n",
      "Epoch 13/25\n",
      "674/688 [============================>.] - ETA: 0s - loss: 0.6142 - mae: 0.5397\n",
      "Epoch 13: val_loss did not improve from 0.61071\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6141 - mae: 0.5396 - val_loss: 0.6153 - val_mae: 0.5408\n",
      "Epoch 14/25\n",
      "671/688 [============================>.] - ETA: 0s - loss: 0.6136 - mae: 0.5392\n",
      "Epoch 14: val_loss did not improve from 0.61071\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6138 - mae: 0.5394 - val_loss: 0.6152 - val_mae: 0.5404\n",
      "Epoch 15/25\n",
      "668/688 [============================>.] - ETA: 0s - loss: 0.6143 - mae: 0.5399\n",
      "Epoch 15: val_loss did not improve from 0.61071\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6141 - mae: 0.5397 - val_loss: 0.6156 - val_mae: 0.5411\n",
      "Epoch 16/25\n",
      "683/688 [============================>.] - ETA: 0s - loss: 0.6143 - mae: 0.5399\n",
      "Epoch 16: val_loss did not improve from 0.61071\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6143 - mae: 0.5399 - val_loss: 0.6113 - val_mae: 0.5360\n",
      "Epoch 17/25\n",
      "688/688 [==============================] - ETA: 0s - loss: 0.6138 - mae: 0.5395\n",
      "Epoch 17: val_loss did not improve from 0.61071\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6138 - mae: 0.5395 - val_loss: 0.6256 - val_mae: 0.5511\n",
      "Epoch 18/25\n",
      "672/688 [============================>.] - ETA: 0s - loss: 0.6137 - mae: 0.5394\n",
      "Epoch 18: val_loss did not improve from 0.61071\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6138 - mae: 0.5394 - val_loss: 0.6160 - val_mae: 0.5416\n",
      "Epoch 19/25\n",
      "679/688 [============================>.] - ETA: 0s - loss: 0.6145 - mae: 0.5402\n",
      "Epoch 19: val_loss did not improve from 0.61071\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6145 - mae: 0.5402 - val_loss: 0.6181 - val_mae: 0.5434\n",
      "Epoch 20/25\n",
      "681/688 [============================>.] - ETA: 0s - loss: 0.6141 - mae: 0.5398\n",
      "Epoch 20: val_loss did not improve from 0.61071\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6140 - mae: 0.5397 - val_loss: 0.6126 - val_mae: 0.5384\n",
      "Epoch 21/25\n",
      "675/688 [============================>.] - ETA: 0s - loss: 0.6141 - mae: 0.5398\n",
      "Epoch 21: val_loss did not improve from 0.61071\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6141 - mae: 0.5398 - val_loss: 0.6111 - val_mae: 0.5364\n",
      "Epoch 22/25\n",
      "677/688 [============================>.] - ETA: 0s - loss: 0.6135 - mae: 0.5393\n",
      "Epoch 22: val_loss did not improve from 0.61071\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6138 - mae: 0.5395 - val_loss: 0.6109 - val_mae: 0.5370\n",
      "Epoch 23/25\n",
      "667/688 [============================>.] - ETA: 0s - loss: 0.6144 - mae: 0.5402\n",
      "Epoch 23: val_loss did not improve from 0.61071\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6145 - mae: 0.5403 - val_loss: 0.6114 - val_mae: 0.5371\n",
      "Epoch 24/25\n",
      "673/688 [============================>.] - ETA: 0s - loss: 0.6138 - mae: 0.5396\n",
      "Epoch 24: val_loss did not improve from 0.61071\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6138 - mae: 0.5396 - val_loss: 0.6121 - val_mae: 0.5378\n",
      "Epoch 25/25\n",
      "686/688 [============================>.] - ETA: 0s - loss: 0.6138 - mae: 0.5398\n",
      "Epoch 25: val_loss improved from 0.61071 to 0.61061, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it10.e025_vl0.611.h5\n",
      "688/688 [==============================] - 2s 3ms/step - loss: 0.6138 - mae: 0.5398 - val_loss: 0.6106 - val_mae: 0.5366\n",
      "Time elapsed to train: 55.45 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.231 2.918 1.540 3.249 2.257 1.631 1.158 0.890 0.557 0.280 0.141 0.044 0.000]\n",
      "<R> = [2.231 2.918 1.540 3.249 2.257 1.632 1.158 0.890 0.557 0.280 0.141 0.044 0.000]\n",
      "s_R = [0.018 0.003 0.020 0.097 0.044 0.010 0.002 0.011 0.001 0.001 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7271633 3.533167  6.2907796 ... 2.718985  4.0077715 4.418587 ]\n",
      "mag_pred: [3.7271633 3.533167  6.2907796 ... 2.718985  4.0077715 4.418587 ]\n",
      "Time elapsed to make plots: 20.74 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [34.92753   25.577139   6.6281643 ...  3.0905209 32.570293  13.331951 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0159\n",
      "  1% : 0.108\n",
      "  10% : 0.236\n",
      "  50% : 0.622\n",
      "  90% : 3.02\n",
      "  99% : 85.6\n",
      "  100% : 1.61e+04\n",
      "<chi^2/d.o.f.> = 1\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 10942 stars (4.32%) based on chi^2/dof > 10.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.777461 33.971413 13.272999 ...  2.48244   6.602003 16.058725]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0304\n",
      "  1% : 0.11\n",
      "  10% : 0.234\n",
      "  50% : 0.625\n",
      "  90% : 2.87\n",
      "  99% : 92.5\n",
      "  100% : 5.2e+03\n",
      "<chi^2/d.o.f.> = 0.992\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 78.92 s\n",
      "learning rate = 0.008187307976186275\n",
      "setting learning rate to 0.008025187979624785\n",
      "Iteration 12 of 20.\n",
      "Epoch 1/25\n",
      "669/684 [============================>.] - ETA: 0s - loss: 0.6074 - mae: 0.5335\n",
      "Epoch 1: val_loss improved from inf to 0.63839, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it11.e001_vl0.638.h5\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6075 - mae: 0.5336 - val_loss: 0.6384 - val_mae: 0.5641\n",
      "Epoch 2/25\n",
      "677/684 [============================>.] - ETA: 0s - loss: 0.6087 - mae: 0.5347\n",
      "Epoch 2: val_loss improved from 0.63839 to 0.62907, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it11.e002_vl0.629.h5\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6086 - mae: 0.5347 - val_loss: 0.6291 - val_mae: 0.5553\n",
      "Epoch 3/25\n",
      "673/684 [============================>.] - ETA: 0s - loss: 0.6080 - mae: 0.5342\n",
      "Epoch 3: val_loss did not improve from 0.62907\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6081 - mae: 0.5342 - val_loss: 0.6355 - val_mae: 0.5614\n",
      "Epoch 4/25\n",
      "666/684 [============================>.] - ETA: 0s - loss: 0.6084 - mae: 0.5345\n",
      "Epoch 4: val_loss improved from 0.62907 to 0.61924, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it11.e004_vl0.619.h5\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6084 - mae: 0.5345 - val_loss: 0.6192 - val_mae: 0.5450\n",
      "Epoch 5/25\n",
      "665/684 [============================>.] - ETA: 0s - loss: 0.6075 - mae: 0.5336\n",
      "Epoch 5: val_loss did not improve from 0.61924\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6075 - mae: 0.5337 - val_loss: 0.6389 - val_mae: 0.5640\n",
      "Epoch 6/25\n",
      "676/684 [============================>.] - ETA: 0s - loss: 0.6080 - mae: 0.5342\n",
      "Epoch 6: val_loss did not improve from 0.61924\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6080 - mae: 0.5341 - val_loss: 0.6649 - val_mae: 0.5907\n",
      "Epoch 7/25\n",
      "667/684 [============================>.] - ETA: 0s - loss: 0.6074 - mae: 0.5337\n",
      "Epoch 7: val_loss did not improve from 0.61924\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6074 - mae: 0.5336 - val_loss: 0.6381 - val_mae: 0.5637\n",
      "Epoch 8/25\n",
      "666/684 [============================>.] - ETA: 0s - loss: 0.6089 - mae: 0.5350\n",
      "Epoch 8: val_loss did not improve from 0.61924\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6087 - mae: 0.5349 - val_loss: 0.6416 - val_mae: 0.5671\n",
      "Epoch 9/25\n",
      "665/684 [============================>.] - ETA: 0s - loss: 0.6080 - mae: 0.5343\n",
      "Epoch 9: val_loss did not improve from 0.61924\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6080 - mae: 0.5343 - val_loss: 0.6302 - val_mae: 0.5562\n",
      "Epoch 10/25\n",
      "673/684 [============================>.] - ETA: 0s - loss: 0.6078 - mae: 0.5340\n",
      "Epoch 10: val_loss did not improve from 0.61924\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6078 - mae: 0.5341 - val_loss: 0.6527 - val_mae: 0.5785\n",
      "Epoch 11/25\n",
      "668/684 [============================>.] - ETA: 0s - loss: 0.6084 - mae: 0.5347\n",
      "Epoch 11: val_loss did not improve from 0.61924\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6083 - mae: 0.5346 - val_loss: 0.6377 - val_mae: 0.5639\n",
      "Epoch 12/25\n",
      "683/684 [============================>.] - ETA: 0s - loss: 0.6076 - mae: 0.5339\n",
      "Epoch 12: val_loss improved from 0.61924 to 0.60572, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it11.e012_vl0.606.h5\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6076 - mae: 0.5339 - val_loss: 0.6057 - val_mae: 0.5313\n",
      "Epoch 13/25\n",
      "666/684 [============================>.] - ETA: 0s - loss: 0.6069 - mae: 0.5332\n",
      "Epoch 13: val_loss did not improve from 0.60572\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6072 - mae: 0.5334 - val_loss: 0.6584 - val_mae: 0.5849\n",
      "Epoch 14/25\n",
      "672/684 [============================>.] - ETA: 0s - loss: 0.6074 - mae: 0.5338\n",
      "Epoch 14: val_loss did not improve from 0.60572\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6074 - mae: 0.5339 - val_loss: 0.6405 - val_mae: 0.5666\n",
      "Epoch 15/25\n",
      "678/684 [============================>.] - ETA: 0s - loss: 0.6076 - mae: 0.5339\n",
      "Epoch 15: val_loss did not improve from 0.60572\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6075 - mae: 0.5338 - val_loss: 0.6234 - val_mae: 0.5500\n",
      "Epoch 16/25\n",
      "681/684 [============================>.] - ETA: 0s - loss: 0.6073 - mae: 0.5337\n",
      "Epoch 16: val_loss did not improve from 0.60572\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6073 - mae: 0.5337 - val_loss: 0.6298 - val_mae: 0.5566\n",
      "Epoch 17/25\n",
      "680/684 [============================>.] - ETA: 0s - loss: 0.6075 - mae: 0.5340\n",
      "Epoch 17: val_loss did not improve from 0.60572\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6075 - mae: 0.5340 - val_loss: 0.6362 - val_mae: 0.5627\n",
      "Epoch 18/25\n",
      "666/684 [============================>.] - ETA: 0s - loss: 0.6079 - mae: 0.5345\n",
      "Epoch 18: val_loss did not improve from 0.60572\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6080 - mae: 0.5346 - val_loss: 0.6888 - val_mae: 0.6142\n",
      "Epoch 19/25\n",
      "670/684 [============================>.] - ETA: 0s - loss: 0.6073 - mae: 0.5338\n",
      "Epoch 19: val_loss did not improve from 0.60572\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6074 - mae: 0.5339 - val_loss: 0.6125 - val_mae: 0.5385\n",
      "Epoch 20/25\n",
      "665/684 [============================>.] - ETA: 0s - loss: 0.6073 - mae: 0.5338\n",
      "Epoch 20: val_loss did not improve from 0.60572\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6073 - mae: 0.5339 - val_loss: 0.6453 - val_mae: 0.5717\n",
      "Epoch 21/25\n",
      "678/684 [============================>.] - ETA: 0s - loss: 0.6079 - mae: 0.5344\n",
      "Epoch 21: val_loss did not improve from 0.60572\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6078 - mae: 0.5344 - val_loss: 0.6313 - val_mae: 0.5573\n",
      "Epoch 22/25\n",
      "669/684 [============================>.] - ETA: 0s - loss: 0.6076 - mae: 0.5342\n",
      "Epoch 22: val_loss did not improve from 0.60572\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6077 - mae: 0.5343 - val_loss: 0.6252 - val_mae: 0.5510\n",
      "Epoch 23/25\n",
      "664/684 [============================>.] - ETA: 0s - loss: 0.6070 - mae: 0.5336\n",
      "Epoch 23: val_loss did not improve from 0.60572\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6070 - mae: 0.5336 - val_loss: 0.6215 - val_mae: 0.5484\n",
      "Epoch 24/25\n",
      "669/684 [============================>.] - ETA: 0s - loss: 0.6071 - mae: 0.5337\n",
      "Epoch 24: val_loss did not improve from 0.60572\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6070 - mae: 0.5337 - val_loss: 0.6507 - val_mae: 0.5766\n",
      "Epoch 25/25\n",
      "678/684 [============================>.] - ETA: 0s - loss: 0.6072 - mae: 0.5338\n",
      "Epoch 25: val_loss did not improve from 0.60572\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6072 - mae: 0.5338 - val_loss: 0.6676 - val_mae: 0.5932\n",
      "Time elapsed to train: 57.42 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.238 2.921 1.542 3.256 2.262 1.627 1.161 0.894 0.558 0.280 0.135 0.043 0.000]\n",
      "<R> = [2.238 2.920 1.541 3.256 2.261 1.628 1.161 0.894 0.559 0.280 0.135 0.043 0.000]\n",
      "s_R = [0.038 0.028 0.020 0.081 0.021 0.030 0.005 0.009 0.001 0.001 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7135413 3.4569292 6.257512  ... 2.7072015 4.012925  4.414361 ]\n",
      "mag_pred: [3.7135413 3.4569292 6.257512  ... 2.7072015 4.012925  4.414361 ]\n",
      "Time elapsed to make plots: 18.10 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [37.90799   20.7089    11.017115  ...  6.2732987 21.771889  15.325245 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0187\n",
      "  1% : 0.156\n",
      "  10% : 0.325\n",
      "  50% : 0.749\n",
      "  90% : 2.83\n",
      "  99% : 85.1\n",
      "  100% : 1.49e+04\n",
      "<chi^2/d.o.f.> = 1.08\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 12428 stars (4.91%) based on chi^2/dof > 7.9\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [14.8394985 34.19468   14.399615  ...  2.7825677  7.2601256 14.958161 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0264\n",
      "  1% : 0.157\n",
      "  10% : 0.326\n",
      "  50% : 0.749\n",
      "  90% : 2.75\n",
      "  99% : 93.2\n",
      "  100% : 5.18e+03\n",
      "<chi^2/d.o.f.> = 1.07\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 81.00 s\n",
      "learning rate = 0.008025187999010086\n",
      "setting learning rate to 0.007866278610665535\n",
      "Iteration 13 of 20.\n",
      "Epoch 1/25\n",
      "664/679 [============================>.] - ETA: 0s - loss: 0.5980 - mae: 0.5250\n",
      "Epoch 1: val_loss improved from inf to 0.59894, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it12.e001_vl0.599.h5\n",
      "679/679 [==============================] - 3s 3ms/step - loss: 0.5981 - mae: 0.5251 - val_loss: 0.5989 - val_mae: 0.5257\n",
      "Epoch 2/25\n",
      "670/679 [============================>.] - ETA: 0s - loss: 0.5981 - mae: 0.5252\n",
      "Epoch 2: val_loss did not improve from 0.59894\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5983 - mae: 0.5254 - val_loss: 0.5992 - val_mae: 0.5265\n",
      "Epoch 3/25\n",
      "665/679 [============================>.] - ETA: 0s - loss: 0.5970 - mae: 0.5243\n",
      "Epoch 3: val_loss improved from 0.59894 to 0.59698, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it12.e003_vl0.597.h5\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5970 - mae: 0.5242 - val_loss: 0.5970 - val_mae: 0.5247\n",
      "Epoch 4/25\n",
      "661/679 [============================>.] - ETA: 0s - loss: 0.5974 - mae: 0.5246\n",
      "Epoch 4: val_loss improved from 0.59698 to 0.59632, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it12.e004_vl0.596.h5\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5973 - mae: 0.5246 - val_loss: 0.5963 - val_mae: 0.5234\n",
      "Epoch 5/25\n",
      "679/679 [==============================] - ETA: 0s - loss: 0.5973 - mae: 0.5247\n",
      "Epoch 5: val_loss did not improve from 0.59632\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5973 - mae: 0.5247 - val_loss: 0.5997 - val_mae: 0.5266\n",
      "Epoch 6/25\n",
      "666/679 [============================>.] - ETA: 0s - loss: 0.5976 - mae: 0.5249\n",
      "Epoch 6: val_loss did not improve from 0.59632\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5975 - mae: 0.5248 - val_loss: 0.5965 - val_mae: 0.5244\n",
      "Epoch 7/25\n",
      "674/679 [============================>.] - ETA: 0s - loss: 0.5977 - mae: 0.5250\n",
      "Epoch 7: val_loss improved from 0.59632 to 0.59341, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it12.e007_vl0.593.h5\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5978 - mae: 0.5251 - val_loss: 0.5934 - val_mae: 0.5210\n",
      "Epoch 8/25\n",
      "679/679 [==============================] - ETA: 0s - loss: 0.5982 - mae: 0.5255\n",
      "Epoch 8: val_loss did not improve from 0.59341\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5982 - mae: 0.5255 - val_loss: 0.5950 - val_mae: 0.5230\n",
      "Epoch 9/25\n",
      "664/679 [============================>.] - ETA: 0s - loss: 0.5968 - mae: 0.5242\n",
      "Epoch 9: val_loss improved from 0.59341 to 0.59263, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it12.e009_vl0.593.h5\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5967 - mae: 0.5240 - val_loss: 0.5926 - val_mae: 0.5201\n",
      "Epoch 10/25\n",
      "674/679 [============================>.] - ETA: 0s - loss: 0.5979 - mae: 0.5254\n",
      "Epoch 10: val_loss did not improve from 0.59263\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5979 - mae: 0.5254 - val_loss: 0.5947 - val_mae: 0.5225\n",
      "Epoch 11/25\n",
      "659/679 [============================>.] - ETA: 0s - loss: 0.5968 - mae: 0.5243\n",
      "Epoch 11: val_loss did not improve from 0.59263\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5969 - mae: 0.5243 - val_loss: 0.6010 - val_mae: 0.5287\n",
      "Epoch 12/25\n",
      "668/679 [============================>.] - ETA: 0s - loss: 0.5969 - mae: 0.5244\n",
      "Epoch 12: val_loss did not improve from 0.59263\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5969 - mae: 0.5244 - val_loss: 0.5960 - val_mae: 0.5237\n",
      "Epoch 13/25\n",
      "672/679 [============================>.] - ETA: 0s - loss: 0.5972 - mae: 0.5248\n",
      "Epoch 13: val_loss did not improve from 0.59263\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5973 - mae: 0.5248 - val_loss: 0.5996 - val_mae: 0.5274\n",
      "Epoch 14/25\n",
      "665/679 [============================>.] - ETA: 0s - loss: 0.5983 - mae: 0.5258\n",
      "Epoch 14: val_loss did not improve from 0.59263\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5981 - mae: 0.5257 - val_loss: 0.5941 - val_mae: 0.5217\n",
      "Epoch 15/25\n",
      "677/679 [============================>.] - ETA: 0s - loss: 0.5973 - mae: 0.5249\n",
      "Epoch 15: val_loss did not improve from 0.59263\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5973 - mae: 0.5249 - val_loss: 0.5963 - val_mae: 0.5238\n",
      "Epoch 16/25\n",
      "663/679 [============================>.] - ETA: 0s - loss: 0.5972 - mae: 0.5249\n",
      "Epoch 16: val_loss did not improve from 0.59263\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5973 - mae: 0.5250 - val_loss: 0.6019 - val_mae: 0.5294\n",
      "Epoch 17/25\n",
      "670/679 [============================>.] - ETA: 0s - loss: 0.5968 - mae: 0.5245\n",
      "Epoch 17: val_loss did not improve from 0.59263\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5967 - mae: 0.5243 - val_loss: 0.5935 - val_mae: 0.5210\n",
      "Epoch 18/25\n",
      "678/679 [============================>.] - ETA: 0s - loss: 0.5976 - mae: 0.5252\n",
      "Epoch 18: val_loss did not improve from 0.59263\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5976 - mae: 0.5252 - val_loss: 0.5955 - val_mae: 0.5229\n",
      "Epoch 19/25\n",
      "676/679 [============================>.] - ETA: 0s - loss: 0.5969 - mae: 0.5246\n",
      "Epoch 19: val_loss did not improve from 0.59263\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5968 - mae: 0.5246 - val_loss: 0.5982 - val_mae: 0.5264\n",
      "Epoch 20/25\n",
      "660/679 [============================>.] - ETA: 0s - loss: 0.5972 - mae: 0.5249\n",
      "Epoch 20: val_loss did not improve from 0.59263\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5972 - mae: 0.5249 - val_loss: 0.5953 - val_mae: 0.5227\n",
      "Epoch 21/25\n",
      "660/679 [============================>.] - ETA: 0s - loss: 0.5967 - mae: 0.5245\n",
      "Epoch 21: val_loss did not improve from 0.59263\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5967 - mae: 0.5245 - val_loss: 0.5951 - val_mae: 0.5227\n",
      "Epoch 22/25\n",
      "659/679 [============================>.] - ETA: 0s - loss: 0.5970 - mae: 0.5248\n",
      "Epoch 22: val_loss did not improve from 0.59263\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5970 - mae: 0.5248 - val_loss: 0.6052 - val_mae: 0.5341\n",
      "Epoch 23/25\n",
      "678/679 [============================>.] - ETA: 0s - loss: 0.5972 - mae: 0.5251\n",
      "Epoch 23: val_loss improved from 0.59263 to 0.59241, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it12.e023_vl0.592.h5\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5973 - mae: 0.5251 - val_loss: 0.5924 - val_mae: 0.5194\n",
      "Epoch 24/25\n",
      "670/679 [============================>.] - ETA: 0s - loss: 0.5968 - mae: 0.5246\n",
      "Epoch 24: val_loss did not improve from 0.59241\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5968 - mae: 0.5246 - val_loss: 0.5980 - val_mae: 0.5259\n",
      "Epoch 25/25\n",
      "664/679 [============================>.] - ETA: 0s - loss: 0.5964 - mae: 0.5242\n",
      "Epoch 25: val_loss did not improve from 0.59241\n",
      "679/679 [==============================] - 2s 3ms/step - loss: 0.5965 - mae: 0.5243 - val_loss: 0.5933 - val_mae: 0.5209\n",
      "Time elapsed to train: 56.20 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.218 2.891 1.537 3.232 2.242 1.620 1.161 0.886 0.548 0.272 0.133 0.041 0.000]\n",
      "<R> = [2.219 2.892 1.539 3.231 2.242 1.620 1.161 0.887 0.548 0.272 0.133 0.041 0.000]\n",
      "s_R = [0.031 0.008 0.012 0.090 0.015 0.013 0.004 0.001 0.003 0.002 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7663872 3.515444  6.294269  ... 2.7628968 4.0564585 4.456208 ]\n",
      "mag_pred: [3.7663872 3.515444  6.294269  ... 2.7628968 4.0564585 4.456208 ]\n",
      "Time elapsed to make plots: 17.98 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [37.30417   25.595253   5.97184   ...  2.5354586 32.736515  12.532759 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.015\n",
      "  1% : 0.104\n",
      "  10% : 0.231\n",
      "  50% : 0.612\n",
      "  90% : 3.01\n",
      "  99% : 86.7\n",
      "  100% : 1.47e+04\n",
      "<chi^2/d.o.f.> = 0.996\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 14850 stars (5.87%) based on chi^2/dof > 6.3\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [10.510613  33.736954  11.827504  ...  2.2257843  6.7279387 15.282526 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0217\n",
      "  1% : 0.107\n",
      "  10% : 0.231\n",
      "  50% : 0.616\n",
      "  90% : 2.87\n",
      "  99% : 94.7\n",
      "  100% : 5.21e+03\n",
      "<chi^2/d.o.f.> = 0.984\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 80.98 s\n",
      "learning rate = 0.007866278290748596\n",
      "setting learning rate to 0.007710515858035663\n",
      "Iteration 14 of 20.\n",
      "Epoch 1/25\n",
      "672/673 [============================>.] - ETA: 0s - loss: 0.5887 - mae: 0.5167\n",
      "Epoch 1: val_loss improved from inf to 0.68019, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it13.e001_vl0.680.h5\n",
      "673/673 [==============================] - 3s 4ms/step - loss: 0.5887 - mae: 0.5167 - val_loss: 0.6802 - val_mae: 0.6078\n",
      "Epoch 2/25\n",
      "666/673 [============================>.] - ETA: 0s - loss: 0.5903 - mae: 0.5183\n",
      "Epoch 2: val_loss improved from 0.68019 to 0.66538, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it13.e002_vl0.665.h5\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5903 - mae: 0.5183 - val_loss: 0.6654 - val_mae: 0.5933\n",
      "Epoch 3/25\n",
      "666/673 [============================>.] - ETA: 0s - loss: 0.5894 - mae: 0.5175\n",
      "Epoch 3: val_loss improved from 0.66538 to 0.61168, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it13.e003_vl0.612.h5\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5894 - mae: 0.5175 - val_loss: 0.6117 - val_mae: 0.5384\n",
      "Epoch 4/25\n",
      "653/673 [============================>.] - ETA: 0s - loss: 0.5894 - mae: 0.5174\n",
      "Epoch 4: val_loss did not improve from 0.61168\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5894 - mae: 0.5174 - val_loss: 0.6378 - val_mae: 0.5644\n",
      "Epoch 5/25\n",
      "670/673 [============================>.] - ETA: 0s - loss: 0.5890 - mae: 0.5171\n",
      "Epoch 5: val_loss did not improve from 0.61168\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5890 - mae: 0.5171 - val_loss: 0.6338 - val_mae: 0.5613\n",
      "Epoch 6/25\n",
      "671/673 [============================>.] - ETA: 0s - loss: 0.5891 - mae: 0.5172\n",
      "Epoch 6: val_loss did not improve from 0.61168\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5891 - mae: 0.5172 - val_loss: 0.6490 - val_mae: 0.5766\n",
      "Epoch 7/25\n",
      "667/673 [============================>.] - ETA: 0s - loss: 0.5897 - mae: 0.5177\n",
      "Epoch 7: val_loss did not improve from 0.61168\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5896 - mae: 0.5177 - val_loss: 0.6270 - val_mae: 0.5542\n",
      "Epoch 8/25\n",
      "669/673 [============================>.] - ETA: 0s - loss: 0.5887 - mae: 0.5169\n",
      "Epoch 8: val_loss did not improve from 0.61168\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5887 - mae: 0.5169 - val_loss: 0.6180 - val_mae: 0.5460\n",
      "Epoch 9/25\n",
      "653/673 [============================>.] - ETA: 0s - loss: 0.5888 - mae: 0.5170\n",
      "Epoch 9: val_loss did not improve from 0.61168\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5888 - mae: 0.5170 - val_loss: 0.6725 - val_mae: 0.5999\n",
      "Epoch 10/25\n",
      "665/673 [============================>.] - ETA: 0s - loss: 0.5896 - mae: 0.5178\n",
      "Epoch 10: val_loss did not improve from 0.61168\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5896 - mae: 0.5178 - val_loss: 0.6591 - val_mae: 0.5862\n",
      "Epoch 11/25\n",
      "661/673 [============================>.] - ETA: 0s - loss: 0.5884 - mae: 0.5164\n",
      "Epoch 11: val_loss did not improve from 0.61168\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5884 - mae: 0.5164 - val_loss: 0.6654 - val_mae: 0.5928\n",
      "Epoch 12/25\n",
      "671/673 [============================>.] - ETA: 0s - loss: 0.5887 - mae: 0.5169\n",
      "Epoch 12: val_loss did not improve from 0.61168\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5887 - mae: 0.5169 - val_loss: 0.6903 - val_mae: 0.6184\n",
      "Epoch 13/25\n",
      "663/673 [============================>.] - ETA: 0s - loss: 0.5894 - mae: 0.5176\n",
      "Epoch 13: val_loss did not improve from 0.61168\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5894 - mae: 0.5176 - val_loss: 0.6609 - val_mae: 0.5881\n",
      "Epoch 14/25\n",
      "672/673 [============================>.] - ETA: 0s - loss: 0.5895 - mae: 0.5177\n",
      "Epoch 14: val_loss did not improve from 0.61168\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5895 - mae: 0.5177 - val_loss: 0.6976 - val_mae: 0.6262\n",
      "Epoch 15/25\n",
      "672/673 [============================>.] - ETA: 0s - loss: 0.5897 - mae: 0.5179\n",
      "Epoch 15: val_loss did not improve from 0.61168\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5897 - mae: 0.5179 - val_loss: 0.6717 - val_mae: 0.5998\n",
      "Epoch 16/25\n",
      "667/673 [============================>.] - ETA: 0s - loss: 0.5890 - mae: 0.5173\n",
      "Epoch 16: val_loss did not improve from 0.61168\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5890 - mae: 0.5173 - val_loss: 0.6195 - val_mae: 0.5470\n",
      "Epoch 17/25\n",
      "669/673 [============================>.] - ETA: 0s - loss: 0.5887 - mae: 0.5170\n",
      "Epoch 17: val_loss did not improve from 0.61168\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5887 - mae: 0.5170 - val_loss: 0.6402 - val_mae: 0.5684\n",
      "Epoch 18/25\n",
      "664/673 [============================>.] - ETA: 0s - loss: 0.5893 - mae: 0.5177\n",
      "Epoch 18: val_loss improved from 0.61168 to 0.59913, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it13.e018_vl0.599.h5\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5893 - mae: 0.5176 - val_loss: 0.5991 - val_mae: 0.5272\n",
      "Epoch 19/25\n",
      "660/673 [============================>.] - ETA: 0s - loss: 0.5884 - mae: 0.5168\n",
      "Epoch 19: val_loss did not improve from 0.59913\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5884 - mae: 0.5168 - val_loss: 0.6683 - val_mae: 0.5962\n",
      "Epoch 20/25\n",
      "673/673 [==============================] - ETA: 0s - loss: 0.5886 - mae: 0.5169\n",
      "Epoch 20: val_loss did not improve from 0.59913\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5886 - mae: 0.5169 - val_loss: 0.6233 - val_mae: 0.5513\n",
      "Epoch 21/25\n",
      "653/673 [============================>.] - ETA: 0s - loss: 0.5889 - mae: 0.5173\n",
      "Epoch 21: val_loss did not improve from 0.59913\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5888 - mae: 0.5171 - val_loss: 0.6708 - val_mae: 0.5993\n",
      "Epoch 22/25\n",
      "666/673 [============================>.] - ETA: 0s - loss: 0.5891 - mae: 0.5176\n",
      "Epoch 22: val_loss did not improve from 0.59913\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5891 - mae: 0.5175 - val_loss: 0.7145 - val_mae: 0.6423\n",
      "Epoch 23/25\n",
      "656/673 [============================>.] - ETA: 0s - loss: 0.5903 - mae: 0.5187\n",
      "Epoch 23: val_loss did not improve from 0.59913\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5902 - mae: 0.5186 - val_loss: 0.6628 - val_mae: 0.5912\n",
      "Epoch 24/25\n",
      "664/673 [============================>.] - ETA: 0s - loss: 0.5888 - mae: 0.5173\n",
      "Epoch 24: val_loss did not improve from 0.59913\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5889 - mae: 0.5174 - val_loss: 0.6892 - val_mae: 0.6176\n",
      "Epoch 25/25\n",
      "657/673 [============================>.] - ETA: 0s - loss: 0.5891 - mae: 0.5176\n",
      "Epoch 25: val_loss did not improve from 0.59913\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 0.5891 - mae: 0.5176 - val_loss: 0.6223 - val_mae: 0.5497\n",
      "Time elapsed to train: 54.87 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.222 2.877 1.532 3.220 2.231 1.615 1.147 0.881 0.542 0.276 0.129 0.041 0.000]\n",
      "<R> = [2.223 2.877 1.532 3.220 2.231 1.613 1.148 0.881 0.542 0.276 0.130 0.041 0.000]\n",
      "s_R = [0.020 0.031 0.009 0.043 0.029 0.010 0.020 0.006 0.001 0.001 0.001 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6360219 3.171477  6.15612   ... 2.3547215 3.983341  4.377734 ]\n",
      "mag_pred: [3.6360219 3.171477  6.15612   ... 2.3547215 3.983341  4.377734 ]\n",
      "Time elapsed to make plots: 21.35 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [32.95254  26.259827 12.117533 ...  4.462426 28.86012  14.844061]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0316\n",
      "  1% : 0.143\n",
      "  10% : 0.283\n",
      "  50% : 0.666\n",
      "  90% : 2.97\n",
      "  99% : 86.4\n",
      "  100% : 1.6e+04\n",
      "<chi^2/d.o.f.> = 1.03\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 17216 stars (6.8%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [10.349152  35.161156  16.219175  ...  3.0722337  7.369153  15.032788 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0317\n",
      "  1% : 0.142\n",
      "  10% : 0.283\n",
      "  50% : 0.668\n",
      "  90% : 2.87\n",
      "  99% : 92.6\n",
      "  100% : 5.2e+03\n",
      "<chi^2/d.o.f.> = 1.02\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 76.14 s\n",
      "learning rate = 0.007710515987128019\n",
      "setting learning rate to 0.007557837414557255\n",
      "Iteration 15 of 20.\n",
      "Epoch 1/25\n",
      "662/666 [============================>.] - ETA: 0s - loss: 0.5762 - mae: 0.5051\n",
      "Epoch 1: val_loss improved from inf to 0.58095, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it14.e001_vl0.581.h5\n",
      "666/666 [==============================] - 3s 4ms/step - loss: 0.5763 - mae: 0.5051 - val_loss: 0.5809 - val_mae: 0.5099\n",
      "Epoch 2/25\n",
      "655/666 [============================>.] - ETA: 0s - loss: 0.5758 - mae: 0.5047\n",
      "Epoch 2: val_loss improved from 0.58095 to 0.57957, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it14.e002_vl0.580.h5\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5758 - mae: 0.5047 - val_loss: 0.5796 - val_mae: 0.5084\n",
      "Epoch 3/25\n",
      "657/666 [============================>.] - ETA: 0s - loss: 0.5762 - mae: 0.5052\n",
      "Epoch 3: val_loss improved from 0.57957 to 0.57790, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it14.e003_vl0.578.h5\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5762 - mae: 0.5052 - val_loss: 0.5779 - val_mae: 0.5063\n",
      "Epoch 4/25\n",
      "655/666 [============================>.] - ETA: 0s - loss: 0.5764 - mae: 0.5055\n",
      "Epoch 4: val_loss did not improve from 0.57790\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5763 - mae: 0.5053 - val_loss: 0.5782 - val_mae: 0.5071\n",
      "Epoch 5/25\n",
      "648/666 [============================>.] - ETA: 0s - loss: 0.5761 - mae: 0.5052\n",
      "Epoch 5: val_loss improved from 0.57790 to 0.57567, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it14.e005_vl0.576.h5\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5760 - mae: 0.5050 - val_loss: 0.5757 - val_mae: 0.5053\n",
      "Epoch 6/25\n",
      "651/666 [============================>.] - ETA: 0s - loss: 0.5764 - mae: 0.5056\n",
      "Epoch 6: val_loss did not improve from 0.57567\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5764 - mae: 0.5055 - val_loss: 0.5777 - val_mae: 0.5068\n",
      "Epoch 7/25\n",
      "654/666 [============================>.] - ETA: 0s - loss: 0.5764 - mae: 0.5055\n",
      "Epoch 7: val_loss improved from 0.57567 to 0.57309, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it14.e007_vl0.573.h5\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5763 - mae: 0.5054 - val_loss: 0.5731 - val_mae: 0.5020\n",
      "Epoch 8/25\n",
      "652/666 [============================>.] - ETA: 0s - loss: 0.5760 - mae: 0.5052\n",
      "Epoch 8: val_loss did not improve from 0.57309\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5761 - mae: 0.5052 - val_loss: 0.5767 - val_mae: 0.5053\n",
      "Epoch 9/25\n",
      "663/666 [============================>.] - ETA: 0s - loss: 0.5759 - mae: 0.5051\n",
      "Epoch 9: val_loss did not improve from 0.57309\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5760 - mae: 0.5052 - val_loss: 0.5821 - val_mae: 0.5113\n",
      "Epoch 10/25\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.5762 - mae: 0.5053\n",
      "Epoch 10: val_loss did not improve from 0.57309\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5762 - mae: 0.5053 - val_loss: 0.5789 - val_mae: 0.5084\n",
      "Epoch 11/25\n",
      "649/666 [============================>.] - ETA: 0s - loss: 0.5758 - mae: 0.5051\n",
      "Epoch 11: val_loss improved from 0.57309 to 0.57244, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it14.e011_vl0.572.h5\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5759 - mae: 0.5051 - val_loss: 0.5724 - val_mae: 0.5021\n",
      "Epoch 12/25\n",
      "657/666 [============================>.] - ETA: 0s - loss: 0.5758 - mae: 0.5051\n",
      "Epoch 12: val_loss did not improve from 0.57244\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5757 - mae: 0.5050 - val_loss: 0.5754 - val_mae: 0.5043\n",
      "Epoch 13/25\n",
      "650/666 [============================>.] - ETA: 0s - loss: 0.5764 - mae: 0.5057\n",
      "Epoch 13: val_loss did not improve from 0.57244\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5765 - mae: 0.5058 - val_loss: 0.5741 - val_mae: 0.5030\n",
      "Epoch 14/25\n",
      "648/666 [============================>.] - ETA: 0s - loss: 0.5758 - mae: 0.5051\n",
      "Epoch 14: val_loss did not improve from 0.57244\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5756 - mae: 0.5049 - val_loss: 0.5756 - val_mae: 0.5048\n",
      "Epoch 15/25\n",
      "649/666 [============================>.] - ETA: 0s - loss: 0.5758 - mae: 0.5051\n",
      "Epoch 15: val_loss did not improve from 0.57244\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5759 - mae: 0.5053 - val_loss: 0.5758 - val_mae: 0.5058\n",
      "Epoch 16/25\n",
      "649/666 [============================>.] - ETA: 0s - loss: 0.5754 - mae: 0.5047\n",
      "Epoch 16: val_loss did not improve from 0.57244\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5754 - mae: 0.5048 - val_loss: 0.5750 - val_mae: 0.5045\n",
      "Epoch 17/25\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.5754 - mae: 0.5047\n",
      "Epoch 17: val_loss did not improve from 0.57244\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5753 - mae: 0.5047 - val_loss: 0.5845 - val_mae: 0.5142\n",
      "Epoch 18/25\n",
      "659/666 [============================>.] - ETA: 0s - loss: 0.5762 - mae: 0.5056\n",
      "Epoch 18: val_loss did not improve from 0.57244\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5762 - mae: 0.5056 - val_loss: 0.5762 - val_mae: 0.5058\n",
      "Epoch 19/25\n",
      "648/666 [============================>.] - ETA: 0s - loss: 0.5753 - mae: 0.5045\n",
      "Epoch 19: val_loss did not improve from 0.57244\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5755 - mae: 0.5047 - val_loss: 0.5875 - val_mae: 0.5171\n",
      "Epoch 20/25\n",
      "658/666 [============================>.] - ETA: 0s - loss: 0.5757 - mae: 0.5051\n",
      "Epoch 20: val_loss improved from 0.57244 to 0.57187, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it14.e020_vl0.572.h5\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5757 - mae: 0.5052 - val_loss: 0.5719 - val_mae: 0.5020\n",
      "Epoch 21/25\n",
      "649/666 [============================>.] - ETA: 0s - loss: 0.5757 - mae: 0.5052\n",
      "Epoch 21: val_loss did not improve from 0.57187\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5757 - mae: 0.5051 - val_loss: 0.5745 - val_mae: 0.5040\n",
      "Epoch 22/25\n",
      "653/666 [============================>.] - ETA: 0s - loss: 0.5752 - mae: 0.5047\n",
      "Epoch 22: val_loss did not improve from 0.57187\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5753 - mae: 0.5048 - val_loss: 0.5807 - val_mae: 0.5098\n",
      "Epoch 23/25\n",
      "650/666 [============================>.] - ETA: 0s - loss: 0.5765 - mae: 0.5060\n",
      "Epoch 23: val_loss did not improve from 0.57187\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5764 - mae: 0.5059 - val_loss: 0.5760 - val_mae: 0.5057\n",
      "Epoch 24/25\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.5756 - mae: 0.5051\n",
      "Epoch 24: val_loss did not improve from 0.57187\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5756 - mae: 0.5051 - val_loss: 0.5765 - val_mae: 0.5059\n",
      "Epoch 25/25\n",
      "658/666 [============================>.] - ETA: 0s - loss: 0.5756 - mae: 0.5051\n",
      "Epoch 25: val_loss did not improve from 0.57187\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5756 - mae: 0.5051 - val_loss: 0.5752 - val_mae: 0.5045\n",
      "Time elapsed to train: 55.52 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.218 2.876 1.529 3.188 2.232 1.614 1.158 0.878 0.548 0.268 0.129 0.040 0.000]\n",
      "<R> = [2.218 2.877 1.529 3.189 2.232 1.615 1.159 0.878 0.548 0.268 0.129 0.040 0.000]\n",
      "s_R = [0.005 0.029 0.004 0.046 0.015 0.009 0.009 0.004 0.001 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7336285 3.3900497 6.368655  ... 2.4574685 4.0835114 4.4950833]\n",
      "mag_pred: [3.7336285 3.3900497 6.368655  ... 2.4574685 4.0835114 4.4950833]\n",
      "Time elapsed to make plots: 18.18 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [35.553444  23.67853    7.1490755 ...  2.672094  31.096745   9.586717 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0115\n",
      "  1% : 0.104\n",
      "  10% : 0.23\n",
      "  50% : 0.608\n",
      "  90% : 3.03\n",
      "  99% : 86.2\n",
      "  100% : 1.31e+04\n",
      "<chi^2/d.o.f.> = 0.993\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 17429 stars (6.89%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [10.736209  33.803024  14.86879   ...  1.7132454  7.400938  14.335274 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0261\n",
      "  1% : 0.108\n",
      "  10% : 0.229\n",
      "  50% : 0.615\n",
      "  90% : 2.89\n",
      "  99% : 93.1\n",
      "  100% : 5.2e+03\n",
      "<chi^2/d.o.f.> = 0.982\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 78.34 s\n",
      "learning rate = 0.007557837292551994\n",
      "setting learning rate to 0.007408182206817179\n",
      "Iteration 16 of 20.\n",
      "Epoch 1/25\n",
      "653/665 [============================>.] - ETA: 0s - loss: 0.5761 - mae: 0.5058\n",
      "Epoch 1: val_loss improved from inf to 0.57756, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it15.e001_vl0.578.h5\n",
      "665/665 [==============================] - 3s 4ms/step - loss: 0.5761 - mae: 0.5057 - val_loss: 0.5776 - val_mae: 0.5073\n",
      "Epoch 2/25\n",
      "660/665 [============================>.] - ETA: 0s - loss: 0.5759 - mae: 0.5056\n",
      "Epoch 2: val_loss improved from 0.57756 to 0.57164, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it15.e002_vl0.572.h5\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5760 - mae: 0.5056 - val_loss: 0.5716 - val_mae: 0.5010\n",
      "Epoch 3/25\n",
      "661/665 [============================>.] - ETA: 0s - loss: 0.5754 - mae: 0.5051\n",
      "Epoch 3: val_loss did not improve from 0.57164\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5754 - mae: 0.5051 - val_loss: 0.5722 - val_mae: 0.5017\n",
      "Epoch 4/25\n",
      "659/665 [============================>.] - ETA: 0s - loss: 0.5760 - mae: 0.5057\n",
      "Epoch 4: val_loss did not improve from 0.57164\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5761 - mae: 0.5057 - val_loss: 0.5765 - val_mae: 0.5054\n",
      "Epoch 5/25\n",
      "661/665 [============================>.] - ETA: 0s - loss: 0.5758 - mae: 0.5055\n",
      "Epoch 5: val_loss did not improve from 0.57164\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5758 - mae: 0.5056 - val_loss: 0.5795 - val_mae: 0.5090\n",
      "Epoch 6/25\n",
      "650/665 [============================>.] - ETA: 0s - loss: 0.5757 - mae: 0.5055\n",
      "Epoch 6: val_loss did not improve from 0.57164\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5757 - mae: 0.5055 - val_loss: 0.5751 - val_mae: 0.5051\n",
      "Epoch 7/25\n",
      "662/665 [============================>.] - ETA: 0s - loss: 0.5760 - mae: 0.5057\n",
      "Epoch 7: val_loss did not improve from 0.57164\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5760 - mae: 0.5057 - val_loss: 0.5758 - val_mae: 0.5060\n",
      "Epoch 8/25\n",
      "650/665 [============================>.] - ETA: 0s - loss: 0.5757 - mae: 0.5055\n",
      "Epoch 8: val_loss did not improve from 0.57164\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5757 - mae: 0.5055 - val_loss: 0.5733 - val_mae: 0.5035\n",
      "Epoch 9/25\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.5760 - mae: 0.5058\n",
      "Epoch 9: val_loss did not improve from 0.57164\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5760 - mae: 0.5058 - val_loss: 0.5818 - val_mae: 0.5118\n",
      "Epoch 10/25\n",
      "652/665 [============================>.] - ETA: 0s - loss: 0.5752 - mae: 0.5051\n",
      "Epoch 10: val_loss did not improve from 0.57164\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5752 - mae: 0.5051 - val_loss: 0.5733 - val_mae: 0.5023\n",
      "Epoch 11/25\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.5757 - mae: 0.5055\n",
      "Epoch 11: val_loss improved from 0.57164 to 0.57054, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it15.e011_vl0.571.h5\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5757 - mae: 0.5055 - val_loss: 0.5705 - val_mae: 0.5003\n",
      "Epoch 12/25\n",
      "654/665 [============================>.] - ETA: 0s - loss: 0.5753 - mae: 0.5052\n",
      "Epoch 12: val_loss did not improve from 0.57054\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5753 - mae: 0.5052 - val_loss: 0.5731 - val_mae: 0.5033\n",
      "Epoch 13/25\n",
      "654/665 [============================>.] - ETA: 0s - loss: 0.5757 - mae: 0.5056\n",
      "Epoch 13: val_loss did not improve from 0.57054\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5757 - mae: 0.5055 - val_loss: 0.5741 - val_mae: 0.5040\n",
      "Epoch 14/25\n",
      "658/665 [============================>.] - ETA: 0s - loss: 0.5755 - mae: 0.5054\n",
      "Epoch 14: val_loss did not improve from 0.57054\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5755 - mae: 0.5054 - val_loss: 0.5733 - val_mae: 0.5034\n",
      "Epoch 15/25\n",
      "648/665 [============================>.] - ETA: 0s - loss: 0.5760 - mae: 0.5059\n",
      "Epoch 15: val_loss did not improve from 0.57054\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5760 - mae: 0.5059 - val_loss: 0.5763 - val_mae: 0.5058\n",
      "Epoch 16/25\n",
      "656/665 [============================>.] - ETA: 0s - loss: 0.5752 - mae: 0.5051\n",
      "Epoch 16: val_loss did not improve from 0.57054\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5752 - mae: 0.5051 - val_loss: 0.5752 - val_mae: 0.5046\n",
      "Epoch 17/25\n",
      "650/665 [============================>.] - ETA: 0s - loss: 0.5755 - mae: 0.5055\n",
      "Epoch 17: val_loss did not improve from 0.57054\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5754 - mae: 0.5054 - val_loss: 0.5725 - val_mae: 0.5018\n",
      "Epoch 18/25\n",
      "648/665 [============================>.] - ETA: 0s - loss: 0.5753 - mae: 0.5053\n",
      "Epoch 18: val_loss did not improve from 0.57054\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5752 - mae: 0.5052 - val_loss: 0.5739 - val_mae: 0.5041\n",
      "Epoch 19/25\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.5755 - mae: 0.5055\n",
      "Epoch 19: val_loss did not improve from 0.57054\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5755 - mae: 0.5055 - val_loss: 0.5779 - val_mae: 0.5080\n",
      "Epoch 20/25\n",
      "652/665 [============================>.] - ETA: 0s - loss: 0.5750 - mae: 0.5049\n",
      "Epoch 20: val_loss did not improve from 0.57054\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5750 - mae: 0.5049 - val_loss: 0.5746 - val_mae: 0.5055\n",
      "Epoch 21/25\n",
      "656/665 [============================>.] - ETA: 0s - loss: 0.5759 - mae: 0.5060\n",
      "Epoch 21: val_loss did not improve from 0.57054\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5758 - mae: 0.5060 - val_loss: 0.5836 - val_mae: 0.5139\n",
      "Epoch 22/25\n",
      "661/665 [============================>.] - ETA: 0s - loss: 0.5748 - mae: 0.5049\n",
      "Epoch 22: val_loss did not improve from 0.57054\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5748 - mae: 0.5048 - val_loss: 0.5742 - val_mae: 0.5041\n",
      "Epoch 23/25\n",
      "648/665 [============================>.] - ETA: 0s - loss: 0.5751 - mae: 0.5052\n",
      "Epoch 23: val_loss did not improve from 0.57054\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5752 - mae: 0.5053 - val_loss: 0.5747 - val_mae: 0.5047\n",
      "Epoch 24/25\n",
      "647/665 [============================>.] - ETA: 0s - loss: 0.5753 - mae: 0.5053\n",
      "Epoch 24: val_loss did not improve from 0.57054\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5753 - mae: 0.5054 - val_loss: 0.5721 - val_mae: 0.5026\n",
      "Epoch 25/25\n",
      "662/665 [============================>.] - ETA: 0s - loss: 0.5752 - mae: 0.5053\n",
      "Epoch 25: val_loss did not improve from 0.57054\n",
      "665/665 [==============================] - 2s 3ms/step - loss: 0.5752 - mae: 0.5052 - val_loss: 0.5717 - val_mae: 0.5025\n",
      "Time elapsed to train: 54.50 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.209 2.887 1.522 3.212 2.236 1.611 1.147 0.880 0.542 0.275 0.130 0.040 0.000]\n",
      "<R> = [2.208 2.887 1.522 3.212 2.236 1.612 1.147 0.880 0.542 0.275 0.130 0.040 0.000]\n",
      "s_R = [0.019 0.009 0.009 0.055 0.026 0.006 0.005 0.003 0.001 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6028845 3.2906318 6.1591926 ... 2.4134345 3.941824  4.3430448]\n",
      "mag_pred: [3.6028845 3.2906318 6.1591926 ... 2.4134345 3.941824  4.3430448]\n",
      "Time elapsed to make plots: 17.89 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [37.033104  26.616697   9.637482  ...  3.7571955 29.044113  16.879238 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0123\n",
      "  1% : 0.111\n",
      "  10% : 0.244\n",
      "  50% : 0.623\n",
      "  90% : 2.79\n",
      "  99% : 84.4\n",
      "  100% : 1.53e+04\n",
      "<chi^2/d.o.f.> = 0.975\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 16663 stars (6.58%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [11.380691  37.24839   12.438411  ...  1.9396793  5.7445636 14.715154 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0195\n",
      "  1% : 0.113\n",
      "  10% : 0.244\n",
      "  50% : 0.628\n",
      "  90% : 2.68\n",
      "  99% : 92\n",
      "  100% : 5.2e+03\n",
      "<chi^2/d.o.f.> = 0.966\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 77.39 s\n",
      "learning rate = 0.0074081821367144585\n",
      "setting learning rate to 0.00726149037073691\n",
      "Iteration 17 of 20.\n",
      "Epoch 1/25\n",
      "666/667 [============================>.] - ETA: 0s - loss: 0.5791 - mae: 0.5094\n",
      "Epoch 1: val_loss improved from inf to 0.57817, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it16.e001_vl0.578.h5\n",
      "667/667 [==============================] - 3s 3ms/step - loss: 0.5791 - mae: 0.5094 - val_loss: 0.5782 - val_mae: 0.5090\n",
      "Epoch 2/25\n",
      "654/667 [============================>.] - ETA: 0s - loss: 0.5792 - mae: 0.5094\n",
      "Epoch 2: val_loss improved from 0.57817 to 0.57706, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it16.e002_vl0.577.h5\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5793 - mae: 0.5094 - val_loss: 0.5771 - val_mae: 0.5071\n",
      "Epoch 3/25\n",
      "650/667 [============================>.] - ETA: 0s - loss: 0.5794 - mae: 0.5096\n",
      "Epoch 3: val_loss improved from 0.57706 to 0.57674, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it16.e003_vl0.577.h5\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5794 - mae: 0.5095 - val_loss: 0.5767 - val_mae: 0.5062\n",
      "Epoch 4/25\n",
      "666/667 [============================>.] - ETA: 0s - loss: 0.5798 - mae: 0.5099\n",
      "Epoch 4: val_loss did not improve from 0.57674\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5798 - mae: 0.5099 - val_loss: 0.5817 - val_mae: 0.5121\n",
      "Epoch 5/25\n",
      "658/667 [============================>.] - ETA: 0s - loss: 0.5796 - mae: 0.5099\n",
      "Epoch 5: val_loss did not improve from 0.57674\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5795 - mae: 0.5098 - val_loss: 0.5799 - val_mae: 0.5098\n",
      "Epoch 6/25\n",
      "650/667 [============================>.] - ETA: 0s - loss: 0.5786 - mae: 0.5089\n",
      "Epoch 6: val_loss did not improve from 0.57674\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5786 - mae: 0.5089 - val_loss: 0.5769 - val_mae: 0.5078\n",
      "Epoch 7/25\n",
      "662/667 [============================>.] - ETA: 0s - loss: 0.5789 - mae: 0.5092\n",
      "Epoch 7: val_loss did not improve from 0.57674\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5789 - mae: 0.5092 - val_loss: 0.5775 - val_mae: 0.5079\n",
      "Epoch 8/25\n",
      "654/667 [============================>.] - ETA: 0s - loss: 0.5791 - mae: 0.5094\n",
      "Epoch 8: val_loss improved from 0.57674 to 0.57653, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it16.e008_vl0.577.h5\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5792 - mae: 0.5094 - val_loss: 0.5765 - val_mae: 0.5071\n",
      "Epoch 9/25\n",
      "664/667 [============================>.] - ETA: 0s - loss: 0.5788 - mae: 0.5091\n",
      "Epoch 9: val_loss did not improve from 0.57653\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5788 - mae: 0.5091 - val_loss: 0.5794 - val_mae: 0.5104\n",
      "Epoch 10/25\n",
      "653/667 [============================>.] - ETA: 0s - loss: 0.5786 - mae: 0.5089\n",
      "Epoch 10: val_loss did not improve from 0.57653\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5785 - mae: 0.5088 - val_loss: 0.5772 - val_mae: 0.5071\n",
      "Epoch 11/25\n",
      "660/667 [============================>.] - ETA: 0s - loss: 0.5797 - mae: 0.5101\n",
      "Epoch 11: val_loss did not improve from 0.57653\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5797 - mae: 0.5100 - val_loss: 0.5769 - val_mae: 0.5068\n",
      "Epoch 12/25\n",
      "659/667 [============================>.] - ETA: 0s - loss: 0.5788 - mae: 0.5091\n",
      "Epoch 12: val_loss did not improve from 0.57653\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5787 - mae: 0.5090 - val_loss: 0.5779 - val_mae: 0.5090\n",
      "Epoch 13/25\n",
      "653/667 [============================>.] - ETA: 0s - loss: 0.5792 - mae: 0.5097\n",
      "Epoch 13: val_loss did not improve from 0.57653\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5793 - mae: 0.5098 - val_loss: 0.5847 - val_mae: 0.5148\n",
      "Epoch 14/25\n",
      "667/667 [==============================] - ETA: 0s - loss: 0.5784 - mae: 0.5088\n",
      "Epoch 14: val_loss did not improve from 0.57653\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5784 - mae: 0.5088 - val_loss: 0.5805 - val_mae: 0.5104\n",
      "Epoch 15/25\n",
      "660/667 [============================>.] - ETA: 0s - loss: 0.5791 - mae: 0.5095\n",
      "Epoch 15: val_loss did not improve from 0.57653\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5791 - mae: 0.5095 - val_loss: 0.5788 - val_mae: 0.5092\n",
      "Epoch 16/25\n",
      "663/667 [============================>.] - ETA: 0s - loss: 0.5792 - mae: 0.5096\n",
      "Epoch 16: val_loss did not improve from 0.57653\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5792 - mae: 0.5096 - val_loss: 0.5821 - val_mae: 0.5128\n",
      "Epoch 17/25\n",
      "653/667 [============================>.] - ETA: 0s - loss: 0.5785 - mae: 0.5089\n",
      "Epoch 17: val_loss did not improve from 0.57653\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5784 - mae: 0.5089 - val_loss: 0.5809 - val_mae: 0.5120\n",
      "Epoch 18/25\n",
      "665/667 [============================>.] - ETA: 0s - loss: 0.5793 - mae: 0.5097\n",
      "Epoch 18: val_loss improved from 0.57653 to 0.57495, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it16.e018_vl0.575.h5\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5793 - mae: 0.5097 - val_loss: 0.5750 - val_mae: 0.5061\n",
      "Epoch 19/25\n",
      "662/667 [============================>.] - ETA: 0s - loss: 0.5791 - mae: 0.5096\n",
      "Epoch 19: val_loss did not improve from 0.57495\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5791 - mae: 0.5096 - val_loss: 0.5780 - val_mae: 0.5085\n",
      "Epoch 20/25\n",
      "659/667 [============================>.] - ETA: 0s - loss: 0.5789 - mae: 0.5095\n",
      "Epoch 20: val_loss did not improve from 0.57495\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5791 - mae: 0.5097 - val_loss: 0.5870 - val_mae: 0.5177\n",
      "Epoch 21/25\n",
      "654/667 [============================>.] - ETA: 0s - loss: 0.5793 - mae: 0.5097\n",
      "Epoch 21: val_loss did not improve from 0.57495\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5793 - mae: 0.5098 - val_loss: 0.5774 - val_mae: 0.5087\n",
      "Epoch 22/25\n",
      "659/667 [============================>.] - ETA: 0s - loss: 0.5785 - mae: 0.5090\n",
      "Epoch 22: val_loss did not improve from 0.57495\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5784 - mae: 0.5090 - val_loss: 0.5790 - val_mae: 0.5092\n",
      "Epoch 23/25\n",
      "655/667 [============================>.] - ETA: 0s - loss: 0.5789 - mae: 0.5095\n",
      "Epoch 23: val_loss did not improve from 0.57495\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5789 - mae: 0.5095 - val_loss: 0.5874 - val_mae: 0.5180\n",
      "Epoch 24/25\n",
      "654/667 [============================>.] - ETA: 0s - loss: 0.5793 - mae: 0.5099\n",
      "Epoch 24: val_loss improved from 0.57495 to 0.57367, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it16.e024_vl0.574.h5\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5794 - mae: 0.5099 - val_loss: 0.5737 - val_mae: 0.5045\n",
      "Epoch 25/25\n",
      "657/667 [============================>.] - ETA: 0s - loss: 0.5786 - mae: 0.5093\n",
      "Epoch 25: val_loss did not improve from 0.57367\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 0.5787 - mae: 0.5094 - val_loss: 0.5803 - val_mae: 0.5112\n",
      "Time elapsed to train: 54.84 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.209 2.881 1.529 3.213 2.229 1.613 1.143 0.888 0.547 0.274 0.128 0.041 0.000]\n",
      "<R> = [2.209 2.881 1.529 3.213 2.230 1.613 1.143 0.888 0.547 0.274 0.128 0.041 0.000]\n",
      "s_R = [0.016 0.011 0.004 0.050 0.027 0.013 0.004 0.003 0.001 0.001 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.7009299 3.312827  6.206474  ... 2.5085847 4.032303  4.4281807]\n",
      "mag_pred: [3.7009299 3.312827  6.206474  ... 2.5085847 4.032303  4.4281807]\n",
      "Time elapsed to make plots: 22.39 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [36.436256 26.121525  7.110777 ...  3.079664 31.350958 13.266693]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0183\n",
      "  1% : 0.112\n",
      "  10% : 0.239\n",
      "  50% : 0.606\n",
      "  90% : 2.9\n",
      "  99% : 86\n",
      "  100% : 1.46e+04\n",
      "<chi^2/d.o.f.> = 0.978\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 17026 stars (6.73%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [10.735139  35.470623  12.225363  ...  2.4747233  5.8367906 16.027573 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0329\n",
      "  1% : 0.113\n",
      "  10% : 0.239\n",
      "  50% : 0.612\n",
      "  90% : 2.78\n",
      "  99% : 93.4\n",
      "  100% : 5.21e+03\n",
      "<chi^2/d.o.f.> = 0.967\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 78.03 s\n",
      "learning rate = 0.007261490449309349\n",
      "setting learning rate to 0.007117703227626096\n",
      "Iteration 18 of 20.\n",
      "Epoch 1/25\n",
      "656/666 [============================>.] - ETA: 0s - loss: 0.5757 - mae: 0.5066\n",
      "Epoch 1: val_loss improved from inf to 0.57793, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it17.e001_vl0.578.h5\n",
      "666/666 [==============================] - 3s 4ms/step - loss: 0.5757 - mae: 0.5066 - val_loss: 0.5779 - val_mae: 0.5094\n",
      "Epoch 2/25\n",
      "652/666 [============================>.] - ETA: 0s - loss: 0.5757 - mae: 0.5067\n",
      "Epoch 2: val_loss improved from 0.57793 to 0.57188, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it17.e002_vl0.572.h5\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5757 - mae: 0.5066 - val_loss: 0.5719 - val_mae: 0.5025\n",
      "Epoch 3/25\n",
      "654/666 [============================>.] - ETA: 0s - loss: 0.5763 - mae: 0.5072\n",
      "Epoch 3: val_loss improved from 0.57188 to 0.57137, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it17.e003_vl0.571.h5\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5763 - mae: 0.5071 - val_loss: 0.5714 - val_mae: 0.5017\n",
      "Epoch 4/25\n",
      "661/666 [============================>.] - ETA: 0s - loss: 0.5759 - mae: 0.5069\n",
      "Epoch 4: val_loss did not improve from 0.57137\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5759 - mae: 0.5069 - val_loss: 0.5790 - val_mae: 0.5094\n",
      "Epoch 5/25\n",
      "650/666 [============================>.] - ETA: 0s - loss: 0.5755 - mae: 0.5065\n",
      "Epoch 5: val_loss did not improve from 0.57137\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5754 - mae: 0.5064 - val_loss: 0.5733 - val_mae: 0.5049\n",
      "Epoch 6/25\n",
      "652/666 [============================>.] - ETA: 0s - loss: 0.5759 - mae: 0.5070\n",
      "Epoch 6: val_loss did not improve from 0.57137\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5758 - mae: 0.5069 - val_loss: 0.5792 - val_mae: 0.5099\n",
      "Epoch 7/25\n",
      "662/666 [============================>.] - ETA: 0s - loss: 0.5759 - mae: 0.5070\n",
      "Epoch 7: val_loss did not improve from 0.57137\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5759 - mae: 0.5070 - val_loss: 0.5765 - val_mae: 0.5079\n",
      "Epoch 8/25\n",
      "661/666 [============================>.] - ETA: 0s - loss: 0.5753 - mae: 0.5064\n",
      "Epoch 8: val_loss did not improve from 0.57137\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5753 - mae: 0.5065 - val_loss: 0.5735 - val_mae: 0.5048\n",
      "Epoch 9/25\n",
      "666/666 [==============================] - ETA: 0s - loss: 0.5757 - mae: 0.5068\n",
      "Epoch 9: val_loss did not improve from 0.57137\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5757 - mae: 0.5068 - val_loss: 0.5733 - val_mae: 0.5042\n",
      "Epoch 10/25\n",
      "649/666 [============================>.] - ETA: 0s - loss: 0.5758 - mae: 0.5069\n",
      "Epoch 10: val_loss did not improve from 0.57137\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5758 - mae: 0.5070 - val_loss: 0.5717 - val_mae: 0.5031\n",
      "Epoch 11/25\n",
      "651/666 [============================>.] - ETA: 0s - loss: 0.5759 - mae: 0.5070\n",
      "Epoch 11: val_loss did not improve from 0.57137\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5760 - mae: 0.5071 - val_loss: 0.5732 - val_mae: 0.5041\n",
      "Epoch 12/25\n",
      "662/666 [============================>.] - ETA: 0s - loss: 0.5755 - mae: 0.5066\n",
      "Epoch 12: val_loss did not improve from 0.57137\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5755 - mae: 0.5067 - val_loss: 0.5721 - val_mae: 0.5037\n",
      "Epoch 13/25\n",
      "647/666 [============================>.] - ETA: 0s - loss: 0.5763 - mae: 0.5075\n",
      "Epoch 13: val_loss did not improve from 0.57137\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5761 - mae: 0.5073 - val_loss: 0.5743 - val_mae: 0.5045\n",
      "Epoch 14/25\n",
      "659/666 [============================>.] - ETA: 0s - loss: 0.5758 - mae: 0.5070\n",
      "Epoch 14: val_loss did not improve from 0.57137\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5759 - mae: 0.5071 - val_loss: 0.5725 - val_mae: 0.5039\n",
      "Epoch 15/25\n",
      "659/666 [============================>.] - ETA: 0s - loss: 0.5757 - mae: 0.5068\n",
      "Epoch 15: val_loss did not improve from 0.57137\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5756 - mae: 0.5067 - val_loss: 0.5784 - val_mae: 0.5102\n",
      "Epoch 16/25\n",
      "666/666 [==============================] - ETA: 0s - loss: 0.5760 - mae: 0.5072\n",
      "Epoch 16: val_loss did not improve from 0.57137\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5760 - mae: 0.5072 - val_loss: 0.5741 - val_mae: 0.5055\n",
      "Epoch 17/25\n",
      "659/666 [============================>.] - ETA: 0s - loss: 0.5753 - mae: 0.5066\n",
      "Epoch 17: val_loss did not improve from 0.57137\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5753 - mae: 0.5066 - val_loss: 0.5731 - val_mae: 0.5042\n",
      "Epoch 18/25\n",
      "649/666 [============================>.] - ETA: 0s - loss: 0.5758 - mae: 0.5071\n",
      "Epoch 18: val_loss improved from 0.57137 to 0.57076, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it17.e018_vl0.571.h5\n",
      "666/666 [==============================] - 2s 4ms/step - loss: 0.5757 - mae: 0.5070 - val_loss: 0.5708 - val_mae: 0.5014\n",
      "Epoch 19/25\n",
      "648/666 [============================>.] - ETA: 0s - loss: 0.5753 - mae: 0.5066\n",
      "Epoch 19: val_loss did not improve from 0.57076\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5755 - mae: 0.5067 - val_loss: 0.5736 - val_mae: 0.5042\n",
      "Epoch 20/25\n",
      "652/666 [============================>.] - ETA: 0s - loss: 0.5755 - mae: 0.5068\n",
      "Epoch 20: val_loss did not improve from 0.57076\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5756 - mae: 0.5068 - val_loss: 0.5727 - val_mae: 0.5043\n",
      "Epoch 21/25\n",
      "659/666 [============================>.] - ETA: 0s - loss: 0.5753 - mae: 0.5066\n",
      "Epoch 21: val_loss did not improve from 0.57076\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5753 - mae: 0.5066 - val_loss: 0.5733 - val_mae: 0.5050\n",
      "Epoch 22/25\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.5750 - mae: 0.5064\n",
      "Epoch 22: val_loss did not improve from 0.57076\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5751 - mae: 0.5064 - val_loss: 0.5872 - val_mae: 0.5185\n",
      "Epoch 23/25\n",
      "661/666 [============================>.] - ETA: 0s - loss: 0.5754 - mae: 0.5067\n",
      "Epoch 23: val_loss did not improve from 0.57076\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5753 - mae: 0.5067 - val_loss: 0.5766 - val_mae: 0.5078\n",
      "Epoch 24/25\n",
      "658/666 [============================>.] - ETA: 0s - loss: 0.5758 - mae: 0.5072\n",
      "Epoch 24: val_loss improved from 0.57076 to 0.57032, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it17.e024_vl0.570.h5\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5758 - mae: 0.5071 - val_loss: 0.5703 - val_mae: 0.5014\n",
      "Epoch 25/25\n",
      "652/666 [============================>.] - ETA: 0s - loss: 0.5753 - mae: 0.5067\n",
      "Epoch 25: val_loss did not improve from 0.57032\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5754 - mae: 0.5068 - val_loss: 0.5761 - val_mae: 0.5071\n",
      "Time elapsed to train: 56.06 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.208 2.883 1.525 3.216 2.249 1.606 1.152 0.879 0.539 0.276 0.127 0.041 0.000]\n",
      "<R> = [2.209 2.885 1.525 3.214 2.248 1.606 1.152 0.879 0.539 0.276 0.127 0.041 0.000]\n",
      "s_R = [0.027 0.022 0.009 0.051 0.022 0.006 0.019 0.002 0.001 0.001 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6506565 3.2235622 6.2038064 ... 2.3664448 4.018418  4.4126368]\n",
      "mag_pred: [3.6506565 3.2235622 6.2038064 ... 2.3664448 4.018418  4.4126368]\n",
      "Time elapsed to make plots: 17.88 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [35.206177  25.994257   7.207125  ...  2.8457084 33.14574   11.483916 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0101\n",
      "  1% : 0.106\n",
      "  10% : 0.23\n",
      "  50% : 0.603\n",
      "  90% : 2.97\n",
      "  99% : 85.4\n",
      "  100% : 1.46e+04\n",
      "<chi^2/d.o.f.> = 0.982\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 17165 stars (6.78%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [ 9.121919  35.072906  13.277091  ...  3.3938026  6.5637965 15.771299 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0249\n",
      "  1% : 0.107\n",
      "  10% : 0.23\n",
      "  50% : 0.607\n",
      "  90% : 2.83\n",
      "  99% : 93.4\n",
      "  100% : 5.21e+03\n",
      "<chi^2/d.o.f.> = 0.974\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 76.19 s\n",
      "learning rate = 0.007117703091353178\n",
      "setting learning rate to 0.0069767632607103105\n",
      "Iteration 19 of 20.\n",
      "Epoch 1/25\n",
      "658/666 [============================>.] - ETA: 0s - loss: 0.5730 - mae: 0.5047\n",
      "Epoch 1: val_loss improved from inf to 0.57094, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it18.e001_vl0.571.h5\n",
      "666/666 [==============================] - 3s 4ms/step - loss: 0.5729 - mae: 0.5046 - val_loss: 0.5709 - val_mae: 0.5030\n",
      "Epoch 2/25\n",
      "654/666 [============================>.] - ETA: 0s - loss: 0.5734 - mae: 0.5052\n",
      "Epoch 2: val_loss did not improve from 0.57094\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5735 - mae: 0.5052 - val_loss: 0.5732 - val_mae: 0.5052\n",
      "Epoch 3/25\n",
      "647/666 [============================>.] - ETA: 0s - loss: 0.5733 - mae: 0.5050\n",
      "Epoch 3: val_loss did not improve from 0.57094\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5732 - mae: 0.5049 - val_loss: 0.5721 - val_mae: 0.5038\n",
      "Epoch 4/25\n",
      "654/666 [============================>.] - ETA: 0s - loss: 0.5730 - mae: 0.5047\n",
      "Epoch 4: val_loss did not improve from 0.57094\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5730 - mae: 0.5047 - val_loss: 0.5754 - val_mae: 0.5072\n",
      "Epoch 5/25\n",
      "655/666 [============================>.] - ETA: 0s - loss: 0.5730 - mae: 0.5048\n",
      "Epoch 5: val_loss did not improve from 0.57094\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5730 - mae: 0.5048 - val_loss: 0.5739 - val_mae: 0.5054\n",
      "Epoch 6/25\n",
      "655/666 [============================>.] - ETA: 0s - loss: 0.5736 - mae: 0.5054\n",
      "Epoch 6: val_loss did not improve from 0.57094\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5736 - mae: 0.5054 - val_loss: 0.5788 - val_mae: 0.5103\n",
      "Epoch 7/25\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.5730 - mae: 0.5048\n",
      "Epoch 7: val_loss improved from 0.57094 to 0.56929, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it18.e007_vl0.569.h5\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5730 - mae: 0.5048 - val_loss: 0.5693 - val_mae: 0.5006\n",
      "Epoch 8/25\n",
      "655/666 [============================>.] - ETA: 0s - loss: 0.5737 - mae: 0.5055\n",
      "Epoch 8: val_loss did not improve from 0.56929\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5737 - mae: 0.5056 - val_loss: 0.5748 - val_mae: 0.5063\n",
      "Epoch 9/25\n",
      "655/666 [============================>.] - ETA: 0s - loss: 0.5728 - mae: 0.5046\n",
      "Epoch 9: val_loss did not improve from 0.56929\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5727 - mae: 0.5045 - val_loss: 0.5807 - val_mae: 0.5125\n",
      "Epoch 10/25\n",
      "665/666 [============================>.] - ETA: 0s - loss: 0.5732 - mae: 0.5051\n",
      "Epoch 10: val_loss did not improve from 0.56929\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5732 - mae: 0.5051 - val_loss: 0.5736 - val_mae: 0.5054\n",
      "Epoch 11/25\n",
      "656/666 [============================>.] - ETA: 0s - loss: 0.5731 - mae: 0.5049\n",
      "Epoch 11: val_loss did not improve from 0.56929\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5730 - mae: 0.5048 - val_loss: 0.5727 - val_mae: 0.5048\n",
      "Epoch 12/25\n",
      "665/666 [============================>.] - ETA: 0s - loss: 0.5735 - mae: 0.5054\n",
      "Epoch 12: val_loss did not improve from 0.56929\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5735 - mae: 0.5054 - val_loss: 0.5696 - val_mae: 0.5017\n",
      "Epoch 13/25\n",
      "652/666 [============================>.] - ETA: 0s - loss: 0.5734 - mae: 0.5053\n",
      "Epoch 13: val_loss did not improve from 0.56929\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5733 - mae: 0.5052 - val_loss: 0.5724 - val_mae: 0.5037\n",
      "Epoch 14/25\n",
      "659/666 [============================>.] - ETA: 0s - loss: 0.5730 - mae: 0.5050\n",
      "Epoch 14: val_loss did not improve from 0.56929\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5730 - mae: 0.5049 - val_loss: 0.5792 - val_mae: 0.5105\n",
      "Epoch 15/25\n",
      "650/666 [============================>.] - ETA: 0s - loss: 0.5735 - mae: 0.5054\n",
      "Epoch 15: val_loss improved from 0.56929 to 0.56793, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it18.e015_vl0.568.h5\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5734 - mae: 0.5053 - val_loss: 0.5679 - val_mae: 0.4998\n",
      "Epoch 16/25\n",
      "657/666 [============================>.] - ETA: 0s - loss: 0.5729 - mae: 0.5050\n",
      "Epoch 16: val_loss did not improve from 0.56793\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5729 - mae: 0.5050 - val_loss: 0.5731 - val_mae: 0.5047\n",
      "Epoch 17/25\n",
      "659/666 [============================>.] - ETA: 0s - loss: 0.5733 - mae: 0.5053\n",
      "Epoch 17: val_loss did not improve from 0.56793\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5733 - mae: 0.5052 - val_loss: 0.5689 - val_mae: 0.5008\n",
      "Epoch 18/25\n",
      "651/666 [============================>.] - ETA: 0s - loss: 0.5729 - mae: 0.5049\n",
      "Epoch 18: val_loss did not improve from 0.56793\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5729 - mae: 0.5049 - val_loss: 0.5711 - val_mae: 0.5025\n",
      "Epoch 19/25\n",
      "653/666 [============================>.] - ETA: 0s - loss: 0.5729 - mae: 0.5049\n",
      "Epoch 19: val_loss did not improve from 0.56793\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5730 - mae: 0.5050 - val_loss: 0.5718 - val_mae: 0.5039\n",
      "Epoch 20/25\n",
      "665/666 [============================>.] - ETA: 0s - loss: 0.5735 - mae: 0.5056\n",
      "Epoch 20: val_loss did not improve from 0.56793\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5735 - mae: 0.5056 - val_loss: 0.5717 - val_mae: 0.5037\n",
      "Epoch 21/25\n",
      "653/666 [============================>.] - ETA: 0s - loss: 0.5727 - mae: 0.5047\n",
      "Epoch 21: val_loss did not improve from 0.56793\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5726 - mae: 0.5046 - val_loss: 0.5787 - val_mae: 0.5107\n",
      "Epoch 22/25\n",
      "656/666 [============================>.] - ETA: 0s - loss: 0.5732 - mae: 0.5052\n",
      "Epoch 22: val_loss did not improve from 0.56793\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5732 - mae: 0.5052 - val_loss: 0.5755 - val_mae: 0.5073\n",
      "Epoch 23/25\n",
      "653/666 [============================>.] - ETA: 0s - loss: 0.5730 - mae: 0.5050\n",
      "Epoch 23: val_loss did not improve from 0.56793\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5731 - mae: 0.5051 - val_loss: 0.5719 - val_mae: 0.5040\n",
      "Epoch 24/25\n",
      "662/666 [============================>.] - ETA: 0s - loss: 0.5731 - mae: 0.5051\n",
      "Epoch 24: val_loss did not improve from 0.56793\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5730 - mae: 0.5051 - val_loss: 0.5778 - val_mae: 0.5095\n",
      "Epoch 25/25\n",
      "648/666 [============================>.] - ETA: 0s - loss: 0.5727 - mae: 0.5048\n",
      "Epoch 25: val_loss did not improve from 0.56793\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5728 - mae: 0.5049 - val_loss: 0.5713 - val_mae: 0.5038\n",
      "Time elapsed to train: 55.13 s\n",
      "Diagnostic plots ...\n",
      "R(<theta>) = [2.214 2.889 1.536 3.224 2.239 1.614 1.161 0.879 0.545 0.278 0.129 0.041 0.000]\n",
      "<R> = [2.214 2.889 1.535 3.225 2.238 1.614 1.161 0.879 0.545 0.278 0.129 0.041 0.000]\n",
      "s_R = [0.024 0.008 0.019 0.040 0.007 0.009 0.009 0.004 0.002 0.000 0.000 0.000 0.000]\n",
      "g = [4.3418007 6.0558577 7.159527  ... 3.0397968 4.041044  5.3262825]\n",
      "ri = [ 0.10039997  0.20469952 -0.9038992  ...  0.20280075  0.09320068\n",
      "  0.17249966]\n",
      "gr = [0.29260063 0.5391998  0.93779945 ... 0.4375     0.30010033 0.42590046]\n",
      "gaia_g = [4.047886  5.5376997 6.2321014 ... 2.5969334 3.7488937 4.9121075]\n",
      "bp_rp = [0.724926   1.0305042  1.4541712  ... 0.9140396  0.73390675 0.9015541 ]\n",
      "mag_pred: [3.6104221 3.2574115 6.1803837 ... 2.3970811 3.9611566 4.3600054]\n",
      "mag_pred: [3.6104221 3.2574115 6.1803837 ... 2.3970811 3.9611566 4.3600054]\n",
      "Time elapsed to make plots: 17.84 s\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 253053 bad. Replacing with 14.28331.\n",
      "Band 1: 5 of 253053 bad. Replacing with 14.66830.\n",
      "Band 2: 5 of 253053 bad. Replacing with 13.72847.\n",
      "Band 3: 35727 of 253053 bad. Replacing with 14.99560.\n",
      "Band 4: 62240 of 253053 bad. Replacing with 14.70110.\n",
      "Band 5: 74474 of 253053 bad. Replacing with 14.60040.\n",
      "Band 6: 47420 of 253053 bad. Replacing with 14.34850.\n",
      "Band 7: 11485 of 253053 bad. Replacing with 14.06080.\n",
      "Band 8: 487 of 253053 bad. Replacing with 13.07900.\n",
      "Band 9: 440 of 253053 bad. Replacing with 12.70900.\n",
      "Band 10: 1629 of 253053 bad. Replacing with 12.62900.\n",
      "Band 11: 323 of 253053 bad. Replacing with 15.29501.\n",
      "Band 12: 342 of 253053 bad. Replacing with 15.96443.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 253050 of 253053 (99.999%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [36.642002  28.409975   7.7166114 ...  3.1089044 33.162178  13.126434 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.01\n",
      "  1% : 0.105\n",
      "  10% : 0.232\n",
      "  50% : 0.609\n",
      "  90% : 2.91\n",
      "  99% : 85\n",
      "  100% : 1.48e+04\n",
      "<chi^2/d.o.f.> = 0.98\n",
      "Filter on chi^2/d.o.f. ...\n",
      "Filtering 16993 stars (6.72%) based on chi^2/dof > 5.0\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Fill in stellar atmospheric parameters ...\n",
      "Fill in stellar magnitudes ...\n",
      "Empty covariance matrix ...\n",
      "Covariance: \\delta m ...\n",
      "Replace NaN magnitudes ...\n",
      "Band 0: 0 of 28118 bad. Replacing with 14.28053.\n",
      "Band 1: 1 of 28118 bad. Replacing with 14.66404.\n",
      "Band 2: 1 of 28118 bad. Replacing with 13.72699.\n",
      "Band 3: 4004 of 28118 bad. Replacing with 14.98840.\n",
      "Band 4: 7002 of 28118 bad. Replacing with 14.70180.\n",
      "Band 5: 8273 of 28118 bad. Replacing with 14.59520.\n",
      "Band 6: 5253 of 28118 bad. Replacing with 14.34220.\n",
      "Band 7: 1248 of 28118 bad. Replacing with 14.06070.\n",
      "Band 8: 66 of 28118 bad. Replacing with 13.08000.\n",
      "Band 9: 54 of 28118 bad. Replacing with 12.70900.\n",
      "Band 10: 189 of 28118 bad. Replacing with 12.63200.\n",
      "Band 11: 43 of 28118 bad. Replacing with 15.29383.\n",
      "Band 12: 46 of 28118 bad. Replacing with 15.96379.\n",
      "Transform y -> B y ...\n",
      "Transform C -> B C B^T ...\n",
      "Calculate J = dM/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "0 NaN parallaxes\n",
      "Covariance: DM uncertainty term ...\n",
      "Estimate DM ...\n",
      "Filter out M_G for poor parallax measurements ...\n",
      "Using 28117 of 28118 (99.996%) of stellar parallaxes.\n",
      "Copy reddenings ...\n",
      "Invert C_y matrices ...\n",
      "Calculate posterior on reddening ...\n",
      "Updating reddenings:\n",
      "  * R^T C_y^(-1) ...\n",
      "  * num = r_0/sigma_r^2 + [R^T C_y^(-1)] dy ...\n",
      "  * den = [R^T C_y^(-1)] R + 1/sigma_r^2 ...\n",
      "  * r_mean, r_var ...\n",
      "Clip reddenings and reddening variances ...\n",
      "Covariance: reddening uncertainty term ...\n",
      "Calculate J = dA/dtheta ...\n",
      "Covariance: J C_theta J^T ...\n",
      "chisq = [11.087017  34.636055  12.651941  ...  2.2274458  7.3683825 14.468913 ]\n",
      "Calculate d.o.f. of each star ...\n",
      "Calculate chi^2/d.o.f. for each star ...\n",
      "chi^2/dof percentiles:\n",
      "  0% : 0.0257\n",
      "  1% : 0.105\n",
      "  10% : 0.233\n",
      "  50% : 0.612\n",
      "  90% : 2.81\n",
      "  99% : 92.6\n",
      "  100% : 5.2e+03\n",
      "<chi^2/d.o.f.> = 0.965\n",
      "Cholesky transform of each stellar covariance matrix ...\n",
      "Calculate L^T y ...\n",
      "Gather inputs and outputs and return ...\n",
      "Time elapsed to prepare data: 77.65 s\n",
      "learning rate = 0.006976763252168894\n",
      "setting learning rate to 0.006838614092123559\n",
      "Iteration 20 of 20.\n",
      "Epoch 1/25\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.5734 - mae: 0.5056\n",
      "Epoch 1: val_loss improved from inf to 0.57316, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it19.e001_vl0.573.h5\n",
      "666/666 [==============================] - 3s 4ms/step - loss: 0.5734 - mae: 0.5057 - val_loss: 0.5732 - val_mae: 0.5054\n",
      "Epoch 2/25\n",
      "654/666 [============================>.] - ETA: 0s - loss: 0.5735 - mae: 0.5056\n",
      "Epoch 2: val_loss improved from 0.57316 to 0.57101, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it19.e002_vl0.571.h5\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5736 - mae: 0.5058 - val_loss: 0.5710 - val_mae: 0.5039\n",
      "Epoch 3/25\n",
      "651/666 [============================>.] - ETA: 0s - loss: 0.5744 - mae: 0.5067\n",
      "Epoch 3: val_loss did not improve from 0.57101\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5743 - mae: 0.5066 - val_loss: 0.5731 - val_mae: 0.5053\n",
      "Epoch 4/25\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.5736 - mae: 0.5058\n",
      "Epoch 4: val_loss did not improve from 0.57101\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5735 - mae: 0.5058 - val_loss: 0.5728 - val_mae: 0.5052\n",
      "Epoch 5/25\n",
      "654/666 [============================>.] - ETA: 0s - loss: 0.5746 - mae: 0.5069\n",
      "Epoch 5: val_loss did not improve from 0.57101\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5745 - mae: 0.5068 - val_loss: 0.5733 - val_mae: 0.5057\n",
      "Epoch 6/25\n",
      "666/666 [==============================] - ETA: 0s - loss: 0.5741 - mae: 0.5064\n",
      "Epoch 6: val_loss did not improve from 0.57101\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5741 - mae: 0.5064 - val_loss: 0.5730 - val_mae: 0.5057\n",
      "Epoch 7/25\n",
      "646/666 [============================>.] - ETA: 0s - loss: 0.5730 - mae: 0.5053\n",
      "Epoch 7: val_loss did not improve from 0.57101\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5731 - mae: 0.5054 - val_loss: 0.5737 - val_mae: 0.5063\n",
      "Epoch 8/25\n",
      "659/666 [============================>.] - ETA: 0s - loss: 0.5741 - mae: 0.5064\n",
      "Epoch 8: val_loss did not improve from 0.57101\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5742 - mae: 0.5065 - val_loss: 0.5737 - val_mae: 0.5064\n",
      "Epoch 9/25\n",
      "655/666 [============================>.] - ETA: 0s - loss: 0.5737 - mae: 0.5061\n",
      "Epoch 9: val_loss did not improve from 0.57101\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5737 - mae: 0.5061 - val_loss: 0.5752 - val_mae: 0.5068\n",
      "Epoch 10/25\n",
      "665/666 [============================>.] - ETA: 0s - loss: 0.5741 - mae: 0.5064\n",
      "Epoch 10: val_loss improved from 0.57101 to 0.56844, saving model to checkpoints/ext_2h_l1mae_lr01-002_mb256_l1n2_2hidden_it19.e010_vl0.568.h5\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5741 - mae: 0.5064 - val_loss: 0.5684 - val_mae: 0.5010\n",
      "Epoch 11/25\n",
      "654/666 [============================>.] - ETA: 0s - loss: 0.5735 - mae: 0.5059\n",
      "Epoch 11: val_loss did not improve from 0.56844\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.5734 - mae: 0.5059 - val_loss: 0.5723 - val_mae: 0.5048\n",
      "Epoch 12/25\n"
     ]
    }
   ],
   "source": [
    "for k in range(0, n_iterations):\n",
    "    # Transform data to inputs and outputs\n",
    "    # On subsequent iterations, inflate errors using\n",
    "    # gradients dM/dtheta from trained model, and derive new\n",
    "    # estimates of the reddenings of the stars.\n",
    "    t0 = time()\n",
    "    io_train = get_inputs_outputs(\n",
    "        d_train,\n",
    "        pretrained_model=None if k == 0 else nn_model,\n",
    "        recalc_reddening=True,\n",
    "        rchisq_max=rchisq_max[k]\n",
    "    )                                                                         \n",
    "    io_test = get_inputs_outputs(\n",
    "        d_test,\n",
    "        pretrained_model=None if k == 0 else nn_model,\n",
    "        recalc_reddening=True,\n",
    "    )                                                                        \n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to prepare data: {t1-t0:.2f} s')\n",
    "    # Set learning rate based on the iteration\n",
    "    # lr = 0.001 * np.exp(-0.2*k)\n",
    "    lr = 0.01*np.exp(-0.02*k)\n",
    "    print('learning rate = {}'.format(K.get_value(nn_model.optimizer.lr)))\n",
    "    print('setting learning rate to {}'.format(lr))\n",
    "    K.set_value(nn_model.optimizer.lr, lr)\n",
    "\n",
    "    # Train the model\n",
    "    print('Iteration {} of {}.'.format(k+1, n_iterations))\n",
    "    t0 = time()\n",
    "    train_model(\n",
    "        nn_model,\n",
    "        io_train,\n",
    "        k,\n",
    "        n_iterations,\n",
    "        epochs=25,\n",
    "        checkpoint_fn='{:s}_{:d}hidden_it{:d}'.format(\n",
    "            nn_name, n_hidden, k\n",
    "        ),\n",
    "        batch_size=batch_size,\n",
    "        suff='{:s}_{:d}hidden_it{:d}'.format(nn_name, n_hidden, k)\n",
    "    )\n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to train: {t1-t0:.2f} s')\n",
    "    nn_model.save(\n",
    "        'models/{:s}_{:d}hidden_it{:d}.h5'.format(\n",
    "            nn_name, n_hidden, k\n",
    "        )\n",
    "    )\n",
    "    nn_model = keras.models.load_model(\n",
    "       'models/{:s}_{:d}hidden_it{:d}.h5'.format(nn_name, n_hidden, k)\n",
    "    )\n",
    "\n",
    "    # Plot results on test set\n",
    "    print('Diagnostic plots ...')\n",
    "    t0 = time()\n",
    "    diagnostic_plots(\n",
    "       nn_model,\n",
    "       io_test,\n",
    "       d_test,\n",
    "       #io_train,\n",
    "       #d_train,\n",
    "       suffix='{:s}_{:d}hidden_it{:d}'.format(nn_name, n_hidden, k)\n",
    "    )\n",
    "    t1 = time()\n",
    "    print(f'Time elapsed to make plots: {t1-t0:.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d8de09-5d9d-43a1-b6ad-5aa70393a40a",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Updating covariances and reddening estimates of test dataset ...')\n",
    "t0 = time()\n",
    "io_test = get_inputs_outputs(\n",
    "    d_test,\n",
    "    pretrained_model=nn_model,\n",
    "    recalc_reddening=True\n",
    ")\n",
    "t1 = time()\n",
    "print(f'Time elapsed to update covariances and reddenings: {t1-t0:.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe20ad0-6076-42e4-b5fa-0a8b44b55833",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate performance on (train, validation and test sets)\n",
    "loss = {}\n",
    "for n,io_eval in (('test',io_test), ('train',io_train)):\n",
    "    loss[n] = evaluate_model(\n",
    "        nn_model,\n",
    "        io_eval,\n",
    "        batch_size=batch_size,\n",
    "        rchisq_max=rchisq_max[-1]\n",
    "    )\n",
    "    print(f'{n} loss: {loss[n]}')\n",
    "fname = 'loss/loss_{:s}_{:d}hidden_it{:d}.json'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "with open(fname, 'w') as f:\n",
    "    json.dump(loss, f, indent=2, sort_keys=True)\n",
    "\n",
    "fname = 'predictions/predictions_{:s}_{:d}hidden_it{:d}.h5'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "save_predictions(fname, nn_model, d_test, io_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef83a49-55d7-41f4-be9e-87606f86734e",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Saving covariance components for small subset of test dataset ...')\n",
    "# Fix random seed (same subset every run)\n",
    "np.random.seed(3)\n",
    "idx = np.arange(d_test.size)\n",
    "np.random.shuffle(idx)\n",
    "idx = idx[:1000]\n",
    "d_comp = d_test[idx]\n",
    "io_comp = get_inputs_outputs(\n",
    "    d_comp,\n",
    "    pretrained_model=nn_model,\n",
    "    recalc_reddening=True,\n",
    "    return_cov_components=True\n",
    ")\n",
    "fname = 'predictions/predictions_{:s}_{:d}hidden_it{:d}_comp.h5'.format(\n",
    "    nn_name, n_hidden, n_iterations-1\n",
    ")\n",
    "save_predictions(fname, nn_model, d_comp, io_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf3ec27-6103-4713-9c21-1222e68e39f1",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Saving data and reddening estimates of subset of test dataset ...')\n",
    "np.random.seed(5)\n",
    "idx = np.arange(d_test.size)\n",
    "np.random.shuffle(idx)\n",
    "idx = idx[:10000]\n",
    "d_small = d_test[idx]\n",
    "r_fit_small = io_test['r'][idx]\n",
    "r_var_small = io_test['r_var'][idx]\n",
    "fname = 'test_data_small/test_data_small_{:s}_{:d}hidden.h5'.format(\n",
    "    nn_name, n_hidden\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82da0ebc-697f-4f8b-ae07-05ba4f0e7217",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'Saving subset to {fname} ...')\n",
    "with h5py.File(fname, 'w') as f:\n",
    "    dset = f.create_dataset(\n",
    "        'data',\n",
    "        data=d_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )\n",
    "    for key in d_attrs:\n",
    "        dset.attrs[key] = d_attrs[key]\n",
    "\n",
    "    # Store updated reddening estimates\n",
    "    dset = f.create_dataset(\n",
    "        'r_fit',\n",
    "        data=r_fit_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )\n",
    "    dset = f.create_dataset(\n",
    "        'r_var',\n",
    "        data=r_var_small,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 2,
      "defaultCellHeight": 40,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
