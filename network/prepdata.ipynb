{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68d6ff70-d455-4f9c-a6c1-d14a8b47c829",
   "metadata": {},
   "source": [
    "### Preparing the data in the same way that Green+2020 did\n",
    "The original functions from data-driven-stars.py are imported above, and below you'll find my adaptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d43e9cf-061d-42dc-a21c-7e8a119e2e3f",
   "metadata": {},
   "source": [
    "Importing the appropriate packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5eda379-1414-42bd-b76e-b13960afc9f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import h5py\n",
    "from glob import glob\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import SkyCoord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d8d8dd-0322-4269-a034-81ee3adbd866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_matrix(cov):\n",
    "    rho = cov.copy()\n",
    "    sqrt_cov_diag = np.sqrt(cov[np.diag_indices(cov.shape[0])])\n",
    "    rho /= sqrt_cov_diag[:,None]\n",
    "    rho /= sqrt_cov_diag[None,:]\n",
    "    rho[np.diag_indices(cov.shape[0])] = sqrt_cov_diag\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4e169c-0e6a-4fb7-8725-4e8f3880ae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_data(d):\n",
    "    # Cuts on atmospheric parameters\n",
    "    err_max = [200., 0.5, 0.5] # (T_eff, logg, [M/H])\n",
    "    idx = np.ones(d.size, dtype='bool')\n",
    "    for i,emax in enumerate(err_max):\n",
    "        idx &= (\n",
    "              np.isfinite(d['atm_param'][:,i])\n",
    "            & np.isfinite(d[f'atm_param_cov'][:,i,i])\n",
    "            & (d[f'atm_param_cov'][:,i,i] < emax*emax)\n",
    "        )\n",
    "    print(f'Filtered out {np.count_nonzero(~idx)} stars based on '\n",
    "           'atmospheric parameters.')\n",
    "    d = d[idx]\n",
    "\n",
    "    # Normalize atmospheric parameters\n",
    "    atm_param_med = np.median(d['atm_param'], axis=0)\n",
    "    atm_param_std = np.std(d['atm_param'], axis=0)\n",
    "    d['atm_param_p'] = (\n",
    "        (d['atm_param'] - atm_param_med[None,:]) / atm_param_std[None,:]\n",
    "    )\n",
    "    d['atm_param_cov_p'][:] = d['atm_param_cov'][:]\n",
    "    for i in range(3):\n",
    "        d['atm_param_cov_p'][:,i,:] /= atm_param_std[i]\n",
    "        d['atm_param_cov_p'][:,:,i] /= atm_param_std[i]\n",
    "\n",
    "    return d, (atm_param_med, atm_param_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3c1f6f-85ce-4fe2-bf87-671123ea23c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(d):\n",
    "    n_d = d.size\n",
    "    \n",
    "    print('Atmospheric parameter source:')\n",
    "    for key in np.unique(d['atm_source']):\n",
    "        n = np.count_nonzero(d['atm_source'] == key)\n",
    "        print(f'  * {key.decode(\"utf-8\")} : {n} ({n/n_d:.3f})')\n",
    "    \n",
    "    print('Reddening source:')\n",
    "    for key in np.unique(d['r_source']):\n",
    "        n = np.count_nonzero(d['r_source'] == key)\n",
    "        print(f'  * {key.decode(\"utf-8\")} : {n} ({n/n_d:.3f})')\n",
    "    \n",
    "    print('Sources per band:')\n",
    "    n_pi = np.count_nonzero(\n",
    "          np.isfinite(d['parallax'])\n",
    "        & (d['parallax'] / d['parallax_err'] > 5.)\n",
    "    )\n",
    "    print(f'  *  pi : {n_pi} ({n_pi/n_d:.3f})')\n",
    "    \n",
    "    n_band = np.count_nonzero(np.isfinite(d['mag']), axis=0)\n",
    "    bands = ['G','BP','RP'] + list('grizyJH') + ['K_s','W_1','W_2']\n",
    "    for b,n in zip(bands,n_band):\n",
    "        print(f'  * {b: >3s} : {n} ({n/n_d:.3f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11cd8ef-37af-4685-8dcf-a658c58916ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('/arc/home/aydanmckay/green2020-stellar-model/green2020_test_data_small.h5', 'r') as f:\n",
    "    d = f['data'][:]       # All the data needed to train or test the model\n",
    "    r_fit = f['r_fit'][:]  # The reddening inferred using the trained model\n",
    "    r_var = f['r_var'][:]  # The variance of the inferred reddening\n",
    "    print(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce7a10d-7ec3-43e2-b38c-57d8fcc9758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ab1ba-782d-4d8f-80f7-4b32c8f0e24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_fit.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258355b6-8735-4ffc-ab49-6ebdad845882",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_var.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec8f945-1a68-489c-8ff1-5d449ee63f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stats(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050b7a60-7f18-4ead-a7ad-c40de9f3ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478ad2cb-3652-4014-b556-f159bef7d1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdu = fits.open('/arc/home/aydanmckay/phottable-x-lamost-final.fits')\n",
    "hdu = fits.open('/arc/home/aydanmckay/union-photometry-table-cuts.fits')\n",
    "d = hdu[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f9c20f-5e85-4145-9b82-8da927eb12d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather into one dataset\n",
    "dtype = [\n",
    "    ('atm_param', '3f4'),\n",
    "    ('atm_param_cov', 'f4', (3,3)),\n",
    "    ('atm_param_p', '3f4'),           # normalized\n",
    "    ('atm_param_cov_p', 'f4', (3,3)), # normalized\n",
    "    ('r', 'f4'),\n",
    "    ('r_err', 'f4'),\n",
    "    ('mag', '13f4'),\n",
    "    ('mag_err', '13f4'),\n",
    "    ('parallax', 'f4'),\n",
    "    ('parallax_err', 'f4'),\n",
    "    ('atm_source', 'S6'),\n",
    "    ('r_source', 'S7')\n",
    "]\n",
    "\n",
    "# mask = (d['r_ps1'] > 13.500888) & (d['E_BV'] < 0.2)\n",
    "# d = d[mask]\n",
    "# this is for the datav3 only, where the mask is applied\n",
    "# just remove everywhere where [mask] exists\n",
    "\n",
    "io_data = np.empty(d.size, dtype=dtype)\n",
    "\n",
    "io_data['atm_source'] = 'lamost'\n",
    "\n",
    "# Copy in parameters\n",
    "# io_data['atm_param'][:,0] = d['TEFF_PASTEL'][:]\n",
    "# io_data['atm_param'][:,1] = d['LOGG_PASTEL'][:]\n",
    "# io_data['atm_param'][:,2] = d['FEH_PASTEL'][:]\n",
    "io_data['atm_param'][:,0] = d['teff_past_lam'][:]\n",
    "io_data['atm_param'][:,1] = d['logg_past_lam'][:]\n",
    "io_data['atm_param'][:,2] = d['feh_past_lam'][:]\n",
    "\n",
    "# Diagonal covariance matrix\n",
    "io_data['atm_param_cov'][:] = 0.\n",
    "# io_data['atm_param_cov'][:,0,0] = d['err_teff_pastel']**2.\n",
    "# io_data['atm_param_cov'][:,1,1] = d['err_logg_pastel']**2.\n",
    "# io_data['atm_param_cov'][:,2,2] = d['err_feh_pastel']**2.\n",
    "io_data['atm_param_cov'][:,0,0] = d['teff_past_lam_err']**2.\n",
    "io_data['atm_param_cov'][:,1,1] = d['logg_past_lam_err']**2.\n",
    "io_data['atm_param_cov'][:,2,2] = d['feh_past_lam_err']**2.\n",
    "\n",
    "# Add in error floor to atmospheric parameters\n",
    "sigma_atm_param_floor = [10., 0.05, 0.03] # (T_eff, logg, [M/H])\n",
    "for i,sig in enumerate(sigma_atm_param_floor):\n",
    "    io_data['atm_param_cov'][:,i,i] += sig**2\n",
    "\n",
    "# Print correlation matrices, for fun\n",
    "for i in range(10):\n",
    "    rho = get_corr_matrix(io_data['atm_param_cov'][i])\n",
    "    print('Correlation matrices:')\n",
    "    print(np.array2string(\n",
    "        rho,\n",
    "        formatter={'float_kind':lambda z:'{: >7.4f}'.format(z)}\n",
    "    ))\n",
    "\n",
    "z_0 = 0.4 # kpc\n",
    "galb = SkyCoord(d['ra'], d['dec'], frame='icrs', unit='deg').galactic.b.value\n",
    "sin_b_over_z = np.abs(np.sin(np.radians(galb))) / z_0\n",
    "idx_z = (d['para_gaia'] + 5*d['para_gaia_err'] < sin_b_over_z)\n",
    "idx_plx_over_err = (d['para_gaia'] / d['para_gaia_err'] > 5.)\n",
    "idx_b19 = np.isfinite(d['E_BV'])\n",
    "\n",
    "idx_sfd = idx_z\n",
    "idx_b19 = ~idx_sfd & idx_plx_over_err & idx_b19\n",
    "idx_default = ~idx_sfd & ~idx_b19\n",
    "\n",
    "print(r'Reddening sources:')\n",
    "print(r' * SFD: {:.4f}'.format(np.count_nonzero(idx_sfd)/idx_sfd.size))\n",
    "print(r' * B19: {:.4f}'.format(np.count_nonzero(idx_b19)/idx_b19.size))\n",
    "print(r' * ---: {:.4f}'.format(np.count_nonzero(idx_default)/idx_default.size))\n",
    "\n",
    "r_err_scale = 0.1\n",
    "\n",
    "io_data['r'][idx_default] = 0.\n",
    "io_data['r_err'][idx_default] = d['E_BV'][idx_default]\n",
    "io_data['r_source'][idx_default] = 'default'\n",
    "\n",
    "#idx = idx_plx_over_err & idx_b19\n",
    "b19_val = d['E_BV'][idx_b19]\n",
    "b19_err = d['e_CaHK'][idx_b19]\n",
    "b19_err = np.sqrt(b19_err**2 + r_err_scale**2*b19_val**2)\n",
    "io_data['r'][idx_b19] = b19_val\n",
    "io_data['r_err'][idx_b19] = b19_err\n",
    "io_data['r_source'][idx_b19] = 'b19'\n",
    "\n",
    "io_data['r'][idx_sfd] = d['E_BV'][idx_sfd]\n",
    "io_data['r_err'][idx_sfd] = 0.1 * d['E_BV'][idx_sfd]\n",
    "io_data['r_source'][idx_sfd] = 'sfd'\n",
    "\n",
    "# Add in reddening error floor\n",
    "r_err_floor = 0.02\n",
    "io_data['r_err'] = np.sqrt(\n",
    "      io_data['r_err']**2\n",
    "    + r_err_floor**2\n",
    "    #+ (r_err_scale*io_data['r'])**2\n",
    ")\n",
    "\n",
    "# Use Bayestar19 reddening by default\n",
    "io_data['r'] = d['E_BV'][:]\n",
    "io_data['r_err'] = d['e_CaHK'][:]\n",
    "\n",
    "# Use SFD reddening as fallback\n",
    "idx = ~np.isfinite(d['E_BV'])\n",
    "io_data['r'][idx] = d['E_BV'][idx]\n",
    "io_data['r_err'][idx] = d['E_BV'][idx]\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "# # Stricter fracflux cut on WISE passbands\n",
    "# idx = (d['unwise_fracflux'] < 0.5)\n",
    "# d['unwise_mag'][idx] = np.nan\n",
    "# d['unwise_mag_err'][idx] = np.nan\n",
    "\n",
    "# Copy in magnitudes\n",
    "io_data['mag'][:,0] = d['g_gaia']\n",
    "io_data['mag_err'][:,0] = d['g_gaia_err']\n",
    "# io_data['mag'][:,1] = d['b_gaia']\n",
    "io_data['mag'][:,1] = d['bp_gaia']\n",
    "# io_data['mag_err'][:,1] = d['b_gaia_err']\n",
    "io_data['mag_err'][:,1] = d['bp_gaia_err']\n",
    "# io_data['mag'][:,2] = d['r_gaia']\n",
    "io_data['mag'][:,1] = d['rp_gaia']\n",
    "# io_data['mag_err'][:,2] = d['r_gaia_err']\n",
    "io_data['mag_err'][:,1] = d['rp_gaia_err']\n",
    "# io_data['mag'][:,3] = d['g_ps1']\n",
    "io_data['mag'][:,3] = d['g_pan1']\n",
    "# io_data['mag_err'][:,3] = d['g_ps1_err']\n",
    "io_data['mag_err'][:,3] = d['g_pan1_err']\n",
    "# io_data['mag'][:,4] = d['r_ps1']\n",
    "io_data['mag'][:,3] = d['r_pan1']\n",
    "# io_data['mag_err'][:,4] = d['r_ps1_err']\n",
    "io_data['mag_err'][:,3] = d['r_pan1_err']\n",
    "# io_data['mag'][:,5] = d['i_ps1']\n",
    "io_data['mag'][:,3] = d['i_pan1']\n",
    "# io_data['mag_err'][:,5] = d['i_ps1_err']\n",
    "io_data['mag_err'][:,3] = d['i_pan1_err']\n",
    "# io_data['mag'][:,6] = d['z_ps1']\n",
    "io_data['mag'][:,3] = d['z_pan1']\n",
    "# io_data['mag_err'][:,6] = d['z_ps1_err']\n",
    "io_data['mag_err'][:,3] = d['z_pan1_err']\n",
    "# io_data['mag'][:,7] = d['y_ps1']\n",
    "io_data['mag'][:,3] = d['y_pan1']\n",
    "# io_data['mag_err'][:,7] = d['y_ps1_err']\n",
    "io_data['mag_err'][:,3] = d['y_pan1_err']\n",
    "# io_data['mag'][:,8] = d['j_2mass']\n",
    "io_data['mag'][:,8] = d['j_mass']\n",
    "# io_data['mag_err'][:,8] = d['j_2mass_err']\n",
    "io_data['mag_err'][:,10] = d['j_mass_err']\n",
    "# io_data['mag'][:,9] = d['h_2mass']\n",
    "io_data['mag'][:,8] = d['h_mass']\n",
    "# io_data['mag_err'][:,9] = d['h_2mass_err']\n",
    "io_data['mag_err'][:,10] = d['h_mass_err']\n",
    "# io_data['mag'][:,10] = d['k_2mass']\n",
    "io_data['mag'][:,8] = d['k_mass']\n",
    "# io_data['mag_err'][:,10] = d['k_2mass_err']\n",
    "io_data['mag_err'][:,10] = d['k_mass_err']\n",
    "\n",
    "# \n",
    "io_data['mag'][:,11] = d['w1_desi']\n",
    "io_data['mag_err'][:,11] = d['w1_desi_err']\n",
    "\n",
    "# \n",
    "io_data['mag'][:,12] = d['w2_desi']\n",
    "io_data['mag_err'][:,12] = d['w2_desi_err']\n",
    "\n",
    "# \n",
    "io_data['parallax'][:] = d['para_gaia']\n",
    "io_data['parallax_err'][:] = d['para_gaia_err']\n",
    "\n",
    "# count = 0\n",
    "# for it,i in enumerate(d['para_gaia']):\n",
    "#     if i <= 0:\n",
    "#         print(i,it)\n",
    "#         print(d['para_gaia_err'][it])\n",
    "#         count += 1\n",
    "# print(count)\n",
    "idx = (io_data['parallax'] <= 0)\n",
    "# print(len(idx[idx == True]))\n",
    "io_data['parallax'][idx] = np.nan\n",
    "io_data['parallax_err'][idx] = np.nan\n",
    "\n",
    "# Add in photometric error floors\n",
    "mag_err_floor = 0.02 * np.ones(13)\n",
    "io_data['mag_err'] = np.sqrt(\n",
    "      io_data['mag_err']**2\n",
    "    + mag_err_floor[None,:]**2\n",
    ")\n",
    "\n",
    "# Filter out magnitudes with err > 0.2\n",
    "idx = (io_data['mag_err'] > 0.2)\n",
    "io_data['mag'][idx] = np.nan\n",
    "io_data['mag_err'][idx] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a466a7eb-5fa7-4bc0-98c0-796ef175ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "io_data,(atm_param_med,atm_param_std) = finalize_data(io_data)\n",
    "print_stats(io_data)\n",
    "\n",
    "# with h5py.File('/arc/home/aydanmckay/ml/network/datasets/datav5.h5', 'w') as f:\n",
    "#     dset = f.create_dataset(\n",
    "#         'io_data',\n",
    "#         data=io_data,\n",
    "#         chunks=True,\n",
    "#         compression='gzip',\n",
    "#         compression_opts=3\n",
    "#     )\n",
    "#     dset.attrs['atm_param_med'] = atm_param_med\n",
    "#     dset.attrs['atm_param_std'] = atm_param_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18e33c4-ff47-41ca-a33a-9a0979ac9eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
