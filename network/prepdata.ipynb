{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68d6ff70-d455-4f9c-a6c1-d14a8b47c829",
   "metadata": {},
   "source": [
    "### Preparing the data in the same way that Green+2020 did\n",
    "The original functions from data-driven-stars.py are imported above, and below you'll find my adaptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d43e9cf-061d-42dc-a21c-7e8a119e2e3f",
   "metadata": {},
   "source": [
    "Importing the appropriate packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5eda379-1414-42bd-b76e-b13960afc9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import h5py\n",
    "from glob import glob\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import SkyCoord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54d8d8dd-0322-4269-a034-81ee3adbd866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_matrix(cov):\n",
    "    rho = cov.copy()\n",
    "    sqrt_cov_diag = np.sqrt(cov[np.diag_indices(cov.shape[0])])\n",
    "    rho /= sqrt_cov_diag[:,None]\n",
    "    rho /= sqrt_cov_diag[None,:]\n",
    "    rho[np.diag_indices(cov.shape[0])] = sqrt_cov_diag\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1ca2792-64c6-446a-a8ee-fb9f4c093bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fnames):\n",
    "    # Load in all the data files\n",
    "    d = []\n",
    "    b19 = []\n",
    "    b19_err = []\n",
    "\n",
    "    for fn in fnames:\n",
    "        print('Loading {:s} ...'.format(fn))\n",
    "        with h5py.File(fn, 'r') as f:\n",
    "            d.append(f['stellar_phot_spec_ast'][:])\n",
    "            b19.append(f['reddening'][:])\n",
    "            b19_err.append(f['reddening_err'][:])\n",
    "\n",
    "    d = np.hstack(d)\n",
    "    b19 = np.hstack(b19)\n",
    "    b19_err = np.hstack(b19_err)\n",
    "\n",
    "    return d, b19, b19_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "406dc615-26c8-4525-80bf-e1aaa9a35c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(d, b19, b19_err):\n",
    "    # Gather into one dataset\n",
    "    dtype = [\n",
    "        ('atm_param', '3f4'),\n",
    "        ('atm_param_cov', 'f4', (3,3)),\n",
    "        ('atm_param_p', '3f4'),           # normalized\n",
    "        ('atm_param_cov_p', 'f4', (3,3)), # normalized\n",
    "        ('r', 'f4'),\n",
    "        ('r_err', 'f4'),\n",
    "        ('mag', '13f4'),\n",
    "        ('mag_err', '13f4'),\n",
    "        ('parallax', 'f4'),\n",
    "        ('parallax_err', 'f4'),\n",
    "        ('atm_source', 'S6'),\n",
    "        ('r_source', 'S7')\n",
    "    ]\n",
    "    io_data = np.empty(d.size, dtype=dtype)\n",
    "    \n",
    "    # Offsets to bring spectroscopic labels from different\n",
    "    # surveys into alignment\n",
    "    offsets = {\n",
    "        'apogee': np.array([23.04715, 0.01189, 0.05019]),\n",
    "        'lamost': np.array([0., 0., 0.]),\n",
    "        'galah': np.array([-3.60096, -0.01396, 0.06770])\n",
    "    }\n",
    "    # Fix offsets to GALAH\n",
    "    offsets['apogee'] -= offsets['galah']\n",
    "    offsets['lamost'] -= offsets['galah']\n",
    "    offsets['galah'][:] = 0.\n",
    "    \n",
    "    print('offsets:')\n",
    "    for key in offsets:\n",
    "        print(f'  * {key}: {offsets[key]}')\n",
    "\n",
    "    # How to load data depends on survey\n",
    "    if 'sdss_aspcap_param' in d.dtype.names: # APOGEE\n",
    "        io_data['atm_source'] = 'apogee'\n",
    "        \n",
    "        param_idx = [0, 1, 3] # (T_eff, logg, [M/H])\n",
    "        param_name = ['teff', 'logg', 'm_h']\n",
    "\n",
    "        # Copy in parameters and corresponding covariance entries\n",
    "        for k,i in enumerate(param_idx):\n",
    "            io_data['atm_param'][:,k] = d['sdss_aspcap_param'][:,i]\n",
    "            for l,j in enumerate(param_idx):\n",
    "                io_data['atm_param_cov'][:,k,l] = d['sdss_aspcap_fparam_cov'][:,9*k+l]\n",
    "        \n",
    "        io_data['atm_param'] -= offsets['apogee'][None,:]\n",
    "\n",
    "        # Copy calibrated errors into diagonals of covariance matrices.\n",
    "        #   - Keep uncalibrated errors if larger.\n",
    "        for k,n in enumerate(param_name):\n",
    "            io_data['atm_param_cov'][:,k,k] = np.maximum(\n",
    "                d[f'sdss_aspcap_{n}_err']**2,\n",
    "                io_data['atm_param_cov'][:,k,k]\n",
    "            )\n",
    "\n",
    "    elif 'ddpayne_teff' in d.dtype.names: # LAMOST DDPAYNE\n",
    "        io_data['atm_source'] = 'lamost'\n",
    "        \n",
    "        # Copy in parameters\n",
    "        io_data['atm_param'][:,0] = d['ddpayne_teff'][:]\n",
    "        io_data['atm_param'][:,1] = d['ddpayne_logg'][:]\n",
    "        io_data['atm_param'][:,2] = d['ddpayne_feh'][:]\n",
    "        io_data['atm_param'] -= offsets['lamost'][None,:]\n",
    "\n",
    "        # Diagonal covariance matrix\n",
    "        io_data['atm_param_cov'][:] = 0.\n",
    "        io_data['atm_param_cov'][:,0,0] = d['ddpayne_teff_err']**2.\n",
    "        io_data['atm_param_cov'][:,1,1] = d['ddpayne_logg_err']**2.\n",
    "        io_data['atm_param_cov'][:,2,2] = d['ddpayne_feh_err']**2.\n",
    "    elif 'snr_c1' in d.dtype.names: # GALAH\n",
    "        io_data['atm_source'] = 'galah'\n",
    "        \n",
    "        # Copy in parameters\n",
    "        io_data['atm_param'][:,0] = d['teff'][:]\n",
    "        io_data['atm_param'][:,1] = d['logg'][:]\n",
    "        io_data['atm_param'][:,2] = d['feh'][:]\n",
    "        io_data['atm_param'] -= offsets['galah'][None,:]\n",
    "\n",
    "        # Diagonal covariance matrix\n",
    "        io_data['atm_param_cov'][:] = 0.\n",
    "        io_data['atm_param_cov'][:,0,0] = d['teff_err']**2.\n",
    "        io_data['atm_param_cov'][:,1,1] = d['logg_err']**2.\n",
    "        io_data['atm_param_cov'][:,2,2] = d['feh_err']**2.\n",
    "    \n",
    "    # Add in error floor to atmospheric parameters\n",
    "    sigma_atm_param_floor = [10., 0.05, 0.03] # (T_eff, logg, [M/H])\n",
    "    for i,sig in enumerate(sigma_atm_param_floor):\n",
    "        io_data['atm_param_cov'][:,i,i] += sig**2\n",
    "\n",
    "    # Print correlation matrices, for fun\n",
    "    for i in range(10):\n",
    "        rho = get_corr_matrix(io_data['atm_param_cov'][i])\n",
    "        print('Correlation matrices:')\n",
    "        print(np.array2string(\n",
    "            rho,\n",
    "            formatter={'float_kind':lambda z:'{: >7.4f}'.format(z)}\n",
    "        ))\n",
    "\n",
    "    # Reddening sources, in order of priority:\n",
    "    #   1. If |z| > 400 pc: Use SFD with 10% uncertainty\n",
    "    #   2. If parallax/error > 5: Use Bayestar19\n",
    "    #   3. Otherwise: Use 0 +- SFD\n",
    "    \n",
    "    z_0 = 0.4 # kpc\n",
    "    sin_b_over_z = np.abs(np.sin(np.radians(d['gal_b']))) / z_0\n",
    "    idx_z = (d['parallax'] + 5*d['parallax_err'] < sin_b_over_z)\n",
    "    idx_plx_over_err = (d['parallax'] / d['parallax_err'] > 5.)\n",
    "    idx_b19 = np.isfinite(b19)\n",
    "    \n",
    "    idx_sfd = idx_z\n",
    "    idx_b19 = ~idx_sfd & idx_plx_over_err & idx_b19\n",
    "    idx_default = ~idx_sfd & ~idx_b19\n",
    "    \n",
    "    print(r'Reddening sources:')\n",
    "    print(r' * SFD: {:.4f}'.format(np.count_nonzero(idx_sfd)/idx_sfd.size))\n",
    "    print(r' * B19: {:.4f}'.format(np.count_nonzero(idx_b19)/idx_b19.size))\n",
    "    print(r' * ---: {:.4f}'.format(np.count_nonzero(idx_default)/idx_default.size))\n",
    "    \n",
    "    r_err_scale = 0.1\n",
    "    \n",
    "    io_data['r'][idx_default] = 0.\n",
    "    io_data['r_err'][idx_default] = d['SFD'][idx_default]\n",
    "    io_data['r_source'][idx_default] = 'default'\n",
    "    \n",
    "    #idx = idx_plx_over_err & idx_b19\n",
    "    b19_val = b19[idx_b19]\n",
    "    b19_err = b19_err[idx_b19]\n",
    "    b19_err = np.sqrt(b19_err**2 + r_err_scale**2*b19_val**2)\n",
    "    io_data['r'][idx_b19] = b19_val\n",
    "    io_data['r_err'][idx_b19] = b19_err\n",
    "    io_data['r_source'][idx_b19] = 'b19'\n",
    "    \n",
    "    io_data['r'][idx_sfd] = d['SFD'][idx_sfd]\n",
    "    io_data['r_err'][idx_sfd] = 0.1 * d['SFD'][idx_sfd]\n",
    "    io_data['r_source'][idx_sfd] = 'sfd'\n",
    "    \n",
    "    # Add in reddening error floor\n",
    "    r_err_floor = 0.02\n",
    "    io_data['r_err'] = np.sqrt(\n",
    "          io_data['r_err']**2\n",
    "        + r_err_floor**2\n",
    "        #+ (r_err_scale*io_data['r'])**2\n",
    "    )\n",
    "    \n",
    "    ## Use Bayestar19 reddening by default\n",
    "    #io_data['r'] = b19[:]\n",
    "    #io_data['r_err'] = b19_err[:]\n",
    "    #\n",
    "    ## Use SFD reddening as fallback\n",
    "    #idx = ~np.isfinite(b19)\n",
    "    #io_data['r'][idx] = d['SFD'][idx]\n",
    "    #io_data['r_err'][idx] = d['SFD'][idx]\n",
    "    \n",
    "    # Stricter fracflux cut on WISE passbands\n",
    "    idx = (d['unwise_fracflux'] < 0.5)\n",
    "    d['unwise_mag'][idx] = np.nan\n",
    "    d['unwise_mag_err'][idx] = np.nan\n",
    "\n",
    "    # Copy in magnitudes\n",
    "    io_data['mag'][:,0] = d['gaia_g_mag']\n",
    "    io_data['mag_err'][:,0] = d['gaia_g_mag_err']\n",
    "    io_data['mag'][:,1] = d['gaia_bp_mag']\n",
    "    io_data['mag_err'][:,1] = d['gaia_bp_mag_err']\n",
    "    io_data['mag'][:,2] = d['gaia_rp_mag']\n",
    "    io_data['mag_err'][:,2] = d['gaia_rp_mag_err']\n",
    "    io_data['mag'][:,3:8] = d['ps1_mag']\n",
    "    io_data['mag_err'][:,3:8] = d['ps1_mag_err']\n",
    "    for i,b in enumerate('JHK'):\n",
    "        io_data['mag'][:,8+i] = d[f'tmass_{b}_mag']\n",
    "        io_data['mag_err'][:,8+i] = d[f'tmass_{b}_mag_err']\n",
    "    io_data['mag'][:,11:13] = d['unwise_mag']\n",
    "    io_data['mag_err'][:,11:13] = d['unwise_mag_err']\n",
    "\n",
    "    io_data['parallax'][:] = d['parallax']\n",
    "    io_data['parallax_err'][:] = d['parallax_err']\n",
    "\n",
    "    # Add in photometric error floors\n",
    "    mag_err_floor = 0.02 * np.ones(13)\n",
    "    io_data['mag_err'] = np.sqrt(\n",
    "          io_data['mag_err']**2\n",
    "        + mag_err_floor[None,:]**2\n",
    "    )\n",
    "\n",
    "    # Filter out magnitudes with err > 0.2\n",
    "    idx = (io_data['mag_err'] > 0.2)\n",
    "    io_data['mag'][idx] = np.nan\n",
    "    io_data['mag_err'][idx] = np.nan\n",
    "\n",
    "    return io_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fe2e3f7-915b-4da4-bc05-72da118d5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_multiple(fname_lists):\n",
    "    d_list = []\n",
    "\n",
    "    for fnames in fname_lists:\n",
    "        d,b19,b19_err = load_data(fnames)\n",
    "        d = extract_data(d, b19, b19_err)\n",
    "        print(f'Extracted {d.size} stars.')\n",
    "        d_list.append(d)\n",
    "\n",
    "    d = np.hstack(d_list)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a4e169c-0e6a-4fb7-8725-4e8f3880ae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_data(d):\n",
    "    # Cuts on atmospheric parameters\n",
    "    err_max = [200., 0.5, 0.5] # (T_eff, logg, [M/H])\n",
    "    idx = np.ones(d.size, dtype='bool')\n",
    "    for i,emax in enumerate(err_max):\n",
    "        idx &= (\n",
    "              np.isfinite(d['atm_param'][:,i])\n",
    "            & np.isfinite(d[f'atm_param_cov'][:,i,i])\n",
    "            & (d[f'atm_param_cov'][:,i,i] < emax*emax)\n",
    "        )\n",
    "    print(f'Filtered out {np.count_nonzero(~idx)} stars based on '\n",
    "           'atmospheric parameters.')\n",
    "    d = d[idx]\n",
    "\n",
    "    # Normalize atmospheric parameters\n",
    "    atm_param_med = np.median(d['atm_param'], axis=0)\n",
    "    atm_param_std = np.std(d['atm_param'], axis=0)\n",
    "    d['atm_param_p'] = (\n",
    "        (d['atm_param'] - atm_param_med[None,:]) / atm_param_std[None,:]\n",
    "    )\n",
    "    d['atm_param_cov_p'][:] = d['atm_param_cov'][:]\n",
    "    for i in range(3):\n",
    "        d['atm_param_cov_p'][:,i,:] /= atm_param_std[i]\n",
    "        d['atm_param_cov_p'][:,:,i] /= atm_param_std[i]\n",
    "\n",
    "    return d, (atm_param_med, atm_param_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba3c1f6f-85ce-4fe2-bf87-671123ea23c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(d):\n",
    "    n_d = d.size\n",
    "    \n",
    "    print('Atmospheric parameter source:')\n",
    "    for key in np.unique(d['atm_source']):\n",
    "        n = np.count_nonzero(d['atm_source'] == key)\n",
    "        print(f'  * {key.decode(\"utf-8\")} : {n} ({n/n_d:.3f})')\n",
    "    \n",
    "    print('Reddening source:')\n",
    "    for key in np.unique(d['r_source']):\n",
    "        n = np.count_nonzero(d['r_source'] == key)\n",
    "        print(f'  * {key.decode(\"utf-8\")} : {n} ({n/n_d:.3f})')\n",
    "    \n",
    "    print('Sources per band:')\n",
    "    n_pi = np.count_nonzero(\n",
    "          np.isfinite(d['parallax'])\n",
    "        & (d['parallax'] / d['parallax_err'] > 5.)\n",
    "    )\n",
    "    print(f'  *  pi : {n_pi} ({n_pi/n_d:.3f})')\n",
    "    \n",
    "    n_band = np.count_nonzero(np.isfinite(d['mag']), axis=0)\n",
    "    bands = ['G','BP','RP'] + list('grizyJH') + ['K_s','W_1','W_2']\n",
    "    for b,n in zip(bands,n_band):\n",
    "        print(f'  * {b: >3s} : {n} ({n/n_d:.3f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb9dc72e-cb05-4140-9a6b-c11576bfe3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fnames = [\n",
    "#     glob('data/dr16_data_*to*.h5'),\n",
    "#     glob('data/ddpayne_data_*to*.h5'),\n",
    "#     glob('data/galah_data_*to*.h5')\n",
    "# ]\n",
    "# d = extract_data_multiple(fnames)\n",
    "# d,(atm_param_med,atm_param_std) = finalize_data(d)\n",
    "# print_stats(d)\n",
    "\n",
    "# with h5py.File('data/apogee_lamost_galah_data.h5', 'w') as f:\n",
    "#     dset = f.create_dataset(\n",
    "#         'io_data',\n",
    "#         data=d,\n",
    "#         chunks=True,\n",
    "#         compression='gzip',\n",
    "#         compression_opts=3\n",
    "#     )\n",
    "#     dset.attrs['atm_param_med'] = atm_param_med\n",
    "#     dset.attrs['atm_param_std'] = atm_param_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f11cd8ef-37af-4685-8dcf-a658c58916ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['data', 'r_fit', 'r_var']>\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('/arc/home/aydanmckay/green2020-stellar-model/green2020_test_data_small.h5', 'r') as f:\n",
    "    d = f['data'][:]       # All the data needed to train or test the model\n",
    "    r_fit = f['r_fit'][:]  # The reddening inferred using the trained model\n",
    "    r_var = f['r_var'][:]  # The variance of the inferred reddening\n",
    "    print(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dce7a10d-7ec3-43e2-b38c-57d8fcc9758c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('atm_param', '<f4', (3,)), ('atm_param_cov', '<f4', (3, 3)), ('atm_param_p', '<f4', (3,)), ('atm_param_cov_p', '<f4', (3, 3)), ('r', '<f4'), ('r_err', '<f4'), ('mag', '<f4', (13,)), ('mag_err', '<f4', (13,)), ('parallax', '<f4'), ('parallax_err', '<f4'), ('atm_source', 'S6'), ('r_source', 'S7')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "200ab1ba-782d-4d8f-80f7-4b32c8f0e24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_fit.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "258355b6-8735-4ffc-ab49-6ebdad845882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_var.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eec8f945-1a68-489c-8ff1-5d449ee63f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atmospheric parameter source:\n",
      "  * apogee : 570 (0.057)\n",
      "  * galah : 466 (0.047)\n",
      "  * lamost : 8964 (0.896)\n",
      "Reddening source:\n",
      "  * b19 : 5086 (0.509)\n",
      "  * default : 949 (0.095)\n",
      "  * sfd : 3965 (0.397)\n",
      "Sources per band:\n",
      "  *  pi : 8462 (0.846)\n",
      "  *   G : 10000 (1.000)\n",
      "  *  BP : 9989 (0.999)\n",
      "  *  RP : 9990 (0.999)\n",
      "  *   g : 8181 (0.818)\n",
      "  *   r : 7046 (0.705)\n",
      "  *   i : 6438 (0.644)\n",
      "  *   z : 7381 (0.738)\n",
      "  *   y : 8419 (0.842)\n",
      "  *   J : 9482 (0.948)\n",
      "  *   H : 9299 (0.930)\n",
      "  * K_s : 8881 (0.888)\n",
      "  * W_1 : 2909 (0.291)\n",
      "  * W_2 : 6498 (0.650)\n"
     ]
    }
   ],
   "source": [
    "print_stats(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "478ad2cb-3652-4014-b556-f159bef7d1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu = fits.open('/arc/home/aydanmckay/phottable-x-lamost-final.fits')\n",
    "d = hdu[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15f9c20f-5e85-4145-9b82-8da927eb12d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation matrices:\n",
      "[[96.9648  0.0000  0.0000]\n",
      " [ 0.0000  0.1866  0.0000]\n",
      " [ 0.0000  0.0000  0.1149]]\n",
      "Correlation matrices:\n",
      "[[83.1902  0.0000  0.0000]\n",
      " [ 0.0000  0.1348  0.0000]\n",
      " [ 0.0000  0.0000  0.0791]]\n",
      "Correlation matrices:\n",
      "[[127.8071  0.0000  0.0000]\n",
      " [ 0.0000  0.2782  0.0000]\n",
      " [ 0.0000  0.0000  0.1788]]\n",
      "Correlation matrices:\n",
      "[[106.5848  0.0000  0.0000]\n",
      " [ 0.0000  0.2174  0.0000]\n",
      " [ 0.0000  0.0000  0.1363]]\n",
      "Correlation matrices:\n",
      "[[93.4956  0.0000  0.0000]\n",
      " [ 0.0000  0.1746  0.0000]\n",
      " [ 0.0000  0.0000  0.1066]]\n",
      "Correlation matrices:\n",
      "[[81.6529  0.0000  0.0000]\n",
      " [ 0.0000  0.1280  0.0000]\n",
      " [ 0.0000  0.0000  0.0744]]\n",
      "Correlation matrices:\n",
      "[[83.8680  0.0000  0.0000]\n",
      " [ 0.0000  0.1377  0.0000]\n",
      " [ 0.0000  0.0000  0.0811]]\n",
      "Correlation matrices:\n",
      "[[82.4166  0.0000  0.0000]\n",
      " [ 0.0000  0.1314  0.0000]\n",
      " [ 0.0000  0.0000  0.0768]]\n",
      "Correlation matrices:\n",
      "[[82.8407  0.0000  0.0000]\n",
      " [ 0.0000  0.1333  0.0000]\n",
      " [ 0.0000  0.0000  0.0780]]\n",
      "Correlation matrices:\n",
      "[[84.7983  0.0000  0.0000]\n",
      " [ 0.0000  0.1417  0.0000]\n",
      " [ 0.0000  0.0000  0.0838]]\n",
      "Reddening sources:\n",
      " * SFD: 0.6814\n",
      " * B19: 0.3186\n",
      " * ---: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Gather into one dataset\n",
    "dtype = [\n",
    "    ('atm_param', '3f4'),\n",
    "    ('atm_param_cov', 'f4', (3,3)),\n",
    "    ('atm_param_p', '3f4'),           # normalized\n",
    "    ('atm_param_cov_p', 'f4', (3,3)), # normalized\n",
    "    ('r', 'f4'),\n",
    "    ('r_err', 'f4'),\n",
    "    ('mag', '13f4'),\n",
    "    ('mag_err', '13f4'),\n",
    "    ('parallax', 'f4'),\n",
    "    ('parallax_err', 'f4'),\n",
    "    ('atm_source', 'S6'),\n",
    "    ('r_source', 'S7')\n",
    "]\n",
    "io_data = np.empty(d.size, dtype=dtype)\n",
    "\n",
    "io_data['atm_source'] = 'lamost'\n",
    "\n",
    "# Copy in parameters\n",
    "io_data['atm_param'][:,0] = d['TEFF_PASTEL'][:]\n",
    "io_data['atm_param'][:,1] = d['LOGG_PASTEL'][:]\n",
    "io_data['atm_param'][:,2] = d['FEH_PASTEL'][:]\n",
    "\n",
    "# Diagonal covariance matrix\n",
    "io_data['atm_param_cov'][:] = 0.\n",
    "io_data['atm_param_cov'][:,0,0] = d['err_teff_pastel']**2.\n",
    "io_data['atm_param_cov'][:,1,1] = d['err_logg_pastel']**2.\n",
    "io_data['atm_param_cov'][:,2,2] = d['err_feh_pastel']**2.\n",
    "\n",
    "# Add in error floor to atmospheric parameters\n",
    "sigma_atm_param_floor = [10., 0.05, 0.03] # (T_eff, logg, [M/H])\n",
    "for i,sig in enumerate(sigma_atm_param_floor):\n",
    "    io_data['atm_param_cov'][:,i,i] += sig**2\n",
    "\n",
    "# Print correlation matrices, for fun\n",
    "for i in range(10):\n",
    "    rho = get_corr_matrix(io_data['atm_param_cov'][i])\n",
    "    print('Correlation matrices:')\n",
    "    print(np.array2string(\n",
    "        rho,\n",
    "        formatter={'float_kind':lambda z:'{: >7.4f}'.format(z)}\n",
    "    ))\n",
    "\n",
    "z_0 = 0.4 # kpc\n",
    "galb = SkyCoord(d['ra'], d['dec'], frame='icrs', unit='deg').galactic.b.value\n",
    "sin_b_over_z = np.abs(np.sin(np.radians(galb))) / z_0\n",
    "idx_z = (d['para_gaia'] + 5*d['para_gaia_err'] < sin_b_over_z)\n",
    "idx_plx_over_err = (d['para_gaia'] / d['para_gaia_err'] > 5.)\n",
    "idx_b19 = np.isfinite(d['E_BV'])\n",
    "\n",
    "idx_sfd = idx_z\n",
    "idx_b19 = ~idx_sfd & idx_plx_over_err & idx_b19\n",
    "idx_default = ~idx_sfd & ~idx_b19\n",
    "\n",
    "print(r'Reddening sources:')\n",
    "print(r' * SFD: {:.4f}'.format(np.count_nonzero(idx_sfd)/idx_sfd.size))\n",
    "print(r' * B19: {:.4f}'.format(np.count_nonzero(idx_b19)/idx_b19.size))\n",
    "print(r' * ---: {:.4f}'.format(np.count_nonzero(idx_default)/idx_default.size))\n",
    "\n",
    "r_err_scale = 0.1\n",
    "\n",
    "io_data['r'][idx_default] = 0.\n",
    "io_data['r_err'][idx_default] = d['E_BV'][idx_default]\n",
    "io_data['r_source'][idx_default] = 'default'\n",
    "\n",
    "#idx = idx_plx_over_err & idx_b19\n",
    "b19_val = d['E_BV'][idx_b19]\n",
    "b19_err = d['e_CaHK'][idx_b19]\n",
    "b19_err = np.sqrt(b19_err**2 + r_err_scale**2*b19_val**2)\n",
    "io_data['r'][idx_b19] = b19_val\n",
    "io_data['r_err'][idx_b19] = b19_err\n",
    "io_data['r_source'][idx_b19] = 'b19'\n",
    "\n",
    "io_data['r'][idx_sfd] = d['E_BV'][idx_sfd]\n",
    "io_data['r_err'][idx_sfd] = 0.1 * d['E_BV'][idx_sfd]\n",
    "io_data['r_source'][idx_sfd] = 'sfd'\n",
    "\n",
    "# Add in reddening error floor\n",
    "r_err_floor = 0.02\n",
    "io_data['r_err'] = np.sqrt(\n",
    "      io_data['r_err']**2\n",
    "    + r_err_floor**2\n",
    "    #+ (r_err_scale*io_data['r'])**2\n",
    ")\n",
    "\n",
    "# Use Bayestar19 reddening by default\n",
    "io_data['r'] = d['E_BV'][:]\n",
    "io_data['r_err'] = d['e_CaHK'][:]\n",
    "\n",
    "# Use SFD reddening as fallback\n",
    "idx = ~np.isfinite(d['E_BV'])\n",
    "io_data['r'][idx] = d['E_BV'][idx]\n",
    "io_data['r_err'][idx] = d['E_BV'][idx]\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "# # Stricter fracflux cut on WISE passbands\n",
    "# idx = (d['unwise_fracflux'] < 0.5)\n",
    "# d['unwise_mag'][idx] = np.nan\n",
    "# d['unwise_mag_err'][idx] = np.nan\n",
    "\n",
    "# Copy in magnitudes\n",
    "io_data['mag'][:,0] = d['g_gaia']\n",
    "io_data['mag_err'][:,0] = d['g_gaia_err']\n",
    "io_data['mag'][:,1] = d['b_gaia']\n",
    "io_data['mag_err'][:,1] = d['b_gaia_err']\n",
    "io_data['mag'][:,2] = d['r_gaia']\n",
    "io_data['mag_err'][:,2] = d['r_gaia_err']\n",
    "io_data['mag'][:,3] = d['g_ps1']\n",
    "io_data['mag_err'][:,3] = d['g_ps1_err']\n",
    "io_data['mag'][:,4] = d['r_ps1']\n",
    "io_data['mag_err'][:,4] = d['r_ps1_err']\n",
    "io_data['mag'][:,5] = d['i_ps1']\n",
    "io_data['mag_err'][:,5] = d['i_ps1_err']\n",
    "io_data['mag'][:,6] = d['z_ps1']\n",
    "io_data['mag_err'][:,6] = d['z_ps1_err']\n",
    "io_data['mag'][:,7] = d['y_ps1']\n",
    "io_data['mag_err'][:,7] = d['y_ps1_err']\n",
    "io_data['mag'][:,8] = d['j_2mass']\n",
    "io_data['mag_err'][:,8] = d['j_2mass_err']\n",
    "io_data['mag'][:,9] = d['h_2mass']\n",
    "io_data['mag_err'][:,9] = d['h_2mass_err']\n",
    "io_data['mag'][:,10] = d['k_2mass']\n",
    "io_data['mag_err'][:,10] = d['k_2mass_err']\n",
    "io_data['mag'][:,9] = d['w1_desi']\n",
    "io_data['mag_err'][:,9] = d['w1_desi_err']\n",
    "io_data['mag'][:,10] = d['w2_desi']\n",
    "io_data['mag_err'][:,10] = d['w2_desi_err']\n",
    "\n",
    "io_data['parallax'][:] = d['para_gaia']\n",
    "io_data['parallax_err'][:] = d['para_gaia_err']\n",
    "\n",
    "# Add in photometric error floors\n",
    "mag_err_floor = 0.02 * np.ones(13)\n",
    "io_data['mag_err'] = np.sqrt(\n",
    "      io_data['mag_err']**2\n",
    "    + mag_err_floor[None,:]**2\n",
    ")\n",
    "\n",
    "# Filter out magnitudes with err > 0.2\n",
    "idx = (io_data['mag_err'] > 0.2)\n",
    "io_data['mag'][idx] = np.nan\n",
    "io_data['mag_err'][idx] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a466a7eb-5fa7-4bc0-98c0-796ef175ab28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 0 stars based on atmospheric parameters.\n",
      "Atmospheric parameter source:\n",
      "  * lamost : 281171 (1.000)\n",
      "Reddening source:\n",
      "  * b19 : 89576 (0.319)\n",
      "  * sfd : 191595 (0.681)\n",
      "Sources per band:\n",
      "  *  pi : 281165 (1.000)\n",
      "  *   G : 281171 (1.000)\n",
      "  *  BP : 281165 (1.000)\n",
      "  *  RP : 281165 (1.000)\n",
      "  *   g : 280624 (0.998)\n",
      "  *   r : 280562 (0.998)\n",
      "  *   i : 280728 (0.998)\n",
      "  *   z : 280746 (0.998)\n",
      "  *   y : 280793 (0.999)\n",
      "  *   J : 281168 (1.000)\n",
      "  *   H : 280805 (0.999)\n",
      "  * K_s : 280783 (0.999)\n",
      "  * W_1 : 281171 (1.000)\n",
      "  * W_2 : 281171 (1.000)\n"
     ]
    }
   ],
   "source": [
    "io_data,(atm_param_med,atm_param_std) = finalize_data(io_data)\n",
    "print_stats(io_data)\n",
    "\n",
    "with h5py.File('/arc/home/aydanmckay/ml/network/data.h5', 'w') as f:\n",
    "    dset = f.create_dataset(\n",
    "        'io_data',\n",
    "        data=io_data,\n",
    "        chunks=True,\n",
    "        compression='gzip',\n",
    "        compression_opts=3\n",
    "    )\n",
    "    dset.attrs['atm_param_med'] = atm_param_med\n",
    "    dset.attrs['atm_param_std'] = atm_param_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e969e1-f81a-4bf0-87d1-f0464837f28b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
