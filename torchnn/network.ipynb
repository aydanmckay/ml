{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e588d14-da9c-4ae9-8da0-7290a55a6f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from gaiaxpy import generate, PhotometricSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de22752-e4bb-4432-aacf-77dd15cbb3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59600fe2-eec9-4fb5-b501-af4087f9eb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /scratch/\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "529b91ee-15c3-40d2-8dfb-6d99ce31956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalers for dataloading\n",
    "metscaler = MinMaxScaler()\n",
    "logscaler = MinMaxScaler()\n",
    "tefscaler = MinMaxScaler()\n",
    "amscaler = MinMaxScaler()\n",
    "scalerlist = [MinMaxScaler() for _ in range(110)] # Hardcoded since we know number of xp coefficients is static\n",
    "\n",
    "# dataloader batchlength, learning rate, epochs for training\n",
    "batchlen = 32\n",
    "lr = 1e-2\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d04e2bfe-9f36-414e-a6cd-5a182788cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the Dataset class\n",
    "class train_set(Dataset):\n",
    "    def __init__(self,file):\n",
    "        fn = h5py.File(file, 'r')\n",
    "        self.f = fn\n",
    "        \n",
    "        # get data\n",
    "        dset = fn['group_1']['data']\n",
    "        self.x = torch.Tensor(dset[:].T)\n",
    "        \n",
    "        # get label\n",
    "        ydset = self.f['group_1']['label']\n",
    "        self.y = torch.Tensor(ydset[:].T)\n",
    "        # torch.from_numpy(y[index]) does not work since y is doubles and not floats.\n",
    "        \n",
    "        # get error in label # comment out for non-error label runs\n",
    "        errdset = self.f['group_1']['e_label']\n",
    "        self.err = torch.Tensor(errdset[:].T)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.f['group_1']['data'].shape[1]\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        xg = self.x[index]\n",
    "        yg = self.y[index]\n",
    "        errg = self.err[index]\n",
    "        return (xg,yg,errg)\n",
    "\n",
    "class valid_set(Dataset):\n",
    "    def __init__(self,file):\n",
    "        fn = h5py.File(file, 'r')\n",
    "        self.f = fn\n",
    "        \n",
    "        # get data\n",
    "        dset = self.f['group_2']['data']\n",
    "        self.x = torch.Tensor(dset[:].T)\n",
    "        \n",
    "        # get label\n",
    "        ydset = self.f['group_2']['label']\n",
    "        self.y = torch.Tensor(ydset[:].T)\n",
    "        # torch.from_numpy(y[index]) does not work since y is doubles and not floats.\n",
    "        \n",
    "        # get error in label # comment out for non-error label runs\n",
    "        errdset = self.f['group_2']['e_label']\n",
    "        self.err = torch.Tensor(errdset[:].T)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.f['group_2']['data'].shape[1]\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        xg = self.x[index]\n",
    "        yg = self.y[index]\n",
    "        errg = self.err[index]\n",
    "        return (xg,yg,errg)\n",
    "\n",
    "class new_data_set(Dataset):\n",
    "    def __init__(self,file,train=True,valid=False,test=False,noscale=False):\n",
    "        fn = h5py.File(file, 'r')\n",
    "        self.f = fn\n",
    "        \n",
    "        # get data\n",
    "        dset = fn['group_1']['data']\n",
    "        d = dset[:]\n",
    "        dat = np.array([\n",
    "            metscaler.fit_transform(d[[0]].T).flatten(),\n",
    "            logscaler.fit_transform(d[[1]].T).flatten(),\n",
    "            tefscaler.fit_transform(d[[2]].T).flatten(),\n",
    "            # amscaler.fit_transform(d[[3]].T).flatten(), # comment out if not\n",
    "        ])\n",
    "        if train:\n",
    "            self.l = dat.shape[1]\n",
    "            self.x = torch.Tensor(dat.T)\n",
    "        elif valid:\n",
    "            dset = fn['group_2']['data']\n",
    "            d = dset[:]\n",
    "            dat = np.array([\n",
    "                metscaler.transform(d[[0]].T).flatten(),\n",
    "                logscaler.transform(d[[1]].T).flatten(),\n",
    "                tefscaler.transform(d[[2]].T).flatten(),\n",
    "                # amscaler.transform(d[[3]].T).flatten(), # comment out if not\n",
    "            ])\n",
    "            self.l = dat.shape[1]\n",
    "            self.x = torch.Tensor(dat.T)\n",
    "        elif test:\n",
    "            dset = fn['group_3']['data']\n",
    "            d = dset[:]\n",
    "            dat = np.array([\n",
    "                metscaler.transform(d[[0]].T).flatten(),\n",
    "                logscaler.transform(d[[1]].T).flatten(),\n",
    "                tefscaler.transform(d[[2]].T).flatten(),\n",
    "                # amscaler.transform(d[[3]].T).flatten(), # comment out if not\n",
    "            ])\n",
    "            self.l = dat.shape[1]\n",
    "            self.x = torch.Tensor(dat.T)\n",
    "        elif noscale:\n",
    "            dset = fn['group_3']['data']\n",
    "            d = dset[:]\n",
    "            self.l = d.shape[1]\n",
    "            self.x = torch.Tensor(d.T)\n",
    "        \n",
    "        # get label\n",
    "        ydset = self.f['group_1']['label']\n",
    "        yd = ydset[:]\n",
    "        ydat = np.array([\n",
    "            scaler.fit_transform(yd[[it]].T).flatten() for it,scaler in enumerate(scalerlist)\n",
    "        ])\n",
    "        if train:\n",
    "            self.y = torch.Tensor(ydat[:].T) # torch.from_numpy(y[index]) does not work since y is doubles and not floats.\n",
    "        elif valid:\n",
    "            ydset = self.f['group_2']['label']\n",
    "            yd = ydset[:]\n",
    "            ydat = np.array([\n",
    "                scaler.transform(yd[[it]].T).flatten() for it,scaler in enumerate(scalerlist)\n",
    "            ])\n",
    "            self.y = torch.Tensor(ydat[:].T)\n",
    "        elif test:\n",
    "            ydset = self.f['group_3']['label']\n",
    "            yd = ydset[:]\n",
    "            ydat = np.array([\n",
    "                scaler.transform(yd[[it]].T).flatten() for it,scaler in enumerate(scalerlist)\n",
    "            ])\n",
    "            self.y = torch.Tensor(ydat[:].T)\n",
    "        elif noscale:\n",
    "            ydset = self.f['group_3']['label']\n",
    "            yd = ydset[:]\n",
    "            self.y = torch.Tensor(yd.T)\n",
    "        \n",
    "        # get error in label # comment out for non-error label runs\n",
    "        if train:\n",
    "            errdset = self.f['group_1']['e_label']\n",
    "            self.err = torch.Tensor(errdset[:].T)\n",
    "        elif valid:\n",
    "            errdset = self.f['group_2']['e_label']\n",
    "            self.err = torch.Tensor(errdset[:].T)\n",
    "        elif test or noscale:\n",
    "            errdset = self.f['group_3']['e_label']\n",
    "            self.err = torch.Tensor(errdset[:].T)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.l\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        xg = self.x[index]\n",
    "        yg = self.y[index]\n",
    "        errg = self.err[index]\n",
    "        return (xg,yg,errg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad6a4b81-bcad-4074-b0df-339d4b387267",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, nodes):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.res_block1 = nn.Sequential(\n",
    "            nn.Linear(nodes,nodes),\n",
    "            nn.BatchNorm1d(nodes),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.res_block2 = nn.Sequential(\n",
    "            nn.Linear(nodes,nodes),\n",
    "            nn.BatchNorm1d(nodes),\n",
    "        )\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "#         add dropout in the init\n",
    "        self.do = nn.Dropout() #\n",
    "    \n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        x = self.res_block1(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = x + res\n",
    "        output = self.lrelu(x)\n",
    "#         add dropout after the relu\n",
    "        output = self.do(x) #\n",
    "        return output\n",
    "        \n",
    "class ResNetMcK(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetMcK, self).__init__()\n",
    "        self.input_block = nn.Sequential(\n",
    "            nn.Linear(3,16),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.blocklist = nn.ModuleList([\n",
    "            ResBlock(16),\n",
    "            ResBlock(16),\n",
    "            nn.Linear(16,32),\n",
    "            ResBlock(32),\n",
    "            ResBlock(32),\n",
    "            nn.Linear(32,64),\n",
    "            ResBlock(64),\n",
    "            ResBlock(64),\n",
    "            nn.Linear(64,128),\n",
    "            ResBlock(128),\n",
    "            ResBlock(128),\n",
    "        ])\n",
    "        self.output_block = nn.Sequential(\n",
    "            nn.Linear(128,110),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.input_block(x)\n",
    "        for i, _ in enumerate(self.blocklist):\n",
    "            x = self.blocklist[i](x)\n",
    "        logits = self.output_block(x)\n",
    "        return logits\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(3, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 110),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "# try 3-layer simple network with sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73923470-976b-42e9-a4d6-2c2ddfd6dcac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# '/arc/home/aydanmckay/smallcutdata.h5'\n",
    "training_data = new_data_set('/arc/home/aydanmckay/input_catalogue_datacuts.h5')\n",
    "valid_data = new_data_set('/arc/home/aydanmckay/input_catalogue_datacuts.h5',train=False,valid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77a956c7-1af4-433d-ba15-15ee29aa36dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    training_data,\n",
    "    batch_size=batchlen,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_data,\n",
    "    batch_size=batchlen,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "# add gaussian noise to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98d63eb4-0dcc-4349-a5f0-16927365f037",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetMcK()\n",
    "# model = Net()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "499cbd4e-0faa-4d4f-9a27-29d328dcb1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = nn.L1Loss()\n",
    "loss_fn = nn.MSELoss()\n",
    "# loss_fn = nn.GaussianNLLLoss()\n",
    "# MAELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5d2ce5b-304a-4aeb-88da-d008d3cda243",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=lr,\n",
    "    momentum=0.9,\n",
    "    # weight_decay=1e-1\n",
    ")\n",
    "# weight decay -> 1e-1, 1e-3, 1e-5\n",
    "\n",
    "# optimizer = torch.optim.Adam(\n",
    "#     model.parameters(),\n",
    "#     lr=lr\n",
    "# )\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=1,\n",
    "    gamma=0.995\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79ef33a4-ee7c-467f-9b6c-9c5dc489b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res(preds,dataloader,epoch,resi='rel'):\n",
    "    fig, axs = plt.subplots(110)\n",
    "    fig.set_figheight(600)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for num, (X, y, z) in enumerate(dataloader):\n",
    "            if resi == 'rel':\n",
    "                residual = (y-preds[num])/y\n",
    "                string = 'Relative Residual'\n",
    "            elif resi == 'err':\n",
    "                residual = (y-preds[num])/z\n",
    "                string = 'Residual Over Label Error'\n",
    "            elif resi == 'res':\n",
    "                residual = y-preds[num]\n",
    "                string = 'Residual'\n",
    "            for it in range(len(y.T)):\n",
    "                axs[it].plot(y.T[it],residual.T[it],'k.',alpha=0.1)\n",
    "                axs[it].set_xlabel('Observed XP Coefficient Value')\n",
    "                axs[it].set_ylabel('Relative Residual')\n",
    "                axs[it].set_title('XP Coefficient '+str(it+1)+' '+string)\n",
    "                \n",
    "    plt.savefig('/arc/home/aydanmckay/torchplots/test'+resi+'residualsWL1epoch'+str(epoch)+'scalecutsep5.png')\n",
    "    plt.close()\n",
    "    \n",
    "def diagplot(preds,dataloader,epoch):\n",
    "    # fig, axs = plt.subplots(110)\n",
    "    # fig.set_figheight(600)\n",
    "    data = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for num, (X, y, z) in enumerate(dataloader):\n",
    "            for datum,true in zip(X,y):\n",
    "                data.append(datum)\n",
    "                labels.append(true)\n",
    "        plt.scatter([datum[0] for datum in data],[(pred[0]-y[0])/y[0] for pred,y in zip(preds,labels)],label='Bp Coefficient 1')\n",
    "        plt.scatter([datum[0] for datum in data],[(pred[54]-y[54])/y[54] for pred,y in zip(preds,labels)],label='Rp Coefficient 1')\n",
    "        plt.legend()\n",
    "        plt.title('BP and RP Coefficient 1')\n",
    "        plt.xlabel('Teff')\n",
    "        plt.ylabel('Relative Residual')\n",
    "        # plt.savefig('/arc/home/aydanmckay/torchresplots/test'+str(epoch)+'minmaxnoscalebig32diagplot.png')\n",
    "        # plt.close()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adf3653e-c574-488c-8ace-b2afc0012a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    running_loss = 0.\n",
    "    for batch, (X, y, z) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        # z = z.to(device)\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (batch % 1000 == 0):\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {running_loss/(batch+1):>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        \n",
    "    scheduler.step()\n",
    "            \n",
    "    print(f\"loss: {running_loss/len(dataloader):>7f}  [{size:>5d}/{size:>5d}]\")\n",
    "    return running_loss/len(dataloader)\n",
    "\n",
    "def valid(dataloader, model, loss_fn, epoch, device, plots = False):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    valid_loss, correct = 0, 0\n",
    "\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for X, y, z in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # z = z.to(device)\n",
    "            \n",
    "            pred = model(X)\n",
    "            valid_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred == y).type(torch.float).sum().item()\n",
    "            if plots == True:\n",
    "                for prediction in pred:\n",
    "                    preds.append(prediction.to('cpu'))\n",
    "    \n",
    "    if plots == True:\n",
    "        preds = np.array(preds)\n",
    "        # res(preds,dataloader,epoch,resi='res')\n",
    "        # res(preds,dataloader,epoch,resi='rel')\n",
    "        # res(preds,dataloader,epoch,resi='err')\n",
    "        diagplot(preds,dataloader,epoch)\n",
    "    \n",
    "    valid_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {valid_loss:>8f} \\n\")\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ad014d9-69c0-4678-9d56-f499f6a5a425",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 11.886822  [    0/2196737]\n",
      "loss: 0.203128  [32000/2196737]\n",
      "loss: 0.105295  [64000/2196737]\n",
      "loss: 0.072003  [96000/2196737]\n",
      "loss: 0.055082  [128000/2196737]\n",
      "loss: 0.044804  [160000/2196737]\n",
      "loss: 0.037859  [192000/2196737]\n",
      "loss: 0.032855  [224000/2196737]\n",
      "loss: 0.029051  [256000/2196737]\n",
      "loss: 0.026063  [288000/2196737]\n",
      "loss: 0.023650  [320000/2196737]\n",
      "loss: 0.021664  [352000/2196737]\n",
      "loss: 0.019993  [384000/2196737]\n",
      "loss: 0.018568  [416000/2196737]\n",
      "loss: 0.017339  [448000/2196737]\n",
      "loss: 0.016267  [480000/2196737]\n",
      "loss: 0.015322  [512000/2196737]\n",
      "loss: 0.014484  [544000/2196737]\n",
      "loss: 0.013735  [576000/2196737]\n",
      "loss: 0.013061  [608000/2196737]\n",
      "loss: 0.012452  [640000/2196737]\n",
      "loss: 0.011897  [672000/2196737]\n",
      "loss: 0.011393  [704000/2196737]\n",
      "loss: 0.010929  [736000/2196737]\n",
      "loss: 0.010503  [768000/2196737]\n",
      "loss: 0.010110  [800000/2196737]\n",
      "loss: 0.009746  [832000/2196737]\n",
      "loss: 0.009407  [864000/2196737]\n",
      "loss: 0.009093  [896000/2196737]\n",
      "loss: 0.008798  [928000/2196737]\n",
      "loss: 0.008523  [960000/2196737]\n",
      "loss: 0.008266  [992000/2196737]\n",
      "loss: 0.008023  [1024000/2196737]\n",
      "loss: 0.007795  [1056000/2196737]\n",
      "loss: 0.007580  [1088000/2196737]\n",
      "loss: 0.007377  [1120000/2196737]\n",
      "loss: 0.007185  [1152000/2196737]\n",
      "loss: 0.007003  [1184000/2196737]\n",
      "loss: 0.006830  [1216000/2196737]\n",
      "loss: 0.006666  [1248000/2196737]\n",
      "loss: 0.006510  [1280000/2196737]\n",
      "loss: 0.006362  [1312000/2196737]\n",
      "loss: 0.006220  [1344000/2196737]\n",
      "loss: 0.006085  [1376000/2196737]\n",
      "loss: 0.005956  [1408000/2196737]\n",
      "loss: 0.005832  [1440000/2196737]\n",
      "loss: 0.005714  [1472000/2196737]\n",
      "loss: 0.005601  [1504000/2196737]\n",
      "loss: 0.005492  [1536000/2196737]\n",
      "loss: 0.005388  [1568000/2196737]\n",
      "loss: 0.005288  [1600000/2196737]\n",
      "loss: 0.005192  [1632000/2196737]\n",
      "loss: 0.005099  [1664000/2196737]\n",
      "loss: 0.005010  [1696000/2196737]\n",
      "loss: 0.004924  [1728000/2196737]\n",
      "loss: 0.004842  [1760000/2196737]\n",
      "loss: 0.004762  [1792000/2196737]\n",
      "loss: 0.004685  [1824000/2196737]\n",
      "loss: 0.004611  [1856000/2196737]\n",
      "loss: 0.004539  [1888000/2196737]\n",
      "loss: 0.004469  [1920000/2196737]\n",
      "loss: 0.004402  [1952000/2196737]\n",
      "loss: 0.004337  [1984000/2196737]\n",
      "loss: 0.004274  [2016000/2196737]\n",
      "loss: 0.004213  [2048000/2196737]\n",
      "loss: 0.004153  [2080000/2196737]\n",
      "loss: 0.004096  [2112000/2196737]\n",
      "loss: 0.004040  [2144000/2196737]\n",
      "loss: 0.003986  [2176000/2196737]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 16])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m trainloss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m25\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      8\u001b[0m     validloss \u001b[38;5;241m=\u001b[39m valid(\n\u001b[1;32m      9\u001b[0m         valid_dataloader,\n\u001b[1;32m     10\u001b[0m         model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# plots = True,\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     )\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer, scheduler, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# z = z.to(device)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred,y)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mResNetMcK.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_block(x)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocklist):\n\u001b[0;32m---> 54\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocklist\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_block(x)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mResBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     18\u001b[0m     res \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m---> 19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mres_block1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres_block2(x)\n\u001b[1;32m     21\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m res\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/functional.py:2436\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2424\u001b[0m         batch_norm,\n\u001b[1;32m   2425\u001b[0m         (\u001b[38;5;28minput\u001b[39m, running_mean, running_var, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2433\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m   2434\u001b[0m     )\n\u001b[1;32m   2435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m-> 2436\u001b[0m     \u001b[43m_verify_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m   2439\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled\n\u001b[1;32m   2440\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/functional.py:2404\u001b[0m, in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2402\u001b[0m     size_prods \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m size[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m   2403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_prods \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 2404\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected more than 1 value per channel when training, got input size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(size))\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 16])"
     ]
    }
   ],
   "source": [
    "valloss = []\n",
    "traloss = []\n",
    "for t in range(epochs):\n",
    "    t0 = time()\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    trainloss = train(train_dataloader, model, loss_fn, optimizer, scheduler, device)\n",
    "    if t % 25 == 0:\n",
    "        validloss = valid(\n",
    "            valid_dataloader,\n",
    "            model,\n",
    "            loss_fn,\n",
    "            t,\n",
    "            device,\n",
    "            # plots = True,\n",
    "        )\n",
    "    else:\n",
    "        validloss = valid(\n",
    "            valid_dataloader,\n",
    "            model,\n",
    "            loss_fn,\n",
    "            t,\n",
    "            device,\n",
    "        )\n",
    "    valloss.append(validloss)\n",
    "    traloss.append(trainloss)\n",
    "    # torch.save({\n",
    "    #             'epoch': t,\n",
    "    #             'model_state_dict': model.state_dict(),\n",
    "    #             'optimizer_state_dict': optimizer.state_dict(),\n",
    "    #             'loss': tloss,\n",
    "    #             }, '/arc/home/aydanmckay/ml/torchnn/checkpoints/checkpointWGLsmallepoch'+str(t)+'scalecutsep5.pth')\n",
    "    # torch.save(model.state_dict(), \"/arc/home/aydanmckay/torchmodel/torchmodelWsmallscalecutsep5iter\"+str(t)+\".pth\")\n",
    "    t1 = time()\n",
    "    print(f'Elapsed epoch time: {t1-t0:.2f} s')\n",
    "print(\"Training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e9db6-f4f2-4460-8e85-80a7651e7bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,len(traloss)+1),traloss,'-o',label='Train Loss')\n",
    "plt.plot(range(1,len(valloss)+1),valloss,'-o',label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (L2)')\n",
    "# plt.ylim(0.65,0.67)\n",
    "plt.legend(fancybox=True)\n",
    "plt.title('Loss per Epoch')\n",
    "plt.savefig('/arc/home/aydanmckay/torchresplots/inputcatlossL2minmaxcutsbl32lr-2SGDep100dropout.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c10a35-3783-4200-b9a2-c1c7f4d2ca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(range(1,len(traloss)+1),traloss,'-o',label='Train Loss')\n",
    "plt.semilogy(range(1,len(valloss)+1),valloss,'-o',label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Log Loss (L2)')\n",
    "# plt.ylim(0.65,0.67)\n",
    "plt.legend(fancybox=True)\n",
    "plt.title('Loss per Epoch')\n",
    "plt.savefig('/arc/home/aydanmckay/torchresplots/inputcatsemilogylossL2minmaxcutsbl32lr-2SGDep100dropout.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f880d560-115e-4973-930b-52595ba21aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"/arc/home/aydanmckay/torchresmodel/inputcatmodelL2minmaxcutsbl32lr-2SGDep100dropout.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4532b6f9-2f44-4654-b145-1039e1a3d36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"/arc/home/aydanmckay/torchresmodel/inputcatmodelL2minmaxcutsbl32lr-2SGDep100dropout.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc6b361-8975-4a4a-8d76-70a9ecce0551",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = new_data_set('/arc/home/aydanmckay/input_catalogue_datacuts.h5',train=False,test=True)\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batchlen,\n",
    "    # shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "unscaled_data = new_data_set('/arc/home/aydanmckay/input_catalogue_datacuts.h5',train=False,noscale=True)\n",
    "unscaled_dataloader = DataLoader(\n",
    "    unscaled_data,\n",
    "    batch_size=batchlen,\n",
    "    # shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e676ae98-1cff-44bd-be50-421825c7b5c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # throw this into a class\n",
    "def mag_generator(model,loaded_data,scalerlist):\n",
    "    preds = []\n",
    "    covbs = []\n",
    "    covrs = []\n",
    "    with torch.no_grad():\n",
    "        for X, y, z in loaded_data:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            z = z.to(device)\n",
    "            pred = model(X)\n",
    "            for prediction,err in zip(pred,z):\n",
    "                covbp = np.zeros((55,55))\n",
    "                covrp = np.zeros((55,55))\n",
    "                preds.append(prediction)\n",
    "                for it in range(len(err[:55])):\n",
    "                    covbp[it][it] += err[it].item()**2\n",
    "                    covrp[it][it] += err[it+55].item()**2\n",
    "                covbs.append(covbp)\n",
    "                covrs.append(covrp)\n",
    "    preds = np.array([pred.to('cpu').numpy() for pred in preds]).T\n",
    "    xpnewpred = []\n",
    "    for pred,scaler in zip(preds,scalerlist):\n",
    "        xpnewpred.append(scaler.inverse_transform(np.array([pred]).T).flatten())\n",
    "    bpnews = np.array(xpnewpred[:55]).T\n",
    "    rpnews = np.array(xpnewpred[55:]).T\n",
    "    df = pd.DataFrame(\n",
    "        {'source_id':range(len(preds.T)),\n",
    "         'bp_coefficients':list(bpnews),\n",
    "         'bp_standard_deviation':[np.std(bp) for bp in bpnews],\n",
    "         'bp_coefficient_covariances':covbs,\n",
    "         'rp_coefficients':list(rpnews),\n",
    "         'rp_coefficient_covariances':covrs,\n",
    "         'rp_standard_deviation':[np.std(rp) for rp in rpnews]\n",
    "        }\n",
    "    )\n",
    "    synthetic_photometry = generate(df, photometric_system=PhotometricSystem.Pristine)\n",
    "    return synthetic_photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f54910-844c-4cdb-b9a5-79146404688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_phot = mag_generator(model,test_dataloader,scalerlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f9b65e-cad4-492f-9b0f-57cfe3c11425",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_phot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7772bf4-56a0-435e-a4ae-01b143bb86c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # throw this into a class\n",
    "def mag_generator_unscaled(model,loaded_data):\n",
    "    preds = []\n",
    "    covbs = []\n",
    "    covrs = []\n",
    "    with torch.no_grad():\n",
    "        for X, y, z in loaded_data:\n",
    "            y = y.to(device)\n",
    "            z = z.to(device)\n",
    "            pred = y\n",
    "            for prediction,err in zip(pred,z):\n",
    "                covbp = np.zeros((55,55))\n",
    "                covrp = np.zeros((55,55))\n",
    "                preds.append(prediction)\n",
    "                for it in range(len(err[:55])):\n",
    "                    covbp[it][it] += err[it].item()**2\n",
    "                    covrp[it][it] += err[it+55].item()**2\n",
    "                covbs.append(covbp)\n",
    "                covrs.append(covrp)\n",
    "    preds = np.array([pred.to('cpu').numpy() for pred in preds]).T\n",
    "    bpnews = np.array(preds[:55]).T\n",
    "    rpnews = np.array(preds[55:]).T\n",
    "    df = pd.DataFrame(\n",
    "        {'source_id':range(len(preds.T)),\n",
    "         'bp_coefficients':list(bpnews),\n",
    "         'bp_standard_deviation':[np.std(bp) for bp in bpnews],\n",
    "         'bp_coefficient_covariances':covbs,\n",
    "         'rp_coefficients':list(rpnews),\n",
    "         'rp_coefficient_covariances':covrs,\n",
    "         'rp_standard_deviation':[np.std(rp) for rp in rpnews]\n",
    "        }\n",
    "    )\n",
    "    synthetic_photometry = generate(df, photometric_system=PhotometricSystem.Pristine)\n",
    "    return synthetic_photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062127b3-234a-461d-b799-f2cdb7ad02ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_phot2 = mag_generator_unscaled(model,unscaled_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157ebcf6-7dce-4ca5-875b-972197295636",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_phot2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad46e958-0dd6-400a-8aa5-7c4db97558db",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_phot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4363af3a-7cd4-48bb-9fa3-0ba058710b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(synth_phot['Pristine_mag_CaHK'],synth_phot2['Pristine_mag_CaHK'],c='k',alpha=0.03)\n",
    "plt.hexbin(synth_phot['Pristine_mag_CaHK'],synth_phot2['Pristine_mag_CaHK'],mincnt=5)\n",
    "plt.plot(np.arange(14,26),np.arange(14,26))\n",
    "plt.xlim(13,26)\n",
    "plt.xlabel('Synthetic Magnitude from Predicted Bp/Rp Spectra Coefficients')\n",
    "plt.ylabel('Synthetic Magnitude from Observed Bp/Rp Spectra Coefficients')\n",
    "plt.title('Generated Pristine CaHK Magnitude Comparison between Predicted an/d True Xp Coefficient Labels');\n",
    "plt.savefig('/arc/home/aydanmckay/torchresplots/inputcatsmallpredictionscomparisons.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20efe2fe-c5f3-45d9-8f4b-d8dbfced59ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
