{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e588d14-da9c-4ae9-8da0-7290a55a6f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de22752-e4bb-4432-aacf-77dd15cbb3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d04e2bfe-9f36-414e-a6cd-5a182788cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the Dataset class\n",
    "class train_set(Dataset):\n",
    "    def __init__(self,file):\n",
    "        fn = h5py.File(file, 'r')\n",
    "        self.f = fn\n",
    "        \n",
    "        # get data\n",
    "        dset = fn['group_1']['data']\n",
    "        self.x = torch.Tensor(dset[:].T)\n",
    "        \n",
    "        # get label\n",
    "        ydset = self.f['group_1']['label']\n",
    "        self.y = torch.Tensor(ydset[:].T)\n",
    "        # torch.from_numpy(y[index]) does not work since y is doubles and not floats.\n",
    "        \n",
    "        # get error in label # comment out for non-error label runs\n",
    "        errdset = self.f['group_1']['e_label']\n",
    "        self.err = torch.Tensor(errdset[:].T)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.f['group_1']['data'].shape[1]\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        xg = self.x[index]\n",
    "        yg = self.y[index]\n",
    "        errg = self.err[index]\n",
    "        return (xg,yg,errg)\n",
    "\n",
    "class valid_set(Dataset):\n",
    "    def __init__(self,file):\n",
    "        fn = h5py.File(file, 'r')\n",
    "        self.f = fn\n",
    "        \n",
    "        # get data\n",
    "        dset = self.f['group_2']['data']\n",
    "        self.x = torch.Tensor(dset[:].T)\n",
    "        \n",
    "        # get label\n",
    "        ydset = self.f['group_2']['label']\n",
    "        self.y = torch.Tensor(ydset[:].T)\n",
    "        # torch.from_numpy(y[index]) does not work since y is doubles and not floats.\n",
    "        \n",
    "        # get error in label # comment out for non-error label runs\n",
    "        errdset = self.f['group_2']['e_label']\n",
    "        self.err = torch.Tensor(errdset[:].T)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.f['group_2']['data'].shape[1]\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        xg = self.x[index]\n",
    "        yg = self.y[index]\n",
    "        errg = self.err[index]\n",
    "        return (xg,yg,errg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad6a4b81-bcad-4074-b0df-339d4b387267",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, nodes):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.res_block1 = nn.Sequential(\n",
    "            nn.Linear(nodes,nodes),\n",
    "            nn.BatchNorm1d(nodes),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.res_block2 = nn.Sequential(\n",
    "            nn.Linear(nodes,nodes),\n",
    "            nn.BatchNorm1d(nodes),\n",
    "        )\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        x = self.res_block1(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = x + res\n",
    "        output = self.lrelu(x)\n",
    "        return output\n",
    "        \n",
    "class ResNetMcK(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetMcK, self).__init__()\n",
    "        self.input_block = nn.Sequential(\n",
    "            nn.Linear(3,16),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.blocklist = nn.ModuleList([\n",
    "            ResBlock(16),\n",
    "            ResBlock(16),\n",
    "            nn.Linear(16,32),\n",
    "            ResBlock(32),\n",
    "            ResBlock(32),\n",
    "            nn.Linear(32,64),\n",
    "            ResBlock(64),\n",
    "            ResBlock(64),\n",
    "            nn.Linear(64,128),\n",
    "            ResBlock(128),\n",
    "            ResBlock(128),\n",
    "        ])\n",
    "        self.output_block = nn.Sequential(\n",
    "            nn.Linear(128,110),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.input_block(x)\n",
    "        for i, _ in enumerate(self.blocklist):\n",
    "            x = self.blocklist[i](x)\n",
    "        logits = self.output_block(x)\n",
    "        return logits\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(3, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 110),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73923470-976b-42e9-a4d6-2c2ddfd6dcac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data = train_set(\"/arc/home/aydanmckay/elabelssmallcutdatascaled.h5\")\n",
    "valid_data = valid_set(\"/arc/home/aydanmckay/elabelssmallcutdatascaled.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77a956c7-1af4-433d-ba15-15ee29aa36dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchlen = 16\n",
    "train_dataloader = DataLoader(\n",
    "    training_data,\n",
    "    batch_size=batchlen,\n",
    "    # shuffle=True\n",
    "    num_workers=0\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_data,\n",
    "    batch_size=batchlen,\n",
    "    num_workers=0\n",
    "    # shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98d63eb4-0dcc-4349-a5f0-16927365f037",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetMcK()\n",
    "model = model.to(device)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "339472c1-88ef-47c4-8867-22722202c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a623584c-4569-4587-8d05-e21f47b20735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = nn.L1Loss()\n",
    "loss_fn = nn.MSELoss()\n",
    "# loss_fn = nn.GaussianNLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5d2ce5b-304a-4aeb-88da-d008d3cda243",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=lr,\n",
    "    momentum=0.9\n",
    ")\n",
    "# optimizer = torch.optim.Adam(\n",
    "#     model.parameters(),\n",
    "#     lr=lr\n",
    "# )\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=1,\n",
    "    gamma=0.995\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79ef33a4-ee7c-467f-9b6c-9c5dc489b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res(preds,dataloader,epoch,resi='rel'):\n",
    "    fig, axs = plt.subplots(110)\n",
    "    fig.set_figheight(600)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for num, (X, y, z) in enumerate(dataloader):\n",
    "            if resi == 'rel':\n",
    "                residual = (y-preds[num])/y\n",
    "                string = 'Relative Residual'\n",
    "            elif resi == 'err':\n",
    "                residual = (y-preds[num])/z\n",
    "                string = 'Residual Over Label Error'\n",
    "            elif resi == 'res':\n",
    "                residual = y-preds[num]\n",
    "                string = 'Residual'\n",
    "            for it in range(len(y.T)):\n",
    "                axs[it].plot(y.T[it],residual.T[it],'k.',alpha=0.1)\n",
    "                axs[it].set_xlabel('Observed XP Coefficient Value')\n",
    "                axs[it].set_ylabel('Relative Residual')\n",
    "                axs[it].set_title('XP Coefficient '+str(it+1)+' '+string)\n",
    "                \n",
    "    plt.savefig('/arc/home/aydanmckay/torchplots/test'+resi+'residualsWL1smallepoch'+str(epoch)+'scalecutsep5.png')\n",
    "    plt.close()\n",
    "    \n",
    "def diagplot(preds,dataloader,epoch):\n",
    "    # fig, axs = plt.subplots(110)\n",
    "    # fig.set_figheight(600)\n",
    "    data = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for num, (X, y, z) in enumerate(dataloader):\n",
    "            for datum,true in zip(X,y):\n",
    "                data.append(datum)\n",
    "                labels.append(true)\n",
    "        plt.scatter([datum[0] for datum in data],[(pred[0]-y[0])/y[0] for pred,y in zip(preds,labels)],label='Bp Coefficient 1')\n",
    "        plt.scatter([datum[0] for datum in data],[(pred[54]-y[54])/y[54] for pred,y in zip(preds,labels)],label='Rp Coefficient 1')\n",
    "        \n",
    "            # for it in range(len(y.T)):\n",
    "            #     axs[it].plot(y.T[it],pred.T[it],'k.',alpha=0.1)\n",
    "            #     axs[it].set_xlabel('Observed')\n",
    "            #     axs[it].set_ylabel('Predicted')\n",
    "            #     axs[it].set_title('XP Coefficient '+str(it+1))\n",
    "        plt.legend()\n",
    "        plt.title('BP and RP Coefficient 1')\n",
    "        plt.xlabel('Teff')\n",
    "        plt.ylabel('Relative Residual')\n",
    "        plt.savefig('/arc/home/aydanmckay/torchresplots/test'+str(epoch)+'diagplot.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adf3653e-c574-488c-8ace-b2afc0012a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    running_loss = 0.\n",
    "    for batch, (X, y, z) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        # z = z.to(device)\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (batch % 1000 == 0) and (batch != 0):\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {running_loss/batch:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        \n",
    "    scheduler.step()\n",
    "            \n",
    "    print(f\"loss: {running_loss/len(dataloader):>7f}  [{size:>5d}/{size:>5d}]\")\n",
    "    return running_loss/len(dataloader)\n",
    "\n",
    "def valid(dataloader, model, loss_fn, epoch, device, plots = False):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    valid_loss, correct = 0, 0\n",
    "\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for X, y, z in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # z = z.to(device)\n",
    "            \n",
    "            pred = model(X)\n",
    "            valid_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred == y).type(torch.float).sum().item()\n",
    "            if plots == True:\n",
    "                for prediction in pred:\n",
    "                    preds.append(prediction.to('cpu'))\n",
    "    \n",
    "    if plots == True:\n",
    "        preds = np.array(preds)\n",
    "        # res(preds,dataloader,epoch,resi='res')\n",
    "        # res(preds,dataloader,epoch,resi='rel')\n",
    "        # res(preds,dataloader,epoch,resi='err')\n",
    "        diagplot(preds,dataloader,epoch)\n",
    "    \n",
    "    valid_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {valid_loss:>8f} \\n\")\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ad014d9-69c0-4678-9d56-f499f6a5a425",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.912994  [16000/45000]\n",
      "loss: 0.895806  [32000/45000]\n",
      "loss: 0.881752  [45000/45000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1328751/154121105.py:49: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  preds = np.array(preds)\n",
      "/tmp/ipykernel_1328751/154121105.py:49: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  preds = np.array(preds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.834674 \n",
      "\n",
      "Elapsed epoch time: 29.23 s\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.856738  [16000/45000]\n",
      "loss: 0.856729  [32000/45000]\n",
      "loss: 0.849592  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.827429 \n",
      "\n",
      "Elapsed epoch time: 25.66 s\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.844546  [16000/45000]\n",
      "loss: 0.845810  [32000/45000]\n",
      "loss: 0.839500  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.824150 \n",
      "\n",
      "Elapsed epoch time: 23.80 s\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.837492  [16000/45000]\n",
      "loss: 0.839111  [32000/45000]\n",
      "loss: 0.833099  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.821369 \n",
      "\n",
      "Elapsed epoch time: 19.78 s\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.832068  [16000/45000]\n",
      "loss: 0.834040  [32000/45000]\n",
      "loss: 0.828188  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.819370 \n",
      "\n",
      "Elapsed epoch time: 22.24 s\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.827770  [16000/45000]\n",
      "loss: 0.829793  [32000/45000]\n",
      "loss: 0.824007  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.817704 \n",
      "\n",
      "Elapsed epoch time: 29.72 s\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.824284  [16000/45000]\n",
      "loss: 0.826567  [32000/45000]\n",
      "loss: 0.820829  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.817955 \n",
      "\n",
      "Elapsed epoch time: 24.87 s\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.821322  [16000/45000]\n",
      "loss: 0.823844  [32000/45000]\n",
      "loss: 0.818125  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.818074 \n",
      "\n",
      "Elapsed epoch time: 19.61 s\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.819092  [16000/45000]\n",
      "loss: 0.821737  [32000/45000]\n",
      "loss: 0.815962  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.815321 \n",
      "\n",
      "Elapsed epoch time: 19.48 s\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.817208  [16000/45000]\n",
      "loss: 0.819922  [32000/45000]\n",
      "loss: 0.814174  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.814445 \n",
      "\n",
      "Elapsed epoch time: 21.88 s\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.815717  [16000/45000]\n",
      "loss: 0.818266  [32000/45000]\n",
      "loss: 0.812495  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.811929 \n",
      "\n",
      "Elapsed epoch time: 26.61 s\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.814173  [16000/45000]\n",
      "loss: 0.816779  [32000/45000]\n",
      "loss: 0.810986  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.812606 \n",
      "\n",
      "Elapsed epoch time: 25.80 s\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.812793  [16000/45000]\n",
      "loss: 0.815437  [32000/45000]\n",
      "loss: 0.809685  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.812311 \n",
      "\n",
      "Elapsed epoch time: 20.71 s\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.811730  [16000/45000]\n",
      "loss: 0.814195  [32000/45000]\n",
      "loss: 0.808473  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.812028 \n",
      "\n",
      "Elapsed epoch time: 19.95 s\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.810703  [16000/45000]\n",
      "loss: 0.813138  [32000/45000]\n",
      "loss: 0.807383  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.812652 \n",
      "\n",
      "Elapsed epoch time: 19.56 s\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.809192  [16000/45000]\n",
      "loss: 0.811887  [32000/45000]\n",
      "loss: 0.806237  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.812602 \n",
      "\n",
      "Elapsed epoch time: 19.54 s\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.808545  [16000/45000]\n",
      "loss: 0.811063  [32000/45000]\n",
      "loss: 0.805278  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.811249 \n",
      "\n",
      "Elapsed epoch time: 22.05 s\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.807214  [16000/45000]\n",
      "loss: 0.809777  [32000/45000]\n",
      "loss: 0.804072  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.813086 \n",
      "\n",
      "Elapsed epoch time: 22.46 s\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.806224  [16000/45000]\n",
      "loss: 0.808741  [32000/45000]\n",
      "loss: 0.803039  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.812359 \n",
      "\n",
      "Elapsed epoch time: 27.62 s\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.805217  [16000/45000]\n",
      "loss: 0.807716  [32000/45000]\n",
      "loss: 0.802004  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.813628 \n",
      "\n",
      "Elapsed epoch time: 26.11 s\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.804297  [16000/45000]\n",
      "loss: 0.806612  [32000/45000]\n",
      "loss: 0.800921  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.813425 \n",
      "\n",
      "Elapsed epoch time: 20.74 s\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.802970  [16000/45000]\n",
      "loss: 0.805621  [32000/45000]\n",
      "loss: 0.799999  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.814750 \n",
      "\n",
      "Elapsed epoch time: 26.38 s\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.802526  [16000/45000]\n",
      "loss: 0.804796  [32000/45000]\n",
      "loss: 0.799107  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.815467 \n",
      "\n",
      "Elapsed epoch time: 24.56 s\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.801661  [16000/45000]\n",
      "loss: 0.803988  [32000/45000]\n",
      "loss: 0.798228  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.818021 \n",
      "\n",
      "Elapsed epoch time: 23.46 s\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.800958  [16000/45000]\n",
      "loss: 0.803075  [32000/45000]\n",
      "loss: 0.797066  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.816427 \n",
      "\n",
      "Elapsed epoch time: 21.93 s\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.799551  [16000/45000]\n",
      "loss: 0.802228  [32000/45000]\n",
      "loss: 0.796293  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.817682 \n",
      "\n",
      "Elapsed epoch time: 26.67 s\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.798728  [16000/45000]\n",
      "loss: 0.801254  [32000/45000]\n",
      "loss: 0.795345  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.819417 \n",
      "\n",
      "Elapsed epoch time: 29.96 s\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.798217  [16000/45000]\n",
      "loss: 0.800723  [32000/45000]\n",
      "loss: 0.794737  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.818991 \n",
      "\n",
      "Elapsed epoch time: 25.57 s\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.797326  [16000/45000]\n",
      "loss: 0.799712  [32000/45000]\n",
      "loss: 0.793767  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.819215 \n",
      "\n",
      "Elapsed epoch time: 24.11 s\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.796162  [16000/45000]\n",
      "loss: 0.798657  [32000/45000]\n",
      "loss: 0.792945  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.821780 \n",
      "\n",
      "Elapsed epoch time: 20.51 s\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.795823  [16000/45000]\n",
      "loss: 0.798245  [32000/45000]\n",
      "loss: 0.792302  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.821006 \n",
      "\n",
      "Elapsed epoch time: 20.42 s\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.794941  [16000/45000]\n",
      "loss: 0.797173  [32000/45000]\n",
      "loss: 0.791230  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.822890 \n",
      "\n",
      "Elapsed epoch time: 23.14 s\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.794307  [16000/45000]\n",
      "loss: 0.796065  [32000/45000]\n",
      "loss: 0.790103  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.824434 \n",
      "\n",
      "Elapsed epoch time: 23.43 s\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.793097  [16000/45000]\n",
      "loss: 0.794532  [32000/45000]\n",
      "loss: 0.788828  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.821153 \n",
      "\n",
      "Elapsed epoch time: 22.05 s\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.792602  [16000/45000]\n",
      "loss: 0.794073  [32000/45000]\n",
      "loss: 0.787933  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.825216 \n",
      "\n",
      "Elapsed epoch time: 21.39 s\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.792641  [16000/45000]\n",
      "loss: 0.793239  [32000/45000]\n",
      "loss: 0.787020  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.825018 \n",
      "\n",
      "Elapsed epoch time: 25.36 s\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.791174  [16000/45000]\n",
      "loss: 0.793127  [32000/45000]\n",
      "loss: 0.786769  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.827947 \n",
      "\n",
      "Elapsed epoch time: 23.91 s\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.789839  [16000/45000]\n",
      "loss: 0.791312  [32000/45000]\n",
      "loss: 0.785282  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.829519 \n",
      "\n",
      "Elapsed epoch time: 27.33 s\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.788976  [16000/45000]\n",
      "loss: 0.789745  [32000/45000]\n",
      "loss: 0.784158  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.832294 \n",
      "\n",
      "Elapsed epoch time: 24.76 s\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.788570  [16000/45000]\n",
      "loss: 0.789596  [32000/45000]\n",
      "loss: 0.783390  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.833125 \n",
      "\n",
      "Elapsed epoch time: 25.21 s\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.787673  [16000/45000]\n",
      "loss: 0.787762  [32000/45000]\n",
      "loss: 0.782217  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.829675 \n",
      "\n",
      "Elapsed epoch time: 23.06 s\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.785208  [16000/45000]\n",
      "loss: 0.786132  [32000/45000]\n",
      "loss: 0.780215  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.827654 \n",
      "\n",
      "Elapsed epoch time: 20.22 s\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.786538  [16000/45000]\n",
      "loss: 0.786620  [32000/45000]\n",
      "loss: 0.780678  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.822481 \n",
      "\n",
      "Elapsed epoch time: 22.02 s\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.782094  [16000/45000]\n",
      "loss: 0.784140  [32000/45000]\n",
      "loss: 0.778476  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.822136 \n",
      "\n",
      "Elapsed epoch time: 25.21 s\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.783021  [16000/45000]\n",
      "loss: 0.783504  [32000/45000]\n",
      "loss: 0.777381  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.823600 \n",
      "\n",
      "Elapsed epoch time: 28.39 s\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.781816  [16000/45000]\n",
      "loss: 0.782924  [32000/45000]\n",
      "loss: 0.777275  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.825196 \n",
      "\n",
      "Elapsed epoch time: 25.94 s\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.779399  [16000/45000]\n",
      "loss: 0.780572  [32000/45000]\n",
      "loss: 0.774375  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.827066 \n",
      "\n",
      "Elapsed epoch time: 21.58 s\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.788295  [16000/45000]\n",
      "loss: 0.784268  [32000/45000]\n",
      "loss: 0.777611  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.821573 \n",
      "\n",
      "Elapsed epoch time: 24.11 s\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.778868  [16000/45000]\n",
      "loss: 0.778982  [32000/45000]\n",
      "loss: 0.772689  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.826404 \n",
      "\n",
      "Elapsed epoch time: 27.99 s\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.778624  [16000/45000]\n",
      "loss: 0.778381  [32000/45000]\n",
      "loss: 0.771844  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.826762 \n",
      "\n",
      "Elapsed epoch time: 26.88 s\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.779179  [16000/45000]\n",
      "loss: 0.778465  [32000/45000]\n",
      "loss: 0.772398  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.826947 \n",
      "\n",
      "Elapsed epoch time: 28.24 s\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.774845  [16000/45000]\n",
      "loss: 0.775019  [32000/45000]\n",
      "loss: 0.769578  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.828654 \n",
      "\n",
      "Elapsed epoch time: 25.33 s\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.774209  [16000/45000]\n",
      "loss: 0.774076  [32000/45000]\n",
      "loss: 0.767609  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.830238 \n",
      "\n",
      "Elapsed epoch time: 22.64 s\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.773285  [16000/45000]\n",
      "loss: 0.773412  [32000/45000]\n",
      "loss: 0.766625  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.825946 \n",
      "\n",
      "Elapsed epoch time: 23.09 s\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.778424  [16000/45000]\n",
      "loss: 0.775495  [32000/45000]\n",
      "loss: 0.767365  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.831745 \n",
      "\n",
      "Elapsed epoch time: 25.78 s\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.772450  [16000/45000]\n",
      "loss: 0.770517  [32000/45000]\n",
      "loss: 0.763498  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.830807 \n",
      "\n",
      "Elapsed epoch time: 26.25 s\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.768232  [16000/45000]\n",
      "loss: 0.768957  [32000/45000]\n",
      "loss: 0.762162  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.833427 \n",
      "\n",
      "Elapsed epoch time: 26.81 s\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.767988  [16000/45000]\n",
      "loss: 0.769426  [32000/45000]\n",
      "loss: 0.762823  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.833554 \n",
      "\n",
      "Elapsed epoch time: 23.72 s\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.767838  [16000/45000]\n",
      "loss: 0.766285  [32000/45000]\n",
      "loss: 0.760500  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.831833 \n",
      "\n",
      "Elapsed epoch time: 23.88 s\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.763276  [16000/45000]\n",
      "loss: 0.766461  [32000/45000]\n",
      "loss: 0.759102  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.833665 \n",
      "\n",
      "Elapsed epoch time: 25.39 s\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.762767  [16000/45000]\n",
      "loss: 0.763130  [32000/45000]\n",
      "loss: 0.755658  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.838479 \n",
      "\n",
      "Elapsed epoch time: 24.88 s\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.762289  [16000/45000]\n",
      "loss: 0.762510  [32000/45000]\n",
      "loss: 0.755634  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.837152 \n",
      "\n",
      "Elapsed epoch time: 24.82 s\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.760112  [16000/45000]\n",
      "loss: 0.761444  [32000/45000]\n",
      "loss: 0.754416  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.832930 \n",
      "\n",
      "Elapsed epoch time: 26.36 s\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.758199  [16000/45000]\n",
      "loss: 0.758418  [32000/45000]\n",
      "loss: 0.752068  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.837395 \n",
      "\n",
      "Elapsed epoch time: 24.32 s\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.758740  [16000/45000]\n",
      "loss: 0.757696  [32000/45000]\n",
      "loss: 0.751056  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.839283 \n",
      "\n",
      "Elapsed epoch time: 23.59 s\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.757482  [16000/45000]\n",
      "loss: 0.757858  [32000/45000]\n",
      "loss: 0.750708  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.842914 \n",
      "\n",
      "Elapsed epoch time: 21.58 s\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.756726  [16000/45000]\n",
      "loss: 0.755701  [32000/45000]\n",
      "loss: 0.748626  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.833372 \n",
      "\n",
      "Elapsed epoch time: 25.05 s\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.753207  [16000/45000]\n",
      "loss: 0.753632  [32000/45000]\n",
      "loss: 0.748646  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.831490 \n",
      "\n",
      "Elapsed epoch time: 24.32 s\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.752232  [16000/45000]\n",
      "loss: 0.752197  [32000/45000]\n",
      "loss: 0.746507  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.841086 \n",
      "\n",
      "Elapsed epoch time: 21.65 s\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.749507  [16000/45000]\n",
      "loss: 0.749282  [32000/45000]\n",
      "loss: 0.743623  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.836954 \n",
      "\n",
      "Elapsed epoch time: 25.11 s\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.746475  [16000/45000]\n",
      "loss: 0.747647  [32000/45000]\n",
      "loss: 0.741700  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.836209 \n",
      "\n",
      "Elapsed epoch time: 21.90 s\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.752479  [16000/45000]\n",
      "loss: 0.751001  [32000/45000]\n",
      "loss: 0.744389  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.829871 \n",
      "\n",
      "Elapsed epoch time: 25.01 s\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.744595  [16000/45000]\n",
      "loss: 0.746325  [32000/45000]\n",
      "loss: 0.739545  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.838364 \n",
      "\n",
      "Elapsed epoch time: 21.42 s\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.741387  [16000/45000]\n",
      "loss: 0.742470  [32000/45000]\n",
      "loss: 0.735879  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.842895 \n",
      "\n",
      "Elapsed epoch time: 22.81 s\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.740274  [16000/45000]\n",
      "loss: 0.742968  [32000/45000]\n",
      "loss: 0.737744  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.843590 \n",
      "\n",
      "Elapsed epoch time: 22.53 s\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.736926  [16000/45000]\n",
      "loss: 0.738829  [32000/45000]\n",
      "loss: 0.732997  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.835954 \n",
      "\n",
      "Elapsed epoch time: 28.02 s\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.736659  [16000/45000]\n",
      "loss: 0.736756  [32000/45000]\n",
      "loss: 0.731645  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.842065 \n",
      "\n",
      "Elapsed epoch time: 28.69 s\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.733587  [16000/45000]\n",
      "loss: 0.734852  [32000/45000]\n",
      "loss: 0.728865  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.841469 \n",
      "\n",
      "Elapsed epoch time: 22.44 s\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.730125  [16000/45000]\n",
      "loss: 0.734112  [32000/45000]\n",
      "loss: 0.728618  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.841427 \n",
      "\n",
      "Elapsed epoch time: 20.09 s\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.729467  [16000/45000]\n",
      "loss: 0.732431  [32000/45000]\n",
      "loss: 0.726162  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.845684 \n",
      "\n",
      "Elapsed epoch time: 23.18 s\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.728246  [16000/45000]\n",
      "loss: 0.730887  [32000/45000]\n",
      "loss: 0.725603  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.843046 \n",
      "\n",
      "Elapsed epoch time: 22.16 s\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.727594  [16000/45000]\n",
      "loss: 0.728735  [32000/45000]\n",
      "loss: 0.722751  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.846303 \n",
      "\n",
      "Elapsed epoch time: 22.96 s\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.723260  [16000/45000]\n",
      "loss: 0.726317  [32000/45000]\n",
      "loss: 0.720372  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.848429 \n",
      "\n",
      "Elapsed epoch time: 22.15 s\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.725653  [16000/45000]\n",
      "loss: 0.726097  [32000/45000]\n",
      "loss: 0.719729  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.844703 \n",
      "\n",
      "Elapsed epoch time: 25.71 s\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.722133  [16000/45000]\n",
      "loss: 0.724333  [32000/45000]\n",
      "loss: 0.719013  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.849649 \n",
      "\n",
      "Elapsed epoch time: 25.74 s\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.720849  [16000/45000]\n",
      "loss: 0.723412  [32000/45000]\n",
      "loss: 0.717963  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.852679 \n",
      "\n",
      "Elapsed epoch time: 23.18 s\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.721653  [16000/45000]\n",
      "loss: 0.723035  [32000/45000]\n",
      "loss: 0.716587  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.858610 \n",
      "\n",
      "Elapsed epoch time: 21.70 s\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.720354  [16000/45000]\n",
      "loss: 0.722481  [32000/45000]\n",
      "loss: 0.716477  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.854818 \n",
      "\n",
      "Elapsed epoch time: 20.89 s\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.716068  [16000/45000]\n",
      "loss: 0.718771  [32000/45000]\n",
      "loss: 0.713109  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.850213 \n",
      "\n",
      "Elapsed epoch time: 20.09 s\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.716696  [16000/45000]\n",
      "loss: 0.718519  [32000/45000]\n",
      "loss: 0.713318  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.845806 \n",
      "\n",
      "Elapsed epoch time: 20.09 s\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.710731  [16000/45000]\n",
      "loss: 0.715684  [32000/45000]\n",
      "loss: 0.710141  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.850370 \n",
      "\n",
      "Elapsed epoch time: 21.92 s\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.709674  [16000/45000]\n",
      "loss: 0.713669  [32000/45000]\n",
      "loss: 0.709136  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.848952 \n",
      "\n",
      "Elapsed epoch time: 22.49 s\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.708550  [16000/45000]\n",
      "loss: 0.712509  [32000/45000]\n",
      "loss: 0.706916  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.849215 \n",
      "\n",
      "Elapsed epoch time: 21.22 s\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.706093  [16000/45000]\n",
      "loss: 0.709868  [32000/45000]\n",
      "loss: 0.705060  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.854234 \n",
      "\n",
      "Elapsed epoch time: 25.04 s\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.701578  [16000/45000]\n",
      "loss: 0.706633  [32000/45000]\n",
      "loss: 0.703073  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.857381 \n",
      "\n",
      "Elapsed epoch time: 27.76 s\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.702087  [16000/45000]\n",
      "loss: 0.707451  [32000/45000]\n",
      "loss: 0.701652  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.856553 \n",
      "\n",
      "Elapsed epoch time: 24.56 s\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.700890  [16000/45000]\n",
      "loss: 0.703377  [32000/45000]\n",
      "loss: 0.698972  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.859781 \n",
      "\n",
      "Elapsed epoch time: 23.62 s\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.701969  [16000/45000]\n",
      "loss: 0.704914  [32000/45000]\n",
      "loss: 0.699360  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.857903 \n",
      "\n",
      "Elapsed epoch time: 23.75 s\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.698278  [16000/45000]\n",
      "loss: 0.702505  [32000/45000]\n",
      "loss: 0.697238  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.855720 \n",
      "\n",
      "Elapsed epoch time: 24.41 s\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.695244  [16000/45000]\n",
      "loss: 0.699453  [32000/45000]\n",
      "loss: 0.694929  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.864072 \n",
      "\n",
      "Elapsed epoch time: 19.84 s\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "valloss = []\n",
    "traloss = []\n",
    "for t in range(epochs):\n",
    "    t0 = time()\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    trainloss = train(train_dataloader, model, loss_fn, optimizer, scheduler, device)\n",
    "    if t % 25 == 0:\n",
    "        validloss = valid(valid_dataloader, model, loss_fn, t, device, plots = True)\n",
    "    else:\n",
    "        validloss = valid(valid_dataloader, model, loss_fn, t, device)\n",
    "    valloss.append(validloss)\n",
    "    traloss.append(trainloss)\n",
    "    # torch.save({\n",
    "    #             'epoch': t,\n",
    "    #             'model_state_dict': model.state_dict(),\n",
    "    #             'optimizer_state_dict': optimizer.state_dict(),\n",
    "    #             'loss': tloss,\n",
    "    #             }, '/arc/home/aydanmckay/ml/torchnn/checkpoints/checkpointWGLsmallepoch'+str(t)+'scalecutsep5.pth')\n",
    "    # torch.save(model.state_dict(), \"/arc/home/aydanmckay/torchmodel/torchmodelWsmallscalecutsep5iter\"+str(t)+\".pth\")\n",
    "    t1 = time()\n",
    "    print(f'Elapsed epoch time: {t1-t0:.2f} s')\n",
    "print(\"Training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "983e9db6-f4f2-4460-8e85-80a7651e7bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,len(traloss)+1),traloss,'-o',label='Train Loss')\n",
    "plt.plot(range(1,len(valloss)+1),valloss,'-o',label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (L2)')\n",
    "# plt.ylim(0.65,0.67)\n",
    "plt.legend(fancybox=True)\n",
    "plt.title('Loss per Epoch')\n",
    "plt.savefig('/arc/home/aydanmckay/torchresplots/lossL2smallscalecutsbl16lr-2SGDep100.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f880d560-115e-4973-930b-52595ba21aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"/arc/home/aydanmckay/torchresmodel/modelL2smallscalecutsbl16lr-2SGDep100.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e676ae98-1cff-44bd-be50-421825c7b5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
