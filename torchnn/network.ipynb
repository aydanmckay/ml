{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e588d14-da9c-4ae9-8da0-7290a55a6f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de22752-e4bb-4432-aacf-77dd15cbb3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d04e2bfe-9f36-414e-a6cd-5a182788cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the Dataset class\n",
    "class train_set(Dataset):\n",
    "    def __init__(self,file):\n",
    "        fn = h5py.File(file, 'r')\n",
    "        self.f = fn\n",
    "        \n",
    "        # get data\n",
    "        dset = fn['group_1']['data']\n",
    "        self.x = torch.Tensor(dset[:].T)\n",
    "        \n",
    "        # get label\n",
    "        ydset = self.f['group_1']['label']\n",
    "        self.y = torch.Tensor(ydset[:].T)\n",
    "        # torch.from_numpy(y[index]) does not work since y is doubles and not floats.\n",
    "        \n",
    "        # get error in label # comment out for non-error label runs\n",
    "        errdset = self.f['group_1']['e_label']\n",
    "        self.err = torch.Tensor(errdset[:].T)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.f['group_1']['data'].shape[1]\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        xg = self.x[index]\n",
    "        yg = self.y[index]\n",
    "        errg = self.err[index]\n",
    "        return (xg,yg,errg)\n",
    "\n",
    "class valid_set(Dataset):\n",
    "    def __init__(self,file):\n",
    "        fn = h5py.File(file, 'r')\n",
    "        self.f = fn\n",
    "        \n",
    "        # get data\n",
    "        dset = self.f['group_2']['data']\n",
    "        self.x = torch.Tensor(dset[:].T)\n",
    "        \n",
    "        # get label\n",
    "        ydset = self.f['group_2']['label']\n",
    "        self.y = torch.Tensor(ydset[:].T)\n",
    "        # torch.from_numpy(y[index]) does not work since y is doubles and not floats.\n",
    "        \n",
    "        # get error in label # comment out for non-error label runs\n",
    "        errdset = self.f['group_2']['e_label']\n",
    "        self.err = torch.Tensor(errdset[:].T)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.f['group_2']['data'].shape[1]\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        xg = self.x[index]\n",
    "        yg = self.y[index]\n",
    "        errg = self.err[index]\n",
    "        return (xg,yg,errg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad6a4b81-bcad-4074-b0df-339d4b387267",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, nodes):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.res_block1 = nn.Sequential(\n",
    "            nn.Linear(nodes,nodes),\n",
    "            nn.BatchNorm1d(nodes),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.res_block2 = nn.Sequential(\n",
    "            nn.Linear(nodes,nodes),\n",
    "            nn.BatchNorm1d(nodes),\n",
    "        )\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        x = self.res_block1(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = x + res\n",
    "        output = self.lrelu(x)\n",
    "        return output\n",
    "        \n",
    "class ResNetMcK(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetMcK, self).__init__()\n",
    "        self.input_block = nn.Sequential(\n",
    "            nn.Linear(3,16),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.blocklist = nn.ModuleList([\n",
    "            ResBlock(16),\n",
    "            ResBlock(16),\n",
    "            nn.Linear(16,32),\n",
    "            ResBlock(32),\n",
    "            ResBlock(32),\n",
    "            nn.Linear(32,64),\n",
    "            ResBlock(64),\n",
    "            ResBlock(64),\n",
    "            nn.Linear(64,128),\n",
    "            ResBlock(128),\n",
    "            ResBlock(128),\n",
    "        ])\n",
    "        self.output_block = nn.Sequential(\n",
    "            nn.Linear(128,110),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.input_block(x)\n",
    "        for i, _ in enumerate(self.blocklist):\n",
    "            x = self.blocklist[i](x)\n",
    "        logits = self.output_block(x)\n",
    "        return logits\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(3, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 110),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "# try 3-layer simple network with sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73923470-976b-42e9-a4d6-2c2ddfd6dcac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data = train_set(\"/arc/home/aydanmckay/smallcutdataMinMaxscaled.h5\")\n",
    "valid_data = valid_set(\"/arc/home/aydanmckay/smallcutdataMinMaxscaled.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77a956c7-1af4-433d-ba15-15ee29aa36dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchlen = 32\n",
    "train_dataloader = DataLoader(\n",
    "    training_data,\n",
    "    batch_size=batchlen,\n",
    "    # shuffle=True\n",
    "    num_workers=0\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_data,\n",
    "    batch_size=batchlen,\n",
    "    num_workers=0\n",
    "    # shuffle=True\n",
    ")\n",
    "# add gaussian noise to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98d63eb4-0dcc-4349-a5f0-16927365f037",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetMcK()\n",
    "# model = Net()\n",
    "model = model.to(device)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "339472c1-88ef-47c4-8867-22722202c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a623584c-4569-4587-8d05-e21f47b20735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = nn.L1Loss()\n",
    "loss_fn = nn.MSELoss()\n",
    "# loss_fn = nn.GaussianNLLLoss()\n",
    "# MAELoss\n",
    "# regularization\n",
    "# switch to relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5d2ce5b-304a-4aeb-88da-d008d3cda243",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=lr,\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "# weight decay -> 1e-1, 1e-3, 1e-5\n",
    "\n",
    "# optimizer = torch.optim.Adam(\n",
    "#     model.parameters(),\n",
    "#     lr=lr\n",
    "# )\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=1,\n",
    "    gamma=0.995\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79ef33a4-ee7c-467f-9b6c-9c5dc489b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res(preds,dataloader,epoch,resi='rel'):\n",
    "    fig, axs = plt.subplots(110)\n",
    "    fig.set_figheight(600)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for num, (X, y, z) in enumerate(dataloader):\n",
    "            if resi == 'rel':\n",
    "                residual = (y-preds[num])/y\n",
    "                string = 'Relative Residual'\n",
    "            elif resi == 'err':\n",
    "                residual = (y-preds[num])/z\n",
    "                string = 'Residual Over Label Error'\n",
    "            elif resi == 'res':\n",
    "                residual = y-preds[num]\n",
    "                string = 'Residual'\n",
    "            for it in range(len(y.T)):\n",
    "                axs[it].plot(y.T[it],residual.T[it],'k.',alpha=0.1)\n",
    "                axs[it].set_xlabel('Observed XP Coefficient Value')\n",
    "                axs[it].set_ylabel('Relative Residual')\n",
    "                axs[it].set_title('XP Coefficient '+str(it+1)+' '+string)\n",
    "                \n",
    "    plt.savefig('/arc/home/aydanmckay/torchplots/test'+resi+'residualsWL1smallepoch'+str(epoch)+'scalecutsep5.png')\n",
    "    plt.close()\n",
    "    \n",
    "def diagplot(preds,dataloader,epoch):\n",
    "    # fig, axs = plt.subplots(110)\n",
    "    # fig.set_figheight(600)\n",
    "    data = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for num, (X, y, z) in enumerate(dataloader):\n",
    "            for datum,true in zip(X,y):\n",
    "                data.append(datum)\n",
    "                labels.append(true)\n",
    "        plt.scatter([datum[0] for datum in data],[(pred[0]-y[0])/y[0] for pred,y in zip(preds,labels)],label='Bp Coefficient 1')\n",
    "        plt.scatter([datum[0] for datum in data],[(pred[54]-y[54])/y[54] for pred,y in zip(preds,labels)],label='Rp Coefficient 1')\n",
    "        \n",
    "            # for it in range(len(y.T)):\n",
    "            #     axs[it].plot(y.T[it],pred.T[it],'k.',alpha=0.1)\n",
    "            #     axs[it].set_xlabel('Observed')\n",
    "            #     axs[it].set_ylabel('Predicted')\n",
    "            #     axs[it].set_title('XP Coefficient '+str(it+1))\n",
    "        plt.legend()\n",
    "        plt.title('BP and RP Coefficient 1')\n",
    "        plt.xlabel('Teff')\n",
    "        plt.ylabel('Relative Residual')\n",
    "        plt.savefig('/arc/home/aydanmckay/torchresplots/test'+str(epoch)+'minmaxwd-5_32diagplot.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adf3653e-c574-488c-8ace-b2afc0012a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    running_loss = 0.\n",
    "    for batch, (X, y, z) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        # z = z.to(device)\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # if (batch % 1000 == 0) and (batch != 0):\n",
    "        #     loss, current = loss.item(), batch * len(X)\n",
    "        #     print(f\"loss: {running_loss/batch:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        \n",
    "    scheduler.step()\n",
    "            \n",
    "    print(f\"loss: {running_loss/len(dataloader):>7f}  [{size:>5d}/{size:>5d}]\")\n",
    "    return running_loss/len(dataloader)\n",
    "\n",
    "def valid(dataloader, model, loss_fn, epoch, device, plots = False):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    valid_loss, correct = 0, 0\n",
    "\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for X, y, z in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # z = z.to(device)\n",
    "            \n",
    "            pred = model(X)\n",
    "            valid_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred == y).type(torch.float).sum().item()\n",
    "            if plots == True:\n",
    "                for prediction in pred:\n",
    "                    preds.append(prediction.to('cpu'))\n",
    "    \n",
    "    if plots == True:\n",
    "        preds = np.array(preds)\n",
    "        # res(preds,dataloader,epoch,resi='res')\n",
    "        # res(preds,dataloader,epoch,resi='rel')\n",
    "        # res(preds,dataloader,epoch,resi='err')\n",
    "        diagplot(preds,dataloader,epoch)\n",
    "    \n",
    "    valid_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {valid_loss:>8f} \\n\")\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ad014d9-69c0-4678-9d56-f499f6a5a425",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.013231  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.003566 \n",
      "\n",
      "Elapsed epoch time: 15.32 s\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.003253  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002959 \n",
      "\n",
      "Elapsed epoch time: 14.18 s\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.002854  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002774 \n",
      "\n",
      "Elapsed epoch time: 15.93 s\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.002672  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002681 \n",
      "\n",
      "Elapsed epoch time: 15.15 s\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.002565  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002617 \n",
      "\n",
      "Elapsed epoch time: 13.94 s\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.002493  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002572 \n",
      "\n",
      "Elapsed epoch time: 14.64 s\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.002442  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002534 \n",
      "\n",
      "Elapsed epoch time: 15.61 s\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.002403  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002504 \n",
      "\n",
      "Elapsed epoch time: 16.31 s\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.002373  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002478 \n",
      "\n",
      "Elapsed epoch time: 16.23 s\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.002348  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002457 \n",
      "\n",
      "Elapsed epoch time: 14.10 s\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.002328  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002442 \n",
      "\n",
      "Elapsed epoch time: 13.75 s\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.002311  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002425 \n",
      "\n",
      "Elapsed epoch time: 14.87 s\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.002295  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002410 \n",
      "\n",
      "Elapsed epoch time: 12.96 s\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.002282  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002395 \n",
      "\n",
      "Elapsed epoch time: 13.85 s\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.002270  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002383 \n",
      "\n",
      "Elapsed epoch time: 12.88 s\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.002259  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002369 \n",
      "\n",
      "Elapsed epoch time: 13.29 s\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.002249  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002360 \n",
      "\n",
      "Elapsed epoch time: 15.53 s\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.002240  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.1%, Avg loss: 0.002351 \n",
      "\n",
      "Elapsed epoch time: 13.65 s\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.002232  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002345 \n",
      "\n",
      "Elapsed epoch time: 12.72 s\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.002225  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002338 \n",
      "\n",
      "Elapsed epoch time: 13.30 s\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.002218  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002331 \n",
      "\n",
      "Elapsed epoch time: 16.16 s\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.002212  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002324 \n",
      "\n",
      "Elapsed epoch time: 16.64 s\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.002206  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002318 \n",
      "\n",
      "Elapsed epoch time: 12.91 s\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.002201  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002312 \n",
      "\n",
      "Elapsed epoch time: 14.36 s\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.002196  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002306 \n",
      "\n",
      "Elapsed epoch time: 13.58 s\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.002191  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002301 \n",
      "\n",
      "Elapsed epoch time: 13.71 s\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.002186  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002295 \n",
      "\n",
      "Elapsed epoch time: 15.13 s\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.002182  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002291 \n",
      "\n",
      "Elapsed epoch time: 13.51 s\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.002178  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002286 \n",
      "\n",
      "Elapsed epoch time: 13.98 s\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.002174  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002282 \n",
      "\n",
      "Elapsed epoch time: 13.53 s\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.002170  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002278 \n",
      "\n",
      "Elapsed epoch time: 13.31 s\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.002167  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002273 \n",
      "\n",
      "Elapsed epoch time: 13.14 s\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.002163  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002268 \n",
      "\n",
      "Elapsed epoch time: 14.92 s\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.002160  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002265 \n",
      "\n",
      "Elapsed epoch time: 15.15 s\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.002157  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002262 \n",
      "\n",
      "Elapsed epoch time: 15.35 s\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.002154  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002257 \n",
      "\n",
      "Elapsed epoch time: 15.45 s\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.002151  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002254 \n",
      "\n",
      "Elapsed epoch time: 14.94 s\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.002148  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002251 \n",
      "\n",
      "Elapsed epoch time: 13.86 s\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.002145  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002248 \n",
      "\n",
      "Elapsed epoch time: 20.75 s\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.002142  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002245 \n",
      "\n",
      "Elapsed epoch time: 14.31 s\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.002140  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002242 \n",
      "\n",
      "Elapsed epoch time: 15.14 s\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.002137  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002239 \n",
      "\n",
      "Elapsed epoch time: 13.59 s\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.002135  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002236 \n",
      "\n",
      "Elapsed epoch time: 13.58 s\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.002132  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002234 \n",
      "\n",
      "Elapsed epoch time: 14.03 s\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.002130  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002231 \n",
      "\n",
      "Elapsed epoch time: 13.97 s\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.002128  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002228 \n",
      "\n",
      "Elapsed epoch time: 13.09 s\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.002125  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002225 \n",
      "\n",
      "Elapsed epoch time: 13.35 s\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.002123  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002223 \n",
      "\n",
      "Elapsed epoch time: 14.15 s\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.002121  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002220 \n",
      "\n",
      "Elapsed epoch time: 15.22 s\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.002119  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002217 \n",
      "\n",
      "Elapsed epoch time: 14.72 s\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.002117  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002215 \n",
      "\n",
      "Elapsed epoch time: 15.12 s\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.002115  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002213 \n",
      "\n",
      "Elapsed epoch time: 14.43 s\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.002113  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002210 \n",
      "\n",
      "Elapsed epoch time: 16.89 s\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.002111  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002207 \n",
      "\n",
      "Elapsed epoch time: 13.71 s\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.002109  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002205 \n",
      "\n",
      "Elapsed epoch time: 13.76 s\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.002108  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002203 \n",
      "\n",
      "Elapsed epoch time: 17.28 s\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.002106  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002201 \n",
      "\n",
      "Elapsed epoch time: 13.37 s\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.002104  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002198 \n",
      "\n",
      "Elapsed epoch time: 16.45 s\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.002103  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002196 \n",
      "\n",
      "Elapsed epoch time: 14.59 s\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.002101  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002194 \n",
      "\n",
      "Elapsed epoch time: 13.54 s\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.002099  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002192 \n",
      "\n",
      "Elapsed epoch time: 13.39 s\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.002098  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002191 \n",
      "\n",
      "Elapsed epoch time: 13.89 s\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.002096  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002188 \n",
      "\n",
      "Elapsed epoch time: 14.36 s\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.002095  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002187 \n",
      "\n",
      "Elapsed epoch time: 15.71 s\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.002093  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002185 \n",
      "\n",
      "Elapsed epoch time: 15.48 s\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.002092  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002183 \n",
      "\n",
      "Elapsed epoch time: 15.08 s\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.002091  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002181 \n",
      "\n",
      "Elapsed epoch time: 14.62 s\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.002089  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002179 \n",
      "\n",
      "Elapsed epoch time: 17.12 s\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.002088  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002177 \n",
      "\n",
      "Elapsed epoch time: 18.17 s\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.002087  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002175 \n",
      "\n",
      "Elapsed epoch time: 13.96 s\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.002085  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002173 \n",
      "\n",
      "Elapsed epoch time: 16.68 s\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.002084  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002171 \n",
      "\n",
      "Elapsed epoch time: 13.67 s\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.002083  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002170 \n",
      "\n",
      "Elapsed epoch time: 14.57 s\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.002082  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002168 \n",
      "\n",
      "Elapsed epoch time: 14.46 s\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.002081  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002167 \n",
      "\n",
      "Elapsed epoch time: 13.95 s\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.002080  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002165 \n",
      "\n",
      "Elapsed epoch time: 12.96 s\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.002079  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002164 \n",
      "\n",
      "Elapsed epoch time: 14.23 s\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.002078  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002162 \n",
      "\n",
      "Elapsed epoch time: 14.90 s\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.002076  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002161 \n",
      "\n",
      "Elapsed epoch time: 15.72 s\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.002075  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002159 \n",
      "\n",
      "Elapsed epoch time: 15.29 s\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.002074  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002158 \n",
      "\n",
      "Elapsed epoch time: 14.96 s\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.002074  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002156 \n",
      "\n",
      "Elapsed epoch time: 12.74 s\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.002073  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002154 \n",
      "\n",
      "Elapsed epoch time: 24.87 s\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.002072  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002153 \n",
      "\n",
      "Elapsed epoch time: 14.12 s\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.002071  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002151 \n",
      "\n",
      "Elapsed epoch time: 16.25 s\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.002070  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002150 \n",
      "\n",
      "Elapsed epoch time: 13.92 s\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.002069  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002149 \n",
      "\n",
      "Elapsed epoch time: 13.71 s\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.002068  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002148 \n",
      "\n",
      "Elapsed epoch time: 15.12 s\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.002067  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002146 \n",
      "\n",
      "Elapsed epoch time: 14.20 s\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.002066  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002145 \n",
      "\n",
      "Elapsed epoch time: 14.22 s\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.002066  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002144 \n",
      "\n",
      "Elapsed epoch time: 13.37 s\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.002065  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002142 \n",
      "\n",
      "Elapsed epoch time: 15.85 s\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.002064  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002141 \n",
      "\n",
      "Elapsed epoch time: 14.10 s\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.002063  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002140 \n",
      "\n",
      "Elapsed epoch time: 15.10 s\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.002063  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002139 \n",
      "\n",
      "Elapsed epoch time: 15.20 s\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.002062  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002138 \n",
      "\n",
      "Elapsed epoch time: 15.96 s\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.002061  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002136 \n",
      "\n",
      "Elapsed epoch time: 14.42 s\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.002060  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002135 \n",
      "\n",
      "Elapsed epoch time: 15.03 s\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.002060  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002134 \n",
      "\n",
      "Elapsed epoch time: 17.50 s\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.002059  [45000/45000]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.002133 \n",
      "\n",
      "Elapsed epoch time: 14.56 s\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "valloss = []\n",
    "traloss = []\n",
    "for t in range(epochs):\n",
    "    t0 = time()\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    trainloss = train(train_dataloader, model, loss_fn, optimizer, scheduler, device)\n",
    "    if t % 25 == 0:\n",
    "        validloss = valid(\n",
    "            valid_dataloader,\n",
    "            model,\n",
    "            loss_fn,\n",
    "            t,\n",
    "            device,\n",
    "            # plots = True,\n",
    "        )\n",
    "    else:\n",
    "        validloss = valid(\n",
    "            valid_dataloader,\n",
    "            model,\n",
    "            loss_fn,\n",
    "            t,\n",
    "            device,\n",
    "        )\n",
    "    valloss.append(validloss)\n",
    "    traloss.append(trainloss)\n",
    "    # torch.save({\n",
    "    #             'epoch': t,\n",
    "    #             'model_state_dict': model.state_dict(),\n",
    "    #             'optimizer_state_dict': optimizer.state_dict(),\n",
    "    #             'loss': tloss,\n",
    "    #             }, '/arc/home/aydanmckay/ml/torchnn/checkpoints/checkpointWGLsmallepoch'+str(t)+'scalecutsep5.pth')\n",
    "    # torch.save(model.state_dict(), \"/arc/home/aydanmckay/torchmodel/torchmodelWsmallscalecutsep5iter\"+str(t)+\".pth\")\n",
    "    t1 = time()\n",
    "    print(f'Elapsed epoch time: {t1-t0:.2f} s')\n",
    "print(\"Training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "983e9db6-f4f2-4460-8e85-80a7651e7bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,len(traloss)+1),traloss,'-o',label='Train Loss')\n",
    "plt.plot(range(1,len(valloss)+1),valloss,'-o',label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (L2)')\n",
    "# plt.ylim(0.65,0.67)\n",
    "plt.legend(fancybox=True)\n",
    "plt.title('Loss per Epoch')\n",
    "plt.savefig('/arc/home/aydanmckay/torchresplots/lossL2smallminmaxscalecutsbl32lr-2wd-5SGDep100new.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f880d560-115e-4973-930b-52595ba21aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"/arc/home/aydanmckay/torchresmodel/modelL2smallminmaxscalecutsbl32lr-2wd-5SGDep100new.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e676ae98-1cff-44bd-be50-421825c7b5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
